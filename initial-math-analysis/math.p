(dp1
S'Heuristic'
p2
(lp3
VA heuristic technique (; Greek: "\u0395\u1f51\u03c1\u03af\u03c3\u03ba\u03c9", "find" or "discover"), sometimes called simply a "heuristic", is any approach to problem solving, learning, or discovery that employs a practical methodology not guaranteed to be optimal or perfect, but sufficient for the immediate goals. Where finding an optimal solution is impossible or impractical, heuristic methods can be used to speed up the process of finding a satisfactory solution. Heuristics can be mental shortcuts that ease the cognitive load of making a decision. Examples of this method include using a rule of thumb, an educated guess, an intuitive judgment, stereotyping, profiling, or common sense.
p4
aVMore precisely, heuristics are strategies using readily accessible, though loosely applicable, information to control problem solving in human beings and machines.
p5
aVExample.
p6
aVThe most fundamental heuristic is trial and error, which can be used in everything from matching nuts and bolts to finding the values of variables in algebra problems.
p7
aVHere are a few other commonly used heuristics, from George Pólya's 1945 book, "How to Solve It":
p8
aVPsychology.
p9
aVIn psychology, heuristics are simple, efficient rules, learned or hard-coded by evolutionary processes, that have been proposed to explain how people make decisions, come to judgments, and solve problems typically when facing complex problems or incomplete information. Researchers test if people use those rules with various methods. These rules work well under most circumstances, but in certain cases lead to systematic errors or cognitive biases.
p10
aVAlthough much of the work of discovering heuristics in human decision-makers was done by the Israeli psychologists Amos Tversky and Daniel Kahneman, the concept was originally introduced by Nobel laureate Herbert A. Simon. Simon's original, primary object of research was problem solving which showed that we operate within what he calls bounded rationality. He coined the term "satisficing", which denotes the situation where people seek solutions or accept choices or judgments that are "good enough" for their purposes, but could be optimized.
p11
aVGerd Gigerenzer focused on the "fast and frugal" properties of heuristics, i.e., using heuristics in a way that is principally accurate and thus eliminating most cognitive bias. From one particular batch of research, Gigerenzer and Wolfgang Gaissmaier found that both individuals and organizations rely on heuristics in an adaptive way. They also found that ignoring part of the information a decision, rather than weighing all the options, can actually lead to more accurate decisions.
p12
aVHeuristics, through greater refinement and research, have begun to be applied to other theories, or be explained by them. For example: the Cognitive-Experiential Self-Theory (CEST) also an adaptive view of heuristic processing. CEST breaks down two systems that process information. At some times, roughly speaking, individuals consider issues rationally, systematically, logically, deliberately, effortfully, and verbally. On other occasions, individuals consider issues intuitively, effortlessly, globally, and emotionally. From this perspective, heuristics are part of a larger experiential processing system that is often adaptive, but vulnerable to error in situations that require logical analysis.
p13
aVIn 2002, Daniel Kahneman and Shane Frederick proposed that cognitive heuristics work by a process called "attribute substitution", which happens without conscious awareness. According to this theory, when somebody makes a judgment (of a "target attribute") that is computationally complex, a rather easier calculated "heuristic attribute" is substituted. In effect, a cognitively difficult problem is dealt with by answering a rather simpler problem, without being aware of this happening. This theory explains cases where judgments fail to show regression toward the mean. Heuristics can be considered to reduce the complexity of clinical judgements in healthcare.
p14
aVCognitive maps.
p15
aVHeuristics were also found to be used in the manipulation and creation of cognitive maps. Cognitive maps are internal representations of our physical environment, particularly associated with spatial relationships. These internal representations of our environment are used as memory as a guide in our external environment. It was found that when questioned about maps imaging, distancing, etc., people commonly made distortions to images. These distortions took shape in the regularization of images (i.e., images are represented as more like pure abstract geometric images, though they are irregular in shape).
p16
aVThere are several ways that humans form and use cognitive maps. Visual intake is a key part of mapping. The first is by using "landmarks". This is where a person uses a mental image to estimate a relationship, usually distance, between two objects. Second, is "route-road" knowledge, and this is generally developed after a person has performed a task and is relaying the information of that task to another person. Third, is survey. A person estimates a distance based on a mental image that, to them, might appear like an actual map. This image is generally created when a person's brain begins making image corrections. These are presented in five ways: 1. "Right-angle bias" is when a person straightens out an image, like mapping an intersection, and begins to give everything 90-degree angles, when in reality it may not be that way. 2. "Symmetry heuristic" is when people tend to think of shapes, or buildings, as being more symmetrical than they really are. 3. "Rotation heuristic" is when a person takes a naturally (realistically) distorted image and straightens it out for their mental image. 4. "Alignment heuristic" is similar to the previous, where people align objects mentally to make them straighter than they really are. 5. "Relative-position heuristic": people do not accurately distance landmarks in their mental image based on how well they remember that particular item.
p17
aVAnother method of creating cognitive maps is by means of auditory intake based on verbal descriptions. Using the mapping based from a person's visual intake, another person can create a mental image, such as directions to a certain location.
p18
aVPhilosophy.
p19
aV"Heuristic device" is used when an entity X exists to enable understanding of, or knowledge concerning, some other entity Y. A good example is a model that, as it is never identical with what it models, is a heuristic device to enable understanding of what it models. Stories, metaphors, etc., can also be termed heuristic in that sense. A classic example is the notion of utopia as described in Plato's best-known work, "The Republic". This means that the "ideal city" as depicted in "The Republic" is not given as something to be pursued, or to present an orientation-point for development; rather, it shows how things would have to be connected, and how one thing would lead to another (often with highly problematic results), if one would opt for certain principles and carry them through rigorously.
p20
aV"Heuristic" is also often used as a noun to describe a rule-of-thumb, procedure, or method. Philosophers of science have emphasized the importance of heuristics in creative thought and constructing scientific theories. (See The Logic of Scientific Discovery, and philosophers such as Imre Lakatos, Lindley Darden, William C. Wimsatt, and others.)
p21
aVLaw.
p22
aVIn legal theory, especially in the theory of law and economics, heuristics are used in the law when case-by-case analysis would be impractical, insofar as "practicality" is defined by the interests of a governing body.
p23
aVThe present securities regulation regime largely assumes that all investors act as perfectly, rational persons.
p24
aVIn truth, actual investors face cognitive limitations from biases, heuristics, and framing effects.
p25
aVFor instance, in all states in the United States the legal drinking age for unsupervised persons is 21 years, because it is argued that people need to be mature enough to make decisions involving the risks of alcohol consumption. However, assuming people mature at different rates, the specific age of 21 would be too late for some and too early for others. In this case, the somewhat arbitrary deadline is used because it is impossible or impractical to tell whether an individual is sufficiently mature for society to trust them with that kind of responsibility. Some proposed changes, however, have included the completion of an alcohol education course rather than the attainment of 21 years of age as the criterion for legal alcohol possession. This would put youth alcohol policy more on a case-by-case basis and less on a heuristic one, since the completion of such a course would presumably be voluntary and not uniform across the population.
p26
aVThe same reasoning applies to patent law. Patents are justified on the grounds that inventors must be protected so they have incentive to invent. It is therefore argued that it is in society's best interest that inventors receive a temporary government-granted monopoly on their idea, so that they can recoup investment costs and make economic profit for a limited period. In the United States, the length of this temporary monopoly is 20 years from the date the application for patent was filed, though the monopoly does not actually begin until the application has matured into a patent. However, like the drinking-age problem above, the specific length of time would need to be different for every product to be efficient. A 20-year term is used because it is difficult to tell what the number should be for any individual patent. More recently, some, including University of North Dakota law professor Eric E. Johnson, have argued that patents in different kinds of industries\u2013such as software patents\u2013should be protected for different lengths of time.
p27
aVStereotyping.
p28
aVStereotyping is a type of heuristic that all people use to form opinions or make judgments about things they have never seen or experienced. They work as a mental shortcut to assess everything from the social status of a person based on their actions to assumptions that a plant that is tall, has a trunk, and has leaves is a tree even though the person making the evaluation has never seen that particular type of tree before.
p29
aVStereotypes, as first described by journalist Walter Lippmann in his book "Public Opinion" (1922), are the pictures we have in our heads which are built around experiences as well as what we are told about the world.
p30
asS'History of mathematics'
p31
(lp32
VThe area of study known as the history of mathematics is primarily an investigation into the origin of discoveries in mathematics and, to a lesser extent, an investigation into the mathematical methods and notation of the past.
p33
aVBefore the modern age and the worldwide spread of knowledge, written examples of new mathematical developments have come to light only in a few locales. The most ancient mathematical texts available are "Plimpton 322" (Babylonian mathematics c. 1900 BC), the "Rhind Mathematical Papyrus" (Egyptian mathematics c. 2000-1800 BC) and the "Moscow Mathematical Papyrus" (Egyptian mathematics c. 1890 BC). All of these texts concern the so-called Pythagorean theorem, which seems to be the most ancient and widespread mathematical development after basic arithmetic and geometry.
p34
aVThe study of mathematics as a subject in its own right begins in the 6th century BC with the Pythagoreans, who coined the term "mathematics" from the ancient Greek "\u03bc\u03ac\u03b8\u03b7\u03bc\u03b1" ("mathema"), meaning "subject of instruction". Greek mathematics greatly refined the methods (especially through the introduction of deductive reasoning and mathematical rigor in proofs) and expanded the subject matter of mathematics. Chinese mathematics made early contributions, including a place value system. The Hindu-Arabic numeral system and the rules for the use of its operations, in use throughout the world today, likely evolved over the course of the first millennium AD in India and were transmitted to the west via Islamic mathematics through the work of Mu\u1e25ammad ibn M\u016bs\u0101 al-Khw\u0101rizm\u012b. Islamic mathematics, in turn, developed and expanded the mathematics known to these civilizations. Many Greek and Arabic texts on mathematics were then translated into Latin, which led to further development of mathematics in medieval Europe.
p35
aVFrom ancient times through the Middle Ages, bursts of mathematical creativity were often followed by centuries of stagnation. Beginning in Renaissance Italy in the 16th century, new mathematical developments, interacting with new scientific discoveries, were made at an increasing pace that continues through the present day.
p36
aVPrehistoric mathematics.
p37
aVThe origins of mathematical thought lie in the concepts of number, magnitude, and form. Modern studies of animal cognition have shown that these concepts are not unique to humans. Such concepts would have been part of everyday life in hunter-gatherer societies. The idea of the "number" concept evolving gradually over time is supported by the existence of languages which preserve the distinction between "one", "two", and "many", but not of numbers larger than two.
p38
aVPrehistoric artifacts discovered in Africa, dated 20,000 years old or more suggest early attempts to quantify time.
p39
aVThe evidence is against the Lebombo bone being a mathematical object, but the Ishango bone, found near the headwaters of the Nile river (northeastern Congo), may be as much as 20,000 years old and consists of a series of tally marks carved in three columns running the length of the bone. Common interpretations are that the Ishango bone shows either the earliest known demonstration of sequences of prime numbers or a six-month lunar calendar. In the book "How Mathematics Happened: The First 50,000 Years", Peter Rudman argues that the development of the concept of prime numbers could only have come about after the concept of division, which he dates to after 10,000 BC, with prime numbers probably not being understood until about 500 BC. He also writes that "no attempt has been made to explain why a tally of something should exhibit multiples of two, prime numbers between 10 and 20, and some numbers that are almost multiples of 10." The Ishango bone, according to scholar Alexander Marshack, may have influenced the later development of mathematics in Egypt as, like some entries on the Ishango bone, Egyptian arithmetic also made use of multiplication by 2; this, however, is disputed.
p40
aVPredynastic Egyptians of the 5th millennium BC pictorially represented geometric designs. It has been claimed that megalithic monuments in England and Scotland, dating from the 3rd millennium BC, incorporate geometric ideas such as circles, ellipses, and Pythagorean triples in their design.
p41
aVAll of the above are disputed however, and the currently oldest undisputed mathematical usage is in Babylonian and dynastic Egyptian sources.
p42
aVBabylonian mathematics.
p43
aVBabylonian mathematics refers to any mathematics of the people of Mesopotamia (modern Iraq) from the days of the early Sumerians through the Hellenistic period almost to the dawn of Christianity. It is named Babylonian mathematics due to the central role of Babylon as a place of study. Later under the Arab Empire, Mesopotamia, especially Baghdad, once again became an important center of study for Islamic mathematics.
p44
aVIn contrast to the sparsity of sources in Egyptian mathematics, our knowledge of Babylonian mathematics is derived from more than 400 clay tablets unearthed since the 1850s. Written in Cuneiform script, tablets were inscribed whilst the clay was moist, and baked hard in an oven or by the heat of the sun. Some of these appear to be graded homework.
p45
aVThe earliest evidence of written mathematics dates back to the ancient Sumerians, who built the earliest civilization in Mesopotamia. They developed a complex system of metrology from 3000 BC. From around 2500 BC onwards, the Sumerians wrote multiplication tables on clay tablets and dealt with geometrical exercises and division problems. The earliest traces of the Babylonian numerals also date back to this period.
p46
aVThe majority of recovered clay tablets date from 1800 to 1600 BC, and cover topics which include fractions, algebra, quadratic and cubic equations, and the calculation of regular reciprocal pairs. The tablets also include multiplication tables and methods for solving linear and quadratic equations. The Babylonian tablet YBC 7289 gives an approximation of \u221a2 accurate to five decimal places.
p47
aVBabylonian mathematics were written using a sexagesimal (base-60) numeral system. From this derives the modern day usage of 60 seconds in a minute, 60 minutes in an hour, and 360 (60 x 6) degrees in a circle, as well as the use of seconds and minutes of arc to denote fractions of a degree. Babylonian advances in mathematics were facilitated by the fact that 60 has many divisors. Also, unlike the Egyptians, Greeks, and Romans, the Babylonians had a true place-value system, where digits written in the left column represented larger values, much as in the decimal system. They lacked, however, an equivalent of the decimal point, and so the place value of a symbol often had to be inferred from the context. On the other hand, this "defect" is equivalent to the modern-day usage of floating point arithmetic; moreover, the use of base 60 means that any reciprocal of an integer which is a multiple of divisors of 60 necessarily has a finite expansion to the base 60. (In decimal arithmetic, only reciprocals of multiples of 2 and 5 have finite decimal expansions.) Accordingly, there is a strong argument that arithmetic Old Babylonian style is considerably more sophisticated than that of current usage.
p48
aVThe interpretation of Plimpton 322 was the source of controversy for many years after its significance in the context of Pythagorean triangles was realized. In historical context, inheritance problems involving equal-area subdivision of triangular and trapezoidal fields (with integer length sides) quickly convert into the need to calculate the square root of 2, or to solve the "Pythagorean equation" in integers.
p49
aVRather than considering a square as the sum of two squares, we can equivalently consider a square as a difference of two squares. Let a, b and c be integers that form a Pythagorean Triple: a^2 + b^2 = c^2. Then c^2 - a^2 = b^2, and using the expansion for the difference of two squares we get (c-a)(c+a)= b^2.
p50
aVDividing by b^2, it becomes the product of two rational numbers giving 1: (c/b - a/b)(c/b + a/b) = 1. We require two rational numbers which are reciprocals and which differ by 2(a/b). This is easily solved by consulting a table of reciprocal pairs. E.g., (1/2) (2) = 1 is a pair of reciprocals which differ by 3/2 = 2(a/b) Thus a/b = 3/4, giving a=3, b=4 and so c=5.
p51
aVSolutions of the original equation are thus constructed by choosing a rational number x, from which Pythagorean-triples are 2x, x^2-1, x^2+1. Other triples are made by scaling these by an integer (the scaling integer being half the difference between the largest and one other side). All Pythagorean triples arise in this way, and the examples provided in Plimpton 322 involve some quite large numbers, by modern standards, such as (4601, 4800, 6649) in decimal notation.
p52
aVEgyptian mathematics.
p53
aVEgyptian mathematics refers to mathematics written in the Egyptian language. From the Hellenistic period, Greek replaced Egyptian as the written language of Egyptian scholars. Mathematical study in Egypt later continued under the Arab Empire as part of Islamic mathematics, when Arabic became the written language of Egyptian scholars.
p54
aVThe most extensive Egyptian mathematical text is the Rhind papyrus (sometimes also called the Ahmes Papyrus after its author), dated to c. 1650 BC but likely a copy of an older document from the Middle Kingdom of about 2000-1800 BC. It is an instruction manual for students in arithmetic and geometry. In addition to giving area formulas and methods for multiplication, division and working with unit fractions, it also contains evidence of other mathematical knowledge, including composite and prime numbers; arithmetic, geometric and harmonic means; and simplistic understandings of both the Sieve of Eratosthenes and perfect number theory (namely, that of the number 6). It also shows how to solve first order linear equations as well as arithmetic and geometric series.
p55
aVAnother significant Egyptian mathematical text is the Moscow papyrus, also from the Middle Kingdom period, dated to c. 1890 BC. It consists of what are today called "word problems" or "story problems", which were apparently intended as entertainment. One problem is considered to be of particular importance because it gives a method for finding the volume of a frustum: "If you are told: A truncated pyramid of 6 for the vertical height by 4 on the base by 2 on the top. You are to square this 4, result 16. You are to double 4, result 8. You are to square 2, result 4. You are to add the 16, the 8, and the 4, result 28. You are to take one third of 6, result 2. You are to take 28 twice, result 56. See, it is 56. You will find it right."
p56
aVFinally, the Berlin Papyrus 6619 (c. 1800 BC) shows that ancient Egyptians could solve a second-order algebraic equation.
p57
aVGreek mathematics.
p58
aVGreek mathematics refers to the mathematics written in the Greek language from the time of Thales of Miletus (~600 BC) to the closure of the Academy of Athens in 529 AD. Greek mathematicians lived in cities spread over the entire Eastern Mediterranean, from Italy to North Africa, but were united by culture and language. Greek mathematics of the period following Alexander the Great is sometimes called Hellenistic mathematics.
p59
aVGreek mathematics was much more sophisticated than the mathematics that had been developed by earlier cultures. All surviving records of pre-Greek mathematics show the use of inductive reasoning, that is, repeated observations used to establish rules of thumb. Greek mathematicians, by contrast, used deductive reasoning. The Greeks used logic to derive conclusions from definitions and axioms, and used mathematical rigor to prove them.
p60
aVGreek mathematics is thought to have begun with Thales of Miletus (c. 624\u2013c.546 BC) and Pythagoras of Samos (c. 582\u2013c. 507 BC). Although the extent of the influence is disputed, they were probably inspired by Egyptian and Babylonian mathematics. According to legend, Pythagoras traveled to Egypt to learn mathematics, geometry, and astronomy from Egyptian priests.
p61
aVThales used geometry to solve problems such as calculating the height of pyramids and the distance of ships from the shore. He is credited with the first use of deductive reasoning applied to geometry, by deriving four corollaries to Thales' Theorem. As a result, he has been hailed as the first true mathematician and the first known individual to whom a mathematical discovery has been attributed. Pythagoras established the Pythagorean School, whose doctrine it was that mathematics ruled the universe and whose motto was "All is number". It was the Pythagoreans who coined the term "mathematics", and with whom the study of mathematics for its own sake begins. The Pythagoreans are credited with the first proof of the Pythagorean theorem, though the statement of the theorem has a long history, and with the proof of the existence of irrational numbers.
p62
aVPlato (428/427 BC \u2013 348/347 BC) is important in the history of mathematics for inspiring and guiding others. His Platonic Academy, in Athens, became the mathematical center of the world in the 4th century BC, and it was from this school that the leading mathematicians of the day, such as Eudoxus of Cnidus, came. Plato also discussed the foundations of mathematics, clarified some of the definitions (e.g. that of a line as "breadthless length"), and reorganized the assumptions. The analytic method is ascribed to Plato, while a formula for obtaining Pythagorean triples bears his name.
p63
aVEudoxus (408\u2013c.355 BC) developed the method of exhaustion, a precursor of modern integration and a theory of ratios that avoided the problem of incommensurable magnitudes. The former allowed the calculations of areas and volumes of curvilinear figures, while the latter enabled subsequent geometers to make significant advances in geometry. Though he made no specific technical mathematical discoveries, Aristotle (384\u2014c.322 BC) contributed significantly to the development of mathematics by laying the foundations of logic.
p64
aVIn the 3rd century BC, the premier center of mathematical education and research was the Musaeum of Alexandria. It was there that Euclid (c. 300 BC) taught, and wrote the "Elements", widely considered the most successful and influential textbook of all time. The "Elements" introduced mathematical rigor through the axiomatic method and is the earliest example of the format still used in mathematics today, that of definition, axiom, theorem, and proof. Although most of the contents of the "Elements" were already known, Euclid arranged them into a single, coherent logical framework. The "Elements" was known to all educated people in the West until the middle of the 20th century and its contents are still taught in geometry classes today. In addition to the familiar theorems of Euclidean geometry, the "Elements" was meant as an introductory textbook to all mathematical subjects of the time, such as number theory, algebra and solid geometry, including proofs that the square root of two is irrational and that there are infinitely many prime numbers. Euclid also wrote extensively on other subjects, such as conic sections, optics, spherical geometry, and mechanics, but only half of his writings survive.
p65
aVArchimedes (c.287\u2013212 BC) of Syracuse, widely considered the greatest mathematician of antiquity, used the method of exhaustion to calculate the area under the arc of a parabola with the summation of an infinite series, in a manner not too dissimilar from modern calculus. He also showed one could use the method of exhaustion to calculate the value of \u03c0 with as much precision as desired, and obtained the most accurate value of \u03c0 then known, 3 < \u03c0 < 3. He also studied the spiral bearing his name, obtained formulas for the volumes of surfaces of revolution (paraboloid, ellipsoid, hyperboloid), and an ingenious system for expressing very large numbers. While he is also known for his contributions to physics and several advanced mechanical devices, Archimedes himself placed far greater value on the products of his thought and general mathematical principles. He regarded as his greatest achievement his finding of the surface area and volume of a sphere, which he obtained by proving these are 2/3 the surface area and volume of a cylinder circumscribing the sphere.
p66
aVApollonius of Perga (c. 262-190 BC) made significant advances to the study of conic sections, showing that one can obtain all three varieties of conic section by varying the angle of the plane that cuts a double-napped cone. He also coined the terminology in use today for conic sections, namely parabola ("place beside" or "comparison"), "ellipse" ("deficiency"), and "hyperbola" ("a throw beyond"). His work "Conics" is one of the best known and preserved mathematical works from antiquity, and in it he derives many theorems concerning conic sections that would prove invaluable to later mathematicians and astronomers studying planetary motion, such as Isaac Newton. While neither Apollonius nor any other Greek mathematicians made the leap to coordinate geometry, Apollonius' treatment of curves is in some ways similar to the modern treatment, and some of his work seems to anticipate the development of analytical geometry by Descartes some 1800 years later.
p67
aVAround the same time, Eratosthenes of Cyrene (c. 276-194 BC) devised the Sieve of Eratosthenes for finding prime numbers. The 3rd century BC is generally regarded as the "Golden Age" of Greek mathematics, with advances in pure mathematics henceforth in relative decline. Nevertheless, in the centuries that followed significant advances were made in applied mathematics, most notably trigonometry, largely to address the needs of astronomers. Hipparchus of Nicaea (c. 190-120 BC) is considered the founder of trigonometry for compiling the first known trigonometric table, and to him is also due the systematic use of the 360 degree circle. Heron of Alexandria (c. 10\u201370 AD) is credited with Heron's formula for finding the area of a scalene triangle and with being the first to recognize the possibility of negative numbers possessing square roots. Menelaus of Alexandria (c. 100 AD) pioneered spherical trigonometry through Menelaus' theorem. The most complete and influential trigonometric work of antiquity is the "Almagest" of Ptolemy (c. AD 90-168), a landmark astronomical treatise whose trigonometric tables would be used by astronomers for the next thousand years. Ptolemy is also credited with Ptolemy's theorem for deriving trigonometric quantities, and the most accurate value of \u03c0 outside of China until the medieval period, 3.1416.
p68
aVFollowing a period of stagnation after Ptolemy, the period between 250 and 350 AD is sometimes referred to as the "Silver Age" of Greek mathematics. During this period, Diophantus made significant advances in algebra, particularly indeterminate analysis, which is also known as "Diophantine analysis". The study of Diophantine equations and Diophantine approximations is a significant area of research to this day. His main work was the "Arithmetica", a collection of 150 algebraic problems dealing with exact solutions to determinate and indeterminate equations. The "Arithmetica" had a significant influence on later mathematicians, such as Pierre de Fermat, who arrived at his famous Last Theorem after trying to generalize a problem he had read in the "Arithmetica" (that of dividing a square into two squares). Diophantus also made significant advances in notation, the "Arithmetica" being the first instance of algebraic symbolism and syncopation.
p69
aVThe first woman mathematician recorded by history was Hypatia of Alexandria (AD 350 - 415). She succeeded her father as Librarian at the Great Library and wrote many works on applied mathematics. Because of a political dispute, the Christian community in Alexandria punished her, presuming she was involved, by stripping her naked and scraping off her skin with clamshells (some say roofing tiles).
p70
aVChinese mathematics.
p71
aVEarly Chinese mathematics is so different from that of other parts of the world that it is reasonable to assume independent development. The oldest extant mathematical text from China is the "Chou Pei Suan Ching", variously dated to between 1200 BC and 100 BC, though a date of about 300 BC appears reasonable.
p72
aVOf particular note is the use in Chinese mathematics of a decimal positional notation system, the so-called "rod numerals" in which distinct ciphers were used for numbers between 1 and 10, and additional ciphers for powers of ten. Thus, the number 123 would be written using the symbol for "1", followed by the symbol for "100", then the symbol for "2" followed by the symbol for "10", followed by the symbol for "3". This was the most advanced number system in the world at the time, apparently in use several centuries before the common era and well before the development of the Indian numeral system. Rod numerals allowed the representation of numbers as large as desired and allowed calculations to be carried out on the "suan pan", or Chinese abacus. The date of the invention of the "suan pan" is not certain, but the earliest written mention dates from AD 190, in Xu Yue's "Supplementary Notes on the Art of Figures".
p73
aVThe oldest existent work on geometry in China comes from the philosophical Mohist canon c. 330 BC, compiled by the followers of Mozi (470\u2013390 BC). The "Mo Jing" described various aspects of many fields associated with physical science, and provided a small number of geometrical theorems as well.
p74
aVIn 212 BC, the Emperor Qin Shi Huang (Shi Huang-ti) commanded all books in the Qin Empire other than officially sanctioned ones be burned. This decree was not universally obeyed, but as a consequence of this order little is known about ancient Chinese mathematics before this date. After the book burning of 212 BC, the Han dynasty (202 BC\u2013220 AD) produced works of mathematics which presumably expanded on works that are now lost. The most important of these is "The Nine Chapters on the Mathematical Art", the full title of which appeared by AD 179, but existed in part under other titles beforehand. It consists of 246 word problems involving agriculture, business, employment of geometry to figure height spans and dimension ratios for Chinese pagoda towers, engineering, surveying, and includes material on right triangles and values of \u03c0. It created mathematical proof for the Pythagorean theorem, and a mathematical formula for Gaussian elimination. Liu Hui commented on the work in the 3rd century AD, and gave a value of \u03c0 accurate to 5 decimal places. Though more of a matter of computational stamina than theoretical insight, in the 5th century AD Zu Chongzhi computed the value of \u03c0 to seven decimal places, which remained the most accurate value of \u03c0 for almost the next 1000 years. He also established a method which would later be called Cavalieri's principle to find the volume of a sphere.
p75
aVThe high-water mark of Chinese mathematics occurs in the 13th century (latter part of the Sung period), with the development of Chinese algebra. The most important text from that period is the "Precious Mirror of the Four Elements" by Chu Shih-chieh (fl. 1280-1303), dealing with the solution of simultaneous higher order algebraic equations using a method similar to Horner's method. The "Precious Mirror" also contains a diagram of Pascal's triangle with coefficients of binomial expansions through the eighth power, though both appear in Chinese works as early as 1100. The Chinese also made use of the complex combinatorial diagram known as the magic square and magic circles, described in ancient times and perfected by Yang Hui (AD 1238\u20131298).
p76
aVEven after European mathematics began to flourish during the Renaissance, European and Chinese mathematics were separate traditions, with significant Chinese mathematical output in decline from the 13th century onwards. Jesuit missionaries such as Matteo Ricci carried mathematical ideas back and forth between the two cultures from the 16th to 18th centuries, though at this point far more mathematical ideas were entering China than leaving.
p77
aVIndian mathematics.
p78
aVThe earliest civilization on the Indian subcontinent is the Indus Valley Civilization that flourished between 2600 and 1900 BC in the Indus river basin. Their cities were laid out with geometric regularity, but no known mathematical documents survive from this civilization.
p79
aVThe Hindu-Arabic numerals were invented by mathematicians in India. They were called "Hindu numerals". They were later called "Arabic" numerals by Europeans, because they were introduced in the West by Arab merchants.
p80
aVVarious symbol sets are used to represent numbers in the Hindu\u2013Arabic numeral system, all of which evolved from the Brahmi numerals. Each of the roughly dozen major scripts of India has its own numeral glyphs (as one will note when perusing Unicode character charts). This table shows two examples:
p81
aVThe oldest extant mathematical records from India are the Sulba Sutras (dated variously between the 8th century BC and the 2nd century AD), appendices to religious texts which give simple rules for constructing altars of various shapes, such as squares, rectangles, parallelograms, and others. As with Egypt, the preoccupation with temple functions points to an origin of mathematics in religious ritual. The Sulba Sutras give methods for constructing a circle with approximately the same area as a given square, which imply several different approximations of the value of \u03c0. In addition, they compute the square root of 2 to several decimal places, list Pythagorean triples, and give a statement of the Pythagorean theorem. All of these results are present in Babylonian mathematics, indicating Mesopotamian influence. It is not known to what extent the Sulba Sutras influenced later Indian mathematicians. As in China, there is a lack of continuity in Indian mathematics; significant advances are separated by long periods of inactivity.
p82
aVThe next significant mathematical documents from India after the "Sulba Sutras" are the "Siddhantas", astronomical treatises from the 4th and 5th centuries AD (Gupta period) showing strong Hellenistic influence. They are significant in that they contain the first instance of trigonometric relations based on the half-chord, as is the case in modern trigonometry, rather than the full chord, as was the case in Ptolemaic trigonometry. Through a series of translation errors, the words "sine" and "cosine" derive from the Sanskrit "jiya" and "kojiya".
p83
aVIn the 5th century AD, Aryabhata wrote the "Aryabhatiya", a slim volume, written in verse, intended to supplement the rules of calculation used in astronomy and mathematical mensuration, though with no feeling for logic or deductive methodology. Though about half of the entries are wrong, it is in the "Aryabhatiya" that the decimal place-value system first appears. Several centuries later, the Muslim mathematician Abu Rayhan Biruni described the "Aryabhatiya" as a "mix of common pebbles and costly crystals".
p84
aVIn the 7th century, Brahmagupta identified the Brahmagupta theorem, Brahmagupta's identity and Brahmagupta's formula, and for the first time, in "Brahma-sphuta-siddhanta", he lucidly explained the use of zero as both a placeholder and decimal digit, and explained the Hindu-Arabic numeral system. It was from a translation of this Indian text on mathematics (c. 770) that Islamic mathematicians were introduced to this numeral system, which they adapted as Arabic numerals. Islamic scholars carried knowledge of this number system to Europe by the 12th century, and it has now displaced all older number systems throughout the world. In the 10th century, Halayudha's commentary on Pingala's work contains a study of the Fibonacci sequence and Pascal's triangle, and describes the formation of a matrix.
p85
aVIn the 12th century, Bh\u0101skara II lived in southern India and wrote extensively on all then known branches of mathematics. His work contains mathematical objects equivalent or approximately equivalent to infinitesimals, derivatives, the mean value theorem and the derivative of the sine function. To what extent he anticipated the invention of calculus is a controversial subject among historians of mathematics.
p86
aVIn the 14th century, Madhava of Sangamagrama, the founder of the so-called Kerala School of Mathematics, found the Madhava\u2013Leibniz series, and, using 21 terms, computed the value of \u03c0 as 3.14159265359. Madhava also found the Madhava-Gregory series to determine the arctangent, the Madhava-Newton power series to determine sine and cosine and the Taylor approximation for sine and cosine functions. In the 16th century, Jyesthadeva consolidated many of the Kerala School's developments and theorems in the "Yukti-bh\u0101\u1e63\u0101". However, the Kerala School did not formulate a systematic theory of differentiation and integration, nor is there any direct evidence of their results being transmitted outside Kerala.
p87
aVIslamic mathematics.
p88
aVThe Islamic Empire established across Persia, the Middle East, Central Asia, North Africa, Iberia, and in parts of India in the 8th century made significant contributions towards mathematics. Although most Islamic texts on mathematics were written in Arabic, most of them were not written by Arabs, since much like the status of Greek in the Hellenistic world, Arabic was used as the written language of non-Arab scholars throughout the Islamic world at the time. Persians contributed to the world of Mathematics alongside Arabs.
p89
aVIn the 9th century, the Persian mathematician wrote several important books on the Hindu-Arabic numerals and on methods for solving equations. His book "On the Calculation with Hindu Numerals", written about 825, along with the work of Al-Kindi, were instrumental in spreading Indian mathematics and Indian numerals to the West. The word "algorithm" is derived from the Latinization of his name, Algoritmi, and the word "algebra" from the title of one of his works, "Al-Kit\u0101b al-mukhta\u1e63ar f\u012b h\u012bs\u0101b al-\u011fabr wa\u2019l-muq\u0101bala" ("The Compendious Book on Calculation by Completion and Balancing"). He gave an exhaustive explanation for the algebraic solution of quadratic equations with positive roots, and he was the first to teach algebra in an elementary form and for its own sake. He also discussed the fundamental method of "reduction" and "balancing", referring to the transposition of subtracted terms to the other side of an equation, that is, the cancellation of like terms on opposite sides of the equation. This is the operation which al-Khw\u0101rizm\u012b originally described as "al-jabr". His algebra was also no longer concerned "with a series of problems to be resolved, but an exposition which starts with primitive terms in which the combinations must give all possible prototypes for equations, which henceforward explicitly constitute the true object of study." He also studied an equation for its own sake and "in a generic manner, insofar as it does not simply emerge in the course of solving a problem, but is specifically called on to define an infinite class of problems."
p90
aVFurther developments in algebra were made by Al-Karaji in his treatise "al-Fakhri", where he extends the methodology to incorporate integer powers and integer roots of unknown quantities. Something close to a proof by mathematical induction appears in a book written by Al-Karaji around 1000 AD, who used it to prove the binomial theorem, Pascal's triangle, and the sum of integral cubes. The historian of mathematics, F. Woepcke, praised Al-Karaji for being "the first who introduced the theory of algebraic calculus." Also in the 10th century, Abul Wafa translated the works of Diophantus into Arabic. Ibn al-Haytham was the first mathematician to derive the formula for the sum of the fourth powers, using a method that is readily generalizable for determining the general formula for the sum of any integral powers. He performed an integration in order to find the volume of a paraboloid, and was able to generalize his result for the integrals of polynomials up to the fourth degree. He thus came close to finding a general formula for the integrals of polynomials, but he was not concerned with any polynomials higher than the fourth degree.
p91
aVIn the late 11th century, Omar Khayyam wrote "Discussions of the Difficulties in Euclid", a book about what he perceived as flaws in Euclid's "Elements", especially the parallel postulate. He was also the first to find the general geometric solution to cubic equations. He was also very influential in calendar reform.
p92
aVIn the 13th century, Nasir al-Din Tusi (Nasireddin) made advances in spherical trigonometry. He also wrote influential work on Euclid's parallel postulate. In the 15th century, Ghiyath al-Kashi computed the value of \u03c0 to the 16th decimal place. Kashi also had an algorithm for calculating "n"th roots, which was a special case of the methods given many centuries later by Ruffini and Horner.
p93
aVOther achievements of Muslim mathematicians during this period include the addition of the decimal point notation to the Arabic numerals, the discovery of all the modern trigonometric functions besides the sine, al-Kindi's introduction of cryptanalysis and frequency analysis, the development of analytic geometry by Ibn al-Haytham, the beginning of algebraic geometry by Omar Khayyam and the development of an algebraic notation by al-Qalas\u0101d\u012b.
p94
aVDuring the time of the Ottoman Empire and Safavid Empire from the 15th century, the development of Islamic mathematics became stagnant.
p95
aVMedieval European mathematics.
p96
aVMedieval European interest in mathematics was driven by concerns quite different from those of modern mathematicians. One driving element was the belief that mathematics provided the key to understanding the created order of nature, frequently justified by Plato's "Timaeus" and the biblical passage (in the "Book of Wisdom") that God had "ordered all things in measure, and number, and weight".
p97
aVBoethius provided a place for mathematics in the curriculum in the 6th century when he coined the term "quadrivium" to describe the study of arithmetic, geometry, astronomy, and music. He wrote "De institutione arithmetica", a free translation from the Greek of Nicomachus's "Introduction to Arithmetic"; "De institutione musica", also derived from Greek sources; and a series of excerpts from Euclid's "Elements". His works were theoretical, rather than practical, and were the basis of mathematical study until the recovery of Greek and Arabic mathematical works.
p98
aVIn the 12th century, European scholars traveled to Spain and Sicily seeking scientific Arabic texts, including al-Khw\u0101rizm\u012b's "The Compendious Book on Calculation by Completion and Balancing", translated into Latin by Robert of Chester, and the complete text of Euclid's "Elements", translated in various versions by Adelard of Bath, Herman of Carinthia, and Gerard of Cremona.
p99
aVThese new sources sparked a renewal of mathematics. Fibonacci, writing in the "Liber Abaci", in 1202 and updated in 1254, produced the first significant mathematics in Europe since the time of Eratosthenes, a gap of more than a thousand years. The work introduced Hindu-Arabic numerals to Europe, and discussed many other mathematical problems. 
p100
aVThe 14th century saw the development of new mathematical concepts to investigate a wide range of problems. One important contribution was development of mathematics of local motion.
p101
aVThomas Bradwardine proposed that speed (V) increases in arithmetic proportion as the ratio of force (F) to resistance (R) increases in geometric proportion. Bradwardine expressed this by a series of specific examples, but although the logarithm had not yet been conceived, we can express his conclusion anachronistically by writing:
p102
aVV = log (F/R). Bradwardine's analysis is an example of transferring a mathematical technique used by al-Kindi and Arnald of Villanova to quantify the nature of compound medicines to a different physical problem.
p103
aVOne of the 14th-century Oxford Calculators, William Heytesbury, lacking differential calculus and the concept of limits, proposed to measure instantaneous speed "by the path that would be described by body if... it were moved uniformly at the same degree of speed with which it is moved in that given instant".
p104
aVHeytesbury and others mathematically determined the distance covered by a body undergoing uniformly accelerated motion (today solved by integration), stating that "a moving body uniformly acquiring or losing that increment speed will traverse in some given time a completely equal to that which it would traverse if it were moving continuously through the same time with the mean degree [of speed".
p105
aVNicole Oresme at the University of Paris and the Italian Giovanni di Casali independently provided graphical demonstrations of this relationship, asserting that the area under the line depicting the constant acceleration, represented the total distance traveled. In a later mathematical commentary on Euclid's "Elements", Oresme made a more detailed general analysis in which he demonstrated that a body will acquire in each successive increment of time an increment of any quality that increases as the odd numbers. Since Euclid had demonstrated the sum of the odd numbers are the square numbers, the total quality acquired by the body increases as the square of the time.
p106
aVRenaissance mathematics.
p107
aVDuring the Renaissance, the development of mathematics and of accounting were intertwined. While there is no direct relationship between algebra and accounting, the teaching of the subjects and the books published often intended for the children of merchants who were sent to reckoning schools (in Flanders and Germany) or abacus schools (known as "abbaco" in Italy), where they learned the skills useful for trade and commerce. There is probably no need for algebra in performing bookkeeping operations, but for complex bartering operations or the calculation of compound interest, a basic knowledge of arithmetic was mandatory and knowledge of algebra was very useful.
p108
aVLuca Pacioli's "Summa de Arithmetica, Geometria, Proportioni et Proportionalità" (Italian: "Review of Arithmetic, Geometry, Ratio and Proportion") was first printed and published in Venice in 1494. It included a 27-page treatise on bookkeeping, "Particularis de Computis et Scripturis" (Italian: "Details of Calculation and Recording"). It was written primarily for, and sold mainly to, merchants who used the book as a reference text, as a source of pleasure from the mathematical puzzles it contained, and to aid the education of their sons. In "Summa Arithmetica", Pacioli introduced symbols for plus and minus for the first time in a printed book, symbols that became standard notation in Italian Renaissance mathematics. "Summa Arithmetica" was also the first known book printed in Italy to contain algebra. It is important to note that Pacioli himself had borrowed much of the work of Piero Della Francesca whom he plagiarized.
p109
aVIn Italy, during the first half of the 16th century, Scipione del Ferro and Niccolò Fontana Tartaglia discovered solutions for cubic equations. Gerolamo Cardano published them in his 1545 book "Ars Magna", together with a solution for the quartic equations, discovered by his student Lodovico Ferrari. In 1572 Rafael Bombelli published his "L'Algebra" in which he showed how to deal with the imaginary quantities that could appear in Cardano's formula for solving cubic equations.
p110
aVSimon Stevin's book "De Thiende" ('the art of tenths'), first published in Dutch in 1585, contained the first systematic treatment of decimal notation, which influenced all later work on the real number system.
p111
aVDriven by the demands of navigation and the growing need for accurate maps of large areas, trigonometry grew to be a major branch of mathematics. Bartholomaeus Pitiscus was the first to use the word, publishing his "Trigonometria" in 1595. Regiomontanus's table of sines and cosines was published in 1533.
p112
aVDuring the Renaissance the desire of artists to represent the natural world realistically, together with the rediscovered philosophy of the Greeks, led artists to study mathematics. They were also the engineers and architects of that time, and so had need of mathematics in any case. The art of painting in perspective, and the developments in geometry that involved, were studied intensely.
p113
aVMathematics during the Scientific Revolution.
p114
aV17th century.
p115
aVThe 17th century saw an unprecedented explosion of mathematical and scientific ideas across Europe. Galileo observed the moons of Jupiter in orbit about that planet, using a telescope based on a toy imported from Holland. Tycho Brahe had gathered an enormous quantity of mathematical data describing the positions of the planets in the sky. By his position as Brahe's assistant, Johannes Kepler was first exposed to and seriously interacted with the topic of planetary motion. Kepler's calculations were made simpler by the contemporaneous invention of logarithms by John Napier and Jost Bürgi. Kepler succeeded in formulating mathematical laws of planetary motion.
p116
aVThe analytic geometry developed by René Descartes (1596\u20131650) allowed those orbits to be plotted on a graph, in Cartesian coordinates. Simon Stevin (1585) created the basis for modern decimal notation capable of describing all numbers, whether rational or irrational.
p117
aVBuilding on earlier work by many predecessors, Isaac Newton discovered the laws of physics explaining Kepler's Laws, and brought together the concepts now known as calculus. Independently, Gottfried Wilhelm Leibniz, who is arguably one of the most important mathematicians of the 17th century, developed calculus and much of the calculus notation still in use today. Science and mathematics had become an international endeavor, which would soon spread over the entire world.
p118
aVIn addition to the application of mathematics to the studies of the heavens, applied mathematics began to expand into new areas, with the correspondence of Pierre de Fermat and Blaise Pascal. Pascal and Fermat set the groundwork for the investigations of probability theory and the corresponding rules of combinatorics in their discussions over a game of gambling. Pascal, with his wager, attempted to use the newly developing probability theory to argue for a life devoted to religion, on the grounds that even if the probability of success was small, the rewards were infinite. In some sense, this foreshadowed the development of utility theory in the 18th\u201319th century.
p119
aV18th century.
p120
aVThe most influential mathematician of the 18th century was arguably Leonhard Euler. His contributions range from founding the study of graph theory with the Seven Bridges of Königsberg problem to standardizing many modern mathematical terms and notations. For example, he named the square root of minus 1 with the symbol "i", and he popularized the use of the Greek letter formula_1 to stand for the ratio of a circle's circumference to its diameter. He made numerous contributions to the study of topology, graph theory, calculus, combinatorics, and complex analysis, as evidenced by the multitude of theorems and notations named for him.
p121
aVOther important European mathematicians of the 18th century included Joseph Louis Lagrange, who did pioneering work in number theory, algebra, differential calculus, and the calculus of variations, and Laplace who, in the age of Napoleon, did important work on the foundations of celestial mechanics and on statistics.
p122
aVModern mathematics.
p123
aV19th century.
p124
aVThroughout the 19th century mathematics became increasingly abstract. In the 19th century lived Carl Friedrich Gauss (1777\u20131855). Leaving aside his many contributions to science, in pure mathematics he did revolutionary work on functions of complex variables, in geometry, and on the convergence of series. He gave the first satisfactory proofs of the fundamental theorem of algebra and of the quadratic reciprocity law.
p125
aVThis century saw the development of the two forms of non-Euclidean geometry, where the parallel postulate of Euclidean geometry no longer holds.
p126
aVThe Russian mathematician Nikolai Ivanovich Lobachevsky and his rival, the Hungarian mathematician János Bolyai, independently defined and studied hyperbolic geometry, where uniqueness of parallels no longer holds. In this geometry the sum of angles in a triangle add up to less than 180°. Elliptic geometry was developed later in the 19th century by the German mathematician Bernhard Riemann; here no parallel can be found and the angles in a triangle add up to more than 180°. Riemann also developed Riemannian geometry, which unifies and vastly generalizes the three types of geometry, and he defined the concept of a manifold, which generalizes the ideas of curves and surfaces.
p127
aVThe 19th century saw the beginning of a great deal of abstract algebra. Hermann Grassmann in Germany gave a first version of vector spaces, William Rowan Hamilton in Ireland developed noncommutative algebra. The British mathematician George Boole devised an algebra that soon evolved into what is now called Boolean algebra, in which the only numbers were 0 and 1. Boolean algebra is the starting point of mathematical logic and has important applications in computer science.
p128
aVAugustin-Louis Cauchy, Bernhard Riemann, and Karl Weierstrass reformulated the calculus in a more rigorous fashion.
p129
aVAlso, for the first time, the limits of mathematics were explored. Niels Henrik Abel, a Norwegian, and Évariste Galois, a Frenchman, proved that there is no general algebraic method for solving polynomial equations of degree greater than four (Abel\u2013Ruffini theorem). Other 19th-century mathematicians utilized this in their proofs that straightedge and compass alone are not sufficient to trisect an arbitrary angle, to construct the side of a cube twice the volume of a given cube, nor to construct a square equal in area to a given circle. Mathematicians had vainly attempted to solve all of these problems since the time of the ancient Greeks. On the other hand, the limitation of three dimensions in geometry was surpassed in the 19th century through considerations of parameter space and hypercomplex numbers.
p130
aVAbel and Galois's investigations into the solutions of various polynomial equations laid the groundwork for further developments of group theory, and the associated fields of abstract algebra. In the 20th century physicists and other scientists have seen group theory as the ideal way to study symmetry.
p131
aVIn the later 19th century, Georg Cantor established the first foundations of set theory, which enabled the rigorous treatment of the notion of infinity and has become the common language of nearly all mathematics. Cantor's set theory, and the rise of mathematical logic in the hands of Peano, L. E. J. Brouwer, David Hilbert, Bertrand Russell, and A.N. Whitehead, initiated a long running debate on the foundations of mathematics.
p132
aVThe 19th century saw the founding of a number of national mathematical societies: the London Mathematical Society in 1865, the Société Mathématique de France in 1872, the Circolo Matematico di Palermo in 1884, the Edinburgh Mathematical Society in 1883, and the American Mathematical Society in 1888. The first international, special-interest society, the Quaternion Society, was formed in 1899, in the context of a vector controversy.
p133
aVIn 1897, Hensel introduced p-adic numbers.
p134
aV20th century.
p135
aVThe 20th century saw mathematics become a major profession. Every year, thousands of new Ph.D.s in mathematics were awarded, and jobs were available in both teaching and industry. An effort to catalogue the areas and applications of mathematics was undertaken in Klein's encyclopedia.
p136
aVIn a 1900 speech to the International Congress of Mathematicians, David Hilbert set out a list of 23 unsolved problems in mathematics. These problems, spanning many areas of mathematics, formed a central focus for much of 20th-century mathematics. Today, 10 have been solved, 7 are partially solved, and 2 are still open. The remaining 4 are too loosely formulated to be stated as solved or not.
p137
aVNotable historical conjectures were finally proven. In 1976, Wolfgang Haken and Kenneth Appel used a computer to prove the four color theorem. Andrew Wiles, building on the work of others, proved Fermat's Last Theorem in 1995. Paul Cohen and Kurt Gödel proved that the continuum hypothesis is independent of (could neither be proved nor disproved from) the standard axioms of set theory. In 1998 Thomas Callister Hales proved the Kepler conjecture.
p138
aVMathematical collaborations of unprecedented size and scope took place. An example is the classification of finite simple groups (also called the "enormous theorem"), whose proof between 1955 and 1983 required 500-odd journal articles by about 100 authors, and filling tens of thousands of pages. A group of French mathematicians, including Jean Dieudonné and André Weil, publishing under the pseudonym "Nicolas Bourbaki", attempted to exposit all of known mathematics as a coherent rigorous whole. The resulting several dozen volumes has had a controversial influence on mathematical education.
p139
aVDifferential geometry came into its own when Einstein used it in general relativity. Entire new areas of mathematics such as mathematical logic, topology, and John von Neumann's game theory changed the kinds of questions that could be answered by mathematical methods. All kinds of structures were abstracted using axioms and given names like metric spaces, topological spaces etc. As mathematicians do, the concept of an abstract structure was itself abstracted and led to category theory. Grothendieck and Serre recast algebraic geometry using sheaf theory. Large advances were made in the qualitative study of dynamical systems that Poincaré had begun in the 1890s.
p140
aVMeasure theory was developed in the late 19th and early 20th centuries. Applications of measures include the Lebesgue integral, Kolmogorov's axiomatisation of probability theory, and ergodic theory. Knot theory greatly expanded. Quantum mechanics led to the development of functional analysis. Other new areas include, Laurent Schwartz's distribution theory, fixed point theory, singularity theory and René Thom's catastrophe theory, model theory, and Mandelbrot's fractals. Lie theory with its Lie groups and Lie algebras became one of the major areas of study.
p141
aVNon-standard analysis, introduced by Abraham Robinson, rehabillitated the infinitesimal approach to calculus, which had fallen into disrepute in favour of the theory of limits, by extending the field of real numbers to the Hyperreal numbers which include infinitesimal and infinite quantities. An even larger number system, the surreal numbers were discovered by John Horton Conway in connection with combinatorial games.
p142
aVThe development and continual improvement of computers, at first mechanical analog machines and then digital electronic machines, allowed industry to deal with larger and larger amounts of data to facilitate mass production and distribution and communication, and new areas of mathematics were developed to deal with this: Alan Turing's computability theory; complexity theory; Derrick Henry Lehmer's use of ENIAC to further number theory and the Lucas-Lehmer test; Claude Shannon's information theory; signal processing; data analysis; optimization and other areas of operations research. In the preceding centuries much mathematical focus was on calculus and continuous functions, but the rise of computing and communication networks led to an increasing importance of discrete concepts and the expansion of combinatorics including graph theory. The speed and data processing abilities of computers also enabled the handling of mathematical problems that were too time-consuming to deal with by pencil and paper calculations, leading to areas such as numerical analysis and symbolic computation. Some of the most important methods and algorithms of the 20th century are: the simplex algorithm, the Fast Fourier Transform, error-correcting codes, the Kalman filter from control theory and the RSA algorithm of public-key cryptography.
p143
aVAt the same time, deep insights were made about the limitations to mathematics. In 1929 and 1930, it was proved the truth or falsity of all statements formulated about the natural numbers plus one of addition and multiplication, was decidable, i.e. could be determined by some algorithm. In 1931, Kurt Gödel found that this was not the case for the natural numbers plus both addition and multiplication; this system, known as Peano arithmetic, was in fact incompletable. (Peano arithmetic is adequate for a good deal of number theory, including the notion of prime number.) A consequence of Gödel's two incompleteness theorems is that in any mathematical system that includes Peano arithmetic (including all of analysis and geometry), truth necessarily outruns proof, i.e. there are true statements that cannot be proved within the system. Hence mathematics cannot be reduced to mathematical logic, and David Hilbert's dream of making all of mathematics complete and consistent needed to be reformulated.
p144
aVOne of the more colorful figures in 20th-century mathematics was Srinivasa Aiyangar Ramanujan (1887\u20131920), an Indian autodidact who conjectured or proved over 3000 theorems, including properties of highly composite numbers, the partition function and its asymptotics, and mock theta functions. He also made major investigations in the areas of gamma functions, modular forms, divergent series, hypergeometric series and prime number theory.
p145
aVPaul Erd\u0151s published more papers than any other mathematician in history, working with hundreds of collaborators. Mathematicians have a game equivalent to the Kevin Bacon Game, which leads to the Erd\u0151s number of a mathematician. This describes the "collaborative distance" between a person and Paul Erd\u0151s, as measured by joint authorship of mathematical papers.
p146
aVEmmy Noether has been described by many as the most important woman in the history of mathematics, she revolutionized the theories of rings, fields, and algebras.
p147
aVAs in most areas of study, the explosion of knowledge in the scientific age has led to specialization: by the end of the century there were hundreds of specialized areas in mathematics and the Mathematics Subject Classification was dozens of pages long. More and more mathematical journals were published and, by the end of the century, the development of the world wide web led to online publishing.
p148
aV21st century.
p149
aVIn 2000, the Clay Mathematics Institute announced the seven Millennium Prize Problems, and in 2003 the Poincaré conjecture was solved by Grigori Perelman (who declined to accept an award, as he was critical of the mathematics establishment).
p150
aVMost mathematical journals now have online versions as well as print versions, and many online-only journals are launched. There is an increasing drive towards open access publishing, first popularized by the arXiv.
p151
aVFuture of mathematics.
p152
aVThere are many observable trends in mathematics, the most notable being that the subject is growing ever larger, computers are ever more important and powerful, the application of mathematics to bioinformatics is rapidly expanding, the volume of data to be analyzed being produced by science and industry, facilitated by computers, is explosively expanding.
p153
asS'Ratio'
p154
(lp155
VIn mathematics, a ratio is a relationship between two numbers of the same kind ("e.g.", objects, persons, students, spoonfuls, units of whatever identical dimension), expressed as "a" to "b" or "a":"b", sometimes expressed arithmetically as a dimensionless quotient of the two that explicitly indicates how many times the first number contains the second (not necessarily an integer).
p156
aVIn layman's terms a ratio represents, for every amount of one thing, how much there is of another thing. For example, supposing one has 8 oranges and 6 lemons in a bowl of fruit, the ratio of oranges to lemons would be 4:3 (which is equivalent to 8:6) while the ratio of lemons to oranges would be 3:4. Additionally, the ratio of oranges to the total amount of fruit is 4:7 (equivalent to 8:14). The 4:7 ratio can be further converted to a fraction of 4/7 to represent how much of the fruit is oranges.
p157
aVNotation and terminology.
p158
aVThe ratio of numbers "A" and "B" can be expressed as:
p159
aVThe numbers "A" and "B" are sometimes called "terms" with "A" being the "antecedent" and "B" being the "consequent".
p160
aVThe proportion expressing the equality of the ratios "A":"B" and "C":"D" is written
p161
aV"A":"B" = "C":"D" or "A":"B"::"C":"D". This latter form, when spoken or written in the English language, is often expressed as
p162
aV"A" is to "B" as "C" is to "D".
p163
aV"A", "B", "C" and "D" are called the terms of the proportion. "A" and "D" are called the "extremes", and "B" and "C" are called the "means". The equality of three or more proportions is called a continued proportion.
p164
aVRatios are sometimes used with three or more terms. The ratio of the dimensions of a "two by four" that is ten inches long is 2:4:10. A good concrete mix is sometimes quoted as 1:2:4 for the ratio of cement to sand to gravel.
p165
aVFor a mixture of 4/1 cement to water, it could be said that the ratio of cement to water is 4:1, that there is 4 times as much cement as water, or that there is a quarter (1/4) as much water as cement..
p166
aVOlder televisions have a 4:3 "aspect ratio", which means that the width is 4/3 of the height; modern widescreen TVs have a 16:9 aspect ratio.
p167
aVHistory and etymology.
p168
aVIt is impossible to trace the origin of the "concept" of ratio, because the ideas from which it developed would have been familiar to preliterate cultures. For example, the idea of one village being twice as large as another is so basic that it would have been understood in prehistoric society. However, it is possible to trace the origin of the word "ratio" to the Ancient Greek \u03bb\u03cc\u03b3\u03bf\u03c2 ("logos"). Early translators rendered this into Latin as "ratio" ("reason"; as in the word "rational"). (A rational number may be expressed as the quotient of two integers.) A more modern interpretation of Euclid's meaning is more akin to computation or reckoning. Medieval writers used the word "proportio" ("proportion") to indicate ratio and "proportionalitas" ("proportionality") for the equality of ratios.
p169
aVEuclid collected the results appearing in the Elements from earlier sources. The Pythagoreans developed a theory of ratio and proportion as applied to numbers. The Pythagoreans' conception of number included only what would today be called rational numbers, casting doubt on the validity of the theory in geometry where, as the Pythagoreans also discovered, incommensurable ratios (corresponding to irrational numbers) exist. The discovery of a theory of ratios that does not assume commensurability is probably due to Eudoxus of Cnidus. The exposition of the theory of proportions that appears in Book VII of The Elements reflects the earlier theory of ratios of commensurables.
p170
aVThe existence of multiple theories seems unnecessarily complex to modern sensibility since ratios are, to a large extent, identified with quotients. This is a comparatively recent development however, as can be seen from the fact that modern geometry textbooks still use distinct terminology and notation for ratios and quotients. The reasons for this are twofold. First, there was the previously mentioned reluctance to accept irrational numbers as true numbers. Second, the lack of a widely used symbolism to replace the already established terminology of ratios delayed the full acceptance of fractions as alternative until the 16th century.
p171
aVEuclid's definitions.
p172
aVBook V of Euclid's Elements has 18 definitions, all of which relate to ratios. In addition, Euclid uses ideas that were in such common usage that he did not include definitions for them. The first two definitions say that a "part" of a quantity is another quantity that "measures" it and conversely, a "multiple" of a quantity is another quantity that it measures. In modern terminology, this means that a multiple of a quantity is that quantity multiplied by an integer greater than one\u2014and a part of a quantity (meaning aliquot part) is a part that, when multiplied by an integer greater than one, gives the quantity.
p173
aVEuclid does not define the term "measure" as used here, However, one may infer that if a quantity is taken as a unit of measurement, and a second quantity is given as an integral number of these units, then the first quantity "measures" the second. Note that these definitions are repeated, nearly word for word, as definitions 3 and 5 in book VII.
p174
aVDefinition 3 describes what a ratio is in a general way. It is not rigorous in a mathematical sense and some have ascribed it to Euclid's editors rather than Euclid himself. Euclid defines a ratio as between two quantities "of the same type", so by this definition the ratios of two lengths or of two areas are defined, but not the ratio of a length and an area. Definition 4 makes this more rigorous. It states that a ratio of two quantities exists when there is a multiple of each that exceeds the other. In modern notation, a ratio exists between quantities "p" and "q" if there exist integers "m" and "n" so that "mp">"q" and "nq">"p". This condition is known as the Archimedean property.
p175
aVDefinition 5 is the most complex and difficult. It defines what it means for two ratios to be equal. Today, this can be done by simply stating that ratios are equal when the quotients of the terms are equal, but Euclid did not accept the existence of the quotients of incommensurables, so such a definition would have been meaningless to him. Thus, a more subtle definition is needed where quantities involved are not measured directly to one another. Though it may not be possible to assign a rational value to a ratio, it is possible to compare a ratio with a rational number. Specifically, given two quantities, "p" and "q", and a rational number "m"/"n" we can say that the ratio of "p" to "q" is less than, equal to, or greater than "m"/"n" when "np" is less than, equal to, or greater than "mq" respectively. Euclid's definition of equality can be stated as that two ratios are equal when they behave identically with respect to being less than, equal to, or greater than any rational number. In modern notation this says that given quantities "p", "q", "r" and "s", then "p":"q"::"r":"s" if for any positive integers "m" and "n", "np"<"mq", "np"="mq", "np">"mq" according as "nr"<"ms", "nr"="ms", "nr">"ms" respectively. There is a remarkable similarity between this definition and the theory of Dedekind cuts used in the modern definition of irrational numbers.
p176
aVDefinition 6 says that quantities that have the same ratio are "proportional" or "in proportion". Euclid uses the Greek \u1f00\u03bd\u03b1\u03bb\u03cc\u03b3\u03bf\u03bd (analogon), this has the same root as \u03bb\u03cc\u03b3\u03bf\u03c2 and is related to the English word "analog".
p177
aVDefinition 7 defines what it means for one ratio to be less than or greater than another and is based on the ideas present in definition 5. In modern notation it says that given quantities "p", "q", "r" and "s", then "p":"q">"r":"s" if there are positive integers "m" and "n" so that "np">"mq" and "nr"\u2264"ms".
p178
aVAs with definition 3, definition 8 is regarded by some as being a later insertion by Euclid's editors. It defines three terms "p", "q" and "r" to be in proportion when "p":"q"::"q":"r". This is extended to 4 terms "p", "q", "r" and "s" as "p":"q"::"q":"r"::"r":"s", and so on. Sequences that have the property that the ratios of consecutive terms are equal are called geometric progressions. Definitions 9 and 10 apply this, saying that if "p", "q" and "r" are in proportion then "p":"r" is the "duplicate ratio" of "p":"q" and if "p", "q", "r" and "s" are in proportion then "p":"s" is the "triplicate ratio" of "p":"q". If "p", "q" and "r" are in proportion then "q" is called a "mean proportional" to (or the geometric mean of) "p" and "r". Similarly, if "p", "q", "r" and "s" are in proportion then "q" and "r" are called two mean proportionals to "p" and "s".
p179
aVNumber of terms and use of fractions.
p180
aVIn general, a comparison of the quantities of a two-entity ratio can be expressed as a fraction derived from the ratio. For example, in a ratio of 2:3, the amount, size, volume, or quantity of the first entity is formula_2 that of the second entity.
p181
aVIf there are 2 oranges and 3 apples, the ratio of oranges to apples is 2:3, and the ratio of oranges to the total number of pieces of fruit is 2:5. These ratios can also be expressed in fraction form: there are 2/3 as many oranges as apples, and 2/5 of the pieces of fruit are oranges. If orange juice concentrate is to be diluted with water in the ratio 1:4, then one part of concentrate is mixed with four parts of water, giving five parts total; the amount of orange juice concentrate is 1/4 the amount of water, while the amount of orange juice concentrate is 1/5 of the total liquid. In both ratios and fractions, it is important to be clear what is being compared to what, and beginners often make mistakes for this reason.
p182
aVFractions can also be inferred from ratios with more than two entities; however, a ratio with more than two entities cannot be completely converted into a single fraction, because a fraction can only compare two quantities. A separate fraction can be used to compare the quantities of any two of the entities covered by the ratio: for example, from a ratio of 2:3:7 we can infer that the quantity of the second entity is formula_3 that of the third entity.
p183
aVProportions and percentage ratios.
p184
aVIf we multiply all quantities involved in a ratio by the same number, the ratio remains valid. For example, a ratio of 3:2 is the same as 12:8. It is usual either to reduce terms to the lowest common denominator, or to express them in parts per hundred (percent).
p185
aVIf a mixture contains substances A, B, C and D in the ratio 5:9:4:2 then there are 5 parts of A for every 9 parts of B, 4 parts of C and 2 parts of D. As 5+9+4+2=20, the total mixture contains 5/20 of A (5 parts out of 20), 9/20 of B, 4/20 of C, and 2/20 of D. If we divide all numbers by the total and multiply by 100%, we have converted to percentages: 25% A, 45% B, 20% C, and 10% D (equivalent to writing the ratio as 25:45:20:10).
p186
aVIf the two or more ratio quantities encompass all of the quantities in a particular situation, it is said that "the whole" contains the sum of the parts: for example, a fruit basket containing two apples and three oranges and no other fruit is made up of two parts apples and three parts oranges. In this case, formula_4, or 40% of the whole is apples and formula_5, or 60% of the whole is oranges. This comparison of a specific quantity to "the whole" is called a proportion.
p187
aVReduction.
p188
aVRatios can be reduced (as fractions are) by dividing each quantity by the common factors of all the quantities. As for fractions, the simplest form is considered that in which the numbers in the ratio are the smallest possible integers.
p189
aVThus, the ratio 40:60 is equivalent in meaning to the ratio 2:3, the latter being obtained from the former by dividing both quantities by 20. Mathematically, we write 40:60 = 2:3, or equivalently 40:60::2:3. The verbal equivalent is "40 is to 60 as 2 is to 3."
p190
aVA ratio that has integers for both quantities and that cannot be reduced any further (using integers) is said to be in simplest form or lowest terms.
p191
aVSometimes it is useful to write a ratio in the form 1:"x" or "x":1, where "x" is not necessarily an integer, to enable comparisons of different ratios. For example, the ratio 4:5 can be written as 1:1.25 (dividing both sides by 4) Alternatively, it can be written as 0.8:1 (dividing both sides by 5).
p192
aVWhere the context makes the meaning clear, a ratio in this form is sometimes written without the 1 and the colon, though, mathematically, this makes it a factor or multiplier.
p193
aVDilution ratio.
p194
aVRatios are often used for simple dilutions applied in chemistry and biology. A simple dilution is one in which a unit volume of a liquid material of interest is combined with an appropriate volume of a solvent liquid to achieve the desired concentration. The dilution factor is the total number of unit volumes in which the material is dissolved. The diluted material must then be thoroughly mixed to achieve the true dilution. For example, a 1:5 dilution (verbalize as "1 to 5" dilution) entails combining 1 unit volume of solute (the material to be diluted) with (approximately) 4 unit volumes of the solvent to give 5 units of total volume. (Some solutions and mixtures take up slightly less volume than their components.)
p195
aVThe dilution factor is frequently expressed using exponents: 1:5 would be 5e\u22121 (5\u22121 i.e. one-fifth:one); 1:100 would be 10e\u22122 (10\u22122 i.e. one hundredth:one), and so on.
p196
aVThere is often confusion between dilution ratio (1:n meaning 1 part solute to n parts solvent) and dilution factor (1:n+1) where the second number (n+1) represents the total volume of solute + solvent. In scientific and serial dilutions, the given ratio (or factor) often means the ratio to the final volume, not to just the solvent. The factors then can easily be multiplied to give an overall dilution factor.
p197
aVIn other areas of science such as pharmacy, and in non-scientific usage, a dilution is normally given as a plain ratio of solvent to solute.
p198
aVIrrational ratios.
p199
aVSome ratios are between incommensurable quantities\u2014quantities whose ratio is an irrational number. The earliest discovered example, found by the Pythagoreans, is the ratio of the diagonal to the side of a square, which is the square root of 2.
p200
aVThe ratio of a circle's circumference to its diameter is called pi, and is not only irrational but also transcendental.
p201
aVAnother well-known example is the golden ratio, which is defined as both sides of the equality "a:b" = ("a+b"):"a". Writing this in fractional terms as formula_6 and finding the positive solution gives the golden ratio formula_7 which is irrational. Thus at least one of "a" and "b" has to be irrational for them to be in the golden ratio. An example of an occurrence of the golden ratio is as the limiting value of the ratio of two successive Fibonacci numbers: even though the "n"-th such ratio is the ratio of two integers and hence is rational, the limit of the sequence of these ratios as "n" goes to infinity is the irrational golden ratio.
p202
aVSimilarly, the silver ratio is defined as both sides of the equality "a:b" = (2"a+b"):"a". Again writing it in fractional terms and obtaining the positive solution, we obtain formula_8 which is irrational, so of two quantities "a" and "b" in the silver ratio at least one of them must be irrational.
p203
aVOdds.
p204
aV"Odds" (as in gambling) are expressed as a ratio. For example, odds of "7 to 3 against" (7:3) mean that there are seven chances that the event will not happen to every three chances that it will happen. The probability of success is 30%. In every ten trials, there are expected to be three wins and seven losses.
p205
aVDifferent units.
p206
aVRatios are unitless when they relate quantities in units of the same dimension.
p207
aVFor example, the ratio 1 minute : 40 seconds can be reduced by changing the first value to 60 seconds. Once the units are the same, they can be omitted, and the ratio can be reduced to 3:2.
p208
aVIn chemistry, mass concentration "ratios" are usually expressed as w/v percentages, and are really proportions.
p209
aVFor example, a concentration of 3% w/v usually means 3g of substance in every 100mL of solution. This cannot easily be converted to a pure ratio because of density considerations, and the second figure is the "total" amount, not the volume of solvent.
p210
aVFinancial ratios.
p211
aVVarious financial ratios are used in the fundamental analysis of a business, for example the price\u2013earnings ratio is commonly quoted for shares.
p212
aVTriangular coordinates.
p213
aVThe locations of points relative to a triangle with vertices "A", "B", and "C" and sides "AB", "BC", and "CA" are often expressed in extended ratio form as "triangular coordinates". 
p214
aVIn barycentric coordinates, a point with coordinates formula_9 is the point upon which a weightless sheet of metal in the shape and size of the triangle would exactly balance if weights were put on the vertices, with the ratio of the weights at "A" and "B" being formula_10 the ratio of the weights at "B" and "C" being formula_11 and therefore the ratio of weights at "A" and "C" being formula_12
p215
aVIn trilinear coordinates, a point with coordinates "x:y:z" has perpendicular distances to side "BC" (across from vertex "A") and side "CA" (across from vertex "B") in the ratio "x:y", distances to side "CA" and side "AB" (across from "C") in the ratio "y:z", and therefore distances to sides "BC" and "AB" in the ratio "x:z".
p216
aVSince all information is expressed in terms of ratios (the individual numbers denoted by formula_13 "x, y," and "z" have no meaning by themselves), a triangle analysis using barycentric or trilinear coordinates applies regardless of the size of the triangle.
p217
asS'Probability space'
p218
(lp219
VIn probability theory, a probability space or a probability triple is a mathematical construct that models a real-world process (or "experiment") consisting of states that occur randomly. A probability space is constructed with a specific kind of situation or experiment in mind. One proposes that each time a situation of that kind arises, the set of possible outcomes is the same and the probabilities are also the same.
p220
aVA probability space consists of three parts:
p221
aVAn outcome is the result of a single execution of the model. Since individual outcomes might be of little practical use, more complex "events" are used to characterize groups of outcomes. The collection of all such events is a "\u03c3-algebra" formula_1. Finally, there is a need to specify each event's likelihood of happening. This is done using the "probability measure" function, "P".
p222
aVOnce the probability space is established, it is assumed that \u201cnature\u201d makes its move and selects a single outcome, "\u03c9", from the sample space \u03a9. All the events in formula_1 that contain the selected outcome "\u03c9" (recall that each event is a subset of \u03a9) are said to \u201chave occurred\u201d. The selection performed by nature is done in such a way that if the experiment were to be repeated an infinite number of times, the relative frequencies of occurrence of each of the events would coincide with the probabilities prescribed by the function "P".
p223
aVThe Russian mathematician Andrey Kolmogorov introduced the notion of probability space, together with other axioms of probability, in the 1930s. Nowadays alternative approaches for axiomatization of probability theory exist; see \u201cAlgebra of random variables\u201d, for example.
p224
aVThis article is concerned with the mathematics of manipulating probabilities. The article probability interpretations outlines several alternative views of what "probability" means and how it should be interpreted. In addition, there have been attempts to construct theories for quantities that are notionally similar to probabilities but do not obey all their rules; see, for example, Free probability, Fuzzy logic, Possibility theory, Negative probability and Quantum probability.
p225
aVIntroduction.
p226
aVA probability space is a mathematical triplet (\u03a9, formula_1, "P") that
p227
aVpresents a model for a particular class of real-world situations.
p228
aVAs with other models, its author ultimately defines which elements \u03a9, formula_1, and "P" will contain.
p229
aVNot every subset of the sample space \u03a9 must necessarily be considered an event: some of the subsets are simply not of interest, others cannot be "measured". This is not so obvious in a case like a coin toss. In a different example, one could consider javelin throw lengths, where the events typically are intervals like "between 60 and 65 meters" and unions of such intervals, but not sets like the "irrational numbers between 60 and 65 meters"
p230
aVDefinition.
p231
aVIn short, a probability space is a measure space such that the measure of the whole space is equal to one.
p232
aVThe expanded definition is following: a probability space is a triple formula_8 consisting of:
p233
aVDiscrete case.
p234
aVDiscrete probability theory needs only at most countable sample spaces \u03a9. Probabilities can be ascribed to points of \u03a9 by the probability mass function "p": \u03a9\u2192[0,1] such that \u2211"\u03c9"\u2208\u03a9 "p"("\u03c9") = 1. All subsets of \u03a9 can be treated as events (thus, formula_9 = 2\u03a9 is the power set). The probability measure takes the simple form
p235
aVformula_25
p236
aVThe greatest \u03c3-algebra formula_9 = 2\u03a9 describes the complete information. In general, a \u03c3-algebra formula_9 \u2286 2\u03a9 corresponds to a finite or countable partition \u03a9 = "B"1 \u2294 "B"2 \u2294 ..., the general form of an event "A" \u2208 formula_9 being "A" = "B""k"1 \u2294 "B""k"2 \u2294 ... (here \u2294 means the disjoint union.) See also the examples.
p237
aVThe case "p"("\u03c9") = 0 is permitted by the definition, but rarely used, since such "\u03c9" can safely be excluded from the sample space.
p238
aVGeneral case.
p239
aVIf \u03a9 is uncountable, still, it may happen that "p"("\u03c9") \u2260 0 for some "\u03c9"; such "\u03c9" are called atoms. They are an at most countable (maybe empty) set, whose probability is the sum of probabilities of all atoms. If this sum is equal to 1 then all other points can safely be excluded from the sample space, returning us to the discrete case. Otherwise, if the sum of probabilities of all atoms is less than 1 (maybe 0), then the probability space decomposes into a discrete (atomic) part (maybe empty) and a non-atomic part.
p240
aVNon-atomic case.
p241
aVIf "p"("\u03c9") = 0 for all "\u03c9"\u2208\u03a9 (in this case, \u03a9 must be uncountable, because otherwise P(\u03a9)=1 could not be satisfied), then equation (\u2217) fails: the probability of a set is not the sum over its elements, as summation is only defined for countable amount of elements. This makes the probability space theory much more technical. A formulation stronger than summation, measure theory is applicable. Initially the probabilities are ascribed to some \u201cgenerator\u201d sets (see the examples). Then a limiting procedure allows assigning probabilities to sets that are limits of sequences of generator sets, or limits of limits, and so on. All these sets are the \u03c3-algebra formula_9. For technical details see Carathéodory's extension theorem. Sets belonging to formula_9 are called measurable. In general they are much more complicated than generator sets, but much better than non-measurable sets.
p242
aVComplete probability space.
p243
aVA probability space formula_8 is said to be a complete probability space if for all formula_32 with formula_33 and all formula_34 one has formula_35. Often, the study of probability spaces is restricted to complete probability spaces.
p244
aVExamples.
p245
aVDiscrete examples.
p246
aVExample 1.
p247
aVIf the experiment consists of just one flip of a perfect coin, then the outcomes are either heads or tails: \u03a9 = {H, T}. The \u03c3-algebra formula_9 = 2\u03a9 contains 2² = 4 events, namely: {H} \u2013 \u201cheads\u201d, {T} \u2013 \u201ctails\u201d, {} \u2013 \u201cneither heads nor tails\u201d, and {H,T} \u2013 \u201ceither heads or tails\u201d. So, formula_9 = . There is a fifty percent chance of tossing heads, and fifty percent for tails. Thus the probability measure in this example is "P"({}) = 0, "P"({H}) = 0.5, "P"({T}) = 0.5, "P"({H,T}) = 1.
p248
aVExample 2.
p249
aVThe fair coin is tossed three times. There are 8 possible outcomes: \u03a9 = {HHH, HHT, HTH, HTT, THH, THT, TTH, TTT} (here \u201cHTH\u201d for example means that first time the coin landed heads, the second time tails, and the last time heads again). The complete information is described by the \u03c3-algebra formula_9 = 2\u03a9 of 28 = 256 events, where each of the events is a subset of \u03a9.
p250
aVAlice knows the outcome of the second toss only. Thus her incomplete information is described by the partition \u03a9 = A1 \u2294 A2 = {HHH, HHT, THH, THT} \u2294 {HTH, HTT, TTH, TTT}, and the corresponding \u03c3-algebra formula_9Alice = . Brian knows only the total number of tails. His partition contains four parts: \u03a9 = B0 \u2294 B1 \u2294 B2 \u2294 B3 = {HHH} \u2294 {HHT, HTH, THH} \u2294 {TTH, THT, HTT} \u2294 {TTT}; accordingly, his \u03c3-algebra formula_9Brian contains 24 = 16 events.
p251
aVThe two \u03c3-algebras are incomparable: neither formula_9Alice \u2286 formula_9Brian nor formula_9Brian \u2286 formula_9Alice; both are sub-\u03c3-algebras of 2\u03a9.
p252
aVExample 3.
p253
aVIf 100 voters are to be drawn randomly from among all voters in California and asked whom they will vote for governor, then the set of all sequences of 100 Californian voters would be the sample space \u03a9. We assume that sampling without replacement is used: only sequences of 100 "different" voters are allowed. For simplicity an ordered sample is considered, that is a sequence {Alice, Brian} is different from {Brian, Alice}. We also take for granted that each potential voter knows exactly his future choice, that is he/she doesn\u2019t choose randomly.
p254
aVAlice knows only whether or not Arnold Schwarzenegger has received at least 60 votes. Her incomplete information is described by the \u03c3-algebra formula_9Alice that contains: (1) the set of all sequences in \u03a9 where at least 60 people vote for Schwarzenegger; (2) the set of all sequences where fewer than 60 vote for Schwarzenegger; (3) the whole sample space \u03a9; and (4) the empty set \u2205.
p255
aVBrian knows the exact number of voters who are going to vote for Schwarzenegger. His incomplete information is described by the corresponding partition \u03a9 = B0 \u2294 B1 ... \u2294 B100 (though some of these sets may be empty, depending on the Californian voters...) and the \u03c3-algebra formula_9Brian consists of 2101 events.
p256
aVIn this case Alice\u2019s \u03c3-algebra is a subset of Brian\u2019s: formula_9Alice \u2282 formula_9Brian. The Brian\u2019s \u03c3-algebra is in turn the subset of the much larger \u201ccomplete information\u201d \u03c3-algebra 2\u03a9 consisting of events, where "n" is the number of all potential voters in California.
p257
aVNon-atomic examples.
p258
aVExample 4.
p259
aVA number between 0 and 1 is chosen at random, uniformly. Here \u03a9 = formula_9 is the \u03c3-algebra of Borel sets on \u03a9, and "P" is the Lebesgue measure on [0,1.
p260
aVIn this case the open intervals of the form ("a","b"), where 0 < "a" < "b" < 1, could be taken as the generator sets. Each such set can be ascribed the probability of "P"(("a","b")) = ("b" \u2212 "a"), which generates the Lebesgue measure on [0,1], and the Borel \u03c3-algebra on \u03a9.
p261
aVExample 5.
p262
aVA fair coin is tossed endlessly. Here one can take \u03a9 = {0,1}\u221e, the set of all infinite sequences of numbers 0 and 1. Cylinder sets {("x"1, "x"2, ...) \u2208 \u03a9 : "x"1 = "a"1, ..., "x""n" = "a""n"} may be used as the generator sets. Each such set describes an event in which the first "n" tosses have resulted in a fixed sequence ("a"1, ..., "a""n"), and the rest of the sequence may be arbitrary. Each such event can be naturally given the probability of 2\u2212"n".
p263
aVThese two non-atomic examples are closely related: a sequence ("x"1,"x"2...) \u2208 {0,1}\u221e leads to the number 2\u22121"x"1 + 2\u22122"x"2 + ... \u2208 This is not a one-to-one correspondence between {0,1}\u221e and [0,1 however: it is an isomorphism modulo zero, which allows for treating the two probability spaces as two forms of the same probability space. In fact, all non-pathologic non-atomic probability spaces are the same in this sense. They are so-called standard probability spaces. Basic applications of probability spaces are insensitive to standardness. However, non-discrete conditioning is easy and natural on standard probability spaces, otherwise it becomes obscure.
p264
aVRelated concepts.
p265
aVProbability distribution.
p266
aVAny probability distribution defines a probability measure.
p267
aVRandom variables.
p268
aVA random variable "X" is a measurable function "X": \u03a9\u2192"S" from the sample space \u03a9 to another measurable space "S" called the "state space".
p269
aVThe notation Pr("X"\u2208"A") is a commonly used shorthand for "P"({"\u03c9"\u2208\u03a9: "X"("\u03c9")\u2208"A"}).
p270
aVDefining the events in terms of the sample space.
p271
aVIf \u03a9 is countable we almost always define formula_9 as the power set of \u03a9, i.e. formula_9 = 2\u03a9 which is trivially a \u03c3-algebra and the biggest one we can create using \u03a9. We can therefore omit \u2131 and just write (\u03a9,P) to define the probability space.
p272
aVOn the other hand, if \u03a9 is uncountable and we use formula_9 = 2\u03a9 we get into trouble defining our probability measure "P" because formula_9 is too \u201clarge\u201d, i.e. there will often be sets to which it will be impossible to assign a unique measure. In this case, we have to use a smaller \u03c3-algebra formula_9, for example the Borel algebra of \u03a9, which is the smallest \u03c3-algebra that makes all open sets measurable.
p273
aVConditional probability.
p274
aVKolmogorov\u2019s definition of probability spaces gives rise to the natural concept of conditional probability. Every set "A" with non-zero probability (that is, "P"("A") > 0) defines another probability measure
p275
aV <math>
p276
aVon the space. This is usually pronounced as the \u201cprobability of "B" given "A"\u201d.
p277
aVFor any event "B" such that "P"("B") > 0 the function "Q" defined by "Q"("A") = "P"("A"|"B") for all events "A" is itself a probability measure.
p278
aVIndependence.
p279
aVTwo events, "A" and "B" are said to be independent if "P"("A"\u2229"B")="P"("A")"P"("B").
p280
aVTwo random variables, "X" and "Y", are said to be independent if any event defined in terms of "X" is independent of any event defined in terms of "Y". Formally, they generate independent \u03c3-algebras, where two \u03c3-algebras "G" and "H", which are subsets of "F" are said to be independent if any element of "G" is independent of any element of "H".
p281
aVMutual exclusivity.
p282
aVTwo events, "A" and "B" are said to be mutually exclusive or "disjoint" if "P"("A"\u2229"B") = 0. (This is weaker than "A"\u2229"B" = \u2205, which is the definition of disjoint for sets).
p283
aVIf "A" and "B" are disjoint events, then "P"("A"\u222a"B") = "P"("A") + "P"("B"). This extends to a (finite or countably infinite) sequence of events. However, the probability of the union of an uncountable set of events is not the sum of their probabilities. For example, if "Z" is a normally distributed random variable, then "P"("Z"="x") is 0 for any "x", but "P"("Z"\u2208R) = 1.
p284
aVThe event "A"\u2229"B" is referred to as \u201c"A" and "B"\u201d, and the event "A"\u222a"B" as \u201c"A" or "B"\u201d.
p285
aV: The first major treatise blending calculus with probability theory, originally in French: "Théorie Analytique des Probabilités".
p286
aV: The modern measure-theoretic foundation of probability theory; the original German version ("Grundbegriffe der Wahrscheinlichkeitrechnung") appeared in 1933.
p287
aV: An empiricist, Bayesian approach to the foundations of probability theory.
p288
aV: Discrete foundations of probability theory, based on nonstandard analysis and internal set theory. downloadable. http://www.math.princeton.edu/~nelson/books.html
p289
aV: A lively introduction to probability theory for the beginner, Cambridge Univ. Press.
p290
aV: An undergraduate introduction to measure-theoretic probability, Cambridge Univ. Press.
p291
asS'Planck time'
p292
(lp293
VIn physics, the Planck time () is the unit of time in the system of natural units known as Planck units. It is the time required for light to travel, in a vacuum, a distance of 1 Planck length. The unit is named after Max Planck, who was the first to propose it.
p294
aVThe Planck time is defined as:
p295
aVformula_1
p296
aVwhere:
p297
aV is the reduced Planck constant (sometimes is used instead of in the definition)
p298
aV = gravitational constant
p299
aV = speed of light in a vacuum
p300
aV is the SI unit of time, the second.
p301
aVThe two digits between parentheses denote the standard error of the estimated value.
p302
aVPhysical significance.
p303
aVThe Planck time is the unique combination of the gravitational constant , the special-relativistic constant , and the quantum constant , to produce a constant with units of time. Because the Planck time comes from dimensional analysis, which ignores constant factors, there is no reason to believe that exactly one unit of Planck time has any special physical significance. Rather, the Planck time represents a rough time scale at which quantum gravitational effects are likely to become important. The nature of those effects, and the exact time scale at which they would occur, would need to be derived from an actual theory of quantum gravity. All scientific experiments and human experiences happen over billions of billions of billions of Planck times, making any events happening at the Planck scale hard to detect. , the smallest time interval uncertainty in direct measurements is on the order of 12 attoseconds (1.2 × 10\u221217 seconds), about 3.7 × 1026 Planck times.
p304
asS'Piecewise'
p305
(lp306
VIn mathematics, a piecewise-defined function (also called a piecewise function or a hybrid function) is a function which is defined by multiple sub functions, each sub function applying to a certain interval of the main function's domain (a sub-domain). Piecewise is actually a way of expressing the function, rather than a characteristic of the function itself, but with additional qualification, it can describe the nature of the function. For example, a piecewise polynomial function: a function that is a polynomial on each of its sub-domains, but possibly a different one on each.
p307
aVThe word "piecewise" is also used to describe any property of a piecewise-defined function that holds for each piece but may not hold for the whole domain of the function. A function is piecewise differentiable or piecewise continuously differentiable if each piece is differentiable throughout its subdomain, even though the whole function may not be differentiable at the points between the pieces. In convex analysis, the notion of a derivative may be replaced by that of the subderivative for piecewise functions. Although the "pieces" in a piecewise definition need not be intervals, a function isn't called "piecewise linear" or "piecewise continuous" or "piecewise differentiable" unless the pieces are intervals.
p308
aVNotation and interpretation.
p309
aVPiecewise functions are defined using the common functional notation, where the body of the function is an array of functions and associated subdomains. Crucially, in most settings, there must only be a "finite" number of subdomains, each of which must be an interval, in order for the overall function to be called "piecewise". For example, consider the piecewise definition of the absolute value function:
p310
aVformula_1
p311
aVFor all values of "x" less than zero, the first function (\u2212"x") is used, which negates the sign of the input value, making negative numbers positive. For all values of "x" greater than or equal to zero, the second function ("x") is used, which evaluates trivially to the input value itself.
p312
aVConsider the piecewise function "f"("x") evaluated at certain values of "x":
p313
aVThus, in order to evaluate a piecewise function at a given input value, the appropriate subdomain needs to be chosen in order to select the correct function and produce the correct output value.
p314
aVContinuity.
p315
aVA piecewise function is continuous on a given interval if the following conditions are met:
p316
aVThe pictured function, for example, is piecewise continuous throughout its subdomains, but is not continuous on the entire domain. The pictured function contains a jump discontinuity at formula_2.
p317
asS'Number line'
p318
(lp319
VIn basic mathematics, a number line is a picture of a straight line on which every point is assumed to correspond to a real number and every real number to a point.
p320
aVOften the integers are shown as specially-marked points evenly spaced on the line. Although this image only shows the integers from \u22129 to 9, the line includes all real numbers, continuing forever in each direction, and also numbers not marked that are between the integers. It is often used as an aid in teaching simple addition and subtraction, especially involving negative numbers.
p321
aVIt is divided into two symmetric halves by the origin, that is the number zero.
p322
aVIn advanced mathematics, the expressions "real number line", or "real line" are typically used to indicate the above-mentioned concept that every point on a straight line corresponds to a single real number, and .
p323
aVDrawing the number line.
p324
aVThe number line is usually represented as being horizontal. Positive numbers always lie on the right side of zero, and negative numbers always lie on the left side of zero. An arrowhead on either end of the drawing is meant to suggest that the line continues indefinitely in the positive and negative real numbers, denoted by formula_1. The real numbers consist of irrational numbers and rational numbers, the latter of which include the integers, which in turn include the natural numbers (also called the counting numbers or whole numbers).
p325
aVComparing numbers.
p326
aVIf a particular number is farther to the right on the number line than is another number, then the first number is greater than the second (equivalently, the second is less than the first). The distance between them is the magnitude of their difference\u2014that is, it measures the first number minus the second one, or equivalently the absolute value of the second number minus the first one. Taking this difference is the process of subtraction.
p327
aVThus, for example, the length of a line segment between 0 and some other number represents the magnitude of the latter number.
p328
aVTwo numbers can be added by "picking up" the length from 0 to one of the numbers, and putting it down again with the end that was 0 placed on top of the other number.
p329
aVTwo numbers can be multiplied as in this example: To multiply 5 × 3, note that this is the same as 5 + 5 + 5, so pick up the length from 0 to 5 and place it to the right of 5, and then pick up that length again and place it to the right of the previous result. This gives a result that is 3 combined lengths of 5 each; since the process ends at 15, we find that 5 × 3 = 15.
p330
aVDivision can be performed as in the following example: To divide 6 by 2\u2014that is, to find out how many times 2 goes into 6\u2014note that the length from 0 to 2 lies at the beginning of the length from 0 to 6; pick up the former length and put it down again to the right of its original position, with the end formerly at 0 now placed at 2, and then move the length to the right of its latest position again. This puts the right end of the length 2 at the right end of the length from 0 to 6. Since three lengths of 2 filled the length 6, 2 goes into 6 three times (that is, 6 ÷ 2 = 3).
p331
aVPortions of the number line.
p332
aVThe section of the number line between two numbers is called an interval. If the section includes both numbers it is said to be a closed interval, while if it excludes both numbers it is called an open interval. If it includes one of the numbers but not the other one, it is called a half-open interval.
p333
aVAll the points extending forever in one direction from a particular point are together known as a ray. If the ray includes the particular point, it is a closed ray; otherwise it is an open ray.
p334
aVExtensions of the concept.
p335
aVScaling.
p336
aVSometimes it is convenient to scale the numbers on the number line with a logarithmic scale, using scientific notation. For example, the number one inch to the right of 0 might be 1, then the number once inch farther to the right would be 101 (=10), then one inch to the right of that would be 102 (=100), then 1000, then 10,000, etc. This approach is useful, for example, in illustrating a sequence of events in the history of the universe or of evolution, or in comparing distances to various stars.
p337
aVCombining number lines.
p338
aVA line drawn through the origin at right angles to the real number line can be used to represent the imaginary numbers. This line, called imaginary line, extends the number line to a complex number plane, with points representing complex numbers.
p339
aVAlternatively, one real number line can be drawn horizontally to denote potential values of one real number, commonly called "x", and another real number line can be drawn vertically to denote potential values of another real number, commonly called "y". Together these lines form what is known as the Cartesian coordinate system, and any point in the Cartesian plane denotes the values of a pair of real numbers. Further, the Cartesian coordinate system can itself be extended by visualizing a third number line "coming out of the screen (or page)", measuring a third variable called "z". Positive numbers are closer to the viewer's eyes than the screen is, while negative numbers are "behind the screen"; larger number are farther from the screen. Then any point in the three-dimensional space that we live in represents the values of a trio of real numbers.
p340
asS'Associativity'
p341
(lp342
sS'Discrete mathematics'
p343
(lp344
VDiscrete mathematics is the study of mathematical structures that are fundamentally discrete rather than continuous. In contrast to real numbers that have the property of varying "smoothly", the objects studied in discrete mathematics \u2013 such as integers, graphs, and statements in logic \u2013 do not vary smoothly in this way, but have distinct, separated values. Discrete mathematics therefore excludes topics in "continuous mathematics" such as calculus and analysis. Discrete objects can often be enumerated by integers. More formally, discrete mathematics has been characterized as the branch of mathematics dealing with countable sets (sets that have the same cardinality as subsets of the natural numbers, including rational numbers but not real numbers). However, there is no exact definition of the term "discrete mathematics." Indeed, discrete mathematics is described less by what is included than by what is excluded: continuously varying quantities and related notions.
p345
aVThe set of objects studied in discrete mathematics can be finite or infinite. The term finite mathematics is sometimes applied to parts of the field of discrete mathematics that deals with finite sets, particularly those areas relevant to business.
p346
aVResearch in discrete mathematics increased in the latter half of the twentieth century partly due to the development of digital computers which operate in discrete steps and store data in discrete bits. Concepts and notations from discrete mathematics are useful in studying and describing objects and problems in branches of computer science, such as computer algorithms, programming languages, cryptography, automated theorem proving, and software development. Conversely, computer implementations are significant in applying ideas from discrete mathematics to real-world problems, such as in operations research.
p347
aVAlthough the main objects of study in discrete mathematics are discrete objects, analytic methods from continuous mathematics are often employed as well.
p348
aVIn the university curricula, "Discrete Mathematics" appeared in the 1980s, initially as a computer science support course; its contents was somewhat haphazard at the time. The curriculum has thereafter developed in conjunction to efforts by ACM and MAA into a course that's basically intended to develop mathematical maturity in freshmen; as such it is nowadays a prerequisite for mathematics majors in some universities as well. Some high-school-level discrete mathematics textbooks have appeared as well. At this level, discrete mathematics it is sometimes seen a preparatory course, not unlike precalculus in this respect.
p349
aVThe Fulkerson Prize is awarded for outstanding papers in discrete mathematics.
p350
aVGrand challenges, past and present.
p351
aVThe history of discrete mathematics has involved a number of challenging problems which have focused attention within areas of the field. In graph theory, much research was motivated by attempts to prove the four color theorem, first stated in 1852, but not proved until 1976 (by Kenneth Appel and Wolfgang Haken, using substantial computer assistance).
p352
aVIn logic, the second problem on David Hilbert's list of open problems presented in 1900 was to prove that the axioms of arithmetic are consistent. Gödel's second incompleteness theorem, proved in 1931, showed that this was not possible \u2013 at least not within arithmetic itself. Hilbert's tenth problem was to determine whether a given polynomial Diophantine equation with integer coefficients has an integer solution. In 1970, Yuri Matiyasevich proved that this could not be done.
p353
aVThe need to break German codes in World War II led to advances in cryptography and theoretical computer science, with the first programmable digital electronic computer being developed at England's Bletchley Park with the guidance of Alan Turing and his seminal work, On Computable Numbers. At the same time, military requirements motivated advances in operations research. The Cold War meant that cryptography remained important, with fundamental advances such as public-key cryptography being developed in the following decades. Operations research remained important as a tool in business and project management, with the critical path method being developed in the 1950s. The telecommunication industry has also motivated advances in discrete mathematics, particularly in graph theory and information theory. Formal verification of statements in logic has been necessary for software development of safety-critical systems, and advances in automated theorem proving have been driven by this need.
p354
aVComputational geometry has been an important part of the computer graphics incorporated into modern video games and computer-aided design tools.
p355
aVSeveral fields of discrete mathematics, particularly theoretical computer science, graph theory, and combinatorics, are important in addressing the challenging bioinformatics problems associated with understanding the tree of life.
p356
aVCurrently, one of the most famous open problems in theoretical computer science is the P = NP problem, which involves the relationship between the complexity classes P and NP. The Clay Mathematics Institute has offered a $1 million USD prize for the first correct proof, along with prizes for six other mathematical problems.
p357
aVTopics in discrete mathematics.
p358
aVTheoretical computer science.
p359
aVTheoretical computer science includes areas of discrete mathematics relevant to computing. It draws heavily on graph theory and mathematical logic. Included within theoretical computer science is the study of algorithms for computing mathematical results. Computability studies what can be computed in principle, and has close ties to logic, while complexity studies the time taken by computations. Automata theory and formal language theory are closely related to computability. Petri nets and process algebras are used to model computer systems, and methods from discrete mathematics are used in analyzing VLSI electronic circuits. Computational geometry applies algorithms to geometrical problems, while computer image analysis applies them to representations of images. Theoretical computer science also includes the study of various continuous computational topics.
p360
aVInformation theory.
p361
aVInformation theory involves the quantification of information. Closely related is coding theory which is used to design efficient and reliable data transmission and storage methods. Information theory also includes continuous topics such as: analog signals, analog coding, analog encryption.
p362
aVLogic.
p363
aVLogic is the study of the principles of valid reasoning and inference, as well as of consistency, soundness, and completeness. For example, in most systems of logic (but not in intuitionistic logic) Peirce's law ((("P"\u2192"Q")\u2192"P")\u2192"P") is a theorem. For classical logic, it can be easily verified with a truth table. The study of mathematical proof is particularly important in logic, and has applications to automated theorem proving and formal verification of software.
p364
aVLogical formulas are discrete structures, as are proofs, which form finite trees or, more generally, directed acyclic graph structures (with each inference step combining one or more premise branches to give a single conclusion). The truth values of logical formulas usually form a finite set, generally restricted to two values: "true" and "false", but logic can also be continuous-valued, e.g., fuzzy logic. Concepts such as infinite proof trees or infinite derivation trees have also been studied, e.g. infinitary logic.
p365
aVSet theory.
p366
aVSet theory is the branch of mathematics that studies sets, which are collections of objects, such as {blue, white, red} or the (infinite) set of all prime numbers. Partially ordered sets and sets with other relations have applications in several areas.
p367
aVIn discrete mathematics, countable sets (including finite sets) are the main focus. The beginning of set theory as a branch of mathematics is usually marked by Georg Cantor's work distinguishing between different kinds of infinite set, motivated by the study of trigonometric series, and further development of the theory of infinite sets is outside the scope of discrete mathematics. Indeed, contemporary work in descriptive set theory makes extensive use of traditional continuous mathematics.
p368
aVCombinatorics.
p369
aVCombinatorics studies the way in which discrete structures can be combined or arranged.
p370
aVEnumerative combinatorics concentrates on counting the number of certain combinatorial objects - e.g. the twelvefold way provides a unified framework for counting permutations, combinations and partitions.
p371
aVAnalytic combinatorics concerns the enumeration (i.e., determining the number) of combinatorial structures using tools from complex analysis and probability theory. In contrast with enumerative combinatorics which uses explicit combinatorial formulae and generating functions to describe the results, analytic combinatorics aims at obtaining asymptotic formulae.
p372
aVDesign theory is a study of combinatorial designs, which are collections of subsets with certain intersection properties.
p373
aVPartition theory studies various enumeration and asymptotic problems related to integer partitions, and is closely related to q-series, special functions and orthogonal polynomials. Originally a part of number theory and analysis, partition theory is now considered a part of combinatorics or an independent field.
p374
aVOrder theory is the study of partially ordered sets, both finite and infinite.
p375
aVGraph theory.
p376
aVGraph theory, the study of graphs and networks, is often considered part of combinatorics, but has grown large enough and distinct enough, with its own kind of problems, to be regarded as a subject in its own right. Graphs are one of the prime objects of study in discrete mathematics. They are among the most ubiquitous models of both natural and human-made structures. They can model many types of relations and process dynamics in physical, biological and social systems. In computer science, they can represent networks of communication, data organization, computational devices, the flow of computation, etc. In mathematics, they are useful in geometry and certain parts of topology, e.g. knot theory. Algebraic graph theory has close links with group theory. There are also continuous graphs, however for the most part research in graph theory falls within the domain of discrete mathematics.
p377
aVProbability.
p378
aVDiscrete probability theory deals with events that occur in countable sample spaces. For example, count observations such as the numbers of birds in flocks comprise only natural number values {0, 1, 2, ...}. On the other hand, continuous observations such as the weights of birds comprise real number values and would typically be modeled by a continuous probability distribution such as the normal. Discrete probability distributions can be used to approximate continuous ones and vice versa. For highly constrained situations such as throwing dice or experiments with decks of cards, calculating the probability of events is basically enumerative combinatorics.
p379
aVNumber theory.
p380
aVNumber theory is concerned with the properties of numbers in general, particularly integers. It has applications to cryptography, cryptanalysis, and cryptology, particularly with regard to modular arithmetic, diophantine equations, linear and quadratic congruences, prime numbers and primality testing. Other discrete aspects of number theory include geometry of numbers. In analytic number theory, techniques from continuous mathematics are also used. Topics that go beyond discrete objects include transcendental numbers, diophantine approximation, p-adic analysis and function fields.
p381
aVAlgebra.
p382
aVAlgebraic structures occur as both discrete examples and continuous examples. Discrete algebras include: boolean algebra used in logic gates and programming; relational algebra used in databases; discrete and finite versions of groups, rings and fields are important in algebraic coding theory; discrete semigroups and monoids appear in the theory of formal languages.
p383
aVCalculus of finite differences, discrete calculus or discrete analysis.
p384
aVA function defined on an interval of the integers is usually called a sequence. A sequence could be a finite sequence from a data source or an infinite sequence from a discrete dynamical system. Such a discrete function could be defined explicitly by a list (if its domain is finite), or by a formula for its general term, or it could be given implicitly by a recurrence relation or difference equation. Difference equations are similar to a differential equations, but replace differentiation by taking the difference between adjacent terms; they can be used to approximate differential equations or (more often) studied in their own right. Many questions and methods concerning differential equations have counterparts for difference equations. For instance where there are integral transforms in harmonic analysis for studying continuous functions or analog signals, there are discrete transforms for discrete functions or digital signals. As well as the discrete metric there are more general discrete or finite metric spaces and finite topological spaces.
p385
aVGeometry.
p386
aVDiscrete geometry and combinatorial geometry are about combinatorial properties of "discrete collections" of geometrical objects. A long-standing topic in discrete geometry is tiling of the plane. Computational geometry applies algorithms to geometrical problems.
p387
aVTopology.
p388
aVAlthough topology is the field of mathematics that formalizes and generalizes the intuitive notion of "continuous deformation" of objects, it gives rise to many discrete topics; this can be attributed in part to the focus on topological invariants, which themselves usually take discrete values.
p389
aVSee combinatorial topology, topological graph theory, topological combinatorics, computational topology, discrete topological space, finite topological space, topology (chemistry).
p390
aVOperations research.
p391
aVOperations research provides techniques for solving practical problems in business and other fields \u2014 problems such as allocating resources to maximize profit, or scheduling project activities to minimize risk. Operations research techniques include linear programming and other areas of optimization, queuing theory, scheduling theory, network theory. Operations research also includes continuous topics such as continuous-time Markov process, continuous-time martingales, process optimization, and continuous and hybrid control theory.
p392
aVGame theory, decision theory, utility theory, social choice theory.
p393
aVDecision theory is concerned with identifying the values, uncertainties and other issues relevant in a given decision, its rationality, and the resulting optimal decision.
p394
aVUtility theory is about measures of the relative economic satisfaction from, or desirability of, consumption of various goods and services.
p395
aVSocial choice theory is about voting. A more puzzle-based approach to voting is ballot theory.
p396
aVGame theory deals with situations where success depends on the choices of others, which makes choosing the best course of action more complex. There are even continuous games, see differential game. Topics include auction theory and fair division.
p397
aVDiscretization.
p398
aVDiscretization concerns the process of transferring continuous models and equations into discrete counterparts, often for the purposes of making calculations easier by using approximations. Numerical analysis provides an important example.
p399
aVDiscrete analogues of continuous mathematics.
p400
aVThere are many concepts in continuous mathematics which have discrete versions, such as discrete calculus, discrete probability distributions, discrete Fourier transforms, discrete geometry, discrete logarithms, discrete differential geometry, discrete exterior calculus, discrete Morse theory, difference equations, discrete dynamical systems, and discrete vector measures.
p401
aVIn applied mathematics, discrete modelling is the discrete analogue of continuous modelling. In discrete modelling, discrete formulae are fit to data. A common method in this form of modelling is to use recurrence relation.
p402
aVIn algebraic geometry, the concept of a curve can be extended to discrete geometries by taking the spectra of polynomial rings over finite fields to be models of the affine spaces over that field, and letting subvarieties or spectra of other rings provide the curves that lie in that space. Although the space in which the curves appear has a finite number of points, the curves are not so much sets of points as analogues of curves in continuous settings. For example, every point of the form formula_1 for formula_2 a field can be studied either as formula_3, a point, or as the spectrum formula_4 of the local ring at (x-c), a point together with a neighborhood around it. Algebraic varieties also have a well-defined notion of tangent space called the Zariski tangent space, making many features of calculus applicable even in finite settings.
p403
aVHybrid discrete and continuous mathematics.
p404
aVThe time scale calculus is a unification of the theory of difference equations with that of differential equations, which has applications to fields requiring simultaneous modelling of discrete and continuous data. Another way of modeling such a situation is the notion of hybrid dynamical system.
p405
asS'Weighted average'
p406
(lp407
sS'Modulo operation'
p408
(lp409
VIn computing, the modulo operation finds the remainder after division of one number by another (sometimes called "modulus").
p410
aVGiven two positive numbers, (the dividend) and (the divisor), "a" modulo "n" (abbreviated as "a" mod "n") is the remainder of the Euclidean division of "a" by "n". For instance, the expression "5 mod 2" would evaluate to 1 because 5 divided by 2 leaves a quotient of 2 and a remainder of 1, while "9 mod 3" would evaluate to 0 because the division of 9 by 3 has a quotient of 3 and leaves a remainder of 0; there is nothing to subtract from 9 after multiplying 3 times 3. (Note that doing the division with a calculator will not show the result referred to here by this operation; the quotient will be expressed as a decimal fraction.)
p411
aVAlthough typically performed with "a" and "n" both being integers, many computing systems allow other types of numeric operands. The range of numbers for an integer modulo of "n" is 0 to "n" \u2212 1. ("n" mod 1 is always 0; "n" mod 0 is undefined, possibly resulting in a "Division by zero" error in computer programming languages) See modular arithmetic for an older and related convention applied in number theory.
p412
aVWhen either or is negative, the naive definition breaks down and programming languages differ in how these values are defined.
p413
aV__TOC__
p414
aVRemainder calculation for the modulo operation.
p415
aVIn mathematics the result of the modulo operation is the remainder of the Euclidean division. However, other conventions are possible. Computers and calculators have various ways of storing and representing numbers; thus their definition of the modulo operation depends on the programming language and/or the underlying hardware.
p416
aVIn nearly all computing systems, the quotient and the remainder satisfy
p417
aV formula_1
p418
aV formula_2
p419
aV formula_3
p420
aVThis means that, if the remainder is nonzero, there are two possible choices for the remainder, one negative and the other positive, and there are also two possible choices for the quotient. Usually, in number theory, the positive remainder is always chosen, but programming languages choose depending on the language and the signs of "a" and "n". Pascal and Algol68 give a positive remainder (or 0) even for negative divisors, and some programming languages, such as C89, do not define a result if either of "n" or "a" is negative. See the table for details. "a" modulo 0 is undefined in the majority of systems, although some do define it to be "a".
p421
aVMany implementations use truncated division where the quotient is defined by truncation "q" = trunc("a"/"n"), in other words it is the first integer in the direction of 0 from the exact rational quotient, and the remainder by "r"="a" \u2212 "n" "q". Informally speaking the quotient is "rounded towards zero", and the remainder therefore has the same sign as the dividend.
p422
aVKnuth described floored division where the quotient is defined by the floor function "q"=floor("a"/"n") and the remainder "r" is
p423
aVformula_4
p424
aVHere the quotient is always rounded downwards (even if it is already negative) and the remainder has the same sign as the divisor.
p425
aVRaymond T. Boute describes the Euclidean definition, which is the one in which the remainder is always positive or 0, and is therefore consistent with the division algorithm (see Euclidean division). This definition is marked as "Always positive" in the table. Let "q" be the integer quotient of "a" and "n", then:
p426
aV formula_1
p427
aV formula_2
p428
aV formula_7
p429
aVTwo corollaries are that
p430
aV formula_8
p431
aV formula_9
p432
aVor, equivalently,
p433
aV formula_10
p434
aVAs described by Leijen,
p435
aVBoute argues that Euclidean division is superior to the other ones in terms of regularity and useful mathematical properties, although floored division, promoted by Knuth, is also a good definition. Despite its widespread use, truncated division is shown to be inferior to the other definitions.
p436
aVCommon Lisp also defines round- and ceiling-division where the quotient is given by , .
p437
aVIEEE 754 defines a remainder function where the quotient is rounded according to the round to nearest convention.
p438
aVCommon pitfalls.
p439
aVWhen the result of a modulo operation has the sign of the dividend, it can sometimes lead to surprising mistakes:
p440
aVFor example, to test whether an integer is odd, one might be inclined to test whether the remainder by 2 is equal to 1:
p441
aVBut in a language where modulo has the sign of the dividend, that is incorrect, because when "n" (the dividend) is negative and odd, "n % 2" returns \u22121, and the function returns false.
p442
aVOne correct alternative is to test that it is not 0 (because remainder 0 is the same regardless of the signs):
p443
aVOr, by understanding in the first place that for any odd number, the modulo remainder may be either 1 or \u22121:
p444
aVModulo operation expression.
p445
aVSome calculators have a mod() function button, and many programming languages have a mod() function or similar, expressed as mod("a"," n"), for example. Some also support expressions that use "%", "mod", or "Mod" as a modulo or remainder operator, such as
p446
aVcodice_1
p447
aVor
p448
aVcodice_2
p449
aVor equivalent, for environments lacking a mod() function (note that 'int' inherently produces the floor value of a/n)
p450
aVcodice_3.
p451
aVPerformance issues.
p452
aVModulo operations might be implemented such that a division with a remainder is calculated each time. For special cases, there are faster alternatives on some hardware. For example, the modulo of powers of 2 can alternatively be expressed as a bitwise AND operation:
p453
aVcodice_4.
p454
aVExamples (assuming x is a positive integer):
p455
aVcodice_5
p456
aVcodice_6
p457
aVcodice_7.
p458
aVIn devices and software that implement bitwise operations more efficiently than modulo, these alternative forms can result in faster calculations.
p459
aVOptimizing compilers may recognize expressions of the form codice_8 where codice_9 is a power of two and automatically implement them as codice_10. This can allow the programmer to write clearer code without compromising performance. (Note: This will not work for the languages whose modulo have the sign of the dividend (including C), because if the dividend is negative, the modulo will be negative; however, codice_10 will always produce a positive result. So special treatment has to be made when the dividend can be negative.)
p460
aVEquivalencies.
p461
aVSome modulo operations can be factored or expanded similar to other mathematical operations. This may be useful in cryptography proofs, such as the Diffie\u2013Hellman key exchange.
p462
asS'Function space'
p463
(lp464
VIn mathematics, a function space is a set of functions of a given kind from a set "X" to a set "Y". It is called a space because in many applications it is a topological space (including metric spaces), a vector space, or both. Namely, if "Y" is a field, functions have inherent vector structure with two operations of pointwise addition and multiplication to a scalar. Topological and metrical structures of function spaces are more diverse.
p465
aVExamples.
p466
aVFunction spaces appear in various areas of mathematics:
p467
aVFunctional analysis.
p468
aVFunctional analysis is organized around adequate techniques to bring function spaces as topological vector spaces within reach of the ideas that would apply to normed spaces of finite dimension.
p469
aVNorm.
p470
aVIf is an element of the function space formula_1 of all continuous functions that are defined on a closed interval [a,b], the norm defined on formula_1 is the maximum absolute value of for ,
p471
aVformula_3
p472
asS'Formal language'
p473
(lp474
VIn mathematics, computer science, and linguistics, a formal language is a set of strings of symbols that may be constrained by rules that are specific to it.
p475
aVThe alphabet of a formal language is the set of symbols, letters, or tokens from which the strings of the language may be formed; frequently it is required to be finite. The strings formed from this alphabet are called words, and the words that belong to a particular formal language are sometimes called "well-formed words" or "well-formed formulas". A formal language is often defined by means of a formal grammar such as a regular grammar or context-free grammar, also called its formation rule.
p476
aVThe field of formal language theory studies primarily the purely syntactical aspects of such languages\u2014that is, their internal structural patterns. Formal language theory sprang out of linguistics, as a way of understanding the syntactic regularities of natural languages.
p477
aVIn computer science, formal languages are used among others as the basis for defining the grammar of programming languages and formalized versions of subsets of natural languages in which the words of the language represent concepts that are associated with particular meanings or semantics. In computational complexity theory, decision problems are typically defined as formal languages, and complexity classes are defined as the sets of the formal languages that can be parsed by machines with limited computational power. In logic and the foundations of mathematics, formal languages are used to represent the syntax of axiomatic systems, and mathematical formalism is the philosophy that all of mathematics can be reduced to the syntactic manipulation of formal languages in this way.
p478
aVHistory.
p479
aVThe first formal language is thought be the one used by Gottlob Frege in his "Begriffsschrift" (1879), literally meaning "concept writing", and which Frege described as a "formal language of pure thought."
p480
aVAxel Thue's early Semi-Thue system which can be used for rewriting strings was influential on formal grammars.
p481
aVWords over an alphabet.
p482
aVAn alphabet, in the context of formal languages, can be any set, although it often makes sense to use an alphabet in the usual sense of the word, or more generally a character set such as ASCII or Unicode. Alphabets can also be infinite; e.g. first-order logic is often expressed using an alphabet which, besides symbols such as \u2227, ¬, \u2200 and parentheses, contains infinitely many elements "x"0, "x"1, "x"2, \u2026 that play the role of variables. The elements of an alphabet are called its letters.
p483
aVA word over an alphabet can be any finite sequence, or string, of characters or letters, which sometimes may include spaces, and are separated by specified word separation characters. The set of all words over an alphabet \u03a3 is usually denoted by \u03a3* (using the Kleene star). The length of a word is the number of characters or letters it is composed of. For any alphabet there is only one word of length 0, the "empty word", which is often denoted by e, \u03b5 or \u03bb. By concatenation one can combine two words to form a new word, whose length is the sum of the lengths of the original words. The result of concatenating a word with the empty word is the original word.
p484
aVIn some applications, especially in logic, the alphabet is also known as the "vocabulary" and words are known as "formulas" or "sentences"; this breaks the letter/word metaphor and replaces it by a word/sentence metaphor.
p485
aVDefinition.
p486
aVA formal language "L" over an alphabet \u03a3 is a subset of \u03a3*, that is, a set of words over that alphabet. Sometimes the sets of words are grouped into expressions, whereas rules and constraints may be formulated for the creation of 'well-formed expressions'.
p487
aVIn computer science and mathematics, which do not usually deal with natural languages, the adjective "formal" is often omitted as redundant.
p488
aVWhile formal language theory usually concerns itself with formal languages that are described by some syntactical rules, the actual definition of the concept "formal language" is only as above: a (possibly infinite) set of finite-length strings composed from a given alphabet, no more nor less. In practice, there are many languages that can be described by rules, such as regular languages or context-free languages. The notion of a formal grammar may be closer to the intuitive concept of a "language," one described by syntactic rules. By an abuse of the definition, a particular formal language is often thought of as being equipped with a formal grammar that describes it.
p489
aVExamples.
p490
aVThe following rules describe a formal language  over the alphabet \u03a3 = {\u20090,\u20091,\u20092,\u20093,\u20094,\u20095,\u20096,\u20097,\u20098,\u20099,\u2009+,\u2009=\u2009}:
p491
aVUnder these rules, the string "23+4=555" is in , but the string "=234=+" is not. This formal language expresses natural numbers, well-formed addition statements, and well-formed addition equalities, but it expresses only what they look like (their syntax), not what they mean (semantics). For instance, nowhere in these rules is there any indication that "0" means the number zero, or that "+" means addition.
p492
aVConstructions.
p493
aVFor finite languages one can explicitly enumerate all well-formed words. For example, we can describe a language  as just  = {"a",\u2009"b",\u2009"ab",\u2009"cba"}. The degenerate case of this construction is the empty language, which contains no words at all ( = \u2205).
p494
aVHowever, even over a finite (non-empty) alphabet such as \u03a3 = {a, b} there are infinitely many words: "a", "abb", "ababba", "aaababbbbaab", \u2026. Therefore formal languages are typically infinite, and describing an infinite formal language is not as simple as writing "L" = {"a",\u2009"b",\u2009"ab",\u2009"cba"}. Here are some examples of formal languages:
p495
aVLanguage-specification formalisms.
p496
aVFormal language theory rarely concerns itself with particular languages (except as examples), but is mainly concerned with the study of various types of formalisms to describe languages. For instance, a language can be given as
p497
aVTypical questions asked about such formalisms include:
p498
aVSurprisingly often, the answer to these decision problems is "it cannot be done at all", or "it is extremely expensive" (with a characterization of how expensive). Therefore, formal language theory is a major application area of computability theory and complexity theory. Formal languages may be classified in the Chomsky hierarchy based on the expressive power of their generative grammar as well as the complexity of their recognizing automaton. Context-free grammars and regular grammars provide a good compromise between expressivity and ease of parsing, and are widely used in practical applications.
p499
aVOperations on languages.
p500
aVCertain operations on languages are common. This includes the standard set operations, such as union, intersection, and complement. Another class of operation is the element-wise application of string operations.
p501
aVExamples: suppose "L"1 and "L"2 are languages over some common alphabet.
p502
aVSuch string operations are used to investigate closure properties of classes of languages. A class of languages is closed under a particular operation when the operation, applied to languages in the class, always produces a language in the same class again. For instance, the context-free languages are known to be closed under union, concatenation, and intersection with regular languages, but not closed under intersection or complement. The theory of trios and abstract families of languages studies the most common closure properties of language families in their own right.
p503
aVApplications.
p504
aVProgramming languages.
p505
aVA compiler usually has two distinct components. A lexical analyzer, generated by a tool like codice_1, identifies the tokens of the programming language grammar, e.g. identifiers or keywords, which are themselves expressed in a simpler formal language, usually by means of regular expressions. At the most basic conceptual level, a parser, usually generated by a parser generator like codice_2, attempts to decide if the source program is valid, that is if it belongs to the programming language for which the compiler was built. Of course, compilers do more than just parse the source code\u2014they usually translate it into some executable format. Because of this, a parser usually outputs more than a yes/no answer, typically an abstract syntax tree, which is used by subsequent stages of the compiler to eventually generate an executable containing machine code that runs directly on the hardware, or some intermediate code that requires a virtual machine to execute.
p506
aVFormal theories, systems and proofs.
p507
aVIn mathematical logic, a "formal theory" is a set of sentences expressed in a formal language.
p508
aVA "formal system" (also called a "logical calculus", or a "logical system") consists of a formal language together with a deductive apparatus (also called a "deductive system"). The deductive apparatus may consist of a set of transformation rules which may be interpreted as valid rules of inference or a set of axioms, or have both. A formal system is used to derive one expression from one or more other expressions. Although a formal language can be identified with its formulas, a formal system cannot be likewise identified by its theorems. Two formal systems formula_1 and formula_2 may have all the same theorems and yet differ in some significant proof-theoretic way (a formula A may be a syntactic consequence of a formula B in one but not another for instance).
p509
aVA "formal proof" or "derivation" is a finite sequence of well-formed formulas (which may be interpreted as propositions) each of which is an axiom or follows from the preceding formulas in the sequence by a rule of inference. The last sentence in the sequence is a theorem of a formal system. Formal proofs are useful because their theorems can be interpreted as true propositions.
p510
aVInterpretations and models.
p511
aVFormal languages are entirely syntactic in nature but may be given semantics that give meaning to the elements of the language. For instance, in mathematical logic, the set of possible formulas of a particular logic is a formal language, and an interpretation assigns a meaning to each of the formulas\u2014usually, a truth value.
p512
aVThe study of interpretations of formal languages is called formal semantics. In mathematical logic, this is often done in terms of model theory. In model theory, the terms that occur in a formula are interpreted as mathematical structures, and fixed compositional interpretation rules determine how the truth value of the formula can be derived from the interpretation of its terms; a "model" for a formula is an interpretation of terms such that the formula becomes true.
p513
asS'Theorem'
p514
(lp515
VIn mathematics, a theorem is a statement that has been proven on the basis of previously established statements, such as other theorems\u2014and generally accepted statements, such as axioms. The proof of a mathematical theorem is a logical argument for the theorem statement given in accord with the rules of a deductive system. The proof of a theorem is often interpreted as justification of the truth of the theorem statement. In light of the requirement that theorems be proved, the concept of a theorem is fundamentally "deductive", in contrast to the notion of a scientific theory, which is "empirical".
p516
aVMany mathematical theorems are conditional statements. In this case, the proof deduces the conclusion from conditions called hypotheses. In light of the interpretation of proof as justification of truth, the conclusion is often viewed as a necessary consequence of the hypotheses, namely, that the conclusion is true in case the hypotheses are true, without any further assumptions. However, the conditional could be interpreted differently in certain deductive systems, depending on the meanings assigned to the derivation rules and the conditional symbol.
p517
aVAlthough they can be written in a completely symbolic form, for example, within the propositional calculus, theorems are often expressed in a natural language such as English. The same is true of proofs, which are often expressed as logically organized and clearly worded informal arguments, intended to convince readers of the truth of the statement of the theorem beyond any doubt, and from which a formal symbolic proof can in principle be constructed. Such arguments are typically easier to check than purely symbolic ones\u2014indeed, many mathematicians would express a preference for a proof that not only demonstrates the validity of a theorem, but also explains in some way "why" it is obviously true. In some cases, a picture alone may be sufficient to prove a theorem. Because theorems lie at the core of mathematics, they are also central to its aesthetics. Theorems are often described as being "trivial", or "difficult", or "deep", or even "beautiful". These subjective judgments vary not only from person to person, but also with time: for example, as a proof is simplified or better understood, a theorem that was once difficult may become trivial. On the other hand, a deep theorem may be simply stated, but its proof may involve surprising and subtle connections between disparate areas of mathematics. Fermat's Last Theorem is a particularly well-known example of such a theorem.
p518
aVInformal account of theorems.
p519
aVLogically, many theorems are of the form of an indicative conditional: "if A, then B". Such a theorem does not assert "B", only that "B" is a necessary consequence of "A". In this case "A" is called the hypothesis of the theorem (note that "hypothesis" here is something very different from a conjecture) and "B" the conclusion (formally, "A" and "B" are termed the "antecedent" and "consequent"). The theorem "If "n" is an even natural number then "n"/2 is a natural number" is a typical example in which the hypothesis is ""n" is an even natural number" and the conclusion is ""n"/2 is also a natural number".
p520
aVTo be proven, a theorem must be expressible as a precise, formal statement. Nevertheless, theorems are usually expressed in natural language rather than in a completely symbolic form, with the intention that the reader can produce a formal statement from the informal one.
p521
aVIt is common in mathematics to choose a number of hypotheses within a given language and declare that the theory consists of all statements provable from these hypotheses. These hypothesis form the foundational basis of the theory and are called axioms or postulates. The field of mathematics known as proof theory studies formal languages, axioms and the structure of proofs.
p522
aVSome theorems are "trivial", in the sense that they follow from definitions, axioms, and other theorems in obvious ways and do not contain any surprising insights. Some, on the other hand, may be called "deep", because their proofs may be long and difficult, involve areas of mathematics superficially distinct from the statement of the theorem itself, or show surprising connections between disparate areas of mathematics. A theorem might be simple to state and yet be deep. An excellent example is Fermat's Last Theorem, and there are many other examples of simple yet deep theorems in number theory and combinatorics, among other areas.
p523
aVOther theorems have a known proof that cannot easily be written down. The most prominent examples are the four color theorem and the Kepler conjecture. Both of these theorems are only known to be true by reducing them to a computational search that is then verified by a computer program. Initially, many mathematicians did not accept this form of proof, but it has become more widely accepted. The mathematician Doron Zeilberger has even gone so far as to claim that these are possibly the only nontrivial results that mathematicians have ever proved. Many mathematical theorems can be reduced to more straightforward computation, including polynomial identities, trigonometric identities and hypergeometric identities.
p524
aVProvability and theoremhood.
p525
aVTo establish a mathematical statement as a theorem, a proof is required, that is, a line of reasoning from axioms in the system (and other, already established theorems) to the given statement must be demonstrated. However, the proof is usually considered as separate from the theorem statement. Although more than one proof may be known for a single theorem, only one proof is required to establish the status of a statement as a theorem. The Pythagorean theorem and the law of quadratic reciprocity are contenders for the title of theorem with the greatest number of distinct proofs.
p526
aVRelation with scientific theories.
p527
aVTheorems in mathematics and theories in science are fundamentally different in their epistemology. A scientific theory cannot be proven; its key attribute is that it is falsifiable, that is, it makes predictions about the natural world that are testable by experiments. Any disagreement between prediction and experiment demonstrates the incorrectness of the scientific theory, or at least limits its accuracy or domain of validity. Mathematical theorems, on the other hand, are purely abstract formal statements: the proof of a theorem cannot involve experiments or other empirical evidence in the same way such evidence is used to support scientific theories.
p528
aVNonetheless, there is some degree of empiricism and data collection involved in the discovery of mathematical theorems. By establishing a pattern, sometimes with the use of a powerful computer, mathematicians may have an idea of what to prove, and in some cases even a plan for how to set about doing the proof. For example, the Collatz conjecture has been verified for start values up to about 2.88 × 1018. The Riemann hypothesis has been verified for the first 10 trillion zeroes of the zeta function. Neither of these statements is considered proven.
p529
aVSuch evidence does not constitute proof. For example, the Mertens conjecture is a statement about natural numbers that is now known to be false, but no explicit counterexample (i.e., a natural number "n" for which the Mertens function "M"("n") equals or exceeds the square root of "n") is known: all numbers less than 1014 have the Mertens property, and the smallest number that does not have this property is only known to be less than the exponential of 1.59 × 1040, which is approximately 10 to the power 4.3 × 1039. Since the number of particles in the universe is generally considered less than 10 to the power 100 (a googol), there is no hope to find an explicit counterexample by exhaustive search.
p530
aVNote that the word "theory" also exists in mathematics, to denote a body of mathematical axioms, definitions and theorems, as in, for example, group theory. There are also "theorems" in science, particularly physics, and in engineering, but they often have statements and proofs in which physical assumptions and intuition play an important role; the physical axioms on which such "theorems" are based are themselves falsifiable.
p531
aVTerminology.
p532
aVA number of different terms for mathematical statements exist, these terms indicate the role statements play in a particular subject. The distinction between different terms is sometimes rather arbitrary and the usage of some terms has evolved over time.
p533
aVThere are other terms, less commonly used, that are conventionally attached to proven statements, so that certain theorems are referred to by historical or customary names. For examples:
p534
aVA few well-known theorems have even more idiosyncratic names. The division algorithm (see Euclidean division) is a theorem expressing the outcome of division in the natural numbers and more general rings. The Bézout's identity is a theorem asserting that the greatest common divisor of two numbers may be written as a linear combination of these numbers. The Banach\u2013Tarski paradox is a theorem in measure theory that is paradoxical in the sense that it contradicts common intuitions about volume in three-dimensional space.
p535
aVAn unproven statement that is believed true is called a conjecture (or sometimes a hypothesis, but with a different meaning from the one discussed above). To be considered a conjecture, a statement must usually be proposed publicly, at which point the name of the proponent may be attached to the conjecture, as with Goldbach's conjecture. Other famous conjectures include the Collatz conjecture and the Riemann hypothesis. On the other hand, Fermat's last theorem has always been known by that name, even before it was proven; it was never known as "Fermat's conjecture".
p536
aVLayout.
p537
aVA theorem and its proof are typically laid out as follows:
p538
aVTheorem (name of person who proved it and year of discovery, proof or publication).
p539
aV"Statement of theorem (sometimes called the "proposition")."
p540
aVProof.
p541
aV"Description of proof."
p542
aV"End mark."
p543
aVThe end of the proof may be signalled by the letters Q.E.D. ("quod erat demonstrandum") or by one of the tombstone marks or meaning "End of Proof", introduced by Paul Halmos following their usage in magazine articles.
p544
aVThe exact style depends on the author or publication. Many publications provide instructions or macros for typesetting in the house style.
p545
aVIt is common for a theorem to be preceded by definitions describing the exact meaning of the terms used in the theorem. It is also common for a theorem to be preceded by a number of propositions or lemmas which are then used in the proof. However, lemmas are sometimes embedded in the proof of a theorem, either with nested proofs, or with their proofs presented after the proof of the theorem.
p546
aVCorollaries to a theorem are either presented between the theorem and the proof, or directly after the proof. Sometimes, corollaries have proofs of their own that explain why they follow from the theorem.
p547
aVLore.
p548
aVIt has been estimated that over a quarter of a million theorems are proved every year.
p549
aVThe well-known aphorism, , is probably due to Alfréd Rényi, although it is often attributed to Rényi's colleague Paul Erd\u0151s (and Rényi may have been thinking of Erd\u0151s), who was famous for the many theorems he produced, the number of his collaborations, and his coffee drinking.
p550
aVThe classification of finite simple groups is regarded by some to be the longest proof of a theorem. It comprises tens of thousands of pages in 500 journal articles by some 100 authors. These papers are together believed to give a complete proof, and several ongoing projects hope to shorten and simplify this proof. Another theorem of this type is the Four color theorem whose computer generated proof is too long for a human to read. It is certainly the longest known proof of a theorem whose statement can be easily understood by a layman.
p551
aVTheorems in logic.
p552
aVLogic, especially in the field of proof theory, considers theorems as statements (called formulas or well formed formulas) of a formal language. The statements of the language are strings of symbols and may be broadly divided into nonsense and well-formed formulas. A set of deduction rules, also called transformation rules or rules of inference, must be provided. These deduction rules tell exactly when a formula can be derived from a set of premises. The set of well-formed formulas may be broadly divided into theorems and non-theorems. However, according to Hofstadter, a formal system often simply defines all its well-formed formula as theorems.
p553
aVDifferent sets of derivation rules give rise to different interpretations of what it means for an expression to be a theorem. Some derivation rules and formal languages are intended to capture mathematical reasoning; the most common examples use first-order logic. Other deductive systems describe term rewriting, such as the reduction rules for \u03bb calculus.
p554
aVThe definition of theorems as elements of a formal language allows for results in proof theory that study the structure of formal proofs and the structure of provable formulas. The most famous result is Gödel's incompleteness theorem; by representing theorems about basic number theory as expressions in a formal language, and then representing this language within number theory itself, Gödel constructed examples of statements that are neither provable nor disprovable from axiomatizations of number theory.
p555
aVA theorem may be expressed in a formal language (or "formalized"). A formal theorem is the purely formal analogue of a theorem. In general, a formal theorem is a type of well-formed formula that satisfies certain logical and syntactic conditions. The notation formula_1 is often used to indicate that formula_1 is a theorem.
p556
aVFormal theorems consist of formulas of a formal language and the transformation rules of a formal system. Specifically, a formal theorem is always the last formula of a derivation in some formal system each formula of which is a logical consequence of the formulas that came before it in the derivation. The initially accepted formulas in the derivation are called its axioms, and are the basis on which the theorem is derived. A set of theorems is called a theory.
p557
aVWhat makes formal theorems useful and of interest is that they can be interpreted as true propositions and their derivations may be interpreted as a proof of the truth of the resulting expression. A set of formal theorems may be referred to as a formal theory. A theorem whose interpretation is a true statement about a formal system is called a metatheorem.
p558
aVSyntax and semantics.
p559
aVThe concept of a formal theorem is fundamentally syntactic, in contrast to the notion of a "true proposition," which introduces semantics. Different deductive systems can yield other interpretations, depending on the presumptions of the derivation rules (i.e. belief, justification or other modalities). The soundness of a formal system depends on whether or not all of its theorems are also validities. A validity is a formula that is true under any possible interpretation, e.g. in classical propositional logic validities are tautologies. A formal system is considered semantically complete when all of its tautologies are also theorems.
p560
aVDerivation of a theorem.
p561
aVThe notion of a theorem is very closely connected to its formal proof (also called a "derivation"). To illustrate how derivations are done, we will work in a very simplified formal system. Let us call ours formula_3 Its alphabet consists only of two symbols { A, B } and its formation rule for formulas is:
p562
aVAny string of symbols of formula_3 that is at least three symbols long, and is not infinitely long, is a formula. Nothing else is a formula.
p563
aVThe single axiom of formula_3 is:
p564
aVABBA.
p565
aVThe only rule of inference (transformation rule) for formula_3 is:
p566
aVAny occurrence of "A" in a theorem may be replaced by an occurrence of the string "AB" and the result is a theorem.
p567
aVTheorems in formula_3 are defined as those formulae that have a derivation ending with that formula. For example
p568
aVis a derivation. Therefore "ABBBAB" is a theorem of formula_8 The notion of truth (or falsity) cannot be applied to the formula "ABBBAB" until an interpretation is given to its symbols. Thus in this example, the formula does not yet represent a proposition, but is merely an empty abstraction.
p569
aVTwo metatheorems of formula_3 are:
p570
aVEvery theorem begins with "A".
p571
aVEvery theorem has exactly two "A"s.
p572
asS'Random variable'
p573
(lp574
VIn probability and statistics, a random variable, aleatory variable or stochastic variable is a variable whose value is subject to variations due to chance (i.e. randomness, in a mathematical sense). A random variable can take on a set of possible different values (similarly to other mathematical variables), each with an associated probability, in contrast to other mathematical variables.
p575
aVA random variable's possible values might represent the possible outcomes of a yet-to-be-performed experiment, or the possible outcomes of a past experiment whose already-existing value is uncertain (for example, due to imprecise measurements or quantum uncertainty). They may also conceptually represent either the results of an "objectively" random process (such as rolling a die) or the "subjective" randomness that results from incomplete knowledge of a quantity. The meaning of the probabilities assigned to the potential values of a random variable is not part of probability theory itself but is instead related to philosophical arguments over the interpretation of probability. The mathematics works the same regardless of the particular interpretation in use.
p576
aVThe mathematical function describing the possible values of a random variable and their associated probabilities is known as a probability distribution. "Random variables" can be discrete, that is, taking any of a specified finite or countable list of values, endowed with a probability mass function, characteristic of a probability distribution; or continuous, taking any numerical value in an interval or collection of intervals, via a probability density function that is characteristic of a probability distribution; or a mixture of both types. The realizations of a random variable, that is, the results of randomly choosing values according to the variable's probability distribution function, are called random variates.
p577
aVThe formal mathematical treatment of random variables is a topic in probability theory. In that context, a random variable is understood as a function defined on a sample space whose outputs are numerical values.
p578
aVDefinition.
p579
aVA "random variable" formula_1 is a measurable function from the set of possible outcomes formula_2 to some set formula_3. Usually, formula_4formula_5, otherwise the term "random element" is used instead (see Extensions). The technical axiomatic definition requires both formula_6 and formula_7 to be measurable spaces (see Measure-theoretic definition).
p580
aVAs a real-valued function, formula_8 often describes some numerical quantity of a given event. E.g. the number of heads after a certain number of coin flips; the heights of different people.
p581
aVWhen the image (or range) of formula_8 is finite or countably infinite, the random variable is called a discrete random variable and its distribution can be described by a probability mass function which assigns a probability to each value in the image of formula_8. If the image is uncountably infinite then formula_8 is called a continuous random variable. In the special case that it is absolutely continuous, its distribution can be described by a probability density function, which assigns probabilities to intervals; in particular, each individual point must necessarily have probability zero for an absolutely continuous random variable. Not all continuous random variables are absolutely continuous, for example a mixture distribution. Such random variables cannot be described by a probability density or a probability mass function.
p582
aVAll random variables can be described by their cumulative distribution function, which describes the probability that the random variable will be less than or equal to a certain value.
p583
aVExtensions.
p584
aVThe basic concept of "random variable" in statistics is real-valued, and therefore expected values, variances and other measures can be computed. However, one can consider arbitrary types such as boolean values, categorical variables, complex numbers, vectors, matrices, sequences, trees, sets, shapes, manifolds, functions, and processes. The term "random element" is used to encompass all such related concepts.
p585
aVAnother extension is the stochastic process, a set of indexed random variables (typically indexed by time or space).
p586
aVThese more general concepts are particularly useful in fields such as computer science and natural language processing where many of the basic elements of analysis are non-numerical. Such general random elements can sometimes be treated as sets of real-valued random variables \u2014 often more specifically as random vectors. For example:
p587
aVReduction to numerical values is not essential for dealing with random elements: a randomly selected individual remains an individual, not a number.
p588
aVExamples.
p589
aVDiscrete random variable.
p590
aVIn an experiment a person may be chosen at random, and one random variable may be the person's height. Mathematically, the random variable is interpreted as a function which maps the person to the person's height. Associated with the random variable is a probability distribution that allows the computation of the probability that the height is in any non-pathological subset of possible values, such as probability that the height is between 180 and 190 cm, or the probability that the height is either less than 150 or more than 200 cm.
p591
aVAnother random variable may be the person's number of children; this is a discrete random variable with non-negative integer values. It allows the computation of probabilities for individual integer values \u2013 the probability mass function (PMF) \u2013 or for sets of values, including infinite sets. For example, the event of interest may be "an even number of children". For both finite and infinite event sets, their probabilities can be found by adding up the PMFs of the elements; that is, the probability of an even number of children is the infinite sum PMF(0) + PMF(2) + PMF(4) + ...
p592
aVIn examples such as these, the sample space (the set of all possible persons) is often suppressed, since it is mathematically hard to describe, and the possible values of the random variables are then treated as a sample space. But when two random variables are measured on the same sample space of outcomes, such as the height and number of children being computed on the same random persons, it is easier to track their relationship if it is acknowledged that both height and number of children come from the same random person, for example so that questions of whether such random variables are correlated or not can be posed.
p593
aVCoin Toss.
p594
aVThe possible outcomes for one coin toss can be described by the sample space formula_12. We can introduce a real-valued random variable formula_13 that models a $1 payoff for a successful bet on heads as follows:
p595
aVformula_14 given by:
p596
aVformula_15
p597
aVand (if the dice are fair) has a probability mass function \u0192X given by:
p598
aVformula_16
p599
aVContinuous Random Variable.
p600
aVAn example of a continuous random variable would be one based on a spinner that can choose a horizontal direction. Then the values taken by the random variable are directions. We could represent these directions by North, West, East, South, Southeast, etc. However, it is commonly more convenient to map the sample space to a random variable which takes values which are real numbers. This can be done, for example, by mapping a direction to a bearing in degrees clockwise from North. The random variable then takes values which are real numbers from the interval 360), with all parts of the range being "equally likely". In this case, X = the angle spun. Any real number has probability zero of being selected, but a positive probability can be assigned to any "range" of values. For example, the probability of choosing a number in [0, 180 is . Instead of speaking of a probability mass function, we say that the probability "density" of X is 1/360. The probability of a subset of [0, 360) can be calculated by multiplying the measure of the set by 1/360. In general, the probability of a set for a given continuous random variable can be calculated by integrating the density over the given set.
p601
aVMixed type.
p602
aVAn example of a random variable of mixed type would be based on an experiment where a coin is flipped and the spinner is spun only if the result of the coin toss is heads. If the result is tails, X = \u22121; otherwise X = the value of the spinner as in the preceding example. There is a probability of that this random variable will have the value \u22121. Other ranges of values would have half the probability of the last example.
p603
aVMeasure-theoretic definition.
p604
aVThe most formal, axiomatic definition of a random variable involves measure theory. Continuous random variables are defined in terms of sets of numbers, along with functions that map such sets to probabilities. Because of various difficulties (e.g. the Banach\u2013Tarski paradox) that arise if such sets are insufficiently constrained, it is necessary to introduce what is termed a sigma-algebra to constrain the possible sets over which probabilities can be defined. Normally, a particular such sigma-algebra is used, the Borel \u03c3-algebra, which allows for probabilities to be defined over any sets that can be derived either directly from continuous intervals of numbers or by a finite or countably infinite number of unions and/or intersections of such intervals.
p605
aVThe measure-theoretic definition is as follows.
p606
aVLet formula_17 be a probability space and formula_18 a measurable space. Then an formula_18-valued random variable is a function formula_1 which is formula_21-measurable. The latter means that, for every subset formula_22, its preimage formula_23 where formula_24. This definition enables us to measure any subset formula_25 in the target space by looking at its preimage, which by assumption is measurable.
p607
aVWhen formula_7 is a topological space, then the most common choice for the \u03c3-algebra formula_27 is the Borel \u03c3-algebra formula_28, which is the \u03c3-algebra generated by the collection of all open sets in formula_7. In such case the formula_18-valued random variable is called the formula_7-valued random variable. Moreover, when space formula_7 is the real line formula_5, then such real-valued random variable is called simply the random variable.
p608
aVReal-valued random variables.
p609
aVIn this case the observation space is the real numbers. Recall, formula_17 is the probability space. For real observation space, the function formula_35 is a real-valued random variable if
p610
aVformula_36
p611
aVThis definition is a special case of the above because the set formula_37 generates the Borel \u03c3-algebra on the real numbers, and it suffices to check measurability on any generating set. Here we can prove measurability on this generating set by using the fact that formula_38.
p612
aVDistribution functions of random variables.
p613
aVIf a random variable formula_39 defined on the probability space formula_17 is given, we can ask questions like "How likely is it that the value of formula_8 is equal to 2?". This is the same as the probability of the event formula_42 which is often written as formula_43 or formula_44 for short.
p614
aVRecording all these probabilities of output ranges of a real-valued random variable formula_8 yields the probability distribution of formula_8. The probability distribution "forgets" about the particular probability space used to define formula_8 and only records the probabilities of various values of formula_8. Such a probability distribution can always be captured by its cumulative distribution function
p615
aVformula_49
p616
aVand sometimes also using a probability density function, formula_50. In measure-theoretic terms, we use the random variable formula_8 to "push-forward" the measure formula_52 on formula_6 to a measure formula_50 on formula_5.
p617
aVThe underlying probability space formula_6 is a technical device used to guarantee the existence of random variables, sometimes to construct them, and to define notions such as correlation and dependence or independence based on a joint distribution of two or more random variables on the same probability space. In practice, one often disposes of the space formula_6 altogether and just puts a measure on formula_5 that assigns measure 1 to the whole real line, i.e., one works with probability distributions instead of random variables.
p618
aVMoments.
p619
aVThe probability distribution of a random variable is often characterised by a small number of parameters, which also have a practical interpretation. For example, it is often enough to know what its "average value" is. This is captured by the mathematical concept of expected value of a random variable, denoted E["X"], and also called the first moment. In general, E["f"("X")] is not equal to "f"(E["X"]). Once the "average value" is known, one could then ask how far from this average value the values of "X" typically are, a question that is answered by the variance and standard deviation of a random variable. E["X"] can be viewed intuitively as an average obtained from an infinite population, the members of which are particular evaluations of "X".
p620
aVMathematically, this is known as the (generalised) problem of moments: for a given class of random variables "X", find a collection {"fi"} of functions such that the expectation values E["fi"("X")] fully characterise the distribution of the random variable "X".
p621
aVMoments can only be defined for real-valued functions of random variables (or complex-valued, etc.). If the random variable is itself real-valued, then moments of the variable itself can be taken, which are equivalent to moments of the identity function formula_59 of the random variable. However, even for non-real-valued random variables, moments can be taken of real-valued functions of those variables. For example, for a categorical random variable "X" that can take on the nominal values "red", "blue" or "green", the real-valued function formula_60 can be constructed; this uses the Iverson bracket, and has the value 1 if "X" has the value "green", 0 otherwise. Then, the expected value and other moments of this function can be determined.
p622
aVFunctions of random variables.
p623
aVA new random variable "Y" can be defined by applying a real Borel measurable function formula_61 to the outcomes of a real-valued random variable "X". The cumulative distribution function of formula_62 is
p624
aVformula_63
p625
aVIf function "g" is invertible, i.e. "g"\u22121 exists, and is either increasing or decreasing, then the previous relation can be extended to obtain
p626
aVformula_64
p627
aVand, again with the same hypotheses of invertibility of "g", assuming also differentiability, we can find the relation between the probability density functions by differentiating both sides with respect to "y", in order to obtain
p628
aVformula_65
p629
aVIf there is no invertibility of "g" but each "y" admits at most a countable number of roots (i.e. a finite, or countably infinite, number of "xi" such that "y = g(xi)") then the previous relation between the probability density functions can be generalized with
p630
aVformula_66
p631
aVwhere "xi = gi\u22121(y)". The formulas for densities do not demand "g" to be increasing.
p632
aVIn the measure-theoretic, axiomatic approach to probability, if we have a random variable formula_67 on formula_68 and a Borel measurable function formula_61, then formula_70 will also be a random variable on formula_71, since the composition of measurable functions is also measurable. (However, this is not true if formula_72 is Lebesgue measurable.) The same procedure that allowed one to go from a probability space formula_73 to formula_74 can be used to obtain the distribution of formula_62.
p633
aVExample 1.
p634
aVLet "X" be a real-valued, continuous random variable and let "Y" = "X"2.
p635
aVformula_76
p636
aVIf "y" < 0, then P("X"2 \u2264 "y") = 0, so
p637
aVformula_77
p638
aVIf "y" \u2265 0, then
p639
aVformula_78
p640
aVExample 2.
p641
aVSuppose formula_79 is a random variable with a cumulative distribution
p642
aVformula_80
p643
aVwhere formula_81 is a fixed parameter. Consider the random variable formula_82 Then,
p644
aVformula_83
p645
aVThe last expression can be calculated in terms of the cumulative distribution of formula_84 so
p646
aVformula_85
p647
aV::formula_86
p648
aV::formula_87
p649
aV::formula_88
p650
aVExample 3.
p651
aVSuppose formula_79 is a random variable with a standard normal distribution, whose density is
p652
aVformula_90
p653
aVConsider the random variable formula_91 We can find the density using the above formula for a change of variables:
p654
aVformula_92
p655
aVIn this case the change is not monotonic, because every value of formula_93 has two corresponding values of formula_79 (one positive and negative). However, because of symmetry, both halves will transform identically, i.e.
p656
aVformula_95
p657
aVThe inverse transformation is
p658
aVformula_96
p659
aVand its derivative is
p660
aVformula_97
p661
aVThen:
p662
aVformula_98
p663
aVThis is a chi-squared distribution with one degree of freedom.
p664
aVEquivalence of random variables.
p665
aVThere are several different senses in which random variables can be considered to be equivalent. Two random variables can be equal, equal almost surely, or equal in distribution.
p666
aVIn increasing order of strength, the precise definition of these notions of equivalence is given below.
p667
aVEquality in distribution.
p668
aVIf the sample space is a subset of the real line, random variables "X" and "Y" are "equal in distribution" (denoted formula_99) if
p669
aVthey have the same distribution functions:
p670
aVformula_100
p671
aVTwo random variables having equal moment generating functions have the same distribution. This provides, for example, a useful method of checking equality of certain functions of i.i.d. random variables. However, the moment generating function exists only for distributions that have a defined Laplace transform.
p672
aVAlmost sure equality.
p673
aVTwo random variables "X" and "Y" are "equal almost surely" if, and only if, the probability that they are different is zero:
p674
aVformula_101
p675
aVFor all practical purposes in probability theory, this notion of equivalence is as strong as actual equality. It is associated to the following distance:
p676
aVformula_102
p677
aVwhere "ess sup" represents the essential supremum in the sense of measure theory.
p678
aVEquality.
p679
aVFinally, the two random variables "X" and "Y" are "equal" if they are equal as functions on their measurable space:
p680
aVformula_103
p681
aVConvergence.
p682
aVA significant theme in mathematical statistics consists of obtaining convergence results for certain sequences of random variables; for instance the law of large numbers and the central limit theorem.
p683
aVThere are various senses in which a sequence ("X""n") of random variables can converge to a random variable "X". These are explained in the article on convergence of random variables.
p684
asS'International Mathematical Olympiad'
p685
(lp686
VThe International Mathematical Olympiad (IMO) is an annual six-problem, 42-point mathematical olympiad for pre-collegiate students and is the oldest of the International Science Olympiads. The first IMO was held in Romania in 1959. It has since been held annually, except in 1980. About 100 countries send teams of up to six students, plus one team leader, one deputy leader, and observers.
p687
aVThe content ranges from precalculus problems that are extremely difficult to problems on branches of mathematics not conventionally covered at school and often not at university level either, such as projective and complex geometry, functional equations and well-grounded number theory, of which extensive knowledge of theorems is required. Calculus, though allowed in solutions, is never required, as there is a principle at play that anyone with a basic understanding of mathematics should understand the problems, even if the solutions require a great deal more knowledge. Supporters of this principle claim that this allows more universality and creates an incentive to find elegant, deceptively simple-looking problems which nevertheless require a certain level of ingenuity.
p688
aVThe selection process differs by country, but it often consists of a series of tests which admit fewer students at each progressing test. Awards are given to a top percentage of the individual contestants. Teams are not officially recognized\u2014all scores are given only to individual contestants, but team scoring is unofficially compared more so than individual scores. Contestants must be under the age of 20 and must not be registered at any tertiary institution. Subject to these conditions, an individual may participate any number of times in the IMO.
p689
aVHistory.
p690
aVThe first IMO was held in Romania in 1959. Since then it has been held every year except 1980. That year, it was cancelled due to internal strife in Mongolia. It was initially founded for eastern European countries participating in the Warsaw Pact, under the Soviet bloc of influence, but eventually other countries participated as well. Because of this eastern origin, the earlier IMOs were hosted only in eastern European countries, and gradually spread to other nations.
p691
aVSources differ about the cities hosting some of the early IMOs. This may be partly because leaders are generally housed well away from the students, and partly because after the competition the students did not always stay based in one city for the rest of the IMO. The exact dates cited may also differ, because of leaders arriving before the students, and at more recent IMOs the IMO Advisory Board arriving before the leaders.
p692
aVSeveral students, such as Teodor von Burg, Lisa Sauermann, and Christian Reiher have performed exceptionally well on the IMO, scoring multiple gold medals. Others, such as Grigory Margulis, Jean-Christophe Yoccoz, Laurent Lafforgue, Stanislav Smirnov, Terence Tao, Sucharit Sarkar, Grigori Perelman, Ngô B\u1ea3o Châu and Maryam Mirzakhani have gone on to become notable mathematicians. Several former participants have won awards such as the Fields medal.
p693
aVIn January 2011, Google gave \u20ac1 million to the International Mathematical Olympiad organization. The donation will help the organization cover the costs of the next five global events (2011\u20132015).
p694
aVScoring and format.
p695
aVThe paper consists of six problems, with each problem being worth seven points, the total score thus being 42 points. No calculators are allowed. The examination is held over two consecutive days; the contestants have four-and-a-half hours to solve three problems per day. The problems chosen are from various areas of secondary school mathematics, broadly classifiable as geometry, number theory, algebra, and combinatorics. They require no knowledge of higher mathematics such as calculus and analysis, and solutions are often short and elementary. However, they are usually disguised so as to make the process of finding the solutions difficult. Prominently featured are algebraic inequalities, complex numbers, and construction-oriented geometrical problems, though in recent years the latter has not been as popular as before.
p696
aVEach participating country, other than the host country, may submit suggested problems to a Problem Selection Committee provided by the host country, which reduces the submitted problems to a shortlist. The team leaders arrive at the IMO a few days in advance of the contestants and form the IMO Jury which is responsible for all the formal decisions relating to the contest, starting with selecting the six problems from the shortlist. The Jury aims to select the problems so that the order in increasing difficulty is Q1, Q4, Q2, Q5, Q3 and Q6. As the leaders know the problems in advance of the contestants, they are kept strictly separated and observed.
p697
aVEach country's marks are agreed between that country's leader and deputy leader and coordinators provided by the host country (the leader of the team whose country submitted the problem in the case of the marks of the host country), subject to the decisions of the chief coordinator and ultimately a jury if any disputes cannot be resolved.
p698
aVSelection process.
p699
aVThe selection process for the IMO varies greatly by country. In some countries, especially those in east Asia, the selection process involves several difficult tests of a difficulty comparable to the IMO itself. The Chinese contestants go through a camp, which lasts from March 16 to April 2. In others, such as the USA, possible participants go through a series of easier standalone competitions that gradually increase in difficulty. In the case of the USA, the tests include the American Mathematics Competitions, the American Invitational Mathematics Examination, and the United States of America Mathematical Olympiad, each of which is a competition in its own right. For high scorers on the final competition for the team selection, there also is a summer camp, like that of China.
p700
aVThe former Soviet Union and other eastern European countries' selection process consists of choosing a team several years beforehand, and giving them special training specifically for the event. However, such methods have been discontinued in some countries. In Ukraine, for instance, selection tests consist of four olympiads comparable to the IMO by difficulty and schedule. While identifying the winners, only the results of the current selection olympiads are considered.
p701
aVIn India, the students are subjected to a test called RMO (Regional Mathematics Olympiad) (some regions also hold a pre-RMO test for selection of students for RMO, but in other regions students directly give RMO). Selected Students are subjected to INMO (Indian National Mathematics Olympiad), from which nationally 35-36 children are selected. They are subjected to a rigorous camp, from which 6 are selected to represent India at IMO.
p702
aVAwards.
p703
aVThe participants are ranked based on their individual scores. Medals are awarded to the highest ranked participants, such that slightly less than half of them receive a medal. Subsequently the cutoffs (minimum scores required to receive a gold, silver or bronze medal respectively) are chosen such that the ratio of gold to silver to bronze medals awarded approximates 1:2:3. Participants who do not win a medal but who score seven points on at least one problem receive an honorable mention.
p704
aVSpecial prizes may be awarded for solutions of outstanding elegance or involving good generalisations of a problem. This last happened in 1995 (Nikolay Nikolov, Bulgaria) and 2005 (Iurie Boreico), but was more frequent up to the early 1980s. The special prize in 2005 was awarded to Iurie Boreico, a student from Moldova, who came up with a brilliant solution to question 3, which was an inequality involving three variables.
p705
aVThe rule that at most half the contestants win a medal is sometimes broken if adhering to it causes the number of medals to deviate too much from half the number of contestants. This last happened in 2010, when the choice was to give either 226 (43.71%) or 266 (51.45%) of the 517 (excluding the 6 from North Korea \u2014 see below) contestants a medal, 2012, when the choice was to give either 226 (46.35%) or 277 (50.55%) of the 548 contestants a medal, and 2013, when the choice was to give either 249 (47.16%) or 278 (52.65%) of the 528 contestants a medal.
p706
aVPenalties.
p707
aVNorth Korea was disqualified for cheating at the 32nd IMO in 1991 and the 51st IMO in 2010. It is the only country to have been caught cheating.
p708
aVNotable achievements.
p709
aVThe following nations have achieved the highest team score in the respective competition:
p710
aVThe following nations have achieved an all-members-gold IMO with a full team:
p711
aVThe only country to have its entire team score perfectly on the IMO was the United States, which won IMO 1994 when it accomplished this, coached by Paul Zeitz, and Luxembourg, whose 1-member team got a perfect score in IMO 1981. The USA's success earned a mention in "TIME Magazine". Hungary won IMO 1975 in an unorthodox way when none of the eight team members received a gold medal (five silver, three bronze). Second place team East Germany also did not have a single gold medal winner (four silver, four bronze).
p712
aVSeveral individuals have consistently scored highly and/or earned medals on the IMO: As of July 2012, Teodor von Burg (Serbia) is the most successful participant with four gold medals, one silver, and one bronze medal. Reid Barton (United States) was the first participant to win a gold medal four times (1998-2001). Barton is also one of only eight four-time Putnam Fellow (2001\u201304). In addition, he is the only person to have won both the IMO and the International Olympiad in Informatics (IOI). Christian Reiher (Germany), Lisa Sauermann (Germany), Teodor von Burg (Serbia), Nipun Pitimanaaree (Thailand), and Zhuoqun Alex Song (Canada) are the only other participants to have won four gold medals (2000\u201303, 2008\u201311, 2009\u201312, 2010\u201313, and 2011-2014 respectively); Reiher also received a bronze medal (1999), Sauermann a silver medal (2007), von Burg a silver medal (2008) and a bronze medal (2007), and Pitimanaaree a silver medal (2009). Wolfgang Burmeister (East Germany), Martin Härterich (West Germany), Iurie Boreico (Moldova), and Jeck Lim (Singapore) are the only other participants besides Reiher, Sauermann, von Burg, and Pitimanaaree to win five medals with at least three of them gold. Ciprian Manolescu (Romania) managed to write a perfect paper (42 points) for gold medal more times than anybody else in history of competition, doing it all three times he participated in the IMO (1995, 1996, 1997). Manolescu is also a three-time Putnam Fellow (1997, 1998, 2000). Evgenia Malinnikova (Soviet Union) is the highest-scoring female contestant in IMO history. She has 3 gold medals in IMO 1989 (41 points), IMO 1990 (42) and IMO 1991 (42), missing only 1 point in 1989 to precede Manolescu's achievement.
p713
aVTerence Tao (Australia) participated in IMO 1986, 1987 and 1988, winning bronze, silver and gold medals respectively. He won a gold medal when he just turned thirteen in IMO 1988, becoming the youngest person to receive a gold medal. Tao also holds the distinction of being the youngest medalist with his 1986 bronze medal, alongside 2009 bronze medalist Raúl Chávez Sarmiento (Peru), at the age of 10 and 11 respectively. Representing the United States, Noam Elkies won a gold medal with a perfect paper at the age of 14 in 1981. Note that both Elkies and Tao could have participated in the IMO multiple times following their success, but entered university and therefore became ineligible.
p714
asS'Axiom'
p715
(lp716
VAn axiom or postulate is a premise or starting point of reasoning. As classically conceived, an axiom is a premise so evident as to be accepted as true without controversy.
p717
aVThe word comes from the Greek "axí\u014dma" () 'that which is thought worthy or fit' or 'that which commends itself as evident.' As used in modern logic, an axiom is simply a premise or starting point for reasoning. Axioms define and delimit the realm of analysis; the truth of an axiom is taken for granted within the particular domain of analysis, and serves as a starting point for deducing and inferring other truths.
p718
aVIn mathematics, the term "axiom" is used in two related but distinguishable senses: "logical axioms" and "non-logical axioms". Logical axioms are usually statements that are taken to be true within the system of logic they define (e.g., ("A" and "B") implies "A"), while non-logical axioms (e.g., ) are actually defining properties for the domain of a specific mathematical theory (such as arithmetic). When used in the latter sense, "axiom," "postulate", and "assumption" may be used interchangeably. In general, a non-logical axiom is not a self-evident truth, but rather a formal logical expression used in deduction to build a mathematical theory. As modern mathematics admits multiple, equally "true" systems of logic, precisely the same thing must be said for logical axioms - they both define and are specific to the particular system of logic that is being invoked. To axiomatize a system of knowledge is to show that its claims can be derived from a small, well-understood set of sentences (the axioms). There are typically multiple ways to axiomatize a given mathematical domain.
p719
aVIn both senses, an axiom is any mathematical statement that serves as a starting point from which other statements are logically derived. Within the system they define, axioms (unless redundant) cannot be derived by principles of deduction, nor are they demonstrable by mathematical proofs, simply because they are starting points; there is nothing else from which they logically follow otherwise they would be classified as theorems. However, an axiom in one system may be a theorem in another, and vice versa.
p720
aVEtymology.
p721
aVThe word "axiom" comes from the Greek word ("axioma"), a verbal noun from the verb ("axioein"), meaning "to deem worthy", but also "to require", which in turn comes from ("axios"), meaning "being in balance", and hence "having (the same) value (as)", "worthy", "proper". Among the ancient Greek philosophers an axiom was a claim which could be seen to be true without any need for proof.
p722
aVThe root meaning of the word 'postulate' is to 'demand'; for instance, Euclid demands of us that we agree that some things can be done, e.g. any two points can be joined by a straight line, etc.
p723
aVAncient geometers maintained some distinction between axioms and postulates. While commenting Euclid's books Proclus remarks that "Geminus held that this Postulate should not be classed as a postulate but as an axiom, since it does not, like the first three Postulates, assert the possibility of some construction but expresses an essential property". Boethius translated 'postulate' as "petitio" and called the axioms "notiones communes" but in later manuscripts this usage was not always strictly kept.
p724
aVHistorical development.
p725
aVEarly Greeks.
p726
aVThe logico-deductive method whereby conclusions (new knowledge) follow from premises (old knowledge) through the application of sound arguments (syllogisms, rules of inference), was developed by the ancient Greeks, and has become the core principle of modern mathematics. Tautologies excluded, nothing can be deduced if nothing is assumed. Axioms and postulates are the basic assumptions underlying a given body of deductive knowledge. They are accepted without demonstration. All other assertions (theorems, if we are talking about mathematics) must be proven with the aid of these basic assumptions. However, the interpretation of mathematical knowledge has changed from ancient times to the modern, and consequently the terms "axiom" and "postulate" hold a slightly different meaning for the present day mathematician, than they did for Aristotle and Euclid.
p727
aVThe ancient Greeks considered geometry as just one of several sciences, and held the theorems of geometry on par with scientific facts. As such, they developed and used the logico-deductive method as a means of avoiding error, and for structuring and communicating knowledge. Aristotle's posterior analytics is a definitive exposition of the classical view.
p728
aVAn "axiom", in classical terminology, referred to a self-evident assumption common to many branches of science. A good example would be the assertion that "When an equal amount is taken from equals, an equal amount results."
p729
aVAt the foundation of the various sciences lay certain additional hypotheses which were accepted without proof. Such a hypothesis was termed a "postulate". While the axioms were common to many sciences, the postulates of each particular science were different. Their validity had to be established by means of real-world experience. Indeed, Aristotle warns that the content of a science cannot be successfully communicated, if the learner is in doubt about the truth of the postulates.
p730
aVThe classical approach is well-illustrated by Euclid's Elements, where a list of postulates is given (common-sensical geometric facts drawn from our experience), followed by a list of "common notions" (very basic, self-evident assertions).
p731
aV;Postulates
p732
aV# It is possible to draw a straight line from any point to any other point.
p733
aV# It is possible to extend a line segment continuously in both directions.
p734
aV# It is possible to describe a circle with any center and any radius.
p735
aV# It is true that all right angles are equal to one another.
p736
aV# ("Parallel postulate") It is true that, if a straight line falling on two straight lines make the interior angles on the same side less than two right angles, the two straight lines, if produced indefinitely, intersect on that side on which are the angles less than the two right angles.
p737
aV;Common notions:
p738
aV# Things which are equal to the same thing are also equal to one another.
p739
aV# If equals are added to equals, the wholes are equal.
p740
aV# If equals are subtracted from equals, the remainders are equal.
p741
aV# Things which coincide with one another are equal to one another.
p742
aV# The whole is greater than the part.
p743
aVModern development.
p744
aVA lesson learned by mathematics in the last 150 years is that it is useful to strip the meaning away from the mathematical assertions (axioms, postulates, propositions, theorems) and definitions. One must concede the need for primitive notions, or undefined terms or concepts, in any study. Such abstraction or formalization makes mathematical knowledge more general, capable of multiple different meanings, and therefore useful in multiple contexts. Alessandro Padoa, Mario Pieri, and Giuseppe Peano were pioneers in this movement.
p745
aVStructuralist mathematics goes further, and develops theories and axioms (e.g. field theory, group theory, topology, vector spaces) without "any" particular application in mind. The distinction between an "axiom" and a "postulate" disappears. The postulates of Euclid are profitably motivated by saying that they lead to a great wealth of geometric facts. The truth of these complicated facts rests on the acceptance of the basic hypotheses. However, by throwing out Euclid's fifth postulate we get theories that have meaning in wider contexts, hyperbolic geometry for example. We must simply be prepared to use labels like "line" and "parallel" with greater flexibility. The development of hyperbolic geometry taught mathematicians that postulates should be regarded as purely formal statements, and not as facts based on experience.
p746
aVWhen mathematicians employ the field axioms, the intentions are even more abstract. The propositions of field theory do not concern any one particular application; the mathematician now works in complete abstraction. There are many examples of fields; field theory gives correct knowledge about them all.
p747
aVIt is not correct to say that the axioms of field theory are "propositions that are regarded as true without proof." Rather, the field axioms are a set of constraints. If any given system of addition and multiplication satisfies these constraints, then one is in a position to instantly know a great deal of extra information about this system.
p748
aVModern mathematics formalizes its foundations to such an extent that mathematical theories can be regarded as mathematical objects, and mathematics itself can be regarded as a branch of logic. Frege, Russell, Poincaré, Hilbert, and Gödel are some of the key figures in this development.
p749
aVIn the modern understanding, a set of axioms is any collection of formally stated assertions from which other formally stated assertions follow by the application of certain well-defined rules. In this view, logic becomes just another formal system. A set of axioms should be consistent; it should be impossible to derive a contradiction from the axiom. A set of axioms should also be non-redundant; an assertion that can be deduced from other axioms need not be regarded as an axiom.
p750
aVIt was the early hope of modern logicians that various branches of mathematics, perhaps all of mathematics, could be derived from a consistent collection of basic axioms. An early success of the formalist program was Hilbert's formalization of Euclidean geometry, and the related demonstration of the consistency of those axioms.
p751
aVIn a wider context, there was an attempt to base all of mathematics on Cantor's set theory. Here the emergence of Russell's paradox, and similar antinomies of naïve set theory raised the possibility that any such system could turn out to be inconsistent.
p752
aVThe formalist project suffered a decisive setback, when in 1931 Gödel showed that it is possible, for any sufficiently large set of axioms (Peano's axioms, for example) to construct a statement whose truth is independent of that set of axioms. As a corollary, Gödel proved that the consistency of a theory like Peano arithmetic is an unprovable assertion within the scope of that theory.
p753
aVIt is reasonable to believe in the consistency of Peano arithmetic because it is satisfied by the system of natural numbers, an infinite but intuitively accessible formal system. However, at present, there is no known way of demonstrating the consistency of the modern Zermelo\u2013Fraenkel axioms for set theory. Furthermore, using techniques of forcing (Cohen) one can show that the continuum hypothesis (Cantor) is independent of the Zermelo\u2013Fraenkel axioms. Thus, even this very general set of axioms cannot be regarded as the definitive foundation for mathematics.
p754
aVOther sciences.
p755
aVAxioms play a key role not only in mathematics, but also in other sciences, notably in theoretical physics. In particular, the monumental work of Isaac Newton is essentially based on Euclid's axioms, augmented by a postulate on the non-relation of spacetime and the physics taking place in it at any moment.
p756
aVIn 1905, Newton's axioms were replaced by those of Albert Einstein's special relativity, and later on by those of general relativity.
p757
aVAnother paper of Albert Einstein and coworkers (see EPR paradox), almost immediately contradicted by Niels Bohr, concerned the interpretation of quantum mechanics. This was in 1935. According to Bohr, this new theory should be probabilistic, whereas according to Einstein it should be deterministic. Notably, the underlying quantum mechanical theory, i.e. the set of "theorems" derived by it, seemed to be identical. Einstein even assumed that it would be sufficient to add to quantum mechanics "hidden variables" to enforce determinism. However, thirty years later, in 1964, John Bell found a theorem, involving complicated optical correlations (see Bell inequalities), which yielded measurably different results using Einstein's axioms compared to using Bohr's axioms. And it took roughly another twenty years until an experiment of Alain Aspect got results in favour of Bohr's axioms, not Einstein's. (Bohr's axioms are simply: The theory should be probabilistic in the sense of the Copenhagen interpretation.)
p758
aVAs a consequence, it is not necessary to explicitly cite Einstein's axioms, the more so since they concern subtle points on the "reality" and "locality" of experiments.
p759
aVRegardless, the role of axioms in mathematics and in the above-mentioned sciences is different. In mathematics one neither "proves" nor "disproves" an axiom for a set of theorems; the point is simply that in the conceptual realm identified by the axioms, the theorems logically follow. In contrast, in physics a comparison with experiments always makes sense, since a falsified physical theory needs modification.
p760
aVMathematical logic.
p761
aVIn the field of mathematical logic, a clear distinction is made between two notions of axioms: "logical" and "non-logical" (somewhat similar to the ancient distinction between "axioms" and "postulates" respectively).
p762
aVLogical axioms.
p763
aVThese are certain formulas in a formal language that are universally valid, that is, formulas that are satisfied by every assignment of values. Usually one takes as logical axioms "at least" some minimal set of tautologies that is sufficient for proving all tautologies in the language; in the case of predicate logic more logical axioms than that are required, in order to prove logical truths that are not tautologies in the strict sense.
p764
aVExamples.
p765
aVPropositional logic.
p766
aVIn propositional logic it is common to take as logical axioms all formulae of the following forms, where formula_1, formula_2, and formula_3 can be any formulae of the language and where the included primitive connectives are only "formula_4" for negation of the immediately following proposition and "formula_5" for implication from antecedent to consequent propositions:
p767
aVEach of these patterns is an "axiom schema", a rule for generating an infinite number of axioms. For example, if formula_9, formula_10, and formula_11 are propositional variables, then formula_12 and formula_13 are both instances of axiom schema 1, and hence are axioms. It can be shown that with only these three axiom schemata and "modus ponens", one can prove all tautologies of the propositional calculus. It can also be shown that no pair of these schemata is sufficient for proving all tautologies with "modus ponens".
p768
aVOther axiom schemas involving the same or different sets of primitive connectives can be alternatively constructed.
p769
aVThese axiom schemata are also used in the predicate calculus, but additional logical axioms are needed to include a quantifier in the calculus.
p770
aVFirst-order logic.
p771
aVAxiom of Equality. Let formula_14 be a first-order language. For each variable formula_15, the formula
p772
aVformula_16
p773
aVis universally valid.
p774
aVThis means that, for any variable symbol formula_17 the formula formula_16 can be regarded as an axiom. Also, in this example, for this not to fall into vagueness and a never-ending series of "primitive notions", either a precise notion of what we mean by formula_16 (or, for that matter, "to be equal") has to be well established first, or a purely formal and syntactical usage of the symbol formula_20 has to be enforced, only regarding it as a string and only a string of symbols, and mathematical logic does indeed do that.
p775
aVAnother, more interesting example axiom scheme, is that which provides us with what is known as Universal Instantiation:
p776
aVAxiom scheme for Universal Instantiation. Given a formula formula_21 in a first-order language formula_14, a variable formula_15 and a term formula_24 that is substitutable for formula_15 in formula_21, the formula
p777
aVformula_27
p778
aVis universally valid.
p779
aVWhere the symbol formula_28 stands for the formula formula_21 with the term formula_24 substituted for formula_15. (See Substitution of variables.) In informal terms, this example allows us to state that, if we know that a certain property formula_32 holds for every formula_15 and that formula_24 stands for a particular object in our structure, then we should be able to claim formula_35. Again, "we are claiming that the formula" formula_36 "is valid", that is, we must be able to give a "proof" of this fact, or more properly speaking, a "metaproof". Actually, these examples are "metatheorems" of our theory of mathematical logic since we are dealing with the very concept of "proof" itself. Aside from this, we can also have Existential Generalization:
p780
aVAxiom scheme for Existential Generalization. Given a formula formula_21 in a first-order language formula_14, a variable formula_15 and a term formula_24 that is substitutable for formula_15 in formula_21, the formula
p781
aVformula_43
p782
aVis universally valid.
p783
aVNon-logical axioms.
p784
aVNon-logical axioms are formulas that play the role of theory-specific assumptions. Reasoning about two different structures, for example the natural numbers and the integers, may involve the same logical axioms; the non-logical axioms aim to capture what is special about a particular structure (or set of structures, such as groups). Thus non-logical axioms, unlike logical axioms, are not "tautologies". Another name for a non-logical axiom is "postulate".
p785
aVAlmost every modern mathematical theory starts from a given set of non-logical axioms, and it was thought that in principle every theory could be axiomatized in this way and formalized down to the bare language of logical formulas.
p786
aVNon-logical axioms are often simply referred to as "axioms" in mathematical discourse. This does not mean that it is claimed that they are true in some absolute sense. For example, in some groups, the group operation is commutative, and this can be asserted with the introduction of an additional axiom, but without this axiom we can do quite well developing (the more general) group theory, and we can even take its negation as an axiom for the study of non-commutative groups.
p787
aVThus, an "axiom" is an elementary basis for a formal logic system that together with the rules of inference define a deductive system.
p788
aVExamples.
p789
aVThis section gives examples of mathematical theories that are developed entirely from a set of non-logical axioms (axioms, henceforth). A rigorous treatment of any of these topics begins with a specification of these axioms.
p790
aVBasic theories, such as arithmetic, real analysis and complex analysis are often introduced non-axiomatically, but implicitly or explicitly there is generally an assumption that the axioms being used are the axioms of Zermelo\u2013Fraenkel set theory with choice, abbreviated ZFC, or some very similar system of axiomatic set theory like Von Neumann\u2013Bernays\u2013Gödel set theory, a conservative extension of ZFC. Sometimes slightly stronger theories such as Morse-Kelley set theory or set theory with a strongly inaccessible cardinal allowing the use of a Grothendieck universe are used, but in fact most mathematicians can actually prove all they need in systems weaker than ZFC, such as second-order arithmetic.
p791
aVThe study of topology in mathematics extends all over through point set topology, algebraic topology, differential topology, and all the related paraphernalia, such as homology theory, homotopy theory. The development of "abstract algebra" brought with itself group theory, rings, fields, and Galois theory.
p792
aVThis list could be expanded to include most fields of mathematics, including measure theory, ergodic theory, probability, representation theory, and differential geometry.
p793
aVCombinatorics is an example of a field of mathematics which does not, in general, follow the axiomatic method.
p794
aVArithmetic.
p795
aVThe Peano axioms are the most widely used "axiomatization" of first-order arithmetic. They are a set of axioms strong enough to prove many important facts about number theory and they allowed Gödel to establish his famous second incompleteness theorem.
p796
aVWe have a language formula_44 where formula_45 is a constant symbol and formula_46 is a unary function and the following axioms:
p797
aVThe standard structure is formula_52 where formula_53 is the set of natural numbers, formula_46 is the successor function and formula_45 is naturally interpreted as the number 0.
p798
aVEuclidean geometry.
p799
aVProbably the oldest, and most famous, list of axioms are the 4 + 1 Euclid's postulates of plane geometry. The axioms are referred to as "4 + 1" because for nearly two millennia the fifth (parallel) postulate ("through a point outside a line there is exactly one parallel") was suspected of being derivable from the first four. Ultimately, the fifth postulate was found to be independent of the first four. Indeed, one can assume that exactly one parallel through a point outside a line exists, or that infinitely many exist. This choice gives us two alternative forms of geometry in which the interior angles of a triangle add up to exactly 180 degrees or less, respectively, and are known as Euclidean and hyperbolic geometries. If one also removes the second postulate ("a line can be extended indefinitely") then elliptic geometry arises, where there is no parallel through a point outside a line, and in which the interior angles of a triangle add up to more than 180 degrees.
p800
aVReal analysis.
p801
aVThe object of study is the real numbers. The real numbers are uniquely picked out (up to isomorphism) by the properties of a "Dedekind complete ordered field", meaning that any nonempty set of real numbers with an upper bound has a least upper bound. However, expressing these properties as axioms requires use of second-order logic. The Löwenheim-Skolem theorems tell us that if we restrict ourselves to first-order logic, any axiom system for the reals admits other models, including both models that are smaller than the reals and models that are larger. Some of the latter are studied in non-standard analysis.
p802
aVRole in mathematical logic.
p803
aVDeductive systems and completeness.
p804
aVA deductive system consists of a set formula_56 of logical axioms, a set formula_57 of non-logical axioms, and a set formula_58 of "rules of inference". A desirable property of a deductive system is that it be complete. A system is said to be complete if, for all formulas formula_1,
p805
aVformula_60
p806
aVthat is, for any statement that is a "logical consequence" of formula_57 there actually exists a "deduction" of the statement from formula_57. This is sometimes expressed as "everything that is true is provable", but it must be understood that "true" here means "made true by the set of axioms", and not, for example, "true in the intended interpretation". Gödel's completeness theorem establishes the completeness of a certain commonly used type of deductive system.
p807
aVNote that "completeness" has a different meaning here than it does in the context of Gödel's first incompleteness theorem, which states that no "recursive", "consistent" set of non-logical axioms formula_57 of the Theory of Arithmetic is "complete", in the sense that there will always exist an arithmetic statement formula_21 such that neither formula_21 nor formula_66 can be proved from the given set of axioms.
p808
aVThere is thus, on the one hand, the notion of "completeness of a deductive system" and on the other hand that of "completeness of a set of non-logical axioms". The completeness theorem and the incompleteness theorem, despite their names, do not contradict one another.
p809
aVFurther discussion.
p810
aVEarly mathematicians regarded axiomatic geometry as a model of physical space, and obviously there could only be one such model. The idea that alternative mathematical systems might exist was very troubling to mathematicians of the 19th century and the developers of systems such as Boolean algebra made elaborate efforts to derive them from traditional arithmetic. Galois showed just before his untimely death that these efforts were largely wasted. Ultimately, the abstract parallels between algebraic systems were seen to be more important than the details and modern algebra was born. In the modern view axioms may be any set of formulas, as long as they are not known to be inconsistent.
p811
asS'Least common multiple'
p812
(lp813
VIn arithmetic and number theory, the least common multiple (also called the lowest common multiple or smallest common multiple) of two integers "a" and "b", usually denoted by '"LCM("a", "b")"', is the smallest positive integer that is divisible by both "a" and "b". Since division of integers by zero is undefined, this definition has meaning only if "a" and "b" are both different from zero. However, some authors define lcm("a",0) as 0 for all "a", which is the result of taking the lcm to be the least upper bound in the lattice of divisibility.
p814
aVThe LCM is familiar from grade-school arithmetic as the "lowest common denominator" (LCD) that must be determined before fractions can be added, subtracted or compared.
p815
aVThe LCM of more than two integers is also well-defined: it is the smallest positive integer that is divisible by each of them.
p816
aVOverview.
p817
aVA multiple of a number is the product of that number and an integer. For example, 10 is a multiple of 5 because 5 × 2 = 10, so 10 is divisible by 5 and 2. Because 10 is the smallest positive integer that is divisible by both 5 and 2, it is the least common multiple of 5 and 2. By the same principle, 10 is the least common multiple of \u22125 and 2 as well.
p818
aVNotation.
p819
aVIn this article we will denote the least common multiple of two integers "a" and "b" as lcm( "a", "b" ). Some older textbooks use [ "a", "b" ].
p820
aVExample.
p821
aVWhat is the LCM of 4 and 6?
p822
aVMultiples of 4 are:
p823
aV 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, ...
p824
aVand the multiples of 6 are:
p825
aV 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, ...
p826
aVCommon multiples of 4 and 6 are simply the numbers that are in both lists:
p827
aV 12, 24, 36, 48, 60, 72, ...
p828
aVSo, from this list of the first few common multiples of the numbers 4 and 6, their least common multiple is 12.
p829
aVApplications.
p830
aVWhen adding, subtracting, or comparing vulgar fractions, it is useful to find the least common multiple of the denominators, often called the lowest common denominator, because each of the fractions can be expressed as a fraction with this denominator. For instance,
p831
aVformula_1
p832
aVwhere the denominator 42 was used because it is the least common multiple of 21 and 6.
p833
aVComputing the least common multiple.
p834
aVReduction by the greatest common divisor.
p835
aVThe following formula reduces the problem of computing the least common multiple to the problem of computing the greatest common divisor (GCD), also known as the greatest common factor:
p836
aVformula_2
p837
aVThis formula is also valid when exactly one of "a" and "b" is 0, since gcd("a", 0) = |"a"|. (However, if both "a" and "b" are 0, this formula would cause division by zero; lcm(0, 0) = 0 is a special case.
p838
aVThere are fast algorithms for computing the GCD that do not require the numbers to be factored, such as the Euclidean algorithm. To return to the example above,
p839
aVformula_3
p840
aVBecause gcd("a", "b") is a divisor of both "a" and "b", it's more efficient to compute the LCM by dividing "before" multiplying:
p841
aVformula_4
p842
aVformula_5
p843
aVThis identity is self-dual:
p844
aVformula_6
p845
aVOther.
p846
aVLet "D" be the product of \u03c9("D") distinct prime numbers (i.e. "D" is squarefree).
p847
aVThen
p848
aVformula_7
p849
aVwhere the absolute bars || denote the cardinality of a set.
p850
aVThe LCM in commutative rings.
p851
aVThe least common multiple can be defined generally over commutative rings as follows: Let "a" and "b" be elements of a commutative ring "R". A common multiple of "a" and "b" is an element "m" of "R" such that both "a" and "b" divide "m" (i.e. there exist elements "x" and "y" of "R" such that "ax" = "m" and "by" = "m"). A least common multiple of "a" and "b" is a common multiple that is minimal in the sense that for any other common multiple "n" of "a" and "b", "m" divides "n".
p852
aVIn general, two elements in a commutative ring can have no least common multiple or more than one. However, any two least common multiples of the same pair of elements are associates. In a unique factorization domain, any two elements have a least common multiple. In a principal ideal domain, the least common multiple of "a" and "b" can be characterised as a generator of the intersection of the ideals generated by "a" and "b" (the intersection of a collection of ideals is always an ideal).
p853
asS'Imaginary unit'
p854
(lp855
VThe imaginary unit or unit imaginary number, denoted as , is a mathematical concept which extends the real number system to the complex number system , which in turn provides at least one root for every polynomial (see algebraic closure and fundamental theorem of algebra). The imaginary unit's core property is that . The term "imaginary" is used because there is no real number having a negative square.
p856
aVThere are in fact two complex square roots of \u22121, namely and , just as there are two complex square roots of every other real number, except zero, which has one double square root.
p857
aVIn contexts where is ambiguous or problematic, or the Greek iota (see alternative notations) is sometimes used. In the disciplines of electrical engineering and control systems engineering, the imaginary unit is often denoted by instead of , because is commonly used to denote electric current.
p858
aVFor the history of the imaginary unit, see Complex number: History.
p859
aVDefinition.
p860
aVThe imaginary number is defined solely by the property that its square is \u22121:
p861
aVformula_1
p862
aVWith defined this way, it follows directly from algebra that and are both square roots of \u22121.
p863
aVAlthough the construction is called "imaginary", and although the concept of an imaginary number may be intuitively more difficult to grasp than that of a real number, the construction is perfectly valid from a mathematical standpoint. Real number operations can be extended to imaginary and complex numbers by treating as an unknown quantity while manipulating an expression, and then using the definition to replace any occurrence of with \u22121. Higher integral powers of can also be replaced with , 1, , or \u22121:
p864
aVformula_2
p865
aVformula_3
p866
aVformula_4
p867
aVSimilarly, as with any non-zero real number:
p868
aVformula_5
p869
aVAs a complex number, is equal to , having a unit imaginary component and no real component (i.e., the real component is zero). In polar form, is , having an absolute value (or magnitude) of 1 and an argument (or angle) of \u03c0/2. In the complex plane (also known as the Cartesian plane), is the point located one unit from the origin along the imaginary axis (which is at a right angle to the real axis).
p870
aVand.
p871
aVBeing a quadratic polynomial with no multiple root, the defining equation has "two" distinct solutions, which are equally valid and which happen to be additive and multiplicative inverses of each other. More precisely, once a solution of the equation has been fixed, the value , which is distinct from , is also a solution. Since the equation is the only definition of , it appears that the definition is ambiguous (more precisely, not well-defined). However, no ambiguity results as long as one or other of the solutions is chosen and labelled as "", with the other one then being labelled as . This is because, although and are not "quantitatively" equivalent (they "are" negatives of each other), there is no "algebraic" difference between and . Both imaginary numbers have equal claim to being the number whose square is \u22121. If all mathematical textbooks and published literature referring to imaginary or complex numbers were rewritten with replacing every occurrence of (and therefore every occurrence of replaced by ), all facts and theorems would continue to be equivalently valid. The distinction between the two roots of with one of them labelled with a minus sign is purely a notational relic; neither root can be said to be more primary or fundamental than the other, and neither of them is "positive" or "negative".
p872
aVThe issue can be a subtle one. The most precise explanation is to say that although the complex field, defined as , (see complex number) is unique up to isomorphism, it is "not" unique up to a "unique" isomorphism \u2014 there are exactly 2 field automorphisms of which keep each real number fixed: the identity and the automorphism sending to . See also Complex conjugate and Galois group.
p873
aVA similar issue arises if the complex numbers are interpreted as 2 × 2 real matrices (see matrix representation of complex numbers), because then both
p874
aVformula_6
p875
aVare solutions to the matrix equation
p876
aVformula_7    "(incorrect)".
p877
aVAttempting to correct the calculation by specifying both the positive and negative roots only produces ambiguous results:
p878
aVformula_8   "(ambiguous)".
p879
aVSimilarly:
p880
aVformula_9    "(incorrect)".
p881
aVThe calculation rules
p882
aVformula_10
p883
aVand
p884
aVformula_11
p885
aVare only valid for real, non-negative values of and .
p886
aVThese problems are avoided by writing and manipulating , rather than expressions like . For a more thorough discussion, see Square root and Branch point.
p887
aVProperties.
p888
aVSquare roots.
p889
aVThe square root of can be expressed as either of two complex numbers
p890
aVformula_12
p891
aVIndeed, squaring the right-hand side gives
p892
aVformula_13
p893
aVThis result can also be derived with Euler's formula
p894
aVformula_14
p895
aVby substituting , giving
p896
aVformula_15
p897
aVTaking the square root of both sides gives
p898
aVformula_16
p899
aVwhich, through application of Euler's formula to , gives
p900
aVformula_17
p901
aVSimilarly, the square root of can be expressed as either of two complex numbers using Euler's formula:
p902
aVformula_14
p903
aVby substituting , giving
p904
aVformula_19
p905
aVTaking the square root of both sides gives
p906
aVformula_20
p907
aVwhich, through application of Euler's formula to , gives
p908
aVformula_17
p909
aVMultiplying the square root of by also gives:
p910
aVformula_22
p911
aVMultiplication and division.
p912
aVMultiplying a complex number by gives:
p913
aVformula_23
p914
aVDividing by is equivalent to multiplying by the reciprocal of :
p915
aVformula_24
p916
aVUsing this identity to generalize division by to all complex numbers gives:
p917
aVformula_25
p918
aVPowers.
p919
aVThe powers of repeat in a cycle expressible with the following pattern, where is any integer:
p920
aVformula_26
p921
aVformula_27
p922
aVformula_28
p923
aVformula_29
p924
aVThis leads to the conclusion that
p925
aVformula_30
p926
aVwhere "mod" represents the modulo operation. Equivalently:
p927
aVformula_31
p928
aVraised to the power of.
p929
aVMaking use of Euler's formula, is
p930
aVformula_32
p931
aVwhere formula_33, the set of integers.
p932
aVThe principal value (for ) is or approximately 0.207879576...
p933
aVFactorial.
p934
aVThe factorial of the imaginary unit is most often given in terms of the gamma function evaluated at :
p935
aVformula_34
p936
aVAlso,
p937
aVformula_35
p938
aVOther operations.
p939
aVMany mathematical operations that can be carried out with real numbers can also be carried out with , such as exponentiation, roots, logarithms, and trigonometric functions. However, it should be noted that all of the following functions are complex multi-valued functions, and it should be clearly stated which branch of the Riemann surface the function is defined on in practice. Listed below are results for the most commonly chosen branch.
p940
aVA number raised to the power is:
p941
aVformula_36
p942
aVThe root of a number is:
p943
aVformula_37
p944
aVThe imaginary-base logarithm of a number is:
p945
aVformula_38
p946
aVAs with any complex logarithm, the log base is not uniquely defined.
p947
aVThe cosine of is a real number:
p948
aVformula_39
p949
aVAnd the sine of is purely imaginary:
p950
aVformula_40
p951
aVMatrices.
p952
aVWhen 2 × 2 real matrices "m" are used for a source, and the number one (1) is identified with the identity matrix, and minus one (\u22121) with the negative of the identity matrix, then there are many solutions to "m"2 = \u22121. In fact, there are many solutions to "m"2 = +1 and "m"2 = 0 also. Any such m can be taken as a basis vector, along with 1, to form a planar algebra.
p953
asS'Magnitude (mathematics)'
p954
(lp955
VIn mathematics, magnitude is the size of a mathematical object, a property by which the object can be compared as larger or smaller than other objects of the same kind. More formally, an object's magnitude is an ordering (or ranking) of the class of objects to which it belongs.
p956
aVHistory.
p957
aVThe Greeks distinguished between several types of magnitude, including:
p958
aVThey proved that the first two could not be the same, or even isomorphic systems of magnitude. They did not consider negative magnitudes to be meaningful, and "magnitude" is still chiefly used in contexts in which zero is either the lowest size or less than all possible sizes.
p959
aVNumbers.
p960
aVThe magnitude of any number is usually called its "absolute value" or "modulus", denoted by |"x"|.
p961
aVReal numbers.
p962
aVThe absolute value of a real number "r" is defined by:
p963
aVformula_1
p964
aVformula_2
p965
aVIt may be thought of as the number's distance from zero on the real number line. For example, the absolute value of both 7 and \u22127 is 7.
p966
aVComplex numbers.
p967
aVA complex number "z" may be viewed as the position of a point "P" in a 2-dimensional space, called the complex plane. The absolute value or modulus of "z" may be thought of as the distance of "P" from the origin of that space. The formula for the absolute value of is similar to that for the Euclidean norm of a vector in a 2-dimensional Euclidean space:
p968
aVformula_3
p969
aVwhere the real numbers "a" and "b" are the real part and the imaginary part of "z", respectively. For instance, the modulus of is formula_4. Alternatively, the magnitude of a complex number "z" may be defined as the square root of the product of itself and its complex conjugate, "z"\u2217, where for any complex number , its complex conjugate is . 
p970
aVformula_5
p971
aVVector spaces.
p972
aVEuclidean vector space.
p973
aVA Euclidean vector represents the position of a point "P" in a Euclidean space. Geometrically, it can be described as an arrow from the origin of the space (vector tail) to that point (vector tip). Mathematically, a vector x in an "n"-dimensional Euclidean space can be defined as an ordered list of "n" real numbers (the Cartesian coordinates of "P"): x = ["x"1, "x"2, ..., "x""n"]. Its magnitude or length is most commonly defined as its Euclidean norm (or Euclidean length):
p974
aVformula_7
p975
aVFor instance, in a 3-dimensional space, the magnitude of 5, 6 is \u221a(42 + 52 + 62) = \u221a77 or about 8.775.
p976
aVThis is equivalent to the square root of the dot product of the vector by itself:
p977
aVformula_8
p978
aVThe Euclidean norm of a vector is just a special case of Euclidean distance: the distance between its tail and its tip. Two similar notations are used for the Euclidean norm of a vector x:
p979
aVA disadvantage to the second notation is that it is also used to denote the absolute value of scalars and the determinants of matrices and therefore its meaning can be ambiguous.
p980
aVNormed vector spaces.
p981
aVBy definition, all Euclidean vectors have a magnitude (see above). However, the notion of magnitude cannot be applied to all kinds of vectors.
p982
aVA function that maps objects to their magnitudes is called a norm. A vector space endowed with a norm, such as the Euclidean space, is called a normed vector space. Not all vector spaces are normed.
p983
aVPseudo-Euclidean space.
p984
aVIn a pseudo-Euclidean space, the magnitude of a vector is the value of the quadratic form for that vector.
p985
aVLogarithmic magnitudes.
p986
aVWhen comparing magnitudes, it is often helpful to use a logarithmic scale. Real-world examples include the loudness of a sound (decibel), the brightness of a star, or the Richter scale of earthquake intensity. Logarithmic magnitudes can be negative. It is usually not meaningful to simply add or subtract them.
p987
aV"Order of magnitude".
p988
aVIn advanced mathematics, as well as colloquially in popular culture, especially geek culture, the phrase "order of magnitude" is used to denote a change in a numeric quantity, usually a measurement, by a factor of 10; that is, the moving of the decimal point in a number one way or the other, possibly with the addition of significant zeros.
p989
aVOccasionally the phrase "half an order of magnitude" is also used, generally in more informal contexts. Sometimes, this is used to denote a 5 to 1 change, or alternatively 101/2 to 1 (approximately 3.162 to 1).
p990
asS'Mathematical model'
p991
(lp992
VA mathematical model is a description of a system using mathematical concepts and language. The process of developing a mathematical model is termed mathematical modeling. Mathematical models are used in the natural sciences (such as physics, biology, earth science, meteorology) and engineering disciplines (such as computer science, artificial intelligence), as well as in the social sciences (such as economics, psychology, sociology, political science). Physicists, engineers, statisticians, operations research analysts, and economists use mathematical models most extensively. A model may help to explain a system and to study the effects of different components, and to make predictions about behaviour.
p993
aVMathematical models can take many forms, including but not limited to dynamical systems, statistical models, differential equations, or game theoretic models. These and other types of models can overlap, with a given model involving a variety of abstract structures. In general, mathematical models may include logical models. In many cases, the quality of a scientific field depends on how well the mathematical models developed on the theoretical side agree with results of repeatable experiments. Lack of agreement between theoretical mathematical models and experimental measurements often leads to important advances as better theories are developed.
p994
aVModel classifications in mathematics.
p995
aVMathematical models are usually composed of relationships and "variables". Relationships can be described by "operators", such as algebraic operators, functions, differential operators, etc. Variables are abstractions of system parameters of interest, that can be quantified. Operators can act with or without variables. Models can be classified in the following ways:
p996
aVSignificance in the natural sciences.
p997
aVMathematical models are of great importance in the natural sciences, particularly in physics. Physical theories are almost invariably expressed using mathematical models.
p998
aVThroughout history, more and more accurate mathematical models have been developed. Newton's laws accurately describe many everyday phenomena, but at certain limits relativity theory and quantum mechanics must be used, even these do not apply to all situations and need further refinement. It is possible to obtain the less accurate models in appropriate limits, for example relativistic mechanics reduces to Newtonian mechanics at speeds much less than the speed of light. Quantum mechanics reduces to classical physics when the quantum numbers are high. For example the de Broglie wavelength of a tennis ball is insignificantly small, so classical physics is a good approximation to use in this case.
p999
aVIt is common to use idealized models in physics to simplify things. Massless ropes, point particles, ideal gases and the particle in a box are among the many simplified models used in physics.
p1000
aVThe laws of physics are represented with simple equations such as Newton's laws, Maxwell's equations and the Schrödinger equation. These laws are such as a basis for making mathematical models of real situations. Many real situations are very complex and thus modeled approximate on a computer, a model that is computationally feasible to compute is made from the basic laws or from approximate models made from the basic laws. For example, molecules can be modeled by molecular orbital models that are approximate solutions to the Schrödinger equation. In engineering, physics models are often made by mathematical methods such as finite element analysis.
p1001
aVDifferent mathematical models use different geometries that are not necessarily accurate descriptions of the geometry of the universe. Euclidean geometry is much used in classical physics, while special relativity and general relativity are examples of theories that use geometries which are not Euclidean.
p1002
aVSome applications.
p1003
aVSince prehistorical times simple models such as maps and diagrams have been used.
p1004
aVOften when engineers analyze a system to be controlled or optimized, they use a mathematical model. In analysis, engineers can build a descriptive model of the system as a hypothesis of how the system could work, or try to estimate how an unforeseeable event could affect the system. Similarly, in control of a system, engineers can try out different control approaches in simulations.
p1005
aVA mathematical model usually describes a system by a set of variables and a set of equations that establish relationships between the variables. Variables may be of many types; real or integer numbers, boolean values or strings, for example. The variables represent some properties of the system, for example, measured system outputs often in the form of signals, timing data, counters, and event occurrence (yes/no). The actual model is the set of functions that describe the relations between the different variables.
p1006
aVBuilding blocks.
p1007
aVIn business and engineering, mathematical models may be used to maximize a certain output. The system under consideration will require certain inputs. The system relating inputs to outputs depends on other variables too: decision variables, state variables, exogenous variables, and random variables.
p1008
aVDecision variables are sometimes known as independent variables. Exogenous variables are sometimes known as parameters or constants.
p1009
aVThe variables are not independent of each other as the state variables are dependent on the decision, input, random, and exogenous variables. Furthermore, the output variables are dependent on the state of the system (represented by the state variables).
p1010
aVObjectives and constraints of the system and its users can be represented as functions of the output variables or state variables. The objective functions will depend on the perspective of the model's user. Depending on the context, an objective function is also known as an "index of performance", as it is some measure of interest to the user. Although there is no limit to the number of objective functions and constraints a model can have, using or optimizing the model becomes more involved (computationally) as the number increases.
p1011
aVFor example, in economics students often apply linear algebra when using input-output models. Complicated mathematical models that have many variables may be consolidated by use of vectors where one symbol represents several variables.
p1012
aVA priori information.
p1013
aVMathematical modeling problems are often classified into black box or white box models, according to how much a priori information on the system is available. A black-box model is a system of which there is no a priori information available. A white-box model (also called glass box or clear box) is a system where all necessary information is available. Practically all systems are somewhere between the black-box and white-box models, so this concept is useful only as an intuitive guide for deciding which approach to take.
p1014
aVUsually it is preferable to use as much a priori information as possible to make the model more accurate. Therefore the white-box models are usually considered easier, because if you have used the information correctly, then the model will behave correctly. Often the a priori information comes in forms of knowing the type of functions relating different variables. For example, if we make a model of how a medicine works in a human system, we know that usually the amount of medicine in the blood is an exponentially decaying function. But we are still left with several unknown parameters; how rapidly does the medicine amount decay, and what is the initial amount of medicine in blood? This example is therefore not a completely white-box model. These parameters have to be estimated through some means before one can use the model.
p1015
aVIn black-box models one tries to estimate both the functional form of relations between variables and the numerical parameters in those functions. Using a priori information we could end up, for example, with a set of functions that probably could describe the system adequately. If there is no a priori information we would try to use functions as general as possible to cover all different models. An often used approach for black-box models are neural networks which usually do not make assumptions about incoming data. Alternatively the NARMAX (Nonlinear AutoRegressive Moving Average model with eXogenous inputs) algorithms which were developed as part of nonlinear system identification can be used to select the model terms, determine the model structure, and estimate the unknown parameters in the presence of correlated and nonlinear noise. The advantage of NARMAX models compared to neural networks is that NARMAX produces models that can be written down and related to the underlying process, whereas neural networks produce an approximation that is opaque.
p1016
aVSubjective information.
p1017
aVSometimes it is useful to incorporate subjective information into a mathematical model. This can be done based on intuition, experience, or expert opinion, or based on convenience of mathematical form. Bayesian statistics provides a theoretical framework for incorporating such subjectivity into a rigorous analysis: we specify a prior probability distribution (which can be subjective), and then update this distribution based on empirical data. 
p1018
aVAn example of when such approach would be necessary is a situation in which an experimenter bends a coin slightly and tosses it once, recording whether it comes up heads, and is then given the task of predicting the probability that the next flip comes up heads. After bending the coin, the true probability that the coin will come up heads is unknown; so the experimenter would need to make a decision (perhaps by looking at the shape of the coin) about what prior distribution to use. Incorporation of such subjective information might be important to get an accurate estimate of the probability.
p1019
aVComplexity.
p1020
aVIn general, model complexity involves a trade-off between simplicity and accuracy of the model. Occam's razor is a principle particularly relevant to modeling; the essential idea being that among models with roughly equal predictive power, the simplest one is the most desirable. While added complexity usually improves the realism of a model, it can make the model difficult to understand and analyze, and can also pose computational problems, including numerical instability. Thomas Kuhn argues that as science progresses, explanations tend to become more complex before a Paradigm shift offers radical simplification.
p1021
aVFor example, when modeling the flight of an aircraft, we could embed each mechanical part of the aircraft into our model and would thus acquire an almost white-box model of the system. However, the computational cost of adding such a huge amount of detail would effectively inhibit the usage of such a model. Additionally, the uncertainty would increase due to an overly complex system, because each separate part induces some amount of variance into the model. It is therefore usually appropriate to make some approximations to reduce the model to a sensible size. Engineers often can accept some approximations in order to get a more robust and simple model. For example Newton's classical mechanics is an approximated model of the real world. Still, Newton's model is quite sufficient for most ordinary-life situations, that is, as long as particle speeds are well below the speed of light, and we study macro-particles only.
p1022
aVTraining.
p1023
aVAny model which is not pure white-box contains some parameters that can be used to fit the model to the system it is intended to describe. If the modeling is done by a neural network, the optimization of parameters is called "training". In more conventional modeling through explicitly given mathematical functions, parameters are determined by curve fitting.
p1024
aVModel evaluation.
p1025
aVA crucial part of the modeling process is the evaluation of whether or not a given mathematical model describes a system accurately. This question can be difficult to answer as it involves several different types of evaluation.
p1026
aVFit to empirical data.
p1027
aVUsually the easiest part of model evaluation is checking whether a model fits experimental measurements or other empirical data. In models with parameters, a common approach to test this fit is to split the data into two disjoint subsets: training data and verification data. The training data are used to estimate the model parameters. An accurate model will closely match the verification data even though these data were not used to set the model's parameters. This practice is referred to as cross-validation in statistics.
p1028
aVDefining a metric to measure distances between observed and predicted data is a useful tool of assessing model fit. In statistics, decision theory, and some economic models, a loss function plays a similar role.
p1029
aVWhile it is rather straightforward to test the appropriateness of parameters, it can be more difficult to test the validity of the general mathematical form of a model. In general, more mathematical tools have been developed to test the fit of statistical models than models involving differential equations. Tools from non-parametric statistics can sometimes be used to evaluate how well the data fit a known distribution or to come up with a general model that makes only minimal assumptions about the model's mathematical form.
p1030
aVScope of the model.
p1031
aVAssessing the scope of a model, that is, determining what situations the model is applicable to, can be less straightforward. If the model was constructed based on a set of data, one must determine for which systems or situations the known data is a "typical" set of data.
p1032
aVThe question of whether the model describes well the properties of the system between data points is called interpolation, and the same question for events or data points outside the observed data is called extrapolation.
p1033
aVAs an example of the typical limitations of the scope of a model, in evaluating Newtonian classical mechanics, we can note that Newton made his measurements without advanced equipment, so he could not measure properties of particles travelling at speeds close to the speed of light. Likewise, he did not measure the movements of molecules and other small particles, but macro particles only. It is then not surprising that his model does not extrapolate well into these domains, even though his model is quite sufficient for ordinary life physics.
p1034
aVPhilosophical considerations.
p1035
aVMany types of modeling implicitly involve claims about causality. This is usually (but not always) true of models involving differential equations. As the purpose of modeling is to increase our understanding of the world, the validity of a model rests not only on its fit to empirical observations, but also on its ability to extrapolate to situations or data beyond those originally described in the model. One can think of this as the differentiation between qualitative and quantitative predictions. One can also argue that a model is worthless unless it provides some insight which goes beyond what is already known from direct investigation of the phenomenon being studied.
p1036
aVAn example of such criticism is the argument that the mathematical models of Optimal foraging theory do not offer insight that goes beyond the common-sense conclusions of evolution and other basic principles of ecology.
p1037
aVExamples.
p1038
aV"M" = ("Q", \u03a3, \u03b4, "q"0, "F") where
p1039
aVThe state "S"1 represents that there has been an even number of 0s in the input so far, while "S"2 signifies an odd number. A 1 in the input does not change the state of the automaton. When the input ends, the state will show whether the input contained an even number of 0s or not. If the input did contain an even number of 0s, "M" will finish in state "S"1, an accepting state, so the input string will be accepted.
p1040
aVThe language recognized by "M" is the regular language given by the regular expression 1*( 0 (1*) 0 (1*) )*, where "*" is the Kleene star, e.g., 1* denotes any non-negative number (possibly zero) of symbols "1".
p1041
aV:formula_3
p1042
aVthat can be written also as:
p1043
aV:formula_4
p1044
aVNote this model assumes the particle is a point mass, which is certainly known to be false in many cases in which we use this model; for example, as a model of planetary motion.
p1045
aV: formula_5
p1046
aV: subject to:
p1047
aV: formula_6
p1048
aV: formula_7
p1049
aV This model has been used in general equilibrium theory, particularly to show existence and Pareto efficiency of economic equilibria. However, the fact that this particular formulation assigns "numerical values" to levels of satisfaction is the source of criticism (and even ridicule). However, it is not an essential ingredient of the theory and again this is an idealization.
p1050
aVModeling requires selecting and identifying relevant aspects of a situation in the real world.
p1051
asS'Equivalence relation'
p1052
(lp1053
VIn mathematics, an equivalence relation is the relation that holds between two elements if and only if they are members of the same cell within a set that has been partitioned into cells such that every element of the set is a member of one and only one cell of the partition. The intersection of any two different cells is empty; the union of all the cells equals the original set. These cells are formally called equivalence classes.
p1054
aVNotation.
p1055
aVAlthough various notations are used throughout the literature to denote that two elements "a" and "b" of a set are equivalent with respect to an equivalence relation "R", the most common are ""a" ~ "b" and "a" \u2261 "b", which are used when "R" is the obvious relation being referenced, and variations of "a" ~"R" "b", "a" \u2261"R" "b", or "aRb"" otherwise.
p1056
aVDefinition.
p1057
aVA given binary relation ~ on a set "X" is said to be an equivalence relation if and only if it is reflexive, symmetric and transitive. Equivalently, for all "a", "b" and "c" in "X":
p1058
aV"X" together with the relation ~ is called a setoid. The equivalence class of "a" under ~, denoted ["a"], is defined as formula_1.
p1059
aVExamples.
p1060
aVSimple example.
p1061
aVLet the set formula_2 have the equivalence relation formula_3. The following sets are equivalence classes of this relation:
p1062
aVformula_4.
p1063
aVThe set of all equivalence classes for this relation is formula_5.
p1064
aVEquivalence relations.
p1065
aVThe following are all equivalence relations:
p1066
aVWell-definedness under an equivalence relation.
p1067
aVIf ~ is an equivalence relation on "X", and "P"("x") is a property of elements of "X", such that whenever "x" ~ "y", "P"("x") is true if "P"("y") is true, then the property "P" is said to be well-defined or a "class invariant" under the relation ~.
p1068
aVA frequent particular case occurs when "f" is a function from "X" to another set "Y"; if "x"1 ~ "x"2 implies "f"("x"1) = "f"("x"2) then "f" is said to be a "morphism" for ~, a "class invariant under" ~, or simply "invariant under" ~. This occurs, e.g. in the character theory of finite groups. The latter case with the function "f" can be expressed by a commutative triangle. See also invariant. Some authors use "compatible with ~" or just "respects ~" instead of "invariant under ~".
p1069
aVMore generally, a function may map equivalent arguments (under an equivalence relation ~A) to equivalent values (under an equivalence relation ~B). Such a function is known as a morphism from ~A to ~B.
p1070
aVEquivalence class, quotient set, partition.
p1071
aVLet formula_6. Some definitions:
p1072
aVEquivalence class.
p1073
aVA subset "Y" of "X" such that "a" ~ "b" holds for all "a" and "b" in "Y", and never for "a" in "Y" and "b" outside "Y", is called an equivalence class of "X" by ~. Let formula_7 denote the equivalence class to which "a" belongs. All elements of "X" equivalent to each other are also elements of the same equivalence class.
p1074
aVQuotient set.
p1075
aVThe set of all possible equivalence classes of "X" by ~, denoted formula_8, is the quotient set of "X" by ~. If "X" is a topological space, there is a natural way of transforming "X"/~ into a topological space; see quotient space for the details.
p1076
aVProjection.
p1077
aVThe projection of ~ is the function formula_9 defined by formula_10 which maps elements of "X" into their respective equivalence classes by ~.
p1078
aVTheorem on projections: Let the function "f": "X" \u2192 "B" be such that "a" ~ "b" \u2192 "f"("a") = "f"("b"). Then there is a unique function "g" : "X/~" \u2192 "B", such that "f" = "g"\u03c0. If "f" is a surjection and "a" ~ "b" \u2194 "f"("a") = "f"("b"), then "g" is a bijection.
p1079
aVEquivalence kernel.
p1080
aVThe equivalence kernel of a function "f" is the equivalence relation ~ defined by formula_11. The equivalence kernel of an injection is the identity relation.
p1081
aVPartition.
p1082
aVA partition of "X" is a set "P" of nonempty subsets of "X", such that every element of "X" is an element of a single element of "P". Each element of "P" is a "cell" of the partition. Moreover, the elements of "P" are pairwise disjoint and their union is "X".
p1083
aVCounting possible partitions.
p1084
aVLet "X" be a finite set with "n" elements. Since every equivalence relation over "X" corresponds to a partition of "X", and vice versa, the number of possible equivalence relations on "X" equals the number of distinct partitions of "X", which is the "nth" Bell number "Bn":
p1085
aV formula_12
p1086
aVwhere the above is one of the ways to write the nth Bell number.
p1087
aVFundamental theorem of equivalence relations.
p1088
aVA key result links equivalence relations and partitions:
p1089
aVIn both cases, the cells of the partition of "X" are the equivalence classes of "X" by ~. Since each element of "X" belongs to a unique cell of any partition of "X", and since each cell of the partition is identical to an equivalence class of "X" by ~, each element of "X" belongs to a unique equivalence class of "X" by ~. Thus there is a natural bijection from the set of all possible equivalence relations on "X" and the set of all partitions of "X".
p1090
aVComparing equivalence relations.
p1091
aVIf ~ and \u2248 are two equivalence relations on the same set "S", and "a"~"b" implies "a"\u2248"b" for all "a","b" \u2208 "S", then \u2248 is said to be a coarser relation than ~, and ~ is a finer relation than \u2248. Equivalently,
p1092
aVThe equality equivalence relation is the finest equivalence relation on any set, while the trivial relation that makes all pairs of elements related is the coarsest.
p1093
aVThe relation "~ is finer than \u2248" on the collection of all equivalence relations on a fixed set is itself a partial order relation.
p1094
aVNote that the equivalence relation generated in this manner can be trivial. For instance, the equivalence relation ~ generated by:
p1095
aVAlgebraic structure.
p1096
aVMuch of mathematics is grounded in the study of equivalences, and order relations. Lattice theory captures the mathematical structure of order relations. Even though equivalence relations are as ubiquitous in mathematics as order relations, the algebraic structure of equivalences is not as well known as that of orders. The former structure draws primarily on group theory and, to a lesser extent, on the theory of lattices, categories, and groupoids.
p1097
aVGroup theory.
p1098
aVJust as order relations are grounded in ordered sets, sets closed under pairwise supremum and infimum, equivalence relations are grounded in partitioned sets, which are sets closed under bijections and preserve partition structure. Since all such bijections map an equivalence class onto itself, such bijections are also known as permutations. Hence permutation groups (also known as transformation groups) and the related notion of orbit shed light on the mathematical structure of equivalence relations.
p1099
aVLet '~' denote an equivalence relation over some nonempty set "A", called the universe or underlying set. Let "G" denote the set of bijective functions over "A" that preserve the partition structure of "A": \u2200"x" \u2208 "A" \u2200"g" \u2208 "G" ("g"("x") \u2208 ["x"]). Then the following three connected theorems hold:
p1100
aVIn sum, given an equivalence relation ~ over "A", there exists a transformation group "G" over "A" whose orbits are the equivalence classes of "A" under ~.
p1101
aVThis transformation group characterisation of equivalence relations differs fundamentally from the way lattices characterize order relations. The arguments of the lattice theory operations meet and join are elements of some universe "A". Meanwhile, the arguments of the transformation group operations composition and inverse are elements of a set of bijections, "A" \u2192 "A".
p1102
aVMoving to groups in general, let "H" be a subgroup of some group "G". Let ~ be an equivalence relation on "G", such that "a" ~ "b" \u2194 ("ab"\u22121 \u2208 "H"). The equivalence classes of ~\u2014also called the orbits of the action of "H" on "G"\u2014are the right cosets of "H" in "G". Interchanging "a" and "b" yields the left cosets.
p1103
aV\u2021"Proof". Let function composition interpret group multiplication, and function inverse interpret group inverse. Then "G" is a group under composition, meaning that \u2200"x" \u2208 "A" \u2200"g" \u2208 "G" (["g"("x")] = ["x"]), because "G" satisfies the following four conditions:
p1104
aVLet "f" and "g" be any two elements of "G". By virtue of the definition of "G", ["g"("f"("x"))] = ["f"("x")] and ["f"("x")] = ["x"], so that ["g"("f"("x"))] = ["x"]. Hence "G" is also a transformation group (and an automorphism group) because function composition preserves the partitioning of "A". formula_13
p1105
aVRelated thinking can be found in Rosen (2008: chpt. 10).
p1106
aVCategories and groupoids.
p1107
aVLet "G" be a set and let "~" denote an equivalence relation over "G". Then we can form a groupoid representing this equivalence relation as follows. The objects are the elements of "G", and for any two elements "x" and "y" of "G", there exists a unique morphism from "x" to "y" if and only if "x"~"y".
p1108
aVThe advantages of regarding an equivalence relation as a special case of a groupoid include:
p1109
aVLattices.
p1110
aVThe possible equivalence relations on any set "X", when ordered by set inclusion, form a complete lattice, called Con "X" by convention. The canonical map ker: "X"^"X" \u2192 Con "X", relates the monoid "X"^"X" of all functions on "X" and Con "X". ker is surjective but not injective. Less formally, the equivalence relation ker on "X", takes each function "f": "X"\u2192"X" to its kernel ker "f". Likewise, ker(ker) is an equivalence relation on "X"^"X".
p1111
aVEquivalence relations and mathematical logic.
p1112
aVEquivalence relations are a ready source of examples or counterexamples. For example, an equivalence relation with exactly two infinite equivalence classes is an easy example of a theory which is \u03c9-categorical, but not categorical for any larger cardinal number.
p1113
aVAn implication of model theory is that the properties defining a relation can be proved independent of each other (and hence necessary parts of the definition) if and only if, for each property, examples can be found of relations not satisfying the given property while satisfying all the other properties. Hence the three defining properties of equivalence relations can be proved mutually independent by the following three examples:
p1114
aVProperties definable in first-order logic that an equivalence relation may or may not possess include:
p1115
aVEuclidean relations.
p1116
aVEuclid's "The Elements" includes the following "Common Notion 1":
p1117
aVThings which equal the same thing also equal one another.
p1118
aVNowadays, the property described by Common Notion 1 is called Euclidean (replacing "equal" by "are in relation with"). The following theorem connects Euclidean relations and equivalence relations:
p1119
aV If a relation is Euclidean and reflexive, it is also symmetric and transitive.
p1120
aV ("aRc" \u2227 "bRc") \u2192 "aRb" ["a/c"] = ("aRa" \u2227 "bRa") \u2192 "aRb" ["reflexive"; erase T\u2227] = "bRa" \u2192 "aRb". Hence "R" is symmetric.
p1121
aV ("aRc" \u2227 "bRc") \u2192 "aRb" ["symmetry"] = ("aRc" \u2227 "cRb") \u2192 "aRb". Hence "R" is transitive. formula_14
p1122
aVHence an equivalence relation is a relation that is "Euclidean" and "reflexive". "The Elements" mentions neither symmetry nor reflexivity, and Euclid probably would have deemed the reflexivity of equality too obvious to warrant explicit mention.
p1123
asS'Pigeonhole principle'
p1124
(lp1125
VIn mathematics, the pigeonhole principle states that if "n" items are put into "m" containers, with "n" > "m", then at least one container must contain more than one item. This theorem is exemplified in real-life by truisms like "there must be at least two left gloves or two right gloves in a group of three gloves". It is an example of a counting argument, and despite seeming intuitive it can be used to demonstrate possibly unexpected results; for example, that two people in London have the same number of hairs on their heads (see below).
p1126
aVThe first formalization of the idea is believed to have been made by Peter Gustav Lejeune Dirichlet in 1834 under the name "Schubfachprinzip" ("drawer principle" or "shelf principle"). For this reason it is also commonly called Dirichlet's box principle, Dirichlet's drawer principle or simply "Dirichlet's principle" \u2014 a name that could also refer to the minimum principle for harmonic functions. The original "drawer" name is still in use in French ("principe des tiroirs"), Polish ("zasada szufladkowa"), Hungarian ("skatulyaelv"), Italian ("principio dei cassetti"), German ("Schubfachprinzip"), Danish ("Skuffeprincippet"), and Chinese ("\u62bd\u5c49\u539f\u7406").
p1127
aVThe principle has several generalizations and can be stated in various ways. In a more quantified version: for natural numbers "k" and "m", if objects are distributed among "m" sets, then the pigeonhole principle asserts that one of the sets will contain at least "k" + 1 objects. For arbitrary "n" and "m" this generalizes to "k" + 1 = \u230a("n" - 1)/"m"\u230b + 1, where \u230a...\u230b is the floor function. 
p1128
aVThough the most straightforward application is to finite sets (such as pigeons and boxes), it is also used with infinite sets that cannot be put into one-to-one correspondence. To do so requires the formal statement of the pigeonhole principle, which is "there does not exist an injective function whose codomain is smaller than its domain". Advanced mathematical proofs like Siegel's lemma build upon this more general concept.
p1129
aVExamples.
p1130
aVSock-picking.
p1131
aVAssume you have a mixture of black socks and blue socks, what is the minimum number of socks needed before a pair of the same color can be guaranteed? Using the pigeonhole principle, to have at least one pair of the same color holes, one per color) using one pigeonhole per color, you need only three socks items).
p1132
aVHand-shaking.
p1133
aVIf there are "n" people who can shake hands with one another (where ), the pigeonhole principle shows that there is always a pair of people who will shake hands with the same number of people. As the 'holes', or "m", correspond to number of hands shaken, and each person can shake hands with anybody from 0 to other people, this creates possible holes. This is because either the '0' or the hole must be empty (if one person shakes hands with everybody, it's not possible to have another person who shakes hands with nobody; likewise, if one person shakes hands with no one there cannot be a person who shakes hands with everybody). This leaves "n" people to be placed in at most non-empty holes, guaranteeing duplication.
p1134
aVHair-counting.
p1135
aVWe can demonstrate there must be at least two people in London with the same number of hairs on their heads as follows. Since a typical human head has an average of around 150,000 hairs; it is reasonable to assume (as an upper bound) that no one has more than 1,000,000 hairs on their head holes). There are more than 1,000,000 people in London ("n" is bigger than 1 million items). Assigning a pigeonhole to each number of hairs on a person's head, and assign people to pigeonholes according to the number of hairs on their head, there must be at least two people assigned to the same pigeonhole by the 1,000,001st assignment (because they have the same number of hairs on their heads) (or, ). For the average case (m = 150,000) with the constraint: fewest overlaps, there will be at most one person assigned to every pigeonhole and the 150,001st person assigned to the same pigeonhole as someone else. In the absence of this constraint, there may be empty pigeonholes because the "collision" happens before we get to the 150,001st person. The principle just proves the existence of an overlap; it says nothing of the number of overlaps (which falls under the subject of Probability Distribution).
p1136
aVThe birthday problem.
p1137
aVThe birthday problem asks, for a set of "n" randomly chosen people, what is the probability that some pair of them will have the same birthday. By the pigeonhole principle, if there are 367 people in the room, we know that there is at least one pair who share the same birthday, as there are only 366 possible birthdays to choose from (including February 29, if present). 
p1138
aVThe birthday "paradox" refers to the result that even if the group is as small as consisting of only 23 individuals, there will still be a pair of people with the same birthday with a 50% probability. While at first glance this may seem surprising, it intuitively makes sense when considering that a comparison will actually be made between every possible pair of people rather than fixing one individual and comparing them solely to the rest of the group.
p1139
aVSoftball team.
p1140
aVImagine seven people who want to play softball items), with a limitation of only four softball teams holes) to choose from. The pigeonhole principle tells us that they cannot all play for different teams. At least 2 must play on the same team: 
p1141
aV formula_1
p1142
aVSubset sum.
p1143
aVAny subset of size six from the set "S" = {1,2,3...,9} must contain two elements whose sum is 10. The pigeonholes will be labelled by the two element subsets {1,9}, {2,8}, {3,7}, {4,6} and the singleton {5}, five pigeonholes in all. When the six "pigeons" (elements of the size six subset) are placed into these pigeonholes, each pigeon going into the pigeonhole that has it contained in its label, at least one of pigeonholes labelled with a two element subset will have two pigeons in it. 
p1144
aVUses and applications.
p1145
aVThe pigeonhole principle arises in computer science. For example, collisions are inevitable in a hash table because the number of possible keys exceeds the number of indices in the array. A hashing algorithm, no matter how clever, cannot avoid these collisions.
p1146
aVThe principle can be used to prove that any lossless compression algorithm, provided it makes some inputs smaller (as the name compression suggests), will also make some other inputs larger. Otherwise, the set of all input sequences up to a given length "L" could be mapped to the (much) smaller set of all sequences of length less than "L", and do so without collisions (because the compression is lossless), which possibility the pigeonhole principle excludes.
p1147
aVA notable problem in mathematical analysis is, for a fixed irrational number "a", to show that the set {["na"]: "n" is an integer} of fractional parts is dense in One finds that it is not easy to explicitly find integers "n", "m" such that , where is a small positive number and "a" is some arbitrary irrational number. But if one takes "M" such that , by the pigeonhole principle there must be such that "n"1"a" and "n"2"a" are in the same integer subdivision of size 1/"M" (there are only "M" such subdivisions between consecutive integers). In particular, we can find "n"1, "n"2 such that "n"1"a" is in , and "n"2"a" is in , for some "p", "q" integers and "k" in . We can then easily verify that is in . This implies that , where "n" = or "n" = . This shows that 0 is a limit point of {["na"}. We can then use this fact to prove the case for "p" in (0, 1]: find "n" such that ; then if ], we are done. Otherwise "p" in ], and by setting "k" = sup, one obtains .
p1148
aVAlternate formulations.
p1149
aVThe following are alternate formulations of the pigeonhole principle.
p1150
aVStrong form.
p1151
aVLet be positive integers. If
p1152
aVformula_2
p1153
aVobjects are distributed into "n" boxes, then either the first box contains at least objects, or the second box contains at least objects, ..., or the "n"th box contains at least objects.
p1154
aVThe simple form is obtained from this by taking , which gives "n" + 1 objects. Taking gives the more quantified version of the principle, namely:
p1155
aVLet "n" and "r" be positive integers. If objects are distributed into "n" boxes, then at least one of the boxes contains "r" or more of the objects. 
p1156
aVThis can also be stated as, if "k" discrete objects are to be allocated to "n" containers, then at least one container must hold at least formula_3 objects, where formula_4 is the ceiling function, denoting the smallest integer larger than or equal to "x". 
p1157
aVSimilarly, at least one container must hold no more than formula_5 objects, where formula_6 is the floor function, denoting the largest integer smaller than or equal to "x".
p1158
aVGeneralizations of the pigeonhole principle.
p1159
aVA probabilistic generalization of the pigeonhole principle states that if "n" pigeons are randomly put into "m" pigeonholes with uniform probability 1/"m", then at least one pigeonhole will hold more than one pigeon with probability
p1160
aVformula_7
p1161
aVwhere ("m")"n" is the falling factorial . For "n" = 0 and for "n" = 1 (and "m" > 0), that probability is zero; in other words, if there is just one pigeon, there cannot be a conflict. For "n" > "m" (more pigeons than pigeonholes) it is one, in which case it coincides with the ordinary pigeonhole principle. But even if the number of pigeons does not exceed the number of pigeonholes ("n" \u2264 "m"), due to the random nature of the assignment of pigeons to pigeonholes there is often a substantial chance that clashes will occur. For example, if 2 pigeons are randomly assigned to 4 pigeonholes, there is a 25% chance that at least one pigeonhole will hold more than one pigeon; for 5 pigeons and 10 holes, that probability is 69.76%; and for 10 pigeons and 20 holes it is about 93.45%. If the number of holes stays fixed, there is always a greater probability of a pair when you add more pigeons. This problem is treated at much greater length in the birthday paradox.
p1162
aVA further probabilistic generalisation is that when a real-valued random variable "X" has a finite mean "E"("X"), then the probability is nonzero that "X" is greater than or equal to "E"("X"), and similarly the probability is nonzero that "X" is less than or equal to "E"("X"). To see that this implies the standard pigeonhole principle, take any fixed arrangement of "n" pigeons into "m" holes and let "X" be the number of pigeons in a hole chosen uniformly at random. The mean of "X" is "n"/"m", so if there are more pigeons than holes the mean is greater than one. Therefore, "X" is sometimes at least 2.
p1163
aVInfinite sets.
p1164
aVThe pigeonhole principle can be extended to infinite sets by phrasing it in terms of cardinal numbers: if the cardinality of set A is greater than the cardinality of set B, then there is no injection from A to B. However in this form the principle is tautological, since the meaning of the statement that the cardinality of set A is greater than the cardinality of set B is exactly that there is no injective map from A to B. What makes the situation of finite sets interesting is that adding at least one element to a set is sufficient to ensure that the cardinality increases. 
p1165
aVAnother way to phrase the pigeonhole principle is similar to the principle that finite sets are Dedekind finite: Let A and B be finite sets. If there is a surjection from A to B that is not injective, then no surjection from A to B is injective. In fact no function of any kind from A to B is injective. 
p1166
aVThe above principle is not true for infinite sets: Consider the function on the natural numbers that sends 1 and 2 to 1, 3 and 4 to 2, 5 and 6 to 3... and so on. 
p1167
aVThere is a similar principle for infinite sets: If uncountably many pigeons are stuffed into countably many pigeonholes, there will exist at least one pigeonhole having uncountably many pigeons stuffed into it. 
p1168
aVThis principle is not a generalisation of the pigeonhole principle for finite sets however: It is in general false for finite sets. In technical terms it says that if A and B are finite sets such that any surjective function from A to B is not injective, then there exists an element of b of B such that there exists a bijection between the preimage of b and A. This is a quite different statement, and is absurd for large finite cardinalities.
p1169
asS'American Mathematical Society'
p1170
(lp1171
VThe American Mathematical Society (AMS) is an association of professional mathematicians dedicated to the interests of mathematical research and scholarship, and serves the national and international community through its publications, meetings, advocacy and other programs. 
p1172
aVThe society is one of the four parts of the Joint Policy Board for Mathematics (JPBM) and a member of the Conference Board of the Mathematical Sciences (CBMS).
p1173
aVHistory.
p1174
aVIt was founded in 1888 as the "New York Mathematical Society", the brainchild of Thomas Fiske, who was impressed by the "London Mathematical Society" on a visit to England. John Howard Van Amringe was the first president and Fiske became secretary. The society soon decided to publish a journal, but ran into some resistance, due to concerns about competing with the American Journal of Mathematics. The result was the "Bulletin of the New York Mathematical Society", with Fiske as editor-in-chief. The de facto journal, as intended, was influential in increasing membership. The popularity of the "Bulletin" soon led to Transactions of the American Mathematical Society and Proceedings of the American Mathematical Society, which were also "de facto" journals. In 1891 Charlotte Scott became the first woman to join the society. The society reorganized under its present name and became a national society in 1894, and that year Scott served as the first woman on the first Council of the American Mathematical Society. In 1951, the society's headquarters moved from New York City to Providence, Rhode Island. In 1954 the society called for the creation of a new teaching degree, a Doctor of Arts in Mathematics, similar to a PhD but without a research thesis. Julia Robinson was the first female president of the American Mathematical Society (1983\u20131984), but was unable to complete her term as she was suffering from leukemia. The society also added an office in Ann Arbor, Michigan in 1984 and an office in Washington, D.C. in 1992. In 1988 the Journal of the American Mathematical Society was created, with the intent of being the flagship journal of the AMS.
p1175
aVMeetings.
p1176
aVThe AMS, along with the Mathematical Association of America and other organizations, holds the largest annual research mathematics meeting in the world, the Joint Mathematics Meeting held in early January. The 2013 Joint Mathematics Meeting in San Diego drew over 6,600 attendees. Each of the four regional sections of the AMS (Central, Eastern, Southeastern and Western) hold meetings in the spring and fall of each year. The society also co-sponsors meetings with other international mathematical societies.
p1177
aVFellows.
p1178
aVThe AMS selects an annual class of Fellows who have made outstanding contributions to the advancement of mathematics.
p1179
aVPublications.
p1180
aVThe AMS publishes Mathematical Reviews, a database of reviews of mathematical publications, various journals, and books. In 1997 the AMS acquired the Chelsea Publishing Company, which it continues to use as an imprint.
p1181
aVJournals:
p1182
aVBlogs:
p1183
aVPrizes.
p1184
aVSome prizes are awarded jointly with other mathematical organizations. See specific articles for details.
p1185
aVTypesetting.
p1186
aVThe AMS was an early advocate of the typesetting program TeX, requiring that contributions be written in it and producing its own packages AMS-TeX and AMS-LaTeX. TeX and LaTeX are now ubiquitous in mathematical publishing.
p1187
aVPresidents.
p1188
aVThe AMS is led by the President, who is elected for a two-year term, and cannot serve for two consecutive terms.
p1189
asS'Binomial expansion'
p1190
(lp1191
sS'Combinatorics'
p1192
(lp1193
VCombinatorics is a branch of mathematics concerning the study of finite or countable discrete structures. Aspects of combinatorics include counting the structures of a given kind and size (enumerative combinatorics), deciding when certain criteria can be met, and constructing and analyzing objects meeting the criteria (as in combinatorial designs and matroid theory), finding "largest", "smallest", or "optimal" objects (extremal combinatorics and combinatorial optimization), and studying combinatorial structures arising in an algebraic context, or applying algebraic techniques to combinatorial problems (algebraic combinatorics).
p1194
aVCombinatorial problems arise in many areas of pure mathematics, notably in algebra, probability theory, topology, and geometry, and combinatorics also has many applications in mathematical optimization, computer science, ergodic theory and statistical physics. Many combinatorial questions have historically been considered in isolation, giving an "ad hoc" solution to a problem arising in some mathematical context. In the later twentieth century, however, powerful and general theoretical methods were developed, making combinatorics into an independent branch of mathematics in its own right. One of the oldest and most accessible parts of combinatorics is graph theory, which also has numerous natural connections to other areas. Combinatorics is used frequently in computer science to obtain formulas and estimates in the analysis of algorithms.
p1195
aVA mathematician who studies combinatorics is called a combinatorialist or a combinatorist.
p1196
aVHistory.
p1197
aVBasic combinatorial concepts and enumerative results appeared throughout the ancient world. In 6th century BCE, ancient Indian physician Sushruta asserts in Sushruta Samhita that 63 combinations can be made out of 6 different tastes, taken one at a time, two at a time, etc., thus computing all 26 \u2212 1 possibilities. Greek historian Plutarch discusses an argument between Chrysippus (3rd century BCE) and Hipparchus (2nd century BCE) of a rather delicate enumerative problem, which was later shown to be related to Schröder numbers. In the "Ostomachion", Archimedes (3rd century BCE) considers a tiling puzzle.
p1198
aVIn the Middle Ages, combinatorics continued to be studied, largely outside of the European civilization. The Indian mathematician Mah\u0101v\u012bra (c. 850) provided formulae for the number of permutations and combinations, and these formulas may have been familiar to Indian mathematicians as early as the 6th century CE. The philosopher and astronomer Rabbi Abraham ibn Ezra (c. 1140) established the symmetry of binomial coefficients, while a closed formula was obtained later by the talmudist and mathematician Levi ben Gerson (better known as Gersonides), in 1321.
p1199
aVThe arithmetical triangle\u2014 a graphical diagram showing relationships among the binomial coefficients\u2014 was presented by mathematicians in treatises dating as far back as the 10th century, and would eventually become known as Pascal's triangle. Later, in Medieval England, campanology provided examples of what is now known as Hamiltonian cycles in certain Cayley graphs on permutations.
p1200
aVDuring the Renaissance, together with the rest of mathematics and the sciences, combinatorics enjoyed a rebirth. Works of Pascal, Newton, Jacob Bernoulli and Euler became foundational in the emerging field. In modern times, the works of J. J. Sylvester (late 19th century) and Percy MacMahon (early 20th century) laid the foundation for enumerative and algebraic combinatorics. Graph theory also enjoyed an explosion of interest at the same time, especially in connection with the four color problem.
p1201
aVIn the second half of 20th century, combinatorics enjoyed a rapid growth, which led to establishment of dozens of new journals and conferences in the subject. In part, the growth was spurred by new connections and applications to other fields, ranging from algebra to probability, from functional analysis to number theory, etc. These connections shed the boundaries between combinatorics and parts of mathematics and theoretical computer science, but at the same time led to a partial fragmentation of the field.
p1202
aVApproaches and subfields of combinatorics.
p1203
aVEnumerative combinatorics.
p1204
aVEnumerative combinatorics is the most classical area of combinatorics, and concentrates on counting the number of certain combinatorial objects. Although counting the number of elements in a set is a rather broad mathematical problem, many of the problems that arise in applications have a relatively simple combinatorial description. Fibonacci numbers is the basic example of a problem in enumerative combinatorics. The twelvefold way provides a unified framework for counting permutations, combinations and partitions.
p1205
aVAnalytic combinatorics.
p1206
aVAnalytic combinatorics concerns the enumeration of combinatorial structures using tools from complex analysis and probability theory. In contrast with enumerative combinatorics which uses explicit combinatorial formulae and generating functions to describe the results, analytic combinatorics aims at obtaining asymptotic formulae.
p1207
aVPartition theory.
p1208
aVPartition theory studies various enumeration and asymptotic problems related to integer partitions, and is closely related to q-series, special functions and orthogonal polynomials. Originally a part of number theory and analysis, it is now considered a part of combinatorics or an independent field. It incorporates the bijective approach and various tools in analysis, analytic number theory, and has connections with statistical mechanics.
p1209
aVGraph theory.
p1210
aVGraphs are basic objects in combinatorics. The questions range from counting (e.g., the number of graphs on "n" vertices with "k" edges) to structural (e.g., which graphs contain Hamiltonian cycles) to algebraic questions (e.g., given a graph "G" and two numbers "x" and "y", does the Tutte polynomial "T""G"("x","y") have a combinatorial interpretation?). It should be noted that while there are very strong connections between graph theory and combinatorics, these two are sometimes thought of as separate subjects.
p1211
aVDesign theory.
p1212
aVDesign theory is a study of combinatorial designs, which are collections of subsets with certain intersection properties. Block designs are combinatorial designs of a special type. This area is one of the oldest parts of combinatorics, such as in Kirkman's schoolgirl problem proposed in 1850. The solution of the problem is a special case of a Steiner system, which systems play an important role in the classification of finite simple groups. The area has further connections to coding theory and geometric combinatorics.
p1213
aVFinite geometry.
p1214
aVFinite geometry is the study of geometric systems having only a finite number of points. Structures analogous to those found in continuous geometries (Euclidean plane, real projective space, etc.) but defined combinatorially are the main items studied. This area provides a rich source of examples for Design theory. It should not be confused with Discrete geometry (Combinatorial geometry).
p1215
aVOrder theory.
p1216
aVOrder theory is the study of partially ordered sets, both finite and infinite. Various examples of partial orders appear in algebra, geometry, number theory and throughout combinatorics and graph theory. Notable classes and examples of partial orders include lattices and Boolean algebras.
p1217
aVMatroid theory.
p1218
aVMatroid theory abstracts part of geometry. It studies the properties of sets (usually, finite sets) of vectors in a vector space that do not depend on the particular coefficients in a linear dependence relation. Not only the structure but also enumerative properties belong to matroid theory. Matroid theory was introduced by Hassler Whitney and studied as a part of the order theory. It is now an independent field of study with a number of connections with other parts of combinatorics.
p1219
aVExtremal combinatorics.
p1220
aVExtremal combinatorics studies extremal questions on set systems. The types of questions addressed in this case are about the largest possible graph which satisfies certain properties. For example, the largest triangle-free graph on "2n" vertices is a complete bipartite graph "Kn,n". Often it is too hard even to find the extremal answer "f"("n") exactly and one can only give an asymptotic estimate.
p1221
aVRamsey theory is another part of extremal combinatorics. It states that any sufficiently large configuration will contain some sort of order. It is an advanced generalization of the pigeonhole principle.
p1222
aVProbabilistic combinatorics.
p1223
aVIn probabilistic combinatorics, the questions are of the following type: what is the probability of a certain property for a random discrete object, such as a random graph? For instance, what is the average number of triangles in a random graph? Probabilistic methods are also used to determine the existence of combinatorial objects with certain prescribed properties (for which explicit examples might be difficult to find), simply by observing that the probability of randomly selecting an object with those properties is greater than 0. This approach (often referred to as "the" probabilistic method) proved highly effective in applications to extremal combinatorics and graph theory. A closely related area is the study of finite Markov chains, especially on combinatorial objects. Here again probabilistic tools are used to estimate the mixing time.
p1224
aVOften associated with Paul Erd\u0151s, who did the pioneer work on the subject, probabilistic combinatorics was traditionally viewed as a set of tools to study problems in other parts of combinatorics. However, with the growth of applications to analysis of algorithms in computer science, as well as classical probability, additive and probabilistic number theory, the area recently grew to become an independent field of combinatorics.
p1225
aVAlgebraic combinatorics.
p1226
aVAlgebraic combinatorics is an area of mathematics that employs methods of abstract algebra, notably group theory and representation theory, in various combinatorial contexts and, conversely, applies combinatorial techniques to problems in algebra. Algebraic combinatorics is continuously expanding its scope, in both topics and techniques, and can be seen as the area of mathematics where the interaction of combinatorial and algebraic methods is particularly strong and significant.
p1227
aVCombinatorics on words.
p1228
aVCombinatorics on words deals with formal languages. It arose independently within several branches of mathematics, including number theory, group theory and probability. It has applications to enumerative combinatorics, fractal analysis, theoretical computer science, automata theory and linguistics. While many applications are new, the classical Chomsky\u2013Schützenberger hierarchy of classes of formal grammars is perhaps the best known result in the field.
p1229
aVGeometric combinatorics.
p1230
aVGeometric combinatorics is related to convex and discrete geometry, in particular polyhedral combinatorics. It asks, for example, how many faces of each dimension can a convex polytope have. Metric properties of polytopes play an important role as well, e.g. the Cauchy theorem on rigidity of convex polytopes. Special polytopes are also considered, such as permutohedra, associahedra and Birkhoff polytopes. We should note that combinatorial geometry is an old fashioned name for discrete geometry.
p1231
aVTopological combinatorics.
p1232
aVCombinatorial analogs of concepts and methods in topology are used to study graph coloring, fair division, partitions, partially ordered sets, decision trees, necklace problems and discrete Morse theory. It should not be confused with combinatorial topology which is an older name for algebraic topology.
p1233
aVArithmetic combinatorics.
p1234
aVArithmetic combinatorics arose out of the interplay between number theory, combinatorics, ergodic theory and harmonic analysis. It is about combinatorial estimates associated with arithmetic operations (addition, subtraction, multiplication, and division). "Additive combinatorics" refers to the special case when only the operations of addition and subtraction are involved. One important technique in arithmetic combinatorics is the ergodic theory of dynamical systems.
p1235
aVInfinitary combinatorics.
p1236
aVInfinitary combinatorics, or combinatorial set theory, is an extension of ideas in combinatorics to infinite sets. It is a part of set theory, an area of mathematical logic, but uses tools and ideas from both set theory and extremal combinatorics.
p1237
aVGian-Carlo Rota used the name "continuous combinatorics" to describe probability and measure theory, since there are many analogies between "counting" and "measure".
p1238
aVRelated fields.
p1239
aVCombinatorial optimization.
p1240
aVCombinatorial optimization is the study of optimization on discrete and combinatorial objects. It started as a part of combinatorics and graph theory, but is now viewed as a branch of applied mathematics and computer science, related to operations research, algorithm theory and computational complexity theory.
p1241
aVCoding theory.
p1242
aVCoding theory started as a part of design theory with early combinatorial constructions of error-correcting codes. The main idea of the subject is to design efficient and reliable methods of data transmission. It is now a large field of study, part of information theory.
p1243
aVDiscrete and computational geometry.
p1244
aVDiscrete geometry (also called combinatorial geometry) also began a part of combinatorics, with early results on convex polytopes and kissing numbers. With the emergence of applications of discrete geometry to computational geometry, these two fields partially merged and became a separate field of study. There remain many connections with geometric and topological combinatorics, which themselves can be viewed as outgrowths of the early discrete geometry.
p1245
aVCombinatorics and dynamical systems.
p1246
aVCombinatorial aspects of dynamical systems is another emerging field. Here dynamical systems can be defined on combinatorial objects. See for example 
p1247
aVgraph dynamical system.
p1248
aVCombinatorics and physics.
p1249
aVThere are increasing interactions between combinatorics and physics, particularly statistical physics. Examples include an exact solution of the Ising model, and a connection between the Potts model on one hand, and the chromatic and Tutte polynomials on the other hand.
p1250
asS'Logarithmic scale'
p1251
(lp1252
VA logarithmic scale is a nonlinear scale used when there is a large range of quantities. Common uses include the earthquake strength, sound loudness, light intensity, and pH of solutions. 
p1253
aVIt is based on orders of magnitude, rather than a standard linear scale, so each mark on the scale is the previous mark multiplied by a value.
p1254
aVCommon usages.
p1255
aVThe following are examples of commonly used logarithmic scales, where a larger quantity results in a higher value:
p1256
aVThe following are examples of commonly used logarithmic scales, where a larger quantity results in a lower (or negative) value:
p1257
aVSome of our senses operate in a logarithmic fashion (Weber\u2013Fechner law), which makes logarithmic scales for these input quantities especially appropriate. In particular our sense of hearing perceives equal ratios of frequencies as equal differences in pitch. In addition, studies of young children in an isolated tribe have shown logarithmic scales to be the most natural display of numbers by humans.
p1258
aVGraphic representation.
p1259
aVThe top left graph is linear in the X and Y axis, and the Y-axis ranges from 0 to 10. A base-10 log scale is used for the Y axis of the bottom left graph, therefore the Y axis ranges from 0 to 1,000.
p1260
aVThe top right graph uses a log-10 scale for just the X axis, and the bottom right graph uses a log-10 scale for both the X axis and the Y axis.
p1261
aVPresentation of data on a logarithmic scale can be helpful when the data
p1262
aVA slide rule has logarithmic scales, and nomograms often employ logarithmic scales. The geometric mean of two numbers is midway between the numbers. Before the advent of computer graphics, logarithmic graph paper was a commonly used scientific tool.
p1263
aVLog\u2013log plots.
p1264
aVIf both the vertical and horizontal axis of a plot is scaled logarithmically, the plot is referred to as a log\u2013log plot.
p1265
aVSemi logarithmic plots.
p1266
aVIf only the ordinate or abscissa is scaled logarithmically, the plot is referred to as a semi logarithmic plot.
p1267
asS'Exponential function'
p1268
(lp1269
VThe term exponential function is almost exclusively used as a shortcut for the natural exponential function "e""x", where "e" is Euler's number, a number (approximately 2.718281828) such that the function "e""x" is its own derivative. The exponential function is used to model a relationship in which a constant change in the independent variable gives the same proportional change (i.e. percentage increase or decrease) in the dependent variable. The function is often written as exp("x"), especially when it is impractical to write the independent variable as a superscript. The exponential function is widely used in physics, chemistry, engineering, mathematical biology, economics and mathematics. 
p1270
aVThe graph of is upward-sloping, and increases faster as "x" increases. The graph always lies above the "x"-axis but can get arbitrarily close to it for negative "x"; thus, the "x"-axis is a horizontal asymptote. The slope of the tangent to the graph at each point is equal to its "y" coordinate at that point. The inverse function is the natural logarithm ln("x"); because of this, some old texts refer to the exponential function as the antilogarithm.
p1271
aVIn general, the variable "x" can be any real or complex number or even an entirely different kind of mathematical object; see the formal definition below.
p1272
aVFormal definition.
p1273
aVThe exponential function "e""x" can be characterized in a variety of equivalent ways. In particular it may be defined by the following power series:
p1274
aV formula_1
p1275
aVUsing an alternate definition for the exponential function leads to the same result when expanded as a Taylor series.
p1276
aVLess commonly, "e""x" is defined as the solution "y" to the equation
p1277
aV formula_2
p1278
aVIt is also the following limit:
p1279
aV formula_3
p1280
aVOverview.
p1281
aVThe exponential function arises whenever a quantity grows or decays at a rate proportional to its current value. One such situation is continuously compounded interest, and in fact it was this that led Jacob Bernoulli in 1683 to the number
p1282
aVformula_4
p1283
aVnow known as "e". Later, in 1697, Johann Bernoulli studied the calculus of the exponential function.
p1284
aVIf a principal amount of 1 earns interest at an annual rate of "x" compounded monthly, then the interest earned each month is "x"/12 times the current value, so each month the total value is multiplied by (1+"x"/12), and the value at the end of the year is (1+"x"/12)12. If instead interest is compounded daily, this becomes (1+"x"/365)365. Letting the number of time intervals per year grow without bound leads to the limit definition of the exponential function,
p1285
aVformula_5
p1286
aVfirst given by Euler.
p1287
aVThis is one of a number of characterizations of the exponential function; others involve series or differential equations.
p1288
aVFrom any of these definitions it can be shown that the exponential function obeys the basic exponentiation identity,
p1289
aVformula_6
p1290
aVwhich is why it can be written as "e""x".
p1291
aVThe derivative (rate of change) of the exponential function is the exponential function itself. More generally, a function with a rate of change "proportional" to the function itself (rather than equal to it) is expressible in terms of the exponential function. This function property leads to exponential growth and exponential decay.
p1292
aVThe exponential function extends to an entire function on the complex plane. Euler's formula relates its values at purely imaginary arguments to trigonometric functions. The exponential function also has analogues for which the argument is a matrix, or even an element of a Banach algebra or a Lie algebra.
p1293
aVDerivatives and differential equations.
p1294
aVThe importance of the exponential function in mathematics and the sciences stems mainly from properties of its derivative. In particular,
p1295
aV formula_7
p1296
aVProof:
p1297
aVformula_8
p1298
aVThat is, "e""x" is its own derivative and hence is a simple example of a Pfaffian function. Functions of the form "ce""x" for constant "c" are the only functions with that property (by the Picard\u2013Lindelöf theorem). Other ways of saying the same thing include:
p1299
aVIf a variable's growth or decay rate is proportional to its size\u2014as is the case in unlimited population growth (see Malthusian catastrophe), continuously compounded interest, or radioactive decay\u2014then the variable can be written as a constant times an exponential function of time. Explicitly for any real constant "k", a function "f": R\u2192R satisfies "f"\u2032 = "kf" if and only if "f"("x") = "ce""kx" for some constant "c".
p1300
aVFurthermore for any differentiable function "f"("x"), we find, by the chain rule:
p1301
aV formula_9
p1302
aVContinued fractions for "e""x".
p1303
aVA continued fraction for "e""x" can be obtained via an identity of Euler:
p1304
aVformula_10
p1305
aVThe following generalized continued fraction for "e""z" converges more quickly:
p1306
aVformula_10
p1307
aVor, by applying the substitution "z" = :
p1308
aVformula_10
p1309
aVwith a special case for "z" = 2:
p1310
aVformula_10
p1311
aVThis formula also converges, though more slowly, for "z" > 2. For example:
p1312
aVformula_10
p1313
aVComplex plane.
p1314
aVAs in the real case, the exponential function can be defined on the complex plane in several equivalent forms. One such definition parallels the power series definition for real numbers, where the real variable is replaced by a complex one:
p1315
aV formula_15
p1316
aVThe exponential function is periodic with imaginary period formula_16 and can be written as
p1317
aV formula_17
p1318
aVwhere "a" and "b" are real values and on the right the real functions must be used if used as a definition (see also Euler's formula). This formula connects the exponential function with the trigonometric functions and to the hyperbolic functions.
p1319
aVWhen considered as a function defined on the complex plane, the exponential function retains the properties
p1320
aVfor all "z" and "w".
p1321
aVThe exponential function is an entire function as it is holomorphic over the whole complex plane. It takes on every complex number excepting 0 as value; that is, 0 is a lacunary value of the exponential function. This is an example of Picard's little theorem that any non-constant entire function takes on every complex number as value with at most one value excepted.
p1322
aVExtending the natural logarithm to complex arguments yields the complex logarithm log "z", which is a multivalued function.
p1323
aVWe can then define a more general exponentiation:
p1324
aV formula_23
p1325
aVfor all complex numbers "z" and "w". This is also a multivalued function, even when "z" is real. This distinction is problematic, as the multivalued functions log "z" and "z""w" are easily confused with their single-valued equivalents when substituting a real number for "z". The rule about multiplying exponents for the case of positive real numbers must be modified in a multivalued context:
p1326
aV formula_24, but rather formula_25 multivalued over integers "n"
p1327
aVSee failure of power and logarithm identities for more about problems with combining powers.
p1328
aVThe exponential function maps any line in the complex plane to a logarithmic spiral in the complex plane with the center at the origin. Two special cases might be noted: when the original line is parallel to the real axis, the resulting spiral never closes in on itself; when the original line is parallel to the imaginary axis, the resulting spiral is a circle of some radius.
p1329
aVComputation of "a""b" where both "a" and "b" are complex.
p1330
aVComplex exponentiation "a""b" can be defined by converting "a" to polar coordinates and using the identity ("e"ln("a"))"b" = "a""b":
p1331
aV formula_26
p1332
aVHowever, when "b" is not an integer, this function is multivalued, because "\u03b8" is not unique (see failure of power and logarithm identities).
p1333
aVMatrices and Banach algebras.
p1334
aVThe power series definition of the exponential function makes sense for square matrices (for which the function is called the matrix exponential) and more generally in any Banach algebra "B". In this setting, "e"0 = 1, and "e""x" is invertible with inverse "e"\u2212"x" for any "x" in "B". If "xy" ="yx", then "e""x"+"y" = "e""x""e""y", but this identity can fail for noncommuting "x" and "y".
p1335
aVSome alternative definitions lead to the same function. For instance, "e""x" can be defined as
p1336
aVformula_27
p1337
aVOr "e""x" can be defined as "f"(1), where "f": R\u2192"B" is the solution to the differential equation "f"\u2032("t") = "xf"("t") with initial condition "f"(0) = 1.
p1338
aVLie algebras.
p1339
aVGiven a Lie group "G" and its associated Lie algebra formula_28, the exponential map is a map formula_29 satisfying similar properties. In fact, since R is the Lie algebra of the Lie group of all positive real numbers under multiplication, the ordinary exponential function for real arguments is a special case of the Lie algebra situation. Similarly, since the Lie group GL("n",R) of invertible "n" × "n" matrices has as Lie algebra M("n",R), the space of all "n" × "n" matrices, the exponential function for square matrices is a special case of the Lie algebra exponential map.
p1340
aVThe identity exp("x" + "y") = exp("x")exp("y") can fail for Lie algebra elements "x" and "y" that do not commute; the Baker\u2013Campbell\u2013Hausdorff formula supplies the necessary correction terms.
p1341
aVDouble exponential function.
p1342
aVThe term double exponential function can have two meanings:
p1343
aVFactorials grow faster than exponential functions, but slower than double-exponential functions. Fermat numbers, generated by formula_30 and double Mersenne numbers generated by formula_31 are examples of double exponential functions.
p1344
aVSimilar properties of "e" and the function "e""z".
p1345
aVThe function "e""z" is not in C("z") (i.e., is not the quotient of two polynomials with complex coefficients).
p1346
aVFor "n" distinct complex numbers {"a"1, \u2026, "a""n"}, the set {"e""a"1"z", \u2026, "e""a""n""z"} is linearly independent over C("z").
p1347
aVThe function "e""z" is transcendental over C("z").
p1348
asS'Logarithm'
p1349
(lp1350
VIn mathematics, the logarithm of a number is the exponent to which another fixed value, the base, must be raised to produce that number. For example, the logarithm of 1000 to base 10 is 3, because 10 to the power 3 is 1000: More generally, for any two real numbers "b" and "x" where "b" is positive and "b" \u2260 1,
p1351
aVformula_1
p1352
aVformula_2
p1353
aVThe logarithm to base 10 ("b" = 10) is called the common logarithm and has many applications in science and engineering. The natural logarithm has the irrational (transcendental) number "e" (\u2248 2.718) as its base; its use is widespread in mathematics, especially calculus. The binary logarithm uses base 2 ("b" = 2) and is prominent in computer science.
p1354
aVLogarithms were introduced by John Napier in the early 17th century as a means to simplify calculations. They were rapidly adopted by navigators, scientists, engineers, and others to perform computations more easily, using slide rules and logarithm tables. Tedious multi-digit multiplication steps can be replaced by table look-ups and simpler addition because of the fact\u2014important in its own right\u2014that the logarithm of a product is the sum of the logarithms of the factors:
p1355
aVformula_3
p1356
aVprovided that "b", "x" and "y" are all positive and "b" \u2260 1.
p1357
aVThe present-day notion of logarithms comes from Leonhard Euler, who connected them to the exponential function in the 18th century.
p1358
aVLogarithmic scales reduce wide-ranging quantities to smaller scopes. For example, the decibel is a unit quantifying signal power log-ratios and amplitude log-ratios (of which sound pressure is a common example). In chemistry, pH is a logarithmic measure for the acidity of an aqueous solution. Logarithms are commonplace in scientific formulae, and in measurements of the complexity of algorithms and of geometric objects called fractals. They describe musical intervals, appear in formulae counting prime numbers, inform some models in psychophysics, and can aid in forensic accounting.
p1359
aVIn the same way as the logarithm reverses exponentiation, the complex logarithm is the inverse function of the exponential function applied to complex numbers. The discrete logarithm is another variant; it has uses in public-key cryptography.
p1360
aVMotivation and definition.
p1361
aVThe idea of logarithms is to reverse the operation of exponentiation, that is, raising a number to a power. For example, the third power (or cube) of 2 is 8, because 8 is the product of three factors of 2:
p1362
aVformula_4
p1363
aVIt follows that the logarithm of 8 with respect to base 2 is 3, so log2 8 = 3.
p1364
aVExponentiation.
p1365
aVThe third power of some number "b" is the product of three factors of "b". More generally, raising "b" to the power, where "n" is a natural number, is done by multiplying "n" factors of "b". The power of "b" is written "b""n", so that
p1366
aVformula_5
p1367
aVExponentiation may be extended to "b""y", where "b" is a positive number and the "exponent" "y" is any real number. For example, "b"\u22121 is the reciprocal of "b", that is, . (For further details, including the formula , see exponentiation or for an elementary treatise.)
p1368
aVDefinition.
p1369
aVThe "logarithm" of a positive real number "x" with respect to base "b", a positive real number not equal to 1, is the exponent by which "b" must be raised to yield "x". In other words, the logarithm of "x" to base "b" is the solution "y" to the equation
p1370
aV formula_6
p1371
aVThe logarithm is denoted "log"b"("x")" (pronounced as "the logarithm of "x" to base "b"" or "the logarithm of "x""). In the equation "y" = log"b"("x"), the value "y" is the answer to the question "To what power must "b" be raised, in order to yield "x"?". This question can also be addressed (with a richer answer) for complex numbers, which is done in section "Complex logarithm", and this answer is much more extensively investigated in the page for the complex logarithm.
p1372
aVExamples.
p1373
aVFor example, , since 16. Logarithms can also be negative:
p1374
aVformula_7
p1375
aVsince
p1376
aV formula_8
p1377
aVA third example: log10(150) is approximately 2.176, which lies between 2 and 3, just as 150 lies between and . Finally, for any base "b", and , since and , respectively.
p1378
aVLogarithmic identities.
p1379
aVSeveral important formulas, sometimes called "logarithmic identities" or "log laws", relate logarithms to one another.
p1380
aVProduct, quotient, power and root.
p1381
aVThe logarithm of a product is the sum of the logarithms of the numbers being multiplied; the logarithm of the ratio of two numbers is the difference of the logarithms. The logarithm of the power of a number is "p" times the logarithm of the number itself; the logarithm of a root is the logarithm of the number divided by "p". The following table lists these identities with examples. Each of the identities can be derived after substitution of the logarithm definitions formula_9 or formula_10 in the left hand sides.
p1382
aVChange of base.
p1383
aVThe logarithm log"b"("x") can be computed from the logarithms of "x" and "b" with respect to an arbitrary base "k" using the following formula:
p1384
aV formula_11
p1385
aVTypical scientific calculators calculate the logarithms to bases 10 and "e". Logarithms with respect to any base "b" can be determined using either of these two logarithms by the previous formula:
p1386
aVformula_12
p1387
aVGiven a number "x" and its logarithm log"b"("x") to an unknown base "b", the base is given by:
p1388
aV formula_13
p1389
aVParticular bases.
p1390
aVAmong all choices for the base, three are particularly common. These are "b" = 10, "b" = "e" (the irrational mathematical constant \u2248 2.71828), and "b" = 2. In mathematical analysis, the logarithm to base "e" is widespread because of its particular analytical properties explained below. On the other hand, logarithms are easy to use for manual calculations in the decimal number system:
p1391
aVformula_14
p1392
aVThus, log10("x") is related to the number of decimal digits of a positive integer "x": the number of digits is the smallest integer strictly bigger than log10("x"). For example, log10(1430) is approximately 3.15. The next integer is 4, which is the number of digits of 1430. Both the natural logarithm and the logarithm to base two are used in information theory, corresponding to the use of nats or bits as the fundamental units of information, respectively. Binary logarithms are also used in computer science, where the binary system is ubiquitous, in music theory, where a pitch ratio of two (the octave) is ubiquitous and the cent is the binary logarithm (scaled by 1200) of the ratio between two adjacent equally-tempered pitches, and in photography to measure exposure values.
p1393
aVThe following table lists common notations for logarithms to these bases and the fields where they are used. Many disciplines write log("x") instead of log"b"("x"), when the intended base can be determined from the context. The notation "b"log("x") also occurs. The "ISO notation" column lists designations suggested by the International Organization for Standardization (ISO 31-11).
p1394
aVHistory.
p1395
aVPredecessors.
p1396
aVThe Babylonians sometime in 2000\u20131600 BC may have invented the quarter square multiplication algorithm to multiply two numbers using only addition, subtraction and a table of quarter squares. However, it could not be used for division without an additional table of reciprocals (or the knowledge of a sufficiently simple algorithm to generate reciprocals). Large tables of quarter squares were used to simplify the accurate multiplication of large numbers from 1817 onwards until this was superseded by the use of computers.
p1397
aVThe Indian mathematician Virasena worked with the concept of ardhaccheda: the number of times a number of the form 2n could be halved. For exact powers of 2, this is the logarithm to that base, which is a whole number; for other numbers, it is undefined. He described relations such as the product formula and also introduced integer logarithms in base 3 (trakacheda) and base 4 (caturthacheda).
p1398
aVMichael Stifel published "Arithmetica integra" in Nuremberg in 1544, which contains a table of integers and powers of 2 that has been considered an early version of a logarithmic table.
p1399
aVIn the 16th and early 17th centuries an algorithm called prosthaphaeresis was used to approximate multiplication and division. This used the trigonometric identity
p1400
aVformula_15
p1401
aVor similar to convert the multiplications to additions and table lookups. However, logarithms are more straightforward and require less work. It can be shown using Euler's Formula that the two techniques are related.
p1402
aVFrom Napier to Euler.
p1403
aVThe method of logarithms was publicly propounded by John Napier in 1614, in a book titled "Mirifici Logarithmorum Canonis Descriptio" ("Description of the Wonderful Rule of Logarithms"). Joost Bürgi constructed a table of powers with a basis very close to 1, and this table provides a fine correspondence between the integers 1-10 (or 10-100, etc.) and exponents that can be added. This table was printed (but perhaps not published) in 1620. However, Bürgi did not define an abstract continuous function as Napier did, and he did also not work out the accuracy of interpolations, which was also tackled by Napier.
p1404
aVJohannes Kepler, who used logarithm tables extensively to compile his "Ephemeris" and therefore dedicated it to Napier, remarked:
p1405
aVBy repeated subtractions Napier calculated for "L" ranging from 1 to 100. The result for "L"=100 is approximately 0.99999 = 1 \u2212 10\u22125. Napier then calculated the products of these numbers with for "L" from 1 to 50, and did similarly with and . These computations, which occupied 20 years, allowed him to give, for any number "N" from 5 to 10 million, the number "L" that solves the equation
p1406
aVformula_16
p1407
aVNapier first called "L" an "artificial number", but later introduced the word "logarithm" to mean a number that indicates a ratio: ("logos") meaning proportion, and ("arithmos") meaning number. In modern notation, the relation to natural logarithms is:
p1408
aVformula_17
p1409
aVwhere the very close approximation corresponds to the observation that
p1410
aVformula_18
p1411
aVThe invention was quickly and widely met with acclaim. The works of Bonaventura Cavalieri (Italy), Edmund Wingate (France), Xue Fengzuo (China), and
p1412
aVJohannes Kepler's "Chilias logarithmorum" (Germany) helped spread the concept further.
p1413
aVIn 1649, Alphonse Antonio de Sarasa, a former student of Grégoire de Saint-Vincent, related logarithms to the quadrature of the hyperbola, by pointing out that the area "f"("t") under the hyperbola from to satisfies
p1414
aVformula_19
p1415
aVThe natural logarithm was first described by Nicholas Mercator in his work "Logarithmotechnia" published in 1668, although the mathematics teacher John Speidell had already in 1619 compiled a table of what were effectively natural logarithms, based on Napier's work. Around 1730, Leonhard Euler defined the exponential function and the natural logarithm by
p1416
aVformula_20
p1417
aVformula_21
p1418
aVEuler also showed that the two functions are inverse to one another.
p1419
aVLogarithm tables, slide rules, and historical applications.
p1420
aVBy simplifying difficult calculations, logarithms contributed to the advance of science, and especially of astronomy. They were critical to advances in surveying, celestial navigation, and other domains. Pierre-Simon Laplace called logarithms
p1421
aV:"...n admirable artifice which, by reducing to a few days the labour of many months, doubles the life of the astronomer, and spares him the errors and disgust inseparable from long calculations."
p1422
aVA key tool that enabled the practical use of logarithms before calculators and computers was the "table of logarithms". The first such table was compiled by Henry Briggs in 1617, immediately after Napier's invention. Subsequently, tables with increasing scope and precision were written. These tables listed the values of log"b"("x") and "b""x" for any number "x" in a certain range, at a certain precision, for a certain base "b" (usually "b" = 10). For example, Briggs' first table contained the common logarithms of all integers in the range 1\u20131000, with a precision of 8 digits. As the function is the inverse function of log"b"("x"), it has been called the antilogarithm. The product and quotient of two positive numbers "c" and "d" were routinely calculated as the sum and difference of their logarithms. The product "cd" or quotient "c"/"d" came from looking up the antilogarithm of the sum or difference, also via the same table:
p1423
aVformula_22
p1424
aVand
p1425
aVformula_23
p1426
aVFor manual calculations that demand any appreciable precision, performing the lookups of the two logarithms, calculating their sum or difference, and looking up the antilogarithm is much faster than performing the multiplication by earlier methods such as prosthaphaeresis, which relies on trigonometric identities. Calculations of powers and roots are reduced to multiplications or divisions and look-ups by
p1427
aVformula_24
p1428
aVand
p1429
aVformula_25
p1430
aVMany logarithm tables give logarithms by separately providing the characteristic and mantissa of "x", that is to say, the integer part and the fractional part of log10("x"). The characteristic of is one plus the characteristic of "x", and their significands are the same. This extends the scope of logarithm tables: given a table listing log10("x") for all integers "x" ranging from 1 to 1000, the logarithm of 3542 is approximated by
p1431
aVformula_26
p1432
aVAnother critical application was the slide rule, a pair of logarithmically divided scales used for calculation, as illustrated here:
p1433
aVThe non-sliding logarithmic scale, Gunter's rule, was invented shortly after Napier's invention. William Oughtred enhanced it to create the slide rule\u2014a pair of logarithmic scales movable with respect to each other. Numbers are placed on sliding scales at distances proportional to the differences between their logarithms. Sliding the upper scale appropriately amounts to mechanically adding logarithms. For example, adding the distance from 1 to 2 on the lower scale to the distance from 1 to 3 on the upper scale yields a product of 6, which is read off at the lower part. The slide rule was an essential calculating tool for engineers and scientists until the 1970s, because it allows, at the expense of precision, much faster computation than techniques based on tables.
p1434
aVAnalytic properties.
p1435
aVA deeper study of logarithms requires the concept of a "function". A function is a rule that, given one number, produces another number. An example is the function producing the power of "b" from any real number "x", where the base "b" is a fixed number. This function is written
p1436
aVformula_27
p1437
aVLogarithmic function.
p1438
aVTo justify the definition of logarithms, it is necessary to show that the equation
p1439
aVformula_28
p1440
aVhas a solution "x" and that this solution is unique, provided that "y" is positive and that "b" is positive and unequal to 1. A proof of that fact requires the intermediate value theorem from elementary calculus. This theorem states that a continuous function that produces two values "m" and "n" also produces any value that lies between "m" and "n". A function is "continuous" if it does not "jump", that is, if its graph can be drawn without lifting the pen.
p1441
aVThis property can be shown to hold for the function "f"("x") = "b""x". Because "f" takes arbitrarily large and arbitrarily small positive values, any number lies between "f"("x"0) and "f"("x"1) for suitable "x"0 and "x"1. Hence, the intermediate value theorem ensures that the equation "f"("x") = "y" has a solution. Moreover, there is only one solution to this equation, because the function "f" is strictly increasing (for ), or strictly decreasing (for ).
p1442
aVThe unique solution "x" is the logarithm of "y" to base "b", log"b"("y"). The function that assigns to "y" its logarithm is called "logarithm function" or "logarithmic function" (or just "logarithm").
p1443
aVThe function log"b"("x") is essentially characterized by the above product formula
p1444
aVformula_29
p1445
aVMore precisely, the logarithm to any base is the only increasing function "f" from the positive reals to the reals satisfying "f"("b") = 1 and 
p1446
aVformula_30
p1447
aVInverse function.
p1448
aVThe formula for the logarithm of a power says in particular that for any number "x",
p1449
aVformula_31
p1450
aVIn prose, taking the power of "b" and then the logarithm gives back "x". Conversely, given a positive number "y", the formula
p1451
aVformula_32
p1452
aVsays that first taking the logarithm and then exponentiating gives back "y". Thus, the two possible ways of combining (or composing) logarithms and exponentiation give back the original number. Therefore, the logarithm to base "b" is the "inverse function" of .
p1453
aVInverse functions are closely related to the original functions. Their graphs correspond to each other upon exchanging the "x"- and the "y"-coordinates (or upon reflection at the diagonal line "x" = "y"), as shown at the right: a point ("t", "u" = "b""t") on the graph of "f" yields a point ("u", "t" = log"b""u") on the graph of the logarithm and vice versa. As a consequence, log"b"("x") diverges to infinity (gets bigger than any given number) if "x" grows to infinity, provided that "b" is greater than one. In that case, log"b"("x") is an increasing function. For , log"b"("x") tends to minus infinity instead. When "x" approaches zero, log"b"("x") goes to minus infinity for (plus infinity for , respectively).
p1454
aVDerivative and antiderivative.
p1455
aVAnalytic properties of functions pass to their inverses. Thus, as "f"("x") = "b""x" is a continuous and differentiable function, so is log"b"("y"). Roughly, a continuous function is differentiable if its graph has no sharp "corners". Moreover, as the derivative of "f"("x") evaluates to ln("b")"b""x" by the properties of the exponential function, the chain rule implies that the derivative of log"b"("x") is given by
p1456
aV formula_33
p1457
aVThat is, the slope of the tangent touching the graph of the logarithm at the point equals . In particular, the derivative of ln("x") is 1/"x", which implies that the antiderivative of 1/"x" is . The derivative with a generalised functional argument "f"("x") is
p1458
aVformula_34
p1459
aVThe quotient at the right hand side is called the logarithmic derivative of "f". Computing "f'"("x") by means of the derivative of ln("f"("x")) is known as logarithmic differentiation. The antiderivative of the natural logarithm ln("x") is:
p1460
aV formula_35
p1461
aVRelated formulas, such as antiderivatives of logarithms to other bases can be derived from this equation using the change of bases.
p1462
aVIntegral representation of the natural logarithm.
p1463
aVThe natural logarithm of "t" agrees with the integral of 1/"x" "dx" from 1 to "t":
p1464
aVformula_36
p1465
aVIn other words, ln("t") equals the area between the "x" axis and the graph of the function 1/"x", ranging from to (figure at the right). This is a consequence of the fundamental theorem of calculus and the fact that derivative of ln("x") is 1/"x". The right hand side of this equation can serve as a definition of the natural logarithm. Product and power logarithm formulas can be derived from this definition. For example, the product formula is deduced as:
p1466
aVformula_37
p1467
aVThe equality (1) splits the integral into two parts, while the equality (2) is a change of variable (). In the illustration below, the splitting corresponds to dividing the area into the yellow and blue parts. Rescaling the left hand blue area vertically by the factor "t" and shrinking it by the same factor horizontally does not change its size. Moving it appropriately, the area fits the graph of the function again. Therefore, the left hand blue area, which is the integral of "f"("x") from "t" to "tu" is the same as the integral from 1 to "u". This justifies the equality (2) with a more geometric proof.
p1468
aVThe power formula may be derived in a similar way:
p1469
aVformula_38
p1470
aVThe second equality uses a change of variables (integration by substitution), .
p1471
aVThe sum over the reciprocals of natural numbers,
p1472
aVformula_39
p1473
aVis called the harmonic series. It is closely tied to the natural logarithm: as "n" tends to infinity, the difference,
p1474
aVformula_40
p1475
aVconverges (i.e., gets arbitrarily close) to a number known as the Euler\u2013Mascheroni constant. This relation aids in analyzing the performance of algorithms such as quicksort.
p1476
aVThere is also another integral representation of the logarithm that is useful in some situations.
p1477
aVformula_41
p1478
aVThis can be verified by showing that it has the same value at , and the same derivative.
p1479
aVTranscendence of the logarithm.
p1480
aVReal numbers that are not algebraic are called transcendental; for example, Pi and "e" are such numbers, but formula_42 is not. Almost all real numbers are transcendental. The logarithm is an example of a transcendental function. The Gelfond\u2013Schneider theorem asserts that logarithms usually take transcendental, i.e., "difficult" values.
p1481
aVCalculation.
p1482
aVLogarithms are easy to compute in some cases, such as log10(1,000) = 3. In general, logarithms can be calculated using power series or the arithmetic\u2013geometric mean, or be retrieved from a precalculated logarithm table that provides a fixed precision.
p1483
aVNewton's method, an iterative method to solve equations approximately, can also be used to calculate the logarithm, because its inverse function, the exponential function, can be computed efficiently. Using look-up tables, CORDIC-like methods can be used to compute logarithms if the only available operations are addition and bit shifts. Moreover, the binary logarithm algorithm calculates lb("x") recursively based on repeated squarings of "x", taking advantage of the relation
p1484
aVformula_43
p1485
aVPower series.
p1486
aVFor any real number "z" that satisfies , the following formula holds:
p1487
aVformula_44
p1488
aVThis is a shorthand for saying that ln("z") can be approximated to a more and more accurate value by the following expressions:
p1489
aVformula_45
p1490
aVFor example, with the third approximation yields 0.4167, which is about 0.011 greater than . This series approximates ln("z") with arbitrary precision, provided the number of summands is large enough. In elementary calculus, ln("z") is therefore the "limit" of this series. It is the Taylor series of the natural logarithm at "z" = 1. The Taylor series of ln "z" provides a particularly useful approximation to ln(1+"z") when "z" is small, "|z| < 1", since then
p1491
aVformula_46
p1492
aVFor example, with "z" = 0.1 the first-order approximation gives ln(1.1) \u2248 0.1, which is less than 5% off the correct value 0.0953.
p1493
aVAnother series is based on the area hyperbolic tangent function:
p1494
aVformula_47
p1495
aVfor any real number "z" > 0. Using the Sigma notation, this is also written as
p1496
aVformula_48
p1497
aVThis series can be derived from the above Taylor series. It converges more quickly than the Taylor series, especially if "z" is close to 1. For example, for "z" = 1.5, the first three terms of the second series approximate ln(1.5) with an error of about . The quick convergence for "z" close to 1 can be taken advantage of in the following way: given a low-accuracy approximation and putting
p1498
aVformula_49
p1499
aVthe logarithm of "z" is:
p1500
aVformula_50
p1501
aVThe better the initial approximation "y" is, the closer "A" is to 1, so its logarithm can be calculated efficiently. "A" can be calculated using the exponential series, which converges quickly provided "y" is not too large. Calculating the logarithm of larger "z" can be reduced to smaller values of "z" by writing , so that .
p1502
aVA closely related method can be used to compute the logarithm of integers. From the above series, it follows that:
p1503
aVformula_51
p1504
aVIf the logarithm of a large integer "n" is known, then this series yields a fast converging series for log("n"+1).
p1505
aVArithmetic\u2013geometric mean approximation.
p1506
aVThe arithmetic\u2013geometric mean yields high precision approximations of the natural logarithm. ln("x") is approximated to a precision of 2\u2212"p" (or "p" precise bits) by the following formula (due to Carl Friedrich Gauss):
p1507
aVformula_52
p1508
aVHere "M"(x,y) denotes the arithmetic\u2013geometric mean of x and y. It is obtained by repeatedly calculating the average (x+y)/2 (arithmetic mean) and sqrt(x*y) (geometric mean) of x and y then let those two numbers become the next x and y. The two numbers quickly converge to a common limit which is the value of "M"(x,y). "m" is chosen such that
p1509
aVformula_53
p1510
aVto insure the required precision. A larger "m" makes the "M"(x,y) calculation take more steps (the initial x and y are farther apart so it takes more steps to converge) buts gives more precision. The constants \u03c0 and ln(2) can be calculated with quickly converging series.
p1511
aVApplications.
p1512
aVLogarithms have many applications inside and outside mathematics. Some of these occurrences are related to the notion of scale invariance. For example, each chamber of the shell of a nautilus is an approximate copy of the next one, scaled by a constant factor. This gives rise to a logarithmic spiral. Benford's law on the distribution of leading digits can also be explained by scale invariance. Logarithms are also linked to self-similarity. For example, logarithms appear in the analysis of algorithms that solve a problem by dividing it into two similar smaller problems and patching their solutions. The dimensions of self-similar geometric shapes, that is, shapes whose parts resemble the overall picture are also based on logarithms.
p1513
aVLogarithmic scales are useful for quantifying the relative change of a value as opposed to its absolute difference. Moreover, because the logarithmic function log("x") grows very slowly for large "x", logarithmic scales are used to compress large-scale scientific data. Logarithms also occur in numerous scientific formulas, such as the Tsiolkovsky rocket equation, the Fenske equation, or the Nernst equation.
p1514
aVLogarithmic scale.
p1515
aVScientific quantities are often expressed as logarithms of other quantities, using a "logarithmic scale". For example, the decibel is a unit of measurement associated with logarithmic-scale quantities. It is based on the common logarithm of ratios\u201410 times the common logarithm of a power ratio or 20 times the common logarithm of a voltage ratio. It is used to quantify the loss of voltage levels in transmitting electrical signals, to describe power levels of sounds in acoustics, and the absorbance of light in the fields of spectrometry and optics. The signal-to-noise ratio describing the amount of unwanted noise in relation to a (meaningful) signal is also measured in decibels. In a similar vein, the peak signal-to-noise ratio is commonly used to assess the quality of sound and image compression methods using the logarithm.
p1516
aVThe strength of an earthquake is measured by taking the common logarithm of the energy emitted at the quake. This is used in the moment magnitude scale or the Richter scale. For example, a 5.0 earthquake releases 10 times and a 6.0 releases 100 times the energy of a 4.0. Another logarithmic scale is apparent magnitude. It measures the brightness of stars logarithmically. Yet another example is pH in chemistry; pH is the negative of the common logarithm of the activity of hydronium ions (the form hydrogen ions take in water). The activity of hydronium ions in neutral water is 10\u22127 mol·L\u22121, hence a pH of 7. Vinegar typically has a pH of about 3. The difference of 4 corresponds to a ratio of 104 of the activity, that is, vinegar's hydronium ion activity is about 10\u22123 mol·L\u22121.
p1517
aVSemilog (log-linear) graphs use the logarithmic scale concept for visualization: one axis, typically the vertical one, is scaled logarithmically. For example, the chart at the right compresses the steep increase from 1 million to 1 trillion to the same space (on the vertical axis) as the increase from 1 to 1 million. In such graphs, exponential functions of the form "f"("x") = "a" · "b""x" appear as straight lines with slope equal to the logarithm of "b".
p1518
aVLog-log graphs scale both axes logarithmically, which causes functions of the form "f"("x") = "a" · "x""k" to be depicted as straight lines with slope equal to the exponent "k". This is applied in visualizing and analyzing power laws.
p1519
aVPsychology.
p1520
aVLogarithms occur in several laws describing human perception:
p1521
aVHick's law proposes a logarithmic relation between the time individuals take for choosing an alternative and the number of choices they have. Fitts's law predicts that the time required to rapidly move to a target area is a logarithmic function of the distance to and the size of the target. In psychophysics, the Weber\u2013Fechner law proposes a logarithmic relationship between stimulus and sensation such as the actual vs. the perceived weight of an item a person is carrying. (This "law", however, is less precise than more recent models, such as the Stevens' power law.)
p1522
aVPsychological studies found that individuals with little mathematics education tend to estimate quantities logarithmically, that is, they position a number on an unmarked line according to its logarithm, so that 10 is positioned as close to 100 as 100 is to 1000. Increasing education shifts this to a linear estimate (positioning 1000 10x as far away) in some circumstances, while logarithms are used when the numbers to be plotted are difficult to plot linearly.
p1523
aVProbability theory and statistics.
p1524
aVLogarithms arise in probability theory: the law of large numbers dictates that, for a fair coin, as the number of coin-tosses increases to infinity, the observed proportion of heads approaches one-half. The fluctuations of this proportion about one-half are described by the law of the iterated logarithm.
p1525
aVLogarithms also occur in log-normal distributions. When the logarithm of a random variable has a normal distribution, the variable is said to have a log-normal distribution. Log-normal distributions are encountered in many fields, wherever a variable is formed as the product of many independent positive random variables, for example in the study of turbulence.
p1526
aVLogarithms are used for maximum-likelihood estimation of parametric statistical models. For such a model, the likelihood function depends on at least one parameter that must be estimated. A maximum of the likelihood function occurs at the same parameter-value as a maximum of the logarithm of the likelihood (the ""log likelihood""), because the logarithm is an increasing function. The log-likelihood is easier to maximize, especially for the multiplied likelihoods for independent random variables.
p1527
aVBenford's law describes the occurrence of digits in many data sets, such as heights of buildings. According to Benford's law, the probability that the first decimal-digit of an item in the data sample is "d" (from 1 to 9) equals log10("d" + 1) \u2212 log10("d"), "regardless" of the unit of measurement. Thus, about 30% of the data can be expected to have 1 as first digit, 18% start with 2, etc. Auditors examine deviations from Benford's law to detect fraudulent accounting.
p1528
aVComputational complexity.
p1529
aVAnalysis of algorithms is a branch of computer science that studies the performance of algorithms (computer programs solving a certain problem). Logarithms are valuable for describing algorithms that divide a problem into smaller ones, and join the solutions of the subproblems.
p1530
aVFor example, to find a number in a sorted list, the binary search algorithm checks the middle entry and proceeds with the half before or after the middle entry if the number is still not found. This algorithm requires, on average, log2("N") comparisons, where "N" is the list's length. Similarly, the merge sort algorithm sorts an unsorted list by dividing the list into halves and sorting these first before merging the results. Merge sort algorithms typically require a time approximately proportional to . The base of the logarithm is not specified here, because the result only changes by a constant factor when another base is used. A constant factor, is usually disregarded in the analysis of algorithms under the standard uniform cost model.
p1531
aVA function "f"("x") is said to grow logarithmically if "f"("x") is (exactly or approximately) proportional to the logarithm of "x". (Biological descriptions of organism growth, however, use this term for an exponential function.) For example, any natural number "N" can be represented in binary form in no more than bits. In other words, the amount of memory needed to store "N" grows logarithmically with "N".
p1532
aVEntropy and chaos.
p1533
aVEntropy is broadly a measure of the disorder of some system. In statistical thermodynamics, the entropy "S" of some physical system is defined as
p1534
aVformula_54
p1535
aVThe sum is over all possible states "i" of the system in question, such as the positions of gas particles in a container. Moreover, "p""i" is the probability that the state "i" is attained and "k" is the Boltzmann constant. Similarly, entropy in information theory measures the quantity of information. If a message recipient may expect any one of "N" possible messages with equal likelihood, then the amount of information conveyed by any one such message is quantified as log2("N") bits.
p1536
aVLyapunov exponents use logarithms to gauge the degree of chaoticity of a dynamical system. For example, for a particle moving on an oval billiard table, even small changes of the initial conditions result in very different paths of the particle. Such systems are chaotic in a deterministic way, because small measurement errors of the initial state predictably lead to largely different final states. At least one Lyapunov exponent of a deterministically chaotic system is positive.
p1537
aVFractals.
p1538
aVLogarithms occur in definitions of the dimension of fractals. Fractals are geometric objects that are self-similar: small parts reproduce, at least roughly, the entire global structure. The Sierpinski triangle (pictured) can be covered by three copies of itself, each having sides half the original length. This makes the Hausdorff dimension of this structure log(3)/log(2) \u2248 1.58. Another logarithm-based notion of dimension is obtained by counting the number of boxes needed to cover the fractal in question.
p1539
aVMusic.
p1540
aVLogarithms are related to musical tones and intervals. In equal temperament, the frequency ratio depends only on the interval between two tones, not on the specific frequency, or pitch, of the individual tones. For example, the note "A" has a frequency of 440 Hz and "B-flat" has a frequency of 466 Hz. The interval between "A" and "B-flat" is a semitone, as is the one between "B-flat" and "B" (frequency 493 Hz). Accordingly, the frequency ratios agree:
p1541
aVformula_55
p1542
aVTherefore, logarithms can be used to describe the intervals: an interval is measured in semitones by taking the logarithm of the frequency ratio, while the logarithm of the frequency ratio expresses the interval in cents, hundredths of a semitone. The latter is used for finer encoding, as it is needed for non-equal temperaments.
p1543
aVNumber theory.
p1544
aVNatural logarithms are closely linked to counting prime numbers (2, 3, 5, 7, 11, ...), an important topic in number theory. For any integer "x", the quantity of prime numbers less than or equal to "x" is denoted \u03c0("x"). The prime number theorem asserts that \u03c0("x") is approximately given by
p1545
aVformula_56
p1546
aVin the sense that the ratio of \u03c0("x") and that fraction approaches 1 when "x" tends to infinity. As a consequence, the probability that a randomly chosen number between 1 and "x" is prime is inversely proportional to the number of decimal digits of "x". A far better estimate of \u03c0("x") is given by the
p1547
aVoffset logarithmic integral function Li("x"), defined by
p1548
aVformula_57
p1549
aVThe Riemann hypothesis, one of the oldest open mathematical conjectures, can be stated in terms of comparing \u03c0("x") and Li("x"). The Erd\u0151s\u2013Kac theorem describing the number of distinct prime factors also involves the natural logarithm.
p1550
aVThe logarithm of "n" factorial, "n"! = 1 · 2 · ... · "n", is given by
p1551
aVformula_58
p1552
aVThis can be used to obtain Stirling's formula, an approximation of "n"! for large "n".
p1553
aVGeneralizations.
p1554
aVComplex logarithm.
p1555
aVThe complex numbers "a" solving the equation
p1556
aVformula_59
p1557
aVare called "complex logarithms". Here, "z" is a complex number. A complex number is commonly represented as "z = x + iy", where "x" and "y" are real numbers and "i" is the imaginary unit. Such a number can be visualized by a point in the complex plane, as shown at the right. The polar form encodes a non-zero complex number "z" by its absolute value, that is, the distance "r" to the origin, and an angle between the "x" axis and the line passing through the origin and "z". This angle is called the argument of "z". The absolute value "r" of "z" is
p1558
aVformula_60
p1559
aVThe argument is not uniquely specified by "z": both \u03c6 and \u03c6' = \u03c6 + 2\u03c0 are arguments of "z" because adding 2\u03c0 radians or 360 degrees to \u03c6 corresponds to "winding" around the origin counter-clock-wise by a turn. The resulting complex number is again "z", as illustrated at the right. However, exactly one argument \u03c6 satisfies and . It is called the "principal argument", denoted Arg("z"), with a capital "A". (An alternative normalization is .)
p1560
aVUsing trigonometric functions sine and cosine, or the complex exponential, respectively, "r" and \u03c6 are such that the following identities hold:
p1561
aVformula_61
p1562
aVThis implies that the power of "e" equals "z", where
p1563
aVformula_62
p1564
aV\u03c6 is the principal argument Arg("z") and "n" is an arbitrary integer. Any such "a" is called a complex logarithm of "z". There are infinitely many of them, in contrast to the uniquely defined real logarithm. If "n" = 0, "a" is called the "principal value" of the logarithm, denoted Log("z"). The principal argument of any positive real number "x" is 0; hence Log("x") is a real number and equals the real (natural) logarithm. However, the above formulas for logarithms of products and powers do "not" generalize to the principal value of the complex logarithm.
p1565
aVThe illustration at the right depicts Log("z"). The discontinuity, that is, the jump in the hue at the negative part of the "x"- or real axis, is caused by the jump of the principal argument there. This locus is called a branch cut. This behavior can only be circumvented by dropping the range restriction on \u03c6. Then the argument of "z" and, consequently, its logarithm become multi-valued functions.
p1566
aVInverses of other exponential functions.
p1567
aVExponentiation occurs in many areas of mathematics and its inverse function is often referred to as the logarithm. For example, the logarithm of a matrix is the (multi-valued) inverse function of the matrix exponential. Another example is the "p"-adic logarithm, the inverse function of the "p"-adic exponential. Both are defined via Taylor series analogous to the real case. In the context of differential geometry, the exponential map maps the tangent space at a point of a manifold to a neighborhood of that point. Its inverse is also called the logarithmic (or log) map.
p1568
aVIn the context of finite groups exponentiation is given by repeatedly multiplying one group element "b" with itself. The discrete logarithm is the integer "n" solving the equation
p1569
aVformula_63
p1570
aVwhere "x" is an element of the group. Carrying out the exponentiation can be done efficiently, but the discrete logarithm is believed to be very hard to calculate in some groups. This asymmetry has important applications in public key cryptography, such as for example in the Diffie\u2013Hellman key exchange, a routine that allows secure exchanges of cryptographic keys over unsecured information channels. Zech's logarithm is related to the discrete logarithm in the multiplicative group of non-zero elements of a finite field.
p1571
aVFurther logarithm-like inverse functions include the "double logarithm" ln(ln("x")), the "super- or hyper-4-logarithm" (a slight variation of which is called iterated logarithm in computer science), the Lambert W function, and the logit. They are the inverse functions of the double exponential function, tetration, of , and of the logistic function, respectively.
p1572
aVRelated concepts.
p1573
aVFrom the perspective of pure mathematics, the identity expresses a group isomorphism between positive reals under multiplication and reals under addition. Logarithmic functions are the only continuous isomorphisms between these groups. By means of that isomorphism, the Haar measure (Lebesgue measure) "dx" on the reals corresponds to the Haar measure "dx"/"x" on the positive reals. In complex analysis and algebraic geometry, differential forms of the form "df"/"f" are known as forms with logarithmic poles.
p1574
aVThe polylogarithm is the function defined by
p1575
aVformula_64
p1576
aVIt is related to the natural logarithm by Li1("z") = \u2212ln(1 \u2212 "z"). Moreover, Li"s"(1) equals the Riemann zeta function \u03b6("s").
p1577
asS'Field (mathematics)'
p1578
(lp1579
VIn abstract algebra, a field is a nonzero commutative ring that contains a multiplicative inverse for every nonzero element, or equivalently a ring whose nonzero elements form an abelian group under multiplication. As such it is an algebraic structure with notions of addition, subtraction, multiplication, and division satisfying the appropriate abelian group equations and distributive law. The most commonly used fields are the field of real numbers, the field of complex numbers, and the field of rational numbers, but there are also finite fields, fields of functions, algebraic number fields, "p"-adic fields, and so forth.
p1580
aVAny field may be used as the scalars for a vector space, which is the standard general context for linear algebra. The theory of field extensions (including Galois theory) involves the roots of polynomials with coefficients in a field; among other results, this theory leads to impossibility proofs for the classical problems of angle trisection and squaring the circle with a compass and straightedge, as well as a proof of the Abel\u2013Ruffini theorem on the algebraic insolubility of quintic equations. In modern mathematics, the theory of fields (or field theory) plays an essential role in number theory and algebraic geometry.
p1581
aVAs an algebraic structure, every field is a ring, but not every ring is a field. The most important difference is that fields allow for division (though not division by zero), while a ring need not possess multiplicative inverses; for example the integers form a ring, but 2"x" = 1 has no solution in integers. Also, the multiplication operation in a field is required to be commutative. A ring in which division is possible but commutativity is not assumed (such as the quaternions) is called a "division ring" or "skew field". (Historically, division rings were sometimes referred to as fields, while fields were called "commutative fields".)
p1582
aVAs a ring, a field may be classified as a specific type of integral domain, and can be characterized by the following (not exhaustive) chain of class inclusions:
p1583
aV Commutative rings \u2283 integral domains \u2283 integrally closed domains \u2283 unique factorization domains \u2283 principal ideal domains \u2283 Euclidean domains \u2283 fields \u2283 finite fields.
p1584
aVDefinition and illustration.
p1585
aVIntuitively, a field is a set "F" that is a commutative group with respect to two compatible operations, addition and multiplication (the latter excluding zero), with "compatible" being formalized by "distributivity", and the caveat that the additive and the multiplicative identities are distinct (0 \u2260 1).
p1586
aVThe most common way to formalize this is by defining a "field" as a set together with two operations, usually called "addition" and "multiplication", and denoted by + and ·, respectively, such that the following axioms hold; "subtraction" and "division" are defined in terms of the inverse operations of addition and multiplication:
p1587
aVFor all "a", "b" in "F", both "a" + "b" and "a" · "b" are in "F" (or more formally, + and · are binary operations on "F").
p1588
aVFor all "a", "b", and "c" in "F", the following equalities hold: "a" + ("b" + "c") = ("a" + "b") + "c" and "a" · ("b" · "c") = ("a" · "b") · "c".
p1589
aVFor all "a" and "b" in "F", the following equalities hold: "a" + "b" = "b" + "a" and "a" · "b" = "b" · "a".
p1590
aVThere exists an element of "F", called the "additive identity" element and denoted by 0, such that for all "a" in "F", "a" + 0 = "a". Likewise, there is an element, called the "multiplicative identity" element and denoted by 1, such that for all "a" in "F", "a" · 1 = "a". To exclude the trivial ring, the additive identity and the multiplicative identity are required to be distinct.
p1591
aVFor every "a" in "F", there exists an element \u2212"a" in "F", such that . Similarly, for any "a" in "F" other than 0, there exists an element "a"\u22121 in "F", such that . (The elements and are also denoted and "a"/"b", respectively.) In other words, "subtraction" and "division" operations exist.
p1592
aVFor all "a", "b" and "c" in "F", the following equality holds: .
p1593
aVA field is therefore an algebraic structure ; of type , consisting of two abelian groups:
p1594
aVwith · distributing over +.
p1595
aVFirst example: rational numbers.
p1596
aVA simple example of a field is the field of rational numbers, consisting of numbers which can be written as fractions
p1597
aV"a"/"b", where "a" and "b" are integers, and "b" \u2260 0. The additive inverse of such a fraction is simply \u2212"a"/"b", and the multiplicative inverse (provided that "a" \u2260 0) is "b"/"a". To see the latter, note that
p1598
aVformula_1
p1599
aVThe abstractly required field axioms reduce to standard properties of rational numbers, such as the law of distributivity
p1600
aVformula_2
p1601
aVformula_3
p1602
aVformula_4
p1603
aVformula_5
p1604
aVformula_6
p1605
aVor the law of commutativity and law of associativity.
p1606
aVSecond example: a field with four elements.
p1607
aVIn addition to familiar number systems such as the rationals, there are other, less immediate examples of fields. The following example is a field consisting of four elements called O, I, A and B. The notation is chosen such that O plays the role of the additive identity element (denoted 0 in the axioms), and I is the multiplicative identity (denoted 1 above). One can check that all field axioms are satisfied. For example:
p1608
aVA · (B + A) = A · I = A, which equals A · B + A · A = I + B = A, as required by the distributivity.
p1609
aVThe above field is called a finite field with four elements, and can be denoted F4. Field theory is concerned with understanding the reasons for the existence of this field, defined in a fairly ad-hoc manner, and describing its inner structure. For example, from a glance at the multiplication table, it can be seen that any non-zero element (i.e., I, A, and B) is a power of A: A = A1, B = A2 = A · A, and finally I = A3 = A · A · A. This is not a coincidence, but rather one of the starting points of a deeper understanding of (finite) fields.
p1610
aVAlternative axiomatizations.
p1611
aVAs with other algebraic structures, there exist alternative axiomatizations. Because of the relations between the operations, one can alternatively axiomatize a field by explicitly assuming that there are four binary operations (add, subtract, multiply, divide) with axioms relating these, or (by functional decomposition) in terms of two binary operations (add and multiply) and two unary operations (additive inverse and multiplicative inverse), or other variants.
p1612
aVThe usual axiomatization in terms of the two operations of addition and multiplication is brief and allows the other operations to be defined in terms of these basic ones, but in other contexts, such as topology and category theory, it is important to include all operations as explicitly given, rather than implicitly defined (compare topological group). This is because without further assumptions, the implicitly defined inverses may not be continuous (in topology), or may not be able to be defined (in category theory). Defining an inverse requires that one is working with a set, not a more general object.
p1613
aVFor a very economical axiomatization of the field of real numbers, whose primitives are merely a set R with , addition, and a binary relation, "<". See Tarski's axiomatization of the reals.
p1614
aVRelated algebraic structures.
p1615
aVThe axioms imposed above resemble the ones familiar from other algebraic structures. For example, the existence of the binary operation "·", together with its commutativity, associativity, (multiplicative) identity element and inverses are precisely the axioms for an abelian group. In other words, for any field, the subset of nonzero elements "F" \u005c {0}, also often denoted "F"×, is an abelian group ("F"×, ·) usually called multiplicative group of the field. Likewise is an abelian group. The structure of a field is hence the same as specifying such two group structures (on the same set), obeying the distributivity.
p1616
aVImportant other algebraic structures such as rings arise when requiring only part of the above axioms. For example, if the requirement of commutativity of the multiplication operation · is dropped, one gets structures usually called division rings or "skew fields".
p1617
aVRemarks.
p1618
aVBy elementary group theory, applied to the abelian groups ("F"×, ·), and , the additive inverse \u2212"a" and the multiplicative inverse "a"\u22121 are uniquely determined by "a".
p1619
aVSimilar direct consequences from the field axioms include
p1620
aV\u2212("a · b") = (\u2212"a") · b = "a" · (\u2212"b"), in particular \u2212"a" = (\u22121) · "a"
p1621
aVas well as
p1622
aV"a" · 0 = 0.
p1623
aVBoth can be shown by replacing "b" or "c" with 0 in the distributive property.
p1624
aVHistory.
p1625
aVThe concept of "field" was used implicitly by Niels Henrik Abel and Évariste Galois in their work on the solvability of polynomial equations with rational coefficients of degree five or higher.
p1626
aVIn 1857, Karl von Staudt published his Algebra of Throws which provided a geometric model satisfying the axioms of a field. This construction has been frequently recalled as a contribution to the foundations of mathematics.
p1627
aVIn 1871, Richard Dedekind introduced, for a set of real or complex numbers which is closed under the four arithmetic operations, the German word "Körper", which means "body" or "corpus" (to suggest an organically closed entity), hence the common use of the letter "K" to denote a field. He also defined rings (then called "order" or "order-modul"), but the term "a ring" ("Zahlring") was invented by Hilbert. In 1893, Eliakim Hastings Moore called the concept "field" in English.
p1628
aVIn 1881, Leopold Kronecker defined what he called a "domain of rationality", which is indeed a field of polynomials in modern terms. In 1893, Heinrich M. Weber gave the first clear definition of an abstract field. In 1910, Ernst Steinitz published the very influential paper "Algebraische Theorie der Körper" (). In this paper he axiomatically studies the properties of fields and defines many important field theoretic concepts like prime field, perfect field and the transcendence degree of a field extension.
p1629
aVEmil Artin developed the relationship between groups and fields in great detail from 1928 through 1942.
p1630
aVExamples.
p1631
aVRationals and algebraic numbers.
p1632
aVThe field of rational numbers Q has been introduced above. A related class of fields very important in number theory are algebraic number fields. We will first give an example, namely the field Q(\u03b6) consisting of numbers of the form
p1633
aV"a" + "b"\u03b6
p1634
aVwith "a", "b" \u2208 Q, where \u03b6 is a primitive third root of unity, i.e., a complex number satisfying \u03b63 = 1, . This field extension can be used to prove a special case of Fermat's last theorem, which asserts the non-existence of rational nonzero solutions to the equation
p1635
aV"x"3 + "y"3 = "z"3.
p1636
aVIn the language of field extensions detailed below, Q(\u03b6) is a field extension of degree 2. Algebraic number fields are by definition finite field extensions of Q, that is, fields containing Q having finite dimension as a Q-vector space. 
p1637
aVReals, complex numbers, and "p"-adic numbers.
p1638
aVTake the real numbers R, under the usual operations of addition and multiplication. When the real numbers are given the usual ordering, they form a "complete ordered field"; it is this structure which provides the foundation for most formal treatments of calculus.
p1639
aVThe complex numbers C consist of expressions
p1640
aV"a" + "b"i
p1641
aVwhere i is the imaginary unit, i.e., a (non-real) number satisfying i2 = \u22121.
p1642
aVAddition and multiplication of real numbers are defined in such a way that all field axioms hold for C. For example, the distributive law enforces
p1643
aV("a" + "b"i)·("c" + "d"i) = "ac" + "bc"i + "ad"i + "bd"i2, which equals "ac"\u2212"bd" + ("bc" + "ad")i.
p1644
aVThe real numbers can be constructed by completing the rational numbers, i.e., filling the "gaps": for example \u221a2 is such a gap. By a formally very similar procedure, another important class of fields, the field of "p"-adic numbers Q"p" is built. It is used in number theory and "p"-adic analysis.
p1645
aVHyperreal numbers and superreal numbers extend the real numbers with the addition of infinitesimal and infinite numbers.
p1646
aVConstructible numbers.
p1647
aVIn antiquity, several geometric problems concerned the (in)feasibility of constructing certain numbers with compass and straightedge. For example it was unknown to the Greeks that it is in general impossible to trisect a given angle. Using the field notion and field theory allows these problems to be settled. To do so, the field of constructible numbers is considered. It contains, on the plane, the points 0 and 1, and all complex numbers that can be constructed from these two by a finite number of construction steps using only compass and straightedge. This set, endowed with the usual addition and multiplication of complex numbers does form a field. For example, multiplying two (real) numbers "r"1 and "r"2 that have already been constructed can be done using construction at the right, based on the intercept theorem. This way, the obtained field "F" contains all rational numbers, but is bigger than Q, because for any "f" \u2208 "F", the square root of "f" is also a constructible number.
p1648
aVA closely related concept is that of a Euclidean field, namely an ordered field whose positive elements are closed under square root. The real constructible numbers form the least Euclidean field, and the Euclidean fields are precisely the ordered extensions thereof.
p1649
aVFinite fields.
p1650
aV"Finite fields" (also called "Galois fields") are fields with finitely many elements. The above introductory example F4 is a field with four elements. F2 consists of two elements, 0 and 1. This is the smallest field, because by definition a field has at least two distinct elements 1 \u2260 0. Interpreting the addition and multiplication in this latter field as XOR and AND operations, this field finds applications in computer science, especially in cryptography and coding theory.
p1651
aVIn a finite field there is necessarily an integer "n" such that ("n" repeated terms) equals 0. It can be shown that the smallest such "n" must be a prime number, called the "characteristic" of the field. If a (necessarily infinite) field has the property that is never zero, for any number of summands, such as in Q, for example, the characteristic is said to be zero.
p1652
aVA basic class of finite fields are the fields F"p" with "p" elements ("p" a prime number):
p1653
aVF"p" = Z/"p"Z = {0, 1, ..., "p" \u2212 1},
p1654
aVwhere the operations are defined by performing the operation in the set of integers Z, dividing by "p" and taking the remainder; see modular arithmetic. A field "K" of characteristic "p" necessarily contains F"p", and therefore may be viewed as a vector space over F"p", of finite dimension if "K" is finite. Thus a finite field "K" has prime power order, i.e., "K" has "q" = "p""n" elements (where "n" > 0 is the number of elements in a basis of "K" over F"p"). By developing more field theory, in particular the notion of the splitting field of a polynomial "f" over a field "K", which is the smallest field containing "K" and all roots of "f", one can show that two finite fields with the same number of elements are isomorphic, i.e., there is a one-to-one mapping of one field onto the other that preserves multiplication and addition. Thus we may speak of "the" finite field with "q" elements, usually denoted by F"q" or GF("q").
p1655
aVArchimedean fields.
p1656
aVAn Archimedean field is an ordered field such that for each element there exists a finite expression whose value is greater than that element, that is, there are no infinite elements. Equivalently, the field contains no infinitesimals; or, the field is isomorphic to a subfield of the reals. A necessary condition for an ordered field to be complete is that it be Archimedean, since in any non-Archimedean field there is neither a greatest infinitesimal nor a least positive rational, whence the sequence 1/2, 1/3, 1/4, \u2026, every element of which is greater than every infinitesimal, has no limit. (And since every proper subfield of the reals also contains such gaps, up to isomorphism the reals form the unique complete ordered field.)
p1657
aVField of functions.
p1658
aVGiven a geometric object "X", one can consider functions on such objects. Adding and multiplying them pointwise, i.e., ("f"·"g")("x") = "f"("x") · "g"("x") this leads to a field. However, for having multiplicative inverses, one has to consider partial function, which, almost everywhere, are defined and have a non-zero value.
p1659
aVIf "X" is an algebraic variety over a field "F", then the rational functions "X" \u2192 "F" form a field, the function field of "X". This field consists of the functions that are defined and are the quotient of two polynomial functions outside some subvariety. Likewise, if "X" is a Riemann surface, then the meromorphic functions "S" \u2192 C form a field. Under certain circumstances, namely when "S" is compact, "S" can be reconstructed from this field.
p1660
aVLocal and global fields.
p1661
aVAnother important distinction in the realm of fields, especially with regard to number theory, are local fields and global fields. Local fields are completions of global fields at a given place. For example, Q is a global field, and the attached local fields are Q"p" and R (Ostrowski's theorem). Algebraic number fields and function fields over F"q" are further global fields. Studying arithmetic questions in global fields may sometimes be done by looking at the corresponding questions locally\u2014this technique is called local-global principle.
p1662
aVConstructing fields.
p1663
aVClosure operations.
p1664
aVAssuming the axiom of choice, for every field "F", there exists a field , called the algebraic closure of "F", which contains "F", is algebraic over "F", which means that any element "x" of satisfies a polynomial equation
p1665
aV"f""n""x""n" + "f""n"\u22121"x""n"\u22121 + ··· + "f"1"x" + "f"0 = 0, with coefficients "f""n", ..., "f"0 \u2208 "F",
p1666
aVand is algebraically closed, i.e., any such polynomial does have at least one solution in . The algebraic closure is unique up to isomorphism inducing the identity on "F". However, in many circumstances in mathematics, it is not appropriate to treat as being uniquely determined by "F", since the isomorphism above is not itself unique. In these cases, one refers to such a as "an" algebraic closure of "F". A similar concept is the separable closure, containing all roots of separable polynomials, instead of all polynomials.
p1667
aVFor example, if "F" = Q, the algebraic closure is also called "field of algebraic numbers". The field of algebraic numbers is an example of an algebraically closed field of characteristic zero; as such it satisfies the same first-order sentences as the field of complex numbers C.
p1668
aVIn general, all algebraic closures of a field are isomorphic. However, there is in general no preferable isomorphism between two closures. Likewise for separable closures.
p1669
aVSubfields and field extensions.
p1670
aVA "subfield" is, informally, a small field contained in a bigger one. Formally, a subfield "E" of a field "F" is a subset containing 0 and 1, closed under the operations +, \u2212, · and multiplicative inverses and with its own operations defined by restriction. For example, the real numbers contain several interesting subfields: the real algebraic numbers, the computable numbers and the rational numbers are examples.
p1671
aVThe notion of field extension lies at the heart of field theory, and is crucial to many other algebraic domains. A field extension "F" / "E" is simply a field "F" and a subfield "E" \u2282 "F". Constructing such a field extension "F" / "E" can be done by "adding new elements" or "adjoining elements" to the field "E". For example, given a field "E", the set "F" = "E"("X") of rational functions, i.e., equivalence classes of expressions of the kind
p1672
aVformula_7
p1673
aVwhere "p"("X") and "q"("X") are polynomials with coefficients in "E", and "q" is not the zero polynomial, forms a field. This is the simplest example of a transcendental extension of "E". It also is an example of a domain (the ring of polynomials formula_8 in this case) being embedded into its field of fractions formula_9.
p1674
aVThe ring of formal power series formula_10 is also a domain, and again the (equivalence classes of) fractions of the form "p"("X")/ "q"("X") where "p" and "q" are elements of formula_10 form the field of fractions for formula_10. This field is actually the ring of Laurent series over the field "E", denoted formula_13.
p1675
aVIn the above two cases, the added symbol "X" and its powers did not interact with elements of "E". It is possible however that the adjoined symbol may interact with "E". This idea will be illustrated by adjoining an element to the field of real numbers R. As explained above, C is an extension of R. C can be obtained from R by adjoining the imaginary symbol i which satisfies i2 = \u22121. The result is that R=C. This is different from adjoining the symbol "X" to R, because in that case, the powers of "X" are all distinct objects, but here, i2=\u22121 is actually an element of R.
p1676
aVAnother way to view this last example is to note that i is a zero of the polynomial "p"("X") = "X"2 + 1. The quotient ring formula_14 can be mapped onto C using the map formula_15. Since the ideal ("X"2+1) is generated by a polynomial irreducible over R, the ideal is maximal, hence the quotient ring is a field. This nonzero ring map from the quotient to C is necessarily an isomorphism of rings.
p1677
aVThe above construction generalises to any irreducible polynomial in the polynomial ring "E"["X"], i.e., a polynomial "p"("X") that cannot be written as a product of non-constant polynomials. The quotient ring "F" = "E"["X"] / ("p"("X")), is again a field.
p1678
aVAlternatively, constructing such field extensions can also be done, if a bigger container is already given. Suppose given a field "E", and a field "G" containing "E" as a subfield, for example "G" could be the algebraic closure of "E". Let "x" be an element of "G" not in "E". Then there is a smallest subfield of "G" containing "E" and "x", denoted "F" = "E"("x") and called "field extension F / E generated by x in G". Such extensions are also called "simple extensions". Many extensions are of this type; see the primitive element theorem. For instance, Q("i") is the subfield of C consisting of all numbers of the form "a" + "bi" where both "a" and "b" are rational numbers.
p1679
aVOne distinguishes between extensions having various qualities. For example, an extension "K" of a field "k" is called "algebraic", if every element of "K" is a root of some polynomial with coefficients in "k". Otherwise, the extension is called "transcendental". The aim of Galois theory is the study of "algebraic extensions" of a field.
p1680
aVRings vs fields.
p1681
aVAdding multiplicative inverses to an integral domain "R" yields the field of fractions of "R". For example, the field of fractions of the integers Z is just Q.
p1682
aVAlso, the field "F"("X") is the quotient field of the ring of polynomials "F"["X"]. 
p1683
aVAnother method to obtain a field from a commutative ring "R" is taking the quotient , where "m" is any maximal ideal of "R". The above construction of "F" = "E"["X"] / ("p"("X")), is an example, because the irreducibility of the polynomial "p"("X") is equivalent to the maximality of the ideal generated by this polynomial. Another example are the finite fields F"p" = Z / "p"Z.
p1684
aVUltraproducts.
p1685
aVIf "I" is an index set, "U" is an ultrafilter on "I", and "F""i" is a field for every "i" in "I", the ultraproduct of the "F""i" with respect to "U" is a field.
p1686
aVFor example, a non-principal ultraproduct of finite fields is a pseudo finite field; i.e., a PAC field having exactly one extension of any degree.
p1687
aVGalois theory.
p1688
aVGalois theory aims to study the algebraic extensions of a field by studying the symmetry in the arithmetic operations of addition and multiplication. The fundamental theorem of Galois theory shows that there is a strong relation between the structure of the symmetry group and the set of algebraic extensions.
p1689
aVIn the case where "F" / "E" is a finite (Galois) extension, Galois theory studies the algebraic extensions of "E" that are subfields of "F". Such fields are called intermediate extensions. Specifically, the Galois group of "F" over "E", denoted Gal("F"/"E"), is the group of field automorphisms of "F" that are trivial on "E" (i.e., the bijections \u03c3 : "F" \u2192 "F" that preserve addition and multiplication and that send elements of "E" to themselves), and the fundamental theorem of Galois theory states that there is a one-to-one correspondence between subgroups of Gal("F"/"E") and the set of intermediate extensions of the extension "F"/"E". The theorem, in fact, gives an explicit correspondence and further properties.
p1690
aVTo study all (separable) algebraic extensions of "E" at once, one must consider the absolute Galois group of "E", defined as the Galois group of the separable closure, "E"sep, of "E" over "E" (i.e., Gal("E"sep/"E"). It is possible that the degree of this extension is infinite (as in the case of "E" = Q). It is thus necessary to have a notion of Galois group for an infinite algebraic extension. The Galois group in this case is obtained as a "limit" (specifically an inverse limit) of the Galois groups of the finite Galois extensions of "E". In this way, it acquires a topology. The fundamental theorem of Galois theory can be generalized to the case of infinite Galois extensions by taking into consideration the topology of the Galois group, and in the case of "E"sep/"E" it states that there this a one-to-one correspondence between "closed" subgroups of Gal("E"sep/"E") and the set of all separable algebraic extensions of "E" (technically, one only obtains those separable algebraic extensions of "E" that occur as subfields of the "chosen" separable closure "E"sep, but since all separable closures of "E" are isomorphic, choosing a different separable closure would give the same Galois group and thus an "equivalent" set of algebraic extensions).
p1691
aVGeneralizations.
p1692
aVThere are also proper classes with field structure, which are sometimes called Fields, with a capital F:
p1693
aVIn a different direction, differential fields are fields equipped with a derivation. For example, the field R("X"), together with the standard derivative of polynomials forms a differential field. These fields are central to differential Galois theory. Exponential fields, meanwhile, are fields equipped with an exponential function that provides a homomorphism between the additive and multiplicative groups within the field. The usual exponential function makes the real and complex numbers exponential fields, denoted Rexp and Cexp respectively.
p1694
aVGeneralizing in a more categorical direction yields the field with one element and related objects.
p1695
aVExponentiation.
p1696
aVOne does not in general study generalizations of fields with "three" binary operations. The familiar addition/subtraction, multiplication/division, exponentiation/root-extraction operations from the natural numbers to the reals, each built up in terms of iteration of the last, mean that generalizing exponentiation as a binary operation is tempting, but has generally not proven fruitful; instead, an exponential field assumes a unary exponential function from the additive group to the multiplicative group, not a partially defined binary function. Note that the exponential operation of formula_16 is neither associative nor commutative, nor has a unique inverse (formula_17 are both square roots of 4, for instance), unlike addition and multiplication, and further is not defined for many pairs\u2014for example, formula_18 does not define a single number. These all show that even for rational numbers exponentiation is not nearly as well-behaved as addition and multiplication, which is why one does not in general axiomatize exponentiation.
p1697
aVApplications.
p1698
aVThe concept of a field is of use, for example, in defining vectors and matrices, two structures in linear algebra whose components can be elements of an arbitrary field.
p1699
aVFinite fields are used in number theory, Galois theory, cryptography, coding theory and combinatorics; and again the notion of algebraic extension is an important tool.
p1700
asS'Absolute value'
p1701
(lp1702
VIn mathematics, the absolute value (or modulus) of a real number  is the non-negative value of  without regard to its sign. Namely, for a positive , for a negative  (in which case is positive), and . For example, the absolute value of 3 is 3, and the absolute value of \u22123 is also 3. The absolute value of a number may be thought of as its distance from zero.
p1703
aVGeneralisations of the absolute value for real numbers occur in a wide variety of mathematical settings. For example an absolute value is also defined for the complex numbers, the quaternions, ordered rings, fields and vector spaces. The absolute value is closely related to the notions of magnitude, distance, and norm in various mathematical and physical contexts.
p1704
aVTerminology and notation.
p1705
aVIn 1806, Jean-Robert Argand introduced the term "module", meaning "unit of measure" in French, specifically for the "complex" absolute value, and it was borrowed into English in 1866 as the Latin equivalent "modulus". The term "absolute value" has been used in this sense from at least 1806 in French and 1857 in English. The notation , with a vertical bar on each side, was introduced by Karl Weierstrass in 1841. Other names for "absolute value" include "numerical value" and "magnitude". 
p1706
aVThe same notation is used with sets to denote cardinality; the meaning depends on context.
p1707
aVDefinition and properties.
p1708
aVReal numbers.
p1709
aVFor any real number  the absolute value or modulus of  is denoted by (a vertical bar on each side of the quantity) and is defined as
p1710
aVformula_1
p1711
aVAs can be seen from the above definition, the absolute value of  is always either positive or zero, but never negative.
p1712
aVFrom an analytic geometry point of view, the absolute value of a real number is that number's distance from zero along the real number line, and more generally the absolute value of the difference of two real numbers is the distance between them. Indeed the notion of an abstract distance function in mathematics can be seen to be a generalisation of the absolute value of the difference (see "Distance" below).
p1713
aVSince the square root notation without sign represents the "positive" square root, it follows that
p1714
aVwhich is sometimes used as a definition of absolute value of real numbers.
p1715
aVThe absolute value has the following four fundamental properties:
p1716
aVOther important properties of the absolute value include:
p1717
aVTwo other useful properties concerning inequalities are:
p1718
aVformula_2
p1719
aVformula_3 or formula_4
p1720
aVThese relations may be used to solve inequalities involving absolute values. For example:
p1721
aVAbsolute value is used to define the absolute difference, the standard metric on the real numbers.
p1722
aVComplex numbers.
p1723
aVSince the complex numbers are not ordered, the definition given above for the real absolute value cannot be directly generalised for a complex number. However the geometric interpretation of the absolute value of a real number as its distance from 0 can be generalised. The absolute value of a complex number is defined as its distance in the complex plane from the origin using the Pythagorean theorem. More generally the absolute value of the difference of two complex numbers is equal to the distance between those two complex numbers.
p1724
aVFor any complex number
p1725
aVformula_5
p1726
aVwhere and are real numbers, the absolute value or modulus of  is denoted and is given by
p1727
aVformula_6
p1728
aVWhen the imaginary part is zero this is the same as the absolute value of the real number .
p1729
aVWhen a complex number  is expressed in polar form as
p1730
aVformula_7
p1731
aVwith and \u03b8 real, its absolute value is
p1732
aVformula_8.
p1733
aVThe absolute value of a complex number can be written in the complex analogue of equation (1) above as:
p1734
aVformula_9
p1735
aVwhere is the complex conjugate of .
p1736
aVNotice that, contrary to equation (1):
p1737
aVformula_10.
p1738
aVThe complex absolute value shares all the properties of the real absolute value given in equations (2)\u2013(11) above.
p1739
aVSince the positive reals form a subgroup of the complex numbers under multiplication, we may think of absolute value as an endomorphism of the multiplicative group of the complex numbers.
p1740
aVAbsolute value function.
p1741
aVThe real absolute value function is continuous everywhere. It is differentiable everywhere except for  = 0. It is monotonically decreasing on the interval and monotonically increasing on the interval . Since a real number and its opposite have the same absolute value, it is an even function, and is hence not invertible.
p1742
aVBoth the real and complex functions are idempotent.
p1743
aVIt is a piecewise linear, convex function.
p1744
aVRelationship to the sign function.
p1745
aVThe absolute value function of a real number returns its value irrespective of its sign, whereas the sign (or signum) function returns a number's sign irrespective of its value. The following equations show the relationship between these two functions:
p1746
aVformula_11
p1747
aVor
p1748
aVformula_12
p1749
aVand for ,
p1750
aVformula_13
p1751
aVDerivative.
p1752
aVThe real absolute value function has a derivative for every , but is not differentiable at . Its derivative for is given by the step function
p1753
aVformula_14
p1754
aVThe subdifferential of  at  is the interval .
p1755
aVThe complex absolute value function is continuous everywhere but complex differentiable "nowhere" because it violates the Cauchy\u2013Riemann equations.
p1756
aVThe second derivative of  with respect to  is zero everywhere except zero, where it does not exist. As a generalised function, the second derivative may be taken as two times the Dirac delta function.
p1757
aVAntiderivative.
p1758
aVThe antiderivative (indefinite integral) of the absolute value function is
p1759
aVformula_15
p1760
aVwhere is an arbitrary constant of integration.
p1761
aVDistance.
p1762
aVThe absolute value is closely related to the idea of distance. As noted above, the absolute value of a real or complex number is the distance from that number to the origin, along the real number line, for real numbers, or in the complex plane, for complex numbers, and more generally, the absolute value of the difference of two real or complex numbers is the distance between them.
p1763
aVThe standard Euclidean distance between two points
p1764
aVformula_16
p1765
aVand
p1766
aVformula_17
p1767
aVin Euclidean -space is defined as:
p1768
aVformula_18
p1769
aVThis can be seen to be a generalisation of , since if and are real, then by equation (1),
p1770
aVformula_19
p1771
aVWhile if
p1772
aVformula_20
p1773
aVand
p1774
aVformula_21
p1775
aVare complex numbers, then
p1776
aVThe above shows that the "absolute value" distance for the real numbers or the complex numbers, agrees with the standard Euclidean distance they inherit as a result of considering them as the one and two-dimensional Euclidean spaces respectively.
p1777
aVThe properties of the absolute value of the difference of two real or complex numbers: non-negativity, identity of indiscernibles, symmetry and the triangle inequality given above, can be seen to motivate the more general notion of a distance function as follows:
p1778
aVA real valued function on a set is called a metric (or a "distance function") on , if it satisfies the following four axioms:
p1779
aVGeneralizations.
p1780
aVOrdered rings.
p1781
aVThe definition of absolute value given for real numbers above can be extended to any ordered ring. That is, if  is an element of an ordered ring "R", then the absolute value of , denoted by , is defined to be:
p1782
aVformula_22
p1783
aVwhere is the additive inverse of , and 0 is the additive identity element.
p1784
aVFields.
p1785
aVThe fundamental properties of the absolute value for real numbers given in (2)\u2013(5) above, can be used to generalise the notion of absolute value to an arbitrary field, as follows.
p1786
aVA real-valued function  on a field  is called an "absolute value" (also a "modulus", "magnitude", "value", or "valuation") if it satisfies the following four axioms:
p1787
aVWhere 0 denotes the additive identity element of . It follows from positive-definiteness and multiplicativeness that , where 1 denotes the multiplicative identity element of . The real and complex absolute values defined above are examples of absolute values for an arbitrary field.
p1788
aVIf is an absolute value on , then the function  on , defined by , is a metric and the following are equivalent:
p1789
aVAn absolute value which satisfies any (hence all) of the above conditions is said to be non-Archimedean, otherwise it is said to be Archimedean.
p1790
aVVector spaces.
p1791
aVAgain the fundamental properties of the absolute value for real numbers can be used, with a slight modification, to generalise the notion to an arbitrary vector space.
p1792
aVA real-valued function on a vector space  over a field , represented as , is called an absolute value, but more usually a norm, if it satisfies the following axioms:
p1793
aVFor all  in , and , in ,
p1794
aVThe norm of a vector is also called its "length" or "magnitude".
p1795
aVIn the case of Euclidean space , the function defined by
p1796
aVformula_31
p1797
aVis a norm called the Euclidean norm. When the real numbers  are considered as the one-dimensional vector space , the absolute value is a norm, and is the -norm (see Lp space) for any . In fact the absolute value is the "only" norm on , in the sense that, for every norm on , . The complex absolute value is a special case of the norm in an inner product space. It is identical to the Euclidean norm, if the complex plane is identified with the Euclidean plane .
p1798
asS'Module (mathematics)'
p1799
(lp1800
VIn abstract algebra, the concept of a module over a ring is a generalization of the notion of vector space over a field, wherein the corresponding scalars are the elements of an arbitrary given ring.
p1801
aVThus, a module, like a vector space, is an additive abelian group; a product is defined between elements of the ring and elements of the module that is distributive over the addition operation of each parameter and is compatible with the ring multiplication. 
p1802
aVModules are very closely related to the representation theory of groups. They are also one of the central notions of commutative algebra and homological algebra, and are used widely in algebraic geometry and algebraic topology.
p1803
aVIntroduction.
p1804
aVMotivation.
p1805
aVIn a vector space, the set of scalars forms a field and acts on the vectors by scalar multiplication, subject to certain axioms such as the distributive law. In a module, the scalars need only be a ring, so the module concept represents a significant generalization. In commutative algebra, both ideals and quotient rings are modules, so that many arguments about ideals or quotient rings can be combined into a single argument about modules. In non-commutative algebra the distinction between left ideals, ideals, and modules becomes more pronounced, though some ring theoretic conditions can be expressed either about left ideals or left modules.
p1806
aVMuch of the theory of modules consists of extending as many as possible of the desirable properties of vector spaces to the realm of modules over a "well-behaved" ring, such as a principal ideal domain. However, modules can be quite a bit more complicated than vector spaces; for instance, not all modules have a basis, and even those that do, free modules, need not have a unique rank if the underlying ring does not satisfy the invariant basis number condition, unlike vector spaces, which always have a (possibly infinite) basis whose cardinality is then unique. (These last two assertions require the axiom of choice in general, but not in the case of finite-dimensional spaces, or certain well-behaved infinite-dimensional spaces such as L"p" spaces.)
p1807
aVFormal definition.
p1808
aVSuppose that "R" is a ring and 1"R" is its multiplicative identity.
p1809
aVA '"left "R"-module"' "M" consists of an abelian group and an operation such that for all "r", "s" in "R" and "x", "y" in "M", we have:
p1810
aVThe operation of the ring on "M" is called "scalar multiplication", and is usually written by juxtaposition, i.e. as "rx" for "r" in "R" and "x" in "M". The notation "R""M" indicates a left "R"-module "M". A '"right "R"-module"' "M" or "M""R" is defined similarly, except that the ring acts on the right; i.e., scalar multiplication takes the form , and the above axioms are written with scalars "r" and "s" on the right of "x" and "y". 
p1811
aVAuthors who do not require rings to be unital omit condition 4 above in the definition of an "R"-module, and so would call the structures defined above "unital left "R"-modules". In this article, consistent with the glossary of ring theory, all rings and modules are assumed to be unital.
p1812
aVIf one writes the scalar action as "f""r" so that , and "f" for the map that takes each "r" to its corresponding map "f""r" , then the first axiom states that every "f""r" is a group homomorphism of "M", and the other three axioms assert that the map given by is a ring homomorphism from "R" to the endomorphism ring End("M"). Thus a module is a ring action on an abelian group (cf. group action. Also consider monoid action of multiplicative structure of "R"). In this sense, module theory generalizes representation theory, which deals with group actions on vector spaces, or equivalently group ring actions.
p1813
aVA bimodule is a module that is a left module and a right module such that the two multiplications are compatible.
p1814
aVIf "R" is commutative, then left "R"-modules are the same as right "R"-modules and are simply called "R"-modules.
p1815
aVSubmodules and homomorphisms.
p1816
aVSuppose "M" is a left "R"-module and "N" is a subgroup
p1817
aVof "M". Then "N" is a submodule (or "R"-submodule, to be more explicit) if, for any "n" in "N" and any "r" in "R", the product "rn" is in "N" (or "nr" for a right module).
p1818
aVThe set of submodules of a given module "M", together with the two binary operations + and \u2229, forms a lattice which satisfies the modular law:
p1819
aVGiven submodules "U", "N"1, "N"2 of "M" such that "N"1 \u2282 "N"2, then the following two submodules are equal: ("N"1 + "U") \u2229 "N"2 = "N"1 + ("U" \u2229 "N"2).
p1820
aVIf "M" and "N" are left "R"-modules, then a map 
p1821
aV"f" : "M" \u2192 "N" is a '"homomorphism of "R"-modules"' if, for any "m", "n" in "M"
p1822
aVand "r", "s" in "R", 
p1823
aVformula_5
p1824
aVThis, like any homomorphism of mathematical 
p1825
aVobjects, is just a mapping which preserves the structure of the objects.
p1826
aVAnother name for a homomorphism of modules over "R" is an "R"-linear map.
p1827
aVA bijective module homomorphism is an isomorphism of modules, and the two modules are called "isomorphic". Two isomorphic modules are identical for all practical purposes, differing solely in the notation for their elements.
p1828
aVThe kernel of a module homomorphism "f" : "M" \u2192 "N" is the submodule of "M" consisting of all elements that are sent to zero by "f". The isomorphism theorems familiar from groups and vector spaces are also valid for "R"-modules.
p1829
aVThe left "R"-modules, together with their module homomorphisms, form a category, written as "R"-Mod. This is an abelian category.
p1830
aVTypes of modules.
p1831
aVFinitely generated. An "R"-module "M" is finitely generated if there exist finitely many elements "x"1...,"x""n" in "M" such that every element of "M" is a linear combination of those elements with coefficients from the ring "R".
p1832
aVCyclic. A module is called a cyclic module if it is generated by one element.
p1833
aVFree. A free "R"-module is a module that has a basis, or equivalently, one that is isomorphic to a direct sum of copies of the ring "R". These are the modules that behave very much like vector spaces.
p1834
aVProjective. Projective modules are direct summands of free modules and share many of their desirable properties.
p1835
aVInjective. Injective modules are defined dually to projective modules.
p1836
aVFlat. A module is called flat if taking the tensor product of it with any exact sequence of "R"-modules preserves exactness.
p1837
aVTorsionless module. A module is called torsionless if it embeds into its algebraic dual.
p1838
aVSimple. A simple module "S" is a module that is not {0} and whose only submodules are {0} and "S". Simple modules are sometimes called "irreducible".
p1839
aVSemisimple. A semisimple module is a direct sum (finite or not) of simple modules. Historically these modules are also called "completely reducible".
p1840
aVIndecomposable. An indecomposable module is a non-zero module that cannot be written as a direct sum of two non-zero submodules. Every simple module is indecomposable, but there are indecomposable modules which are not simple (e.g. uniform modules).
p1841
aVFaithful. A faithful module "M" is one where the action of each "r" \u2260 0 in "R" on "M" is nontrivial (i.e. "rx" \u2260 0 for some "x" in "M"). Equivalently, the annihilator of "M" is the zero ideal.
p1842
aVTorsion-free. A torsion-free module is a module over a ring such that 0 is the only element annihilated by a regular element (non zero-divisor) of the ring.
p1843
aVNoetherian. A Noetherian module is a module which satisfies the ascending chain condition on submodules, that is, every increasing chain of submodules becomes stationary after finitely many steps. Equivalently, every submodule is finitely generated.
p1844
aVArtinian. An Artinian module is a module which satisfies the descending chain condition on submodules, that is, every decreasing chain of submodules becomes stationary after finitely many steps.
p1845
aVGraded. A graded module is a module with a decomposition as a direct sum "M" = \u2a01"x" "M""x" over a graded ring "R" = \u2a01"x" "R""x" such that "R""x""M""y" \u2282 "M""x" + "y" for all "x" and "y".
p1846
aVUniform. A uniform module is a module in which all pairs of nonzero submodules have nonzero intersection.
p1847
aVFurther notions.
p1848
aVRelation to representation theory.
p1849
aVIf "M" is a left "R"-module, then the "action" of an element "r" in "R" is defined to be the map "M" \u2192 "M" that sends each "x" to "rx" (or "xr" in the case of a right module), and is necessarily a group endomorphism of the abelian group ("M",+). The set of all group endomorphisms of "M" is denoted EndZ("M") and forms a ring under addition and composition, and sending a ring element "r" of "R" to its action actually defines a ring homomorphism from "R" to EndZ("M").
p1850
aVSuch a ring homomorphism "R" \u2192 EndZ("M") is called a "representation" of "R" over the abelian group "M"; an alternative and equivalent way of defining left "R"-modules is to say that a left "R"-module is an abelian group "M" together with a representation of "R" over it.
p1851
aVA representation is called "faithful" if and only if the map "R" \u2192 EndZ("M") is injective. In terms of modules, this means that if "r" is an element of "R" such that "rx" = 0 for all "x" in "M", then "r" = 0. Every abelian group is a faithful module over the integers or over some modular arithmetic Z/"n"Z.
p1852
aVGeneralizations.
p1853
aVAny ring "R" can be viewed as a preadditive category with a single object. With this understanding, a left "R"-module is nothing but a (covariant) additive functor from "R" to the category Ab of abelian groups. Right "R"-modules are contravariant additive functors. This suggests that, if "C" is any preadditive category, a covariant additive functor from "C" to Ab should be considered a generalized left module over "C"; these functors form a functor category "C"-Mod which is the natural generalization of the module category "R"-Mod.
p1854
aVModules over "commutative" rings can be generalized in a different direction: take a ringed space ("X", O"X") and consider the sheaves of O"X"-modules; see sheaf of modules for more. These form a category O"X"-Mod, and play an important role in modern algebraic geometry. If "X" has only a single point, then this is a module category in the old sense over the commutative ring O"X"("X").
p1855
aVOne can also consider modules over a semiring. Modules over rings are abelian groups, but modules over semirings are only commutative monoids. Most applications of modules are still possible. In particular, for any semiring "S" the matrices over "S" form a semiring over which the tuples of elements from "S" are a module (in this generalized sense only). This allows a further generalization of the concept of vector space incorporating the semirings from theoretical computer science.
p1856
asS'Law of sines'
p1857
(lp1858
VIn trigonometry, the law of sines, sine law, sine formula, or sine rule is an equation relating the lengths of the sides of any shaped triangle to the sines of its angles. According to the law,
p1859
aVformula_1
p1860
aVwhere "a", "b", and "c" are the lengths of the sides of a triangle, and "A", "B", and "C" are the opposite angles (see the figure to the right), and "D" is the diameter of the triangle's circumcircle. When the last part of the equation is not used, sometimes the law is stated using the reciprocal:
p1861
aV formula_2
p1862
aVThe law of sines can be used to compute the remaining sides of a triangle when two angles and a side are known\u2014a technique known as triangulation. However, calculating this may result in numerical error if an angle is close to 90 degrees. It can also be used when two sides and one of the non-enclosed angles are known. In some such cases, the formula gives two possible values for the enclosed angle, leading to an "ambiguous case".
p1863
aVThe law of sines is one of two trigonometric equations commonly applied to find lengths and angles in scalene triangles, with the other being the law of cosines.
p1864
aVThe law of sines can be generalized to higher dimensions on surfaces with constant curvature 
p1865
aVProof.
p1866
aVVia a triangle area formula.
p1867
aVThe area formula_3 of any triangle can be written as one half of its base times its height. Depending on which side one chooses to be the base, the area can be written as any of
p1868
aVformula_4
p1869
aVMultiplying these by formula_5 gives
p1870
aVformula_6
p1871
aVAlternative proof.
p1872
aVThere are three cases to consider in proving the law of sines. The first is when all angles of the triangle are acute. The second is when one angle is a right angle. The third is when one angle is obtuse.
p1873
aVFor acute triangles.
p1874
aVWe make a triangle with the sides "a", "b", and "c", and angles "A", "B", and "C". Then we draw the altitude from vertex "B" to side "b"; by definition it divides the original triangle into two right angle triangles: "ABR" and "R'BC". Mark this line "h1".
p1875
aVUsing the definition of formula_7 we see that for angle "A" on the right angle triangle "ABR" and "C" on "R'BC" we have:
p1876
aVformula_8
p1877
aVSolving for "h1"
p1878
aVformula_9
p1879
aVEquating "h1" in both expressions:
p1880
aVformula_10
p1881
aVTherefore:
p1882
aVformula_11
p1883
aVDoing the same thing from angle "A" to side "a" we call the altitude "h2" and the two right angle triangles "ABR" and "AR'C":
p1884
aVformula_12
p1885
aVSolving for "h2"
p1886
aVformula_13
p1887
aVTherefore:
p1888
aVformula_14
p1889
aVEquating the formula_15 terms in both expressions above we have:
p1890
aVformula_16
p1891
aVFor right angle triangles.
p1892
aVWe make a triangle with the sides "a", "b", and "c", and angles "A", "B", and "C" where "C" is a right angle. 
p1893
aVSince we already have a right angle triangle we can use the definition of sine:
p1894
aVformula_17
p1895
aVSolving for "c":
p1896
aVformula_18
p1897
aVTherefore:
p1898
aVformula_19
p1899
aVFor the remaining angle "C" we need to remember that it is a right angle and sin "C" = 1 in this case. Therefore we can rewrite "c" = "c" / 1 as:
p1900
aVformula_20
p1901
aVEquating "c" in both the equations above we again have:
p1902
aVformula_16
p1903
aVFor obtuse triangles.
p1904
aVWe make a triangle with the sides "a", "b", and "c", and angles "A", "B", and "C" where "A" is an obtuse angle.In this case if we draw an altitude from any angle other than "A" the point where this line will touch the base of the triangle "ABC" will lie outside any of the lines "a", "b", or "c". We draw the altitude from angle "B", calling it "h1" and create the two extended right triangles "RBA'" and "RBC".
p1905
aVFrom the definition of sine we again have:
p1906
aVformula_22
p1907
aVWe use identity formula_23 to express formula_24 in terms of formula_25. By definition we have:
p1908
aVformula_26
p1909
aVformula_27
p1910
aVformula_28
p1911
aVTherefore:
p1912
aVformula_8
p1913
aVand
p1914
aVformula_30
p1915
aVWe now draw an altitude from "A" calling it "h2" and forming two right triangles "ABR" and "AR'C". 
p1916
aVFrom this we straightforwardly get:
p1917
aVformula_12
p1918
aVand
p1919
aVformula_14
p1920
aVEquating the formula_33 in both equations above we again get:
p1921
aVformula_16
p1922
aVProving the theorem in all cases.
p1923
aVThe ambiguous case.
p1924
aVWhen using the law of sines to find a side of a triangle, an ambiguous case occurs when two separate triangles can be constructed from the data provided (i.e., there are two different possible solutions to the triangle). In the case shown below they are triangles "ABC" and "AB'C'".
p1925
aVGiven a general triangle the following conditions would need to be fulfilled for the case to be ambiguous:
p1926
aVIf all the above conditions are true, then both angles "C" or "C' " produce a valid triangle; meaning both of the following are true:
p1927
aV formula_35
p1928
aVFrom there we can find the corresponding "B" and "b" or "B' "and "b' " if required, where "b" is the side bounded by angles "A" and "C" and "b' "bounded by "A" and "C' ".
p1929
aVWithout further information it is impossible to decide which is the triangle being asked for.
p1930
aVExamples.
p1931
aVThe following are examples of how to solve a problem using the law of sines:
p1932
aVGiven: side "a" = 20, side "c" = 24, and angle "C" = 40°
p1933
aVUsing the law of sines, we conclude that
p1934
aVformula_36
p1935
aVformula_37
p1936
aVOr another example of how to solve a problem using the law of sines:
p1937
aVIf two sides of the triangle are equal to "x" and the length of the third side, the chord, is given as 100 feet and the angle "C" opposite the chord is given in degrees, then
p1938
aV formula_38
p1939
aVand
p1940
aVformula_39
p1941
aVformula_40
p1942
aVRelation to the circumcircle.
p1943
aVIn the identity
p1944
aVformula_41
p1945
aVthe common value of the three fractions is actually the diameter of the triangle's circumcircle. It can be shown that this quantity is equal to
p1946
aVformula_42
p1947
aVwhere "S" is the area of the triangle and "s" is the semiperimeter
p1948
aVformula_43
p1949
aVThe second equality above is essentially Heron's formula.
p1950
aVCurvature.
p1951
aVThe Law of Sines takes on a similar form in the presence of curvature.
p1952
aVSpherical case.
p1953
aVIn the spherical case, the formula is:
p1954
aVformula_44
p1955
aVHere, "\u03b1", "\u03b2", and "\u03b3" are the angles at the center of the sphere subtended by the three arcs of the spherical surface triangle "a," "b," and "c," respectively. "A", "B", and "C" are the surface angles opposite their respective arcs.
p1956
aVIt is easy to see how for small spherical triangles, when the radius of the sphere is much greater than the sides of the triangle, this formula becomes the planar formula at the limit, since
p1957
aVformula_45
p1958
aVand the same for formula_46 and formula_47.
p1959
aV See also Spherical law of cosines and Half-side formula.
p1960
aVHyperbolic case.
p1961
aVIn hyperbolic geometry when the curvature is \u22121, the law of sines becomes
p1962
aVformula_48
p1963
aVIn the special case when "B" is a right angle, one gets
p1964
aVformula_49
p1965
aVwhich is the analog of the formula in Euclidean geometry expressing the sine of an angle as the opposite side divided by the hypotenuse.
p1966
aVSee also hyperbolic triangle.
p1967
aVUnified formulation.
p1968
aVDefine a generalized sine function, depending also on a real parameter formula_50:
p1969
aVformula_51
p1970
aVThe law of sines in constant curvature formula_50 reads as
p1971
aVformula_53
p1972
aVBy substituting formula_54, formula_55, and formula_56, one obtains respectively the Euclidean, spherical, and hyperbolic cases of the law of sines described above.
p1973
aVLet formula_57 indicate the circumference of a circle of radius formula_58 in a space of constant curvature formula_50. Then formula_60. Therefore the law of sines can also be expressed as:
p1974
aVformula_61
p1975
aVThis formulation was discovered by János Bolyai.
p1976
aVHigher dimensions.
p1977
aVFor an "n"-dimensional simplex (i.e., triangle ("n"=2), tetrahedron ("n"=3), pentatope ("n"=4), etc.) in "n"-dimensional Euclidean space, the absolute value of the polar sine of the normal vectors of the faces that meet at a vertex, divided by the hyperarea of the face opposite the vertex is independent of the choice of the vertex. For example, a tetrahedron has four triangular faces. The absolute value of the polar sine of the normals to three of the faces (which share a vertex) divided by the area of the fourth face will not depend upon the choice of the vertex:
p1978
aVformula_62
p1979
aVHistory.
p1980
aVAccording to Ubiratàn D'Ambrosio and Helaine Selin, the spherical law of sines was discovered in the 10th century. It is variously attributed to al-Khujandi, Abul Wafa Bozjani, Nasir al-Din al-Tusi and Abu Nasr Mansur.
p1981
aVAl-Jayyani's "The book of unknown arcs of a sphere" in the 11th century introduced the general law of sines. The plane law of sines was later described in the 13th century by Nas\u012br al-D\u012bn al-T\u016bs\u012b. In his "On the Sector Figure", he stated the law of sines for plane and spherical triangles, and provided proofs for this law.
p1982
aVAccording to Glen Van Brummelen, "The Law of Sines is really Regiomontanus's foundation for his solutions of right-angled triangles in Book IV, and these solutions are in turn the bases for his solutions of general triangles." Regiomontanus was a 15th-century German mathematician.
p1983
asS'Odds'
p1984
(lp1985
VOdds are a numerical expression, always consisting of a pair of numbers, used in both gambling and statistics. In statistics, odds for reflect the likelihood that a particular event will take place. Odds against reflect the likelihood that a particular event will not take place. The usages of the term among statisticians and probabilists on the one hand, versus in the gambling world on the other hand, are not consistent with each other (with the exception of horse racing). Conventionally, gambling odds are expressed in the form "X to Y", where X and Y are numbers, and it is implied that the odds are odds against the event on which the gambler is considering wagering. In both gambling and statistics, the 'odds' are a numerical expression of how likely some possible future event is.
p1986
aVIn gambling, odds represent the ratio between the amounts staked by parties to a wager or bet. Thus, odds of 6 to 1 mean the first party (normally a bookmaker) is staking six times the amount that the second party is. Thus, gambling odds of '6 to 1' mean that there are six possible outcomes in which the event will not take place to every one where it will. In other words, the probability that X will not happen is six times the probability that it will.
p1987
aVIn statistics, the odds for an event E are defined as a simple function of the probability of that possible event E. One drawback of expressing the uncertainty of this possible event as odds for is that to regain the probability requires a calculation. The natural way to interpret odds for (without calculating anything) is as the ratio of events to non-events in the long run. A simple example is that the (statistical) odds for rolling six with a fair die (one of a pair of dice) are 1 to 5. This is because, if one rolls the die many times, and keeps a tally of the results, one expects 1 six event for every 5 times the die does not show six. For example, if we roll the fair die 600 times, we would very much expect something in the neighborhood of 100 sixes, and 500 of the other five possible outcomes. That is a ratio of 100 to 500, or simply 1 to 5. To express the (statistical) odds against, the order of the pair is reversed. Hence the odds against rolling a six with a fair die are 5 to 1. The probability of rolling a six with a fair die is the single number 1/6 or approximately 16.7%.
p1988
aVThe gambling and statistical uses of odds are closely interlinked. If a bet is a fair one, as in a wager between friends, then the odds offered to the gamblers will perfectly reflect relative probabilities. A fair bet that a fair die will roll a six will pay the gambler $5 for a $1 wager (and return the bettor his or her wager) in the case of a six and nothing in any other case. The terms of the bet are fair, because on average, five rolls result in something other than a six, at a cost of $5, for every roll that results in a six and a net payout of $5. The profit and the expense exactly offset one another and so there is no disadvantage to gambling over the long run. If the odds being offered to the gamblers do not correspond to probability in this way then one of the parties to the bet has an advantage over the other. Casinos, for example, offer odds that place themselves at an advantage, which is how they guarantee themselves a profit and survive as businesses. The fairness of a particular gamble is more clear in a game involving relatively pure chance, such as the ping-pong ball method used in state lotteries in the United States. It is much harder to judge the fairness of the odds offered in a wager on a sporting event such as a football match.
p1989
aVHistory.
p1990
aVThe language of odds such as "ten to one" for intuitively estimated risks is found in the sixteenth century, well before the discovery of mathematical probability. Shakespeare wrote:
p1991
aVThe sixteenth century polymath Cardano demonstrated the efficacy of defining odds as the ratio of favourable to unfavourable outcomes (which implies that the probability of an event is given by the ratio of favourable outcomes to the total number of possible outcomes ).
p1992
aVTerminology.
p1993
aVOdds are expressed in the form X to Y, where X and Y are numbers. Usually, the word "to" is replaced by a symbol for ease of use. This is conventionally either a slash or hyphen, although a colon is sometimes seen. Thus, 6/1, 6-1 and 6:1 are all interchangeable.
p1994
aVOdds against.
p1995
aVWhen the probability that the event will not happen is greater than the probability that it will, then the odds are "against" that event happening. Odds of, for example, 6 to 1 are therefore sometimes said to be "6 to 1 "against"". To a gambler, "odds against" means that the amount he or she will win is greater than the amount he himself has staked.
p1996
aVOdds on.
p1997
aV"Odds on" is the opposite of "odds against". It means that the event is more likely to happen than not. This is sometimes expressed with the smaller number first (1 to 2) but more often using the word "on" ("2 to 1 "on"") meaning that the event is twice as likely to happen as not. Note that the gambler who bets at "odds on" and wins will still be in profit, as his stake will be returned. For example, if he bets £2, he will be given £1 plus his returned stake of £2, leaving him £1 in profit.
p1998
aVEven odds.
p1999
aV"Even odds" occur when the probability of an event happening is exactly the same as it not happening. In common parlance, this is a "50-50 chance". Guessing heads or tails on a coin toss is the classic example of an event that has even odds. In gambling, it is commonly referred to as "even money" or simply "evens" (1 to 1, or 2 for 1). "Evens" implies that the payout will be one unit per unit wagered plus the original stake, that is, "double-your-money".
p2000
aVBetter than/worse than evens.
p2001
aVThe term "better than evens" (or "worse than evens") varies in meaning depending on context. Looked at from the perspective of a gambler rather than a statistician, "better than evens" means "odds against". If the odds are evens (1/1), and one bets 10 units, one would be returned 20 units, making a profit of 10 units. If the gamble was paying 4/1 and the event occurred, one would make 50 units, or a profit of 40 units. So, it is "better than evens" from the gambler's perspective because it pays out more than one-for-one. If an event is more likely to occur than an even chance, then the odds will be "worse than evens", and the bookmaker will pay out less than one-for-one.
p2002
aVHowever, in popular parlance surrounding uncertain events, the expression "better than evens" usually implies a better than (greater than) 50% chance of the event occurring, which is exactly the opposite of the meaning of the expression when used in a gaming context.
p2003
aVStatistical usage.
p2004
aVIn statistics, odds are an expression of relative probabilities, generally quoted as the odds "in favor." The odds (in favor) of an event or a proposition is the ratio of the probability that the event will happen to the probability that the event will not happen. Mathematically, this is a Bernoulli trial, as it has exactly two outcomes. In case of a finite sample space of equally likely outcomes, this is the ratio of the number of outcomes where the event occurs to the number of outcomes where the event does not occur; these can be represented as "W" and "L" (for Wins and Losses) or "S" and "F" (for Success and Failure). For example, the odds that a randomly chosen day of the week is a weekend are two to five (2:5), as days of the week form a sample space of seven outcomes, and the event occurs for two of the outcomes (Saturday and Sunday), and not for the other five. Conversely, given odds as a ratio of integers, this can be represented by a probability space of a finite number of equally likely outcomes. These definitions are equivalent, since dividing both terms in the ratio by the number of outcomes yields the probabilities: formula_1 Conversely, the odds against is the opposite ratio. For example, the odds against a random day of the week being a weekend are 5:2.
p2005
aVOdds and probability can be expressed in prose via the prepositions "to" and "in:" "odds of so many "to" so many on (or against) event" refers to "odds" \u2013 the ratio of numbers of (equally likely) outcomes in favor and against (or vice versa); "chances of so many "in" so many [outcomes" refers to "probability" \u2013 the number of (equally like) outcomes in favour relative to the number for and against combined. For example, "odds of a weekend are 2 "to" 5", while "chances of a weekend are 2 "in" 7". In casual use, the words "odds" and "chances" (or "chance") are often used interchangeably to vaguely indicate some measure of odds or probability, though the intended meaning can be deduced by noting whether the preposition between the two numbers is "to" or "in".
p2006
aVMathematical relations.
p2007
aVOdds can be expressed as a ratio of two numbers, in which case it is not unique \u2013 scaling both terms by the same factor does not change the proportions: 1:1 odds and 100:100 odds are the same (even odds). Odds can also be expressed as a number, by dividing the terms in the ratio \u2013 in this case it is unique (different fractions can represent the same rational number). Odds as a ratio, odds as a number, and probability (also a number) are related by simple formulas, and similarly odds in favor and odds against, and probability of success and probability of failure have simple relations. Odds range from 0 to infinity, while probabilities range from 0 to 1, and hence are often represented as a percentage between 0% and 100%: reversing the ratio switches odds for with odds against, and similarly probability of success with probability of failure.
p2008
aVGiven odds (in favor) as the ratio W:L (Wins:Losses), the odds in favor (as a number) formula_2 and odds against (as a number) formula_3 can be computed by simply dividing, and a multiplicative inverses:
p2009
aVformula_4
p2010
aVAnalogously, given odds as a ratio, the probability of success or failure can be computed by dividing, and the probability of success and probability of failure sum to unity (one), as they are the only possible outcomes. In case of a finite number of equally likely outcomes, this can be interpreted as the number of outcomes where the event occurs by the total number of events:
p2011
aVformula_5
p2012
aVGiven a probability "p," the odds as a ratio is formula_6 (probability of success to probability of failure), and the odds as numbers can be computed by dividing:
p2013
aVformula_7
p2014
aVConversely, given the odds as a number formula_8 this can be represented as the ratio formula_9 or conversely formula_10 from which the probability of success or failure can be computed:
p2015
aVformula_11
p2016
aVThus if expressed as a fraction with a numerator of 1, probability and odds differ by exactly 1 in the denominator: a probability of 1 "in" 100 (1/100 = 1%) is the same as odds of 1 "to" 99 (1/99 = 0.0101\u2026 = 0.), while odds of 1 "to" 100 (1/100 = 0.01) is the same as a probability of 1 "in" 101 (1/101 = 0.00990099\u2026 = 0.). This is a minor difference if the probability is small (close to zero, or "long odds"), but is a major difference if the probability is large (close to one).
p2017
aVThese are worked out for some simple odds:
p2018
aVThese transforms have certain special geometric properties: the conversions between odds for and odds against (resp. probability of success with probability of failure) and between odds and probability are all Möbius transformations (fractional linear transformations). They are thus are specified by three points (sharply 3-transitive). Swapping odds for and odds against swaps 0 and infinity, fixing 1, while swapping probability of success with probability of failure swaps 0 and 1, fixing .5; these are both order 2, hence circular transforms. Converting odds to probability fixes 0, sends infinity to 1, and sends 1 to .5 (even odds are 50% likely), and conversely; this is a parabolic transform.
p2019
aVApplications.
p2020
aVIn probability theory and Bayesian statistics, odds may sometimes be more natural or more convenient than probabilities. This is often the case in problems of sequential decision making as for instance in problems of how to stop (online) on a last specific event which is solved by the odds algorithm. Similar ratios are used elsewhere in Bayesian statistics, such as the Bayes factor.
p2021
aVThe odds are a ratio of probabilities; an odds ratio is a ratio of odds, that is, a ratio of ratios of probabilities. Odds-ratios are often used in analysis of clinical trials. While they have useful mathematical properties, they can produce counter-intuitive results: an event with an 80% probability of occurring is four times "more likely" to happen than an event with a 20% probability, but the "odds" are 16 times higher on the less likely event (4\u20131 "against", or 4) than on the more likely one (1\u20134, or 4\u20131 "on", or 0.25).
p2022
aVIn some cases the log-odds are used, which is the logit of the probability. Most simply, odds are frequently multiplied or divided, and log converts multiplication to addition and division to subtractions.
p2023
aVExamples.
p2024
aVAnswer: The odds in favour of a blue marble are 2:13. One can equivalently say, that the odds are 13:2 "against". There are 2 out of 15 chances in favour of blue, 13 out of 15 against blue.
p2025
aVIn probability theory and statistics, where the variable "p" is the probability in favor of a binary event, and the probability against the event is therefore 1-"p", "the odds" of the event are the quotient of the two, or formula_12. That value may be regarded as the relative likelihood the event will happen, expressed as a fraction (if it is less than 1), or a multiple (if it is equal to or greater than one) of the likelihood that the event will not happen.
p2026
aVIn the very first example at top, saying the odds of a Sunday are "one to six" or, less commonly, "one-sixth" means the probability of picking a Sunday randomly is one-sixth the probability of not picking a Sunday. While the mathematical probability of an event has a value in the range from zero to one, "the odds" in favor of that same event lie between zero and infinity. The odds against the event with probability given as "p" are formula_13.
p2027
aVThe odds against Sunday are 6:1 or  6/1 = 6. It is 6 times as likely that a random day is not a Sunday.
p2028
aVAnswer: 7:8
p2029
aVGambling usage.
p2030
aVThe use of odds in gambling arose to facilitate betting on events where the relative probabilities of outcomes varied. For example, on a coin toss or a match race between two evenly matched horses, it is reasonable for two people to wager level stakes. However, in more variable situations, such as a multi-runner horse race or a football match between two unequally matched sides, betting "at odds" provides more scope.
p2031
aVIn the modern era, most fixed odds betting takes place between a betting organisation, such as a bookmaker, and an individual, rather than between individuals. Different traditions have grown up in how to express odds to customers.
p2032
aVFractional odds.
p2033
aVFavoured by bookmakers in the United Kingdom and Ireland, and also common in horse racing, fractional odds quote the net total that will be paid out to the bettor, should he win, relative to his stake. Odds of 4/1 ("four-to-one" or less commonly "four-to-one "against"") would imply that the bettor stands to make a £400 profit on a £100 stake. If the odds are 1/4 (read "one-to-four", or "four-to-one "on""), the bettor will make £25 on a £100 stake. In either case, "against" or "on", should he win, the bettor always receives his original stake back, so if the odds are 4/1 the bettor receives a total of £500 (£400 plus the original £100). Odds of 1/1 are known as "evens" or "even money".
p2034
aVThe enumerator and denominator of fractional odds are always integers, thus if the bookmaker's payout was to be £1.25 for every £1 stake, this would be equivalent to £5 for every £4 staked, and the odds would therefore be expressed as 5/4. However, not all fractional odds are traditionally read using the lowest common denominator. For example, given that there is a pattern of odds of 5/4, 7/4, 9/4 and so on, odds which are mathematically 3/2 are more easily compared if expressed in the equivalent form 6/4. Perhaps most unusual is that odds of 10/3 are read as "one-hundred-to-thirty", because "ten-to-three" could be confused with a race time.
p2035
aVFractional odds are also known as "British odds," "UK odds," or, in that country, "traditional odds". They are typically represented with a "/" but can also be represented with a "-", e.g. 4/1 or 4-1.
p2036
aVA variation of fractional odds is known as "Hong Kong" odds. Fractional and Hong Kong odds are actually exchangeable. The only difference is that the UK odds are presented as a fractional notation (e.g. 6/5) whilst the Hong Kong odds are decimal (e.g. 1.2). Both exhibit the net return.
p2037
aVThe European odds also represent the potential winnings (net returns), but in addition they factor in the stake (e.g. 6/5 or 1.2 plus 1 = 2.2).
p2038
aVDecimal odds.
p2039
aVFavoured in continental Europe, Australia, New Zealand and Canada, decimal odds differ from fractional odds in that the bettor must first part with their stake in order to make a bet, the figure quoted is the winning amount that would be paid out to the bettor. Therefore, the decimal odds of an outcome are equivalent to the decimal value of the fractional odds plus one. Thus even odds 1/1 are quoted in decimal odds as 2. The 4/1 fractional odds discussed above are quoted as 5, while the 1/4 odds are quoted as 1.25. This is considered to be ideal for parlay betting, because the odds to be paid out are simply the product of the odds for each outcome wagered on. Decimal odds are also favoured by betting exchanges because they are the easiest to work with for trading.
p2040
aVDecimal odds are also known as "European odds", "digital odds" or "continental odds."
p2041
aVMoneyline odds.
p2042
aVMoneyline odds are favoured by American bookmakers. There are two possibilities, the figure quote can be either positive or negative.
p2043
aVIf the figure quoted is positive, the odds are quoting how much money will be won on a $100 wager (this is done if the odds are better than even). Fractional odds of 4/1 would be quoted as +400, while fractional odds of 1/4 cannot be quoted as a positive figure. (This would correspond to .25/1, quoted as *+25, but this is not done.)
p2044
aVIf the figure quoted is negative, then the moneyline odds are quoting how much money must be wagered to win $100 (this is done if the odds are worse than even). Fractional odds of 1/4 would be quoted as \u2212400, while fractional odds of 4/1 cannot be quoted as a negative figure. (This would correspond to 1/.25, quoted as *\u221225, but this is not done.)
p2045
aVMoneyline odds are often referred to as "American odds". Moneyline refers to odds on the straight-up outcome of a game with no consideration to a point spread.
p2046
aVGambling odds versus probabilities.
p2047
aVIn gambling, the odds on display do not represent the true chances (as imagined by the bookmaker) that the event will or will not occur, but are the amount that the bookmaker will pay out on a winning bet, together with the required stake. For instance, if the bookmaker offers odds of 4:6 against a certain horse winning a race, this means that he'll accept a $6 stake in return for a payoff of $4, plus return of the stake, if the horse wins. If the horse loses, the bookmaker keeps the stake. In formulating his odds to display the bookmaker will have included a profit margin which effectively means that the payout to a successful bettor is less than that represented by the true chance of the event occurring. This profit is known as the 'over-round' on the 'book' (the 'book' refers to the old-fashioned ledger in which wagers were recorded, and is the derivation of the term 'bookmaker') and relates to the sum of the 'odds' in the following way:
p2048
aVIn a 3-horse race, for example, the true probabilities of each of the horses winning based on their relative abilities may be 50%, 40% and 10%. The total of these three percentages is 100%, thus representing a fair 'book'. The true odds against winning for each of the three horses are 1-1, 3-2 and 9-1 respectively.
p2049
aVIn order to generate a profit on the wagers accepted by the bookmaker he may decide to increase the values to 60%, 50% and 20% for the three horses, representing odds against of 4-6, 1-1 and 4-1. These values now total 130%, meaning that the book has an overround of 30 (130 \u2212 100). This value of 30 represents the amount of profit for the bookmaker if he accepts bets in the correct proportions on each of the horses. The art of bookmaking is that he will take in, for example, $130 in wagers and only pay $100 back (including stakes) no matter which horse wins.
p2050
aVProfiting in gambling involves predicting the relationship of the true probabilities to the payout odds. Sports information services are often used by professional and semi-professional sports bettors to help achieve this goal.
p2051
aVThe odds or amounts the bookmaker will pay are determined by the total amount that has been bet on all of the possible events. They reflect the balance of wagers on either side of the event, and include the deduction of a bookmaker\u2019s brokerage fee ("vig" or vigorish).
p2052
aVAlso, depending on how the betting is affected by jurisdiction, taxes may be involved for the bookmaker and/or the winning player. This may be taken into account when offering the odds and/or may reduce the amount won by a player.
p2053
asS'Distribution (mathematics)'
p2054
(lp2055
VDistributions (or generalized functions) are objects that generalize the classical notion of functions in mathematical analysis. Distributions make it possible to differentiate functions whose derivatives do not exist in the classical sense. In particular, any locally integrable function has a distributional derivative. Distributions are widely used in the theory of partial differential equations, where it may be easier to establish the existence of distributional solutions than classical solutions, or appropriate classical solutions may not exist. Distributions are also important in physics and engineering where many problems naturally lead to differential equations whose solutions or initial conditions are distributions, such as the Dirac delta function (which is historically called a "function" even though it is not considered a genuine function mathematically).
p2056
aVAccording to , generalized functions originated in the work of on second-order hyperbolic partial differential equations, and the ideas were developed in somewhat extended form by Laurent Schwartz in the late 1940s. According to his autobiography, Schwartz introduced the term "distribution" by analogy with a distribution of electrical charge, possibly including not only point charges but also dipoles and so on. comments that although the ideas in the transformative book by were not entirely new, it was Schwartz's broad attack and conviction that distributions would be useful almost everywhere in analysis that made the difference.
p2057
aVThe basic idea in distribution theory is to reinterpret functions as linear functionals acting on a space of test functions. Standard functions act by integration against a test function, but many other linear functionals do not arise in this way, and these are the "generalized functions". There are different possible choices for the space of test functions, leading to different spaces of distributions. The basic space of test function consists of smooth functions with compact support, leading to standard distributions. Use of the space of smooth, rapidly decreasing test functions gives instead the tempered distributions, which are important because they have a well-defined distributional Fourier transform. Every tempered distribution is a distribution in the normal sense, but the converse is not true: in general the larger the space of test functions, the more restrictive the notion of distribution. On the other hand, the use of spaces of analytic test functions leads to Sato's theory of hyperfunctions; this theory has a different character from the previous ones because there are no analytic functions with non-empty compact support.
p2058
aVBasic idea.
p2059
aV[Illustration.svg|right|thumb|280px|A typical test function, the bump function "\u03a8"("x"). It is smooth (infinitely differentiable) and has compact support (is zero outside an interval, in this case the interval [\u22121, 1).]]
p2060
aVDistributions are a class of linear functionals that map a set of "test functions" (conventional and well-behaved functions) into the set of real numbers. In the simplest case, the set of test functions considered is D(R), which is the set of functions "\u03c6" : R \u2192 R having two properties:
p2061
aVA distribution "T" is a linear mapping "T" : D(R) \u2192 R. Instead of writing "T"("\u03c6"), it is conventional to write formula_1 for the value of "T" acting on a test function "\u03c6". A simple example of a distribution is the Dirac delta "\u03b4", defined by
p2062
aV formula_2
p2063
aVmeaning that "\u03b4" evaluates a test function at 0. Its physical interpretation is as the density of a point source.
p2064
aVAs described next, there are straightforward mappings from both locally integrable functions and Radon measures to corresponding distributions, but not all distributions can be formed in this manner.
p2065
aVFunctions and measures as distributions.
p2066
aVSuppose that "f" : R \u2192 R is a locally integrable function. Then a corresponding distribution "Tf" may be defined by
p2067
aV formula_3
p2068
aVThis integral is a real number which depends linearly and continuously on \u03c6. Conversely, the values of the distribution "Tf" on test functions in D(R) determine the pointwise almost everywhere values of the function "f" on R. In a conventional abuse of notation, "f" is often used to represent both the original function "f" and the corresponding distribution "Tf". This example suggests the definition of a distribution as a linear and, in an appropriate sense, continuous functional on the space of test functions D(R).
p2069
aVSimilarly, if \u03bc is a Radon measure on R, then a corresponding distribution "R"\u03bc may be defined by
p2070
aV formula_4
p2071
aVThis integral also depends linearly and continuously on \u03c6, so that "R"\u03bc is a distribution. If \u03bc is absolutely continuous with respect to Lebesgue measure with density "f" and "d"\u03bc = "f" "dx", then this definition for "R"\u03bc is the same as the previous one for "Tf", but if \u03bc is not absolutely continuous, then "R"\u03bc is a distribution that is not associated with a function. For example, if "P" is the point-mass measure on R that assigns measure one to the singleton set {0} and measure zero to sets that do not contain zero, then
p2072
aV formula_5
p2073
aVso that "R""P" = "\u03b4" is the Dirac delta.
p2074
aVAdding and multiplying distributions.
p2075
aVDistributions may be multiplied by real numbers and added together, so they form a real vector space.
p2076
aVDistributions may also be multiplied by infinitely differentiable functions, but it is not possible to define a product of general distributions that extends the usual pointwise product of functions and has the same algebraic properties.
p2077
aVDerivatives of distributions.
p2078
aVIt is desirable to choose a definition for the derivative of a distribution which, at least for distributions derived from smooth functions, has the property that formula_6. If "\u03c6" is a test function, we can use integration by parts to see that
p2079
aVformula_7
p2080
aVwhere the last equality follows from the fact that "\u03c6" is zero outside of a bounded set. This suggests that if "T" is a "distribution", we should define its derivative "T"\u2032 by
p2081
aV formula_8
p2082
aVIt turns out that this is the proper definition; it extends the ordinary definition of derivative, every distribution becomes infinitely differentiable and the usual properties of derivatives hold.
p2083
aVExample: Recall that the Dirac delta (so-called Dirac delta function) is the distribution defined by the equation
p2084
aV formula_9
p2085
aVIt is the derivative of the distribution corresponding to the Heaviside step function "H": For any test function "\u03c6",
p2086
aV formula_10
p2087
aVso "H"\u2032 = "\u03b4". Note, "\u03c6"(\u221e) = 0 because of compact support. Similarly, the derivative of the Dirac delta is the distribution defined by the equation
p2088
aVformula_11
p2089
aVThis latter distribution is an example of a distribution that is not derived from a function or a measure. Its physical interpretation is as the density of a dipole source.
p2090
aVTest functions and distributions.
p2091
aVIn the following, real-valued distributions on an open subset "U" of R"n" will be formally defined. With minor modifications, one can also define complex-valued distributions, and one can replace R"n" by any (paracompact) smooth manifold.
p2092
aVThe first object to define is the space D("U") of test functions on "U". Once this is defined, it is then necessary to equip it with a topology by defining the limit of a sequence of elements of D("U"). The space of distributions will then be given as the space of continuous linear functionals on D("U").
p2093
aVTest function space.
p2094
aVThe space D("U") of test functions on "U" is defined as follows. A function "\u03c6" : "U" \u2192 R is said to have compact support if there exists a compact subset "K" of "U" such that "\u03c6"("x") = 0 for all "x" in "U" \u005c "K". The elements of D("U") are the infinitely differentiable functions "\u03c6" : "U" \u2192 R with compact support \u2013 also known as bump functions. This is a real vector space. It can be given a topology by defining the limit of a sequence of elements of D("U"). A sequence ("\u03c6""k") in D("U") is said to converge to "\u03c6" \u2208 D("U") if the following two conditions hold :
p2095
aV:formula_12
p2096
aVWith this definition, D("U") becomes a complete locally convex topological vector space satisfying the Heine\u2013Borel property .
p2097
aVThis topology can be placed in the context of the following general construction: let
p2098
aVformula_15
p2099
aVbe a countable increasing union of locally convex topological vector spaces and \u03b9"i" : "Xi" \u2192 "X" be the inclusion maps. In this context, the inductive limit topology, or final topology, \u03c4 on "X" is the finest locally convex vector space topology making all the inclusion maps formula_16 continuous. The topology \u03c4 can be explicitly described as follows: let "\u03b2" be the collection of convex balanced subsets "W" of "X" such that "W" \u2229 "Xi" is open for all "i". A base for the inductive limit topology \u03c4 then consists of the sets of the form "x" + "W", where "x" in "X" and "W" in "\u03b2".
p2100
aVThe proof that \u03c4 is a vector space topology makes use of the assumption that each "Xi" is locally convex. By construction, "\u03b2" is a local base for "\u03c4". That any locally convex vector space topology on "X" must necessarily contain "\u03c4" means it is the weakest one. One can also show that, for each "i", the subspace topology "Xi" inherits from \u03c4 coincides with its original topology. When each "Xi" is a Fréchet space, ("X", \u03c4) is called an LF space.
p2101
aVNow let "U" be the union of "Ui" where {"Ui"} is a countable nested family of open subsets of "U" with compact closures "Ki" = "i". Then we have the countable increasing union
p2102
aVformula_17
p2103
aVwhere D"Ki" is the set of all smooth functions on "U" with support lying in "Ki". On each D"Ki", consider the topology given by the seminorms
p2104
aVformula_18
p2105
aVi.e. the topology of uniform convergence of derivatives of arbitrary order. This makes each D"Ki" a Fréchet space. The resulting LF space structure on D("U") is the topology described in the beginning of the section.
p2106
aVOn D("U"), one can also consider the topology given by the seminorms
p2107
aVformula_19
p2108
aVHowever, this topology has the disadvantage of not being complete. On the other hand, because of the particular features of D"Ki"'s, a set this bounded with respect to \u03c4 if and only if it lies in some D"Ki"'s. The completeness of ("D"("U"), \u03c4) then follow from that of D"Ki"'s.
p2109
aVThe topology \u03c4 is not metrizable by the Baire category theorem, since D("U") is the union of subspaces of the first category in D("U") .
p2110
aVDistributions.
p2111
aVA distribution on "U" is a continuous linear functional "T" : D("U") \u2192 R (or "T" : D("U") \u2192 C). That is, a distribution "T" assigns to each test function "\u03c6" a real (or complex) scalar "T"("\u03c6") such that
p2112
aVformula_20
p2113
aVfor all test functions "\u03c6"1, "\u03c6"2 and scalars c1, c2.
p2114
aVMoreover, "T" is continuous if and only if
p2115
aVformula_21
p2116
aVfor every convergent sequence "\u03c6""k" in D("U"). (Even though the topology of D("U") is not metrizable, a linear functional on D("U") is continuous if and only if it is sequentially continuous.) Equivalently, "T" is continuous if and only if for every compact subset "K" of "U" there exists a positive constant "CK" and a non-negative integer "NK" such that
p2117
aVformula_22
p2118
aVfor all test functions "\u03c6" with support contained in "K" and all multi-indices "\u03b1" with |"\u03b1"| \u2264 "N""K" .
p2119
aVThe space of distributions on "U" is denoted by D\u2032("U") and it is the continuous dual space of D("U"). No matter what dual topology is placed on D\u2032("U"), a "sequence" of distributions converges in this topology if and only if it converges pointwise (although this need not be true of a net), which is why the topology is sometimes defined to be the weak-* topology. But often the topology of bounded convergence, which in this case is the same as the topology of uniform convergence on compact sets, is placed on D\u2032("U") since it is with this topology that D\u2032("U") becomes a nuclear Montel space and it is with this topology that the kernels theorem of Schwartz holds. No matter which topology is chosen D("U") will be a non-metrizable, locally convex topological vector space.
p2120
aVThe duality pairing between a distribution "T" in D\u2032("U") and a test function "\u03c6" in D("U") is denoted using angle brackets by
p2121
aVformula_23
p2122
aVso that "T","\u03c6" = "T"("\u03c6"). One interprets this notation as the distribution "T" acting on the test function "\u03c6" to give a scalar, or symmetrically as the test function "\u03c6" acting on the distribution "T".
p2123
aVA sequence of distributions ("Tk") converges with respect to the weak-* topology on D\u2032("U") to a distribution "T" if and only if
p2124
aVformula_24
p2125
aVfor every test function "\u03c6" in D("U"). For example, if "fk" : R \u2192 R is the function
p2126
aVformula_25
p2127
aVand "Tk" is the distribution corresponding to "fk", then
p2128
aVformula_26
p2129
aVas "k" \u2192 \u221e, so "T""k" \u2192 "\u03b4" in D\u2032(R). Thus, for large "k", the function "f""k" can be regarded as an approximation of the Dirac delta distribution.
p2130
aVFunctions as distributions.
p2131
aVThe function "f" : "U" \u2192 R is called locally integrable if it is Lebesgue integrable over every compact subset "K" of "U". This is a large class of functions which includes all continuous functions and all "Lp" functions. The topology on D("U") is defined in such a fashion that any locally integrable function "f" yields a continuous linear functional on D("U") \u2013 that is, an element of D\u2032("U") \u2013 denoted here by "Tf", whose value on the test function "\u03c6" is given by the Lebesgue integral:
p2132
aVformula_27
p2133
aVConventionally, one abuses notation by identifying "Tf" with "f", provided no confusion can arise, and thus the pairing between "Tf" and "\u03c6" is often written
p2134
aVformula_28
p2135
aVIf "f" and "g" are two locally integrable functions, then the associated distributions "Tf" and "Tg" are equal to the same element of D\u2032("U") if and only if "f" and "g" are equal almost everywhere (see, for instance, ). In a similar manner, every Radon measure \u03bc on "U" defines an element of D\u2032("U") whose value on the test function "\u03c6" is \u222b"\u03c6" "d\u03bc". As above, it is conventional to abuse notation and write the pairing between a Radon measure "\u03bc" and a test function "\u03c6"as \u27e8"\u03bc", "\u03c6"\u27e9. Conversely, as shown in a theorem by Schwartz (similar to the Riesz representation theorem), every distribution which is non-negative on non-negative functions is of this form for some (positive) Radon measure.
p2136
aVThe test functions are themselves locally integrable, and so define distributions. As such they are dense in D\u2032("U") with respect to the topology on D\u2032("U") in the sense that for any distribution "T" \u2208 D\u2032("U"), there is a sequence "\u03c6""n" \u2208 D("U") such that
p2137
aVformula_29
p2138
aVfor all "\u03a8" \u2208 D("U"). This fact follows from the Hahn\u2013Banach theorem, since the dual of D\u2032("U") with its weak-* topology is the space D("U") , and it can also be proven more constructively by a convolution argument.
p2139
aVOperations on distributions.
p2140
aVMany operations which are defined on smooth functions with compact support can also be defined for distributions. In general, if "A" : D("U") \u2192 D("U") is a linear mapping of vector spaces which is continuous with respect to the weak-* topology, then it is possible to extend "A" to a mapping "A" : D\u2032("U") \u2192 D\u2032("U") by passing to the limit. (This approach works for non-linear mappings as well, provided they are assumed to be uniformly continuous.)
p2141
aVIn practice, however, it is more convenient to define operations on distributions by means of the transpose (; ). If "A" : D("U") \u2192 D("U") is a continuous linear operator, then the transpose is an operator "At" : D("U") \u2192 D("U") such that
p2142
aVformula_30
p2143
aVIf such an operator "At" exists and is continuous on D("U"), then the original operator "A" may be extended to D\u2032("U") by defining "AT" for a distribution "T" as
p2144
aVformula_31
p2145
aVDifferentiation.
p2146
aVSuppose "A" : D("U") \u2192 D("U") is the partial derivative operator
p2147
aVformula_32
p2148
aVIf "\u03c6" and "\u03c8" are in D("U"), then an integration by parts gives
p2149
aVformula_33
p2150
aVso that "At" = \u2212"A". This operator is a continuous linear transformation on D("U"). So, if "T" \u2208 D\u2032("U") is a distribution, then the partial derivative of "T" with respect to the coordinate "xk" is defined by the formula
p2151
aVformula_34
p2152
aVWith this definition, every distribution is infinitely differentiable, and the derivative in the direction "xk" is a linear operator on D\u2032("U").
p2153
aVMore generally, if \u03b1 = (\u03b11, ..., \u03b1"n") is an arbitrary multi-index and \u2202\u03b1 is the associated partial derivative operator, then the partial derivative \u2202\u03b1"T" of the distribution "T" \u2208 D\u2032("U") is defined by
p2154
aVformula_35
p2155
aVThe minimum integer "k" for which such an expansion holds for every distribution "T" is called the order of "P".
p2156
aVThe space D\u2032("U") is a D-module with respect to the action of the ring of linear differential operators.
p2157
aVComposition with a smooth function.
p2158
aVLet "T" be a distribution on an open set "U" \u2282 R"n". Let "V" be an open set in R"n", and "F" : "V" \u2192 "U". Then provided "F" is a submersion, it is possible to define
p2159
aVformula_36
p2160
aVThis is the composition of the distribution "T" with "F", and is also called the pullback of "T" along "F", sometimes written
p2161
aVformula_37
p2162
aVThe pullback is often denoted "F*", although this notation should not be confused with the use of '*' to denote the adjoint of a linear mapping.
p2163
aVThe condition that "F" be a submersion is equivalent to the requirement that the Jacobian derivative "dF"("x") of "F" is a surjective linear map for every "x" \u2208 "V". A necessary (but not sufficient) condition for extending "F"# to distributions is that "F" be an open mapping . The inverse function theorem ensures that a submersion satisfies this condition.
p2164
aVIf "F" is a submersion, then "F"# is defined on distributions by finding the transpose map. Uniqueness of this extension is guaranteed since "F"# is a continuous linear operator on D("U"). Existence, however, requires using the change of variables formula, the inverse function theorem (locally) and a partition of unity argument; see .
p2165
aVIn the special case when "F" is a diffeomorphism from an open subset "V" of R"n" onto an open subset "U" of R"n" change of variables under the integral gives
p2166
aVformula_38
p2167
aVIn this particular case, then, "F"# is defined by the transpose formula:
p2168
aVformula_39
p2169
aVLocalization of distributions.
p2170
aVThere is no way to define the value of a distribution in D\u2032("U") at a particular point of "U". However, as is the case with functions, distributions on "U" restrict to give distributions on open subsets of "U". Furthermore, distributions are "locally determined" in the sense that a distribution on all of "U" can be assembled from a distribution on an open cover of "U" satisfying some compatibility conditions on the overlap. Such a structure is known as a sheaf.
p2171
aVRestriction.
p2172
aVLet "U" and "V" be open subsets of R"n" with "V" \u2282 "U". Let "EVU" : D("V") \u2192 D("U") be the operator which "extends by zero" a given smooth function compactly supported in "V" to a smooth function compactly supported in the larger set "U". Then the restriction mapping \u03c1"VU" is defined to be the transpose of "EVU". Thus for any distribution "T" \u2208 D\u2032("U"), the restriction \u03c1"VU""T" is a distribution in the dual space D\u2032("V") defined by
p2173
aVformula_40
p2174
aVfor all test functions "\u03c6" \u2208 D("V").
p2175
aVUnless "U" = "V", the restriction to "V" is neither injective nor surjective. Lack of surjectivity follows since distributions can blow up towards the boundary of "V". For instance, if "U" = R and "V" = (0, 2), then the distribution
p2176
aVformula_41
p2177
aVis in D\u2032("V") but admits no extension to D\u2032("U").
p2178
aVSupport of a distribution.
p2179
aVLet "T" \u2208 D\u2032("U") be a distribution on an open set "U". Then "T" is said to vanish on an open set "V" of "U" if "T" lies in the kernel of the restriction map \u03c1"VU". Explicitly "T" vanishes on "V" if
p2180
aVformula_42
p2181
aVfor all test functions "\u03c6" \u2208 C\u221e("U") with support in "V". Let "V" be a maximal open set on which the distribution "T" vanishes; i.e., "V" is the union of every open set on which "T" vanishes. The support of "T" is the complement of "V" in "U". Thus
p2182
aVformula_43
p2183
aVThe distribution "T" has compact support if its support is a compact set. Explicitly, "T" has compact support if there is a compact subset "K" of "U" such that for every test function "\u03c6" whose support is completely outside of "K", we have "T"("\u03c6") = 0. Compactly supported distributions define continuous linear functionals on the space C\u221e("U"); the topology on C\u221e("U") is defined such that a sequence of test functions "\u03c6""k" converges to 0 if and only if all derivatives of "\u03c6""k" converge uniformly to 0 on every compact subset of "U". Conversely, it can be shown that every continuous linear functional on this space defines a distribution of compact support. The embedding of Cc\u221e("U") into C\u221e("U"), where the spaces are given their respective topologies, is continuous and has dense image. Thus compactly supported distributions can be identified with those distributions that can be extended from Cc\u221e("U") to C\u221e("U").
p2184
aVTempered distributions and Fourier transform.
p2185
aVBy using a larger space of test functions, one can define the tempered distributions, a subspace of D\u2032(R"n"). These distributions are useful if one studies the Fourier transform: all tempered distributions have a Fourier transform, but not all distributions in D\u2032(R"n") have one.
p2186
aVThe space of test functions employed here, the so-called Schwartz space "S"(R"n"), is the function space of all infinitely differentiable functions that are rapidly decreasing at infinity along with all partial derivatives. Thus is in the Schwartz space provided that any derivative of "\u03c6", multiplied with any power of |"x"|, converges towards 0 for |"x"| \u2192 \u221e. These functions form a complete topological vector space with a suitably defined family of seminorms. More precisely, let
p2187
aVformula_44
p2188
aVfor "\u03b1", "\u03b2" multi-indices of size "n". Then "\u03c6" is a Schwartz function if all the values
p2189
aVformula_45
p2190
aVThe family of seminorms "p""\u03b1", "\u03b2" defines a locally convex topology on the Schwartz space. The seminorms are, in fact, norms on the Schwartz space, since Schwartz functions are smooth. The Schwartz space is metrizable and complete. Because the Fourier transform changes differentiation by "x""\u03b1" into multiplication by "x""\u03b1" and vice versa, this symmetry implies that the Fourier transform of a Schwartz function is also a Schwartz function.
p2191
aVThe space of tempered distributions is defined as the (continuous) dual of the Schwartz space. In other words, a distribution "T" is a tempered distribution if and only if
p2192
aV formula_46
p2193
aVis true whenever,
p2194
aV formula_47
p2195
aVholds for all multi-indices "\u03b1", "\u03b2".
p2196
aVThe derivative of a tempered distribution is again a tempered distribution. Tempered distributions generalize the bounded (or slow-growing) locally integrable functions; all distributions with compact support and all square-integrable functions are tempered distributions. More generally, all functions that are products of polynomials with elements of "Lp"(R"n") for "p" \u2265 1 are tempered distributions.
p2197
aVThe "tempered distributions" can also be characterized as "slowly growing". This characterization is "dual" to the "rapidly falling" behaviour, e.g. formula_48, of the test functions.
p2198
aVTo study the Fourier transform, it is best to consider "complex"-valued test functions and complex-linear distributions. The ordinary continuous Fourier transform "F" yields then an automorphism of Schwartz function space, and we can define the Fourier transform of the tempered distribution "T" by ("FT")("\u03a8") = "T"("F\u03c8") for every Schwartz function "\u03a8". "FT" is thus again a tempered distribution. The Fourier transform is a continuous, linear, bijective operator from the space of tempered distributions to itself. This operation is compatible with differentiation in the sense that
p2199
aVformula_49
p2200
aVand also with convolution: if "T" is a tempered distribution and "\u03a8" is a "slowly increasing" infinitely differentiable function on R"n" (meaning that all derivatives of "\u03a8" grow at most as fast as polynomials), then "\u03c8T" is again 
p2201
aVa tempered distribution and
p2202
aVformula_50
p2203
aVis the convolution of "FT" and "F\u03c8". In particular, the Fourier transform of the constant function equal to 1 is the "\u03b4" distribution.
p2204
aVConvolution.
p2205
aVUnder some circumstances, it is possible to define the convolution of a function with a distribution, or even the convolution of two distributions.
p2206
aVIf "f" \u2208 D(R"n") is a compactly supported smooth test function, then convolution with "f",
p2207
aVformula_51
p2208
aVdefines a linear operator which is continuous with respect to the LF space topology on D(R"n").
p2209
aVConvolution of "f" with a distribution "T" \u2208 D\u2032(R"n") can be defined by taking the transpose of "Cf" relative to the duality pairing of D(R"n") with the space D\u2032(R"n") of distributions . If "f", "g", "\u03c6" \u2208 D(R"n"), then by Fubini's theorem
p2210
aVformula_52
p2211
aVwhere formula_53. Extending by continuity, the convolution of "f" with a distribution "T" is defined by
p2212
aVformula_54
p2213
aVfor all test functions "\u03c6" \u2208 D(R"n").
p2214
aVAn alternative way to define the convolution of a function "f" and a distribution "T" is to use the translation operator \u03c4"x" defined on test functions by
p2215
aVformula_55
p2216
aVand extended by the transpose to distributions in the obvious way . The convolution of the compactly supported function "f" and the distribution "T" is then the function defined for each "x" \u2208 R"n" by
p2217
aVformula_56
p2218
aVIt can be shown that the convolution of a compactly supported function and a distribution is a smooth function. If the distribution "T" has compact support as well, then "f"\u2217"T" is a compactly supported function, and the Titchmarsh convolution theorem implies that
p2219
aVformula_57
p2220
aVwhere "ch" denotes the convex hull.
p2221
aVIt is also possible to define the convolution of two distributions "S" and "T" on R"n", provided one of them has compact support. Informally, in order to define "S"\u2217"T" where "T" has compact support, the idea is to extend the definition of the convolution \u2217 to a linear operation on distributions so that the associativity formula
p2222
aVformula_58
p2223
aVcontinues to hold for all test functions "\u03c6". proves the uniqueness of such an extension.
p2224
aVIt is also possible to provide a more explicit characterization of the convolution of distributions . Suppose that it is "T" that has compact support. For any test function "\u03c6" in D(R"n"), consider the function
p2225
aVformula_59
p2226
aVIt can be readily shown that this defines a smooth function of "x", which moreover has compact support. The convolution of "S" and "T" is defined by
p2227
aVformula_60
p2228
aVThis generalizes the classical notion of convolution of functions and is compatible with differentiation in the following sense:
p2229
aVformula_61
p2230
aVThis definition of convolution remains valid under less restrictive assumptions about "S" and "T"; see for instance and .
p2231
aVDistributions as derivatives of continuous functions.
p2232
aVThe formal definition of distributions exhibits them as a subspace of a very large space, namely the topological dual of D("U") (or S(R"d") for tempered distributions). It is not immediately clear from the definition how exotic a distribution might be. To answer this question, it is instructive to see distributions built up from a smaller space, namely the space of continuous functions. Roughly, any distribution is locally a (multiple) derivative of a continuous function. A precise version of this result, given below, holds for distributions of compact support, tempered distributions, and general distributions. Generally speaking, no proper subset of the space of distributions contains all continuous functions and is closed under differentiation. This says that distributions are not particularly exotic objects; they are only as complicated as necessary.
p2233
aVTempered distributions.
p2234
aVIf "f" \u2208 "S"\u2032(R"n") is a tempered distribution, then there exists a constant "C" > 0, and positive integers "M" and "N" such that for all Schwartz functions "\u03c6" \u2208 "S"(R"n")
p2235
aVformula_62
p2236
aVThis estimate along with some techniques from functional analysis can be used to show that there is a continuous slowly increasing function "F" and a multi-index "\u03b1" such that
p2237
aVformula_63
p2238
aVRestriction of distributions to compact sets.
p2239
aVIf "f" \u2208 D\u2032(R"n"), then for any compact set "K" \u2282 R"n", there exists a continuous function "F " compactly supported 
p2240
aVin R"n" (possibly on a larger set than "K" itself) and a multi-index "\u03b1" such that "f" = "D""\u03b1""F" on Cc\u221e("K").
p2241
aVThis follows from the previously quoted result on tempered distributions by means of a localization argument.
p2242
aVDistributions with point support.
p2243
aVIf "f" has support at a single point {"P"}, then "f" is in fact a finite linear combination of distributional derivatives of the "\u03b4" function at "P". That is, there exists an integer "m" and complex constants "a""\u03b1" for multi-indices |"\u03b1"| \u2264 "m" such that
p2244
aVformula_64
p2245
aVwhere \u03c4"P" is the translation operator.
p2246
aVGeneral distributions.
p2247
aVA version of the above theorem holds locally in the following sense . Let "T" be a distribution on "U", then one can find for every multi-index "\u03b1" a continuous function "g""\u03b1" such that
p2248
aV formula_65
p2249
aVand that any compact subset "K" of "U" intersects the supports of only finitely many "g""\u03b1"; therefore, to evaluate the value of "T" for a given smooth function "f" compactly supported in "U", we only need finitely many "g""\u03b1"; hence the infinite sum above is well-defined as a distribution. If the distribution "T" is of finite order, then one can choose "g""\u03b1" in such a way that only finitely many of them are nonzero.
p2250
aVUsing holomorphic functions as test functions.
p2251
aVThe success of the theory led to investigation of the idea of hyperfunction, in which spaces of holomorphic functions are used as test functions. A refined theory has been developed, in particular Mikio Sato's algebraic analysis, using sheaf theory and several complex variables. This extends the range of symbolic methods that can be made into rigorous mathematics, for example Feynman integrals.
p2252
aVProblem of multiplication.
p2253
aVIt is easy to define the product of a distribution with a smooth function, or more generally the product of two distributions whose singular supports are disjoint. With more effort it is possible to define a well-behaved product of several distributions provided their wave front sets at each point are compatible. 
p2254
aVA limitation of the theory of distributions (and hyperfunctions) is that there is no associative product of two distributions extending the product of a distribution by a smooth function, as has been proved by Laurent Schwartz in the 1950s. For example, if p.v. 1/"x" is the distribution obtained by the Cauchy principal value
p2255
aVformula_66
p2256
aVfor all "\u03c6" \u2208 "S"(R), and "\u03b4" is the Dirac delta distribution then
p2257
aV formula_67
p2258
aVbut
p2259
aV formula_68
p2260
aVso the product of a distribution by a smooth function (which is always well defined) cannot be extended to an associative product on the space of distributions.
p2261
aVThus, nonlinear problems cannot be posed in general and thus not solved within distribution theory alone. In the context of quantum field theory, however, solutions can be found. In more than two spacetime dimensions the problem is related to the regularization of divergences. Here Henri Epstein and Vladimir Glaser developed the mathematically rigorous (but extremely technical) "causal perturbation theory". This does not solve the problem in other situations. Many other interesting theories are non linear, like for example Navier\u2013Stokes equations of fluid dynamics.
p2262
aVIn some cases a solution of the multiplication problem is dictated by the path integral formulation of quantum mechanics. Since this is required to be equivalent to the Schrödinger theory of quantum mechanics which is invariant under coordinate transformations, this property must be shared by path integrals. This fixes some products of distributions as shown by . The result is equivalent to what can be derived from dimensional regularization .
p2263
aVSeveral not entirely satisfactory theories of algebras of generalized functions have been developed, among which Colombeau's (simplified) algebra is maybe the most popular in use today.
p2264
asS'2D'
p2265
(lp2266
V2D or II-D may refer to:
p2267
asS'Limit of a function'
p2268
(lp2269
VAlthough the function (sin "x")/"x" is not defined at zero, as "x" becomes closer and closer to zero, (sin "x")/"x" becomes arbitrarily close to 1. In other words, the limit of (sin "x")/"x" as "x" approaches zero equals 1.
p2270
aVIn mathematics, the limit of a function is a fundamental concept in calculus and analysis concerning the behavior of that function near a particular input.
p2271
aVFormal definitions, first devised in the early 19th century, are given below. Informally, a function "f" assigns an output "f"("x") to every input "x". We say the function has a limit "L" at an input "p": this means "f"("x") gets closer and closer to "L" as "x" moves closer and closer to "p". More specifically, when "f" is applied to any input "sufficiently" close to "p", the output value is forced "arbitrarily" close to "L". On the other hand, if some inputs very close to "p" are taken to outputs that stay a fixed distance apart, we say the limit "does not exist".
p2272
aVThe notion of a limit has many applications in modern calculus. In particular, the many definitions of continuity employ the limit: roughly, a function is continuous if all of its limits agree with the values of the function. It also appears in the definition of the derivative: in the calculus of one variable, this is the limiting value of the slope of secant lines to the graph of a function.
p2273
aVHistory.
p2274
aVAlthough implicit in the development of calculus of the 17th and 18th centuries, the modern idea of the limit of a function goes back to Bolzano who, in 1817, introduced the basics of the epsilon-delta technique to define continuous functions. However, his work was not known during his lifetime . Cauchy discussed limits in his "Cours d'analyse" (1821) and gave essentially the modern definition, but this is not often recognized because he only gave a verbal definition . Weierstrass first introduced the epsilon-delta definition of limit in the form it is usually written today. He also introduced the notations lim and lim"x"\u2192"x"0 .
p2275
aVThe modern notation of placing the arrow below the limit symbol is due to Hardy in his book "A Course of Pure Mathematics" in 1908 .
p2276
aVMotivation.
p2277
aVImagine a person walking over a landscape represented by the graph of "y" = "f"("x"). Her horizontal position is measured by the value of "x", much like the position given by a map of the land or by a global positioning system. Her altitude is given by the coordinate "y". She is walking towards the horizontal position given by "x" = "p". As she gets closer and closer to it, she notices that her altitude approaches "L". If asked about the altitude of "x" = "p", she would then answer "L".
p2278
aVWhat, then, does it mean to say that her altitude approaches "L?" It means that her altitude gets nearer and nearer to "L" except for a possible small error in accuracy. For example, suppose we set a particular accuracy goal for our traveler: she must get within ten meters of "L". She reports back that indeed she can get within ten meters of "L", since she notes that when she is within fifty horizontal meters of "p", her altitude is "always" ten meters or less from "L".
p2279
aVThe accuracy goal is then changed: can she get within one vertical meter? Yes. If she is anywhere within seven horizontal meters of "p", then her altitude always remains within one meter from the target "L". In summary, to say that the traveler's altitude approaches "L" as his horizontal position approaches "p" means that for every target accuracy goal, however small it may be, there is some neighborhood of "p" whose altitude fulfills that accuracy goal.
p2280
aVThe initial informal statement can now be explicated:
p2281
aVThe limit of a function "f"("x") as "x" approaches "p" is a number "L" with the following property: given any target distance from "L", there is a distance from "p" within which the values of "f"("x") remain within the target distance.
p2282
aVThis explicit statement is quite close to the formal definition of the limit of a function with values in a topological space.
p2283
aVTo say that
p2284
aVformula_1
p2285
aVmeans that "\u0192"("x") can be made as close as desired to "L" by making "x" close enough, but not equal, to "p".
p2286
aVThe following definitions (known as (\u03b5, \u03b4)-definitions) are the generally accepted ones for the limit of a function in various contexts.
p2287
aVFunctions of a single variable.
p2288
aVSuppose "f" : R \u2192 R is defined on the real line and "p,L" \u2208 R. It is said '"the limit of "f", as "x" approaches "p", is "L""' and written
p2289
aVformula_2
p2290
aVif the following property holds:
p2291
aVThe value of the limit does not depend on the value of "f"("p"), nor even that "p" be in the domain of "f".
p2292
aVA more general definition applies for functions defined on subsets of the real line. Let ("a", "b") be an open interval in R, and "p" a point of ("a", "b"). Let "f" be a real-valued function defined on all of ("a", "b") except possibly at "p" itself. It is then said that the limit of "f", as "x" approaches "p", is "L" if, for every real "\u03b5" > "0", there exists a real "\u03b4" > "0" such that 0 < | "x" \u2212 "p" | < "\u03b4" and "x" \u2208 ("a", "b") implies | "f"("x") \u2212 "L" | < "\u03b5".
p2293
aVHere again the limit does not depend on "f"("p") being well-defined.
p2294
aVThe letters "\u03b5" and "\u03b4" can be understood as "error" and "distance", and in fact Cauchy used "\u03b5" as an abbreviation for "error" in some of his work . In these terms, the error ("\u03b5") in the measurement of the value at the limit can be made as small as desired by reducing the distance ("\u03b4") to the limit point. As discussed below this definition also works for functions in a more general context. The idea that "\u03b4" and "\u03b5" represent distances helps suggest these generalizations.
p2295
aVExistence and one-sided limits.
p2296
aVAlternatively "x" may approach "p" from above (right) or below (left), in which case the limits may be written as
p2297
aVformula_3
p2298
aVor
p2299
aVformula_4
p2300
aVrespectively. If these limits exist at p and are equal there, then this can be referred to as ""'the" limit of "f"("x") at "p""'. If the one-sided limits exist at "p", but are unequal, there is no limit at "p" (the limit at "p" does not exist). If either one-sided limit does not exist at "p", the limit at p does not exist.
p2301
aVA formal definition is as follows. The limit of "f"("x") as "x" approaches "p" from above is "L" if, for every "\u03b5" > 0, there exists a \u03b4 > 0 such that |"f"("x") \u2212 "L"| < "\u03b5" whenever 0 < "x" \u2212 "p" < \u03b4. The limit of "f"("x") as "x" approaches "p" from below is "L" if, for every \u03b5 > 0, there exists a \u03b4 > 0 such that |"f"("x") \u2212 "L"| < "\u03b5" whenever 0 < "p" \u2212 "x" < "\u03b4".
p2302
aVIf the limit does not exist then the oscillation of "f" at "p" is non-zero.
p2303
aVExamples.
p2304
aVNon-existence of one-sided limit(s).
p2305
aVThe function 
p2306
aVformula_5
p2307
aVhas no limit at formula_6, but has a limit at every other "x"-coordinate.
p2308
aVThe function 
p2309
aVformula_7
p2310
aVhas no limit at any "x"-coordinate.
p2311
aVNon-equality of one-sided limits.
p2312
aVThe function 
p2313
aVformula_8
p2314
aVhas a limit at every non-zero "x"-coordinate. At "x" = 1, the left-hand limit equals 0, whereas the right-hand limit equals 1.
p2315
aVLimits at only one point.
p2316
aVThe function 
p2317
aVformula_9
p2318
aVonly has a limit at x = 0.
p2319
aVThe function 
p2320
aVformula_10
p2321
aVonly has a limit at x = 0.
p2322
aVLimits at countably many points.
p2323
aVThe function 
p2324
aVformula_11
p2325
aVhas a limit at any "x"-coordinate of the form formula_12, where "n" is any integer.
p2326
aVFunctions on metric spaces.
p2327
aVSuppose "M" and "N" are subsets of metric spaces "A" and "B", respectively, and "f" : "M" \u2192 "N" is defined between "M" and "N", with "x" \u2208 "M," "p" a limit point of "M" and "L" \u2208 "N". It is said that '"the limit of "f" as "x" approaches "p" is "L""' and write
p2328
aVformula_13
p2329
aVif the following property holds:
p2330
aVAgain, note that "p" need not be in the domain of "f", nor does "L" need to be in the range of "f", and even if "f"("p") is defined it need not be equal to "L".
p2331
aVAn alternative definition using the concept of neighbourhood is as follows:
p2332
aVformula_13
p2333
aVif, for every neighbourhood "V" of "L" in "B", there exists a neighbourhood "U" of "p" in "A" such that "f"(U \u2229 M \u2212 {"p"}) \u2286 "V".
p2334
aVFunctions on topological spaces.
p2335
aVSuppose "X","Y" are topological spaces with "Y" a Hausdorff space. Let "p" be a limit point of \u03a9 \u2286 "X", and "L" \u2208"Y". For a function "f" : \u03a9 \u2192 "Y", it is said that the '"limit of "f" as "x" approaches "p" is "L""' (i.e., "f(x)"\u2192"L" as "x"\u2192"p") and write
p2336
aVformula_13
p2337
aVif the following property holds:
p2338
aVThis last part of the definition can also be phrased "there exists an open punctured neighbourhood "U" of "p" such that "f"("U"\u2229\u03a9) \u2286 "V" ".
p2339
aVNote that the domain of "f" does not need to contain "p". If it does, then the value of "f" at "p" is irrelevant to the definition of the limit. In particular, if the domain of "f" is "X" \u2212 {"p"} (or all of "X"), then the limit of "f" as "x" \u2192 "p" exists and is equal to "L" if, for all subsets \u03a9 of "X" with limit point "p", the limit of the restriction of "f" to \u03a9 exists and is equal to "L". Sometimes this criterion is used to establish the "non-existence" of the two-sided limit of a function on R by showing that the one-sided limits either fail to exist or do not agree. Such a view is fundamental in the field of general topology, where limits and continuity at a point are defined in terms of special families of subsets, called filters, or generalized sequences known as nets.
p2340
aVAlternatively, the requirement that "Y" be a Hausdorff space can be relaxed to the assumption that "Y" be a general topological space, but then the limit of a function may not be unique. In particular, one can no longer talk about "the limit" of a function at a point, but rather "a limit" or "the set of limits" at a point.
p2341
aVA function is continuous in a limit point "p" of and in its domain if and only if "f(p)" is "the" (or, in the general case, "a") limit of "f(x)" as "x" tends to "p".
p2342
aVLimits involving infinity.
p2343
aVLimits at infinity.
p2344
aVFor "f"("x") a real function, '"the limit of "f" as "x" approaches infinity is "L""', denoted
p2345
aVformula_16
p2346
aVmeans that for all formula_17, there exists "c" such that
p2347
aVformula_18 whenever "x" > "c". Or, symbolically:
p2348
aVformula_19
p2349
aVSimilarly, '"the limit of "f" as "x" approaches negative infinity is "L""', denoted
p2350
aVformula_20
p2351
aVmeans that for all formula_17 there exists "c" such that formula_18 whenever "x" < "c". Or, symbolically:
p2352
aVformula_23
p2353
aVFor example
p2354
aVformula_24
p2355
aVInfinite limits.
p2356
aVLimits can also have infinite values.
p2357
aVWhen infinities are not considered legitimate values, which is standard (but see below), a formalist will insist upon various circumlocutions.
p2358
aVFor example, rather than say that a limit "is" infinity, the "proper" thing is to say that the function "diverges" or "grows without bound".
p2359
aVIn particular, the following informal example of how to pronounce the notation is arguably inappropriate in the classroom (or any other formal setting).
p2360
aVIn any case, for example '"the limit of "f" as "x" approaches "a" is infinity"', denoted
p2361
aVformula_25
p2362
aVmeans that for all formula_17 there exists formula_27 such that formula_28 whenever formula_29.
p2363
aVThese ideas can be combined in a natural way to produce definitions for different combinations, such as
p2364
aVformula_30
p2365
aVFor example
p2366
aVformula_31
p2367
aVLimits involving infinity are connected with the concept of asymptotes.
p2368
aVThese notions of a limit attempt to provide a metric space interpretation to limits at infinity. However, note that these notions of a limit are consistent with the topological space definition of limit if
p2369
aVIn this case, R is a topological space and any function of the form "f": "X" \u2192 "Y" with "X", "Y"\u2286 R is subject to the topological definition of a limit. Note that with this topological definition, it is easy to define infinite limits at finite points, which have not been defined above in the metric sense.
p2370
aVAlternative notation.
p2371
aVMany authors allow for the real projective line to be used as a way to include infinite values as well as extended real line. With this notation, the extended real line is given as R \u222a {\u2212\u221e, +\u221e} and the projective real line is R \u222a {\u221e} where a neighborhood of \u221e is a set of the form {"x": |"x"|>"c"}. The advantage is that one only needs 3 definitions for limits (left, right, and central) to cover all the cases.
p2372
aVAs presented above, for a completely rigorous account, we would need to consider 15 separate cases for each combination of infinities (five directions: \u2212\u221e, left, central, right, and +\u221e; three bounds: \u2212\u221e, finite, or +\u221e). There are also noteworthy pitfalls. For example, when working with the extended real line, formula_32 does not possess a central limit (which is normal):
p2373
aVformula_33
p2374
aVIn contrast, when working with the projective real line, infinities (much like 0) are unsigned, so, the central limit "does" exist in that context:
p2375
aVformula_34
p2376
aVIn fact there are a plethora of conflicting formal systems in use.
p2377
aVIn certain applications of numerical differentiation and integration, it is, for example, convenient to have signed zeroes. 
p2378
aVA simple reason has to do with the converse of formula_35, namely, it is convenient for formula_36 to be considered true.
p2379
aVSuch zeroes can be seen as an approximation to infinitesimals.
p2380
aVLimits at infinity for rational functions.
p2381
aVThere are three basic rules for evaluating limits at infinity for a rational function "f"("x") = "p"("x")/"q"("x"): (where "p" and "q" are polynomials):
p2382
aVIf the limit at infinity exists, it represents a horizontal asymptote at "y" = "L". Polynomials do not have horizontal asymptotes; such asymptotes may however occur with rational functions.
p2383
aVFunctions of more than one variable.
p2384
aVBy noting that |"x" \u2212 "p"| represents a distance, the definition of a limit can be extended to functions of more than one variable. In the case of a function "f" : R2 \u2192 R,
p2385
aVformula_37
p2386
aVif
p2387
aVfor every "\u03b5" > 0 there exists a \u03b4 > 0 such that for all ("x","y") with 0 < ||("x","y") \u2212 ("p","q")|| < \u03b4, then |"f"("x","y") \u2212 "L"| < \u03b5
p2388
aVwhere ||("x","y") \u2212 ("p","q")|| represents the Euclidean distance. This can be extended to any number of variables.
p2389
aVSequential limits.
p2390
aVLet "f" : "X" \u2192 "Y" be a mapping from a topological space "X" into a Hausdorff space "Y", "p"\u2208"X" and "L"\u2208"Y".
p2391
aVThe sequential limit of "f" as "x"\u2192"p" is "L" if, for every sequence ("x"n) in "X" \u2212 {"p"} which converges to "p", the sequence "f"("x"n) converges to "L".
p2392
aVIf "L" is the limit (in the sense above) of "f" as "x" approaches "p", then it is a sequential limit as well, however the converse need not hold in general. If in addition "X" is metrizable, then "L" is the sequential limit of "f" as "x" approaches "p" if and only if it is the limit (in the sense above) of "f" as "x" approaches "p".
p2393
aVOther characterizations.
p2394
aVIn terms of sequences.
p2395
aVFor functions on the real line, one way to define the limit of a function is in terms of the limit of sequences. In this setting:
p2396
aVformula_38
p2397
aVif and only if for all sequences formula_39 (with formula_39 not equal to "a" for all "n") converging to formula_41 the sequence formula_42 converges to formula_43. It was shown by Sierpi\u0144ski in 1916 that proving the equivalence of this definition and the definition above, requires and is equivalent to a weak form of the axiom of choice. Note that defining what it means for a sequence formula_39 to converge to formula_41 requires the epsilon, delta method.
p2398
aVIn non-standard calculus.
p2399
aVIn non-standard calculus the limit of a function is defined by:
p2400
aVformula_38
p2401
aVif and only if for all formula_47, formula_48 is infinitesimal whenever formula_49 is infinitesimal. Here formula_50 are the hyperreal numbers and formula_51 is the natural extension of "f" to the non-standard real numbers. Keisler proved that such a hyperreal definition of limit reduces the quantifier complexity by two quantifiers. On the other hand, Hrbacek writes that for the definitions to be valid for all hyperreal numbers they must implicitly be grounded in the \u03b5-\u03b4 method, and claims that, from the pedagogical point of view, the hope that non-standard calculus could be done without \u03b5-\u03b4 methods can not be realized in full. 
p2402
aVB\u0140aszczyk et al. detail the usefulness of microcontinuity in developing a transparent definition of uniform continuity, and characterize Hrbacek's criticism as a "dubious lament".
p2403
aVIn terms of nearness.
p2404
aVAt the 1908 international congress of mathematics F. Riesz introduced an alternate way defining limits and continuity in concept called "nearness". A point formula_52 is defined to be near a set formula_53 if for every formula_54 there is a point formula_55 so that formula_56. In this setting the 
p2405
aVformula_57
p2406
aVif and only if for all formula_53, formula_43 is near formula_60 whenever formula_41 is near formula_62.
p2407
aVHere formula_60 is the set formula_64. This definition can also be extended to metric and topological spaces.
p2408
aVRelationship to continuity.
p2409
aVThe notion of the limit of a function is very closely related to the concept of continuity. A function "\u0192" is said to be continuous at "c" if it is both defined at "c" and its value at "c" equals the limit of "f" as "x" approaches "c":
p2410
aV formula_65
p2411
aVIf the condition 0 < |"x" \u2212 "c"| is left out of the definition of limit, then the resulting definition would be equivalent to requiring "f" to be continuous at "c".
p2412
aVProperties.
p2413
aVIf a function "f" is real-valued, then the limit of "f" at "p" is "L" if and only if both the right-handed limit and left-handed limit of "f" at "p" exist and are equal to "L".
p2414
aVThe function "f" is continuous at "p" if and only if the limit of "f"("x") as "x" approaches "p" exists and is equal to "f"("p"). If "f" : "M" \u2192 "N" is a function between metric spaces "M" and "N", then it is equivalent that "f" transforms every sequence in "M" which converges towards "p" into a sequence in "N" which converges towards "f"("p").
p2415
aVIf "N" is a normed vector space, then the limit operation is linear in the following sense: if the limit of "f"("x") as "x" approaches "p" is "L" and the limit of "g"("x") as "x" approaches "p" is "P", then the limit of "f"("x") + g("x") as "x" approaches "p" is "L" + "P". If "a" is a scalar from the base field, then the limit of "af"("x") as "x" approaches "p" is "aL".
p2416
aVIf "f" is a real-valued (or complex-valued) function, then taking the limit is compatible with the algebraic operations, "provided" the limits on the "right" sides of the equations below exist (the last identity only holds if the denominator is non-zero). This fact is often called the algebraic limit theorem.
p2417
aVformula_66
p2418
aVIn each case above, when the limits on the right do not exist, or, in the last case, when the limits in both the numerator and the denominator are zero, nonetheless the limit on the left, called an "indeterminate form", may still exist\u2014this depends on the functions "f" and "g". These rules are also valid for one-sided limits, for the case "p" = ±\u221e, and also for infinite limits using the rules
p2419
aV(see extended real number line).
p2420
aVNote that there is "no" general rule for the case "q" / 0; it all depends on the way 0 is approached. Indeterminate forms\u2014for instance, 0/0, 0×\u221e, \u221e\u2212\u221e, and \u221e/\u221e\u2014are also not covered by these rules, but the corresponding limits can often be determined with L'Hôpital's rule or the Squeeze theorem.
p2421
aVChain rule.
p2422
aVIn general, the statement
p2423
aVformula_67 and formula_68,
p2424
aVis not true. However, this "chain rule" does hold if one of the following "additional" conditions holds:
p2425
aVFor a counterexample, consider the following function which violates both additional restrictions:
p2426
aVformula_72
p2427
aVSince the value at "f"(0) is a removable discontinuity,
p2428
aVformula_73 for all formula_41.
p2429
aVThus, the naïve chain rule would suggest that the limit of "f"("f"("x")) is 0. However, it is the case that
p2430
aVformula_75
p2431
aVformula_76 for all formula_41.
p2432
aVLimits of special interest.
p2433
aVThe first limit can be proven with the squeeze theorem. For 0 < x < \u03c0/2:
p2434
aVformula_81
p2435
aVDividing everything by sin(x) yields
p2436
aVformula_82
p2437
aVformula_83
p2438
aVformula_84
p2439
aVformula_85
p2440
aVformula_78
p2441
aVThe second limit can be proven with the first limit and the following identity:
p2442
aVformula_87
p2443
aVStarting with
p2444
aVformula_88
p2445
aVMultiplying numerator and denominator by (1 + cos x) yields
p2446
aVformula_89
p2447
aVformula_90
p2448
aVformula_79
p2449
aVL'Hôpital's rule.
p2450
aVThis rule uses derivatives to find limits of indeterminate forms or , and only applies to such cases. Other indeterminate forms may be manipulated into this form. Given two functions and , defined over an open interval containing the desired limit point "c", then if:
p2451
aVthen: 
p2452
aVformula_96
p2453
aVNormally, the first condition is the most important one.
p2454
aVFor example:
p2455
aVformula_97
p2456
aVSummations and integrals.
p2457
aVSpecifying an infinite bound on a summation or integral is a common shorthand for specifying a limit.
p2458
aVA short way to write the limit formula_98
p2459
aVis formula_99.
p2460
aVA short way to write the limit formula_100
p2461
aVis formula_101.
p2462
aVA short way to write the limit formula_102
p2463
aVis formula_103.
p2464
asVBanach\u2013Tarski paradox
p2465
(lp2466
VThe Banach\u2013Tarski paradox is a theorem in set-theoretic geometry, which states the following: Given a solid ball in 3\u2011dimensional space, there exists a decomposition of the ball into a finite number of disjoint subsets, which can then be put back together in a different way to yield two identical copies of the original ball. Indeed, the reassembly process involves only moving the pieces around and rotating them, without changing their shape. However, the pieces themselves are not "solids" in the usual sense, but infinite scatterings of points. The reconstruction can work with as few as five pieces.
p2467
aVA stronger form of the theorem implies that given any two "reasonable" solid objects (such as a small ball and a huge ball), either one can be reassembled into the other. This is often stated informally as "a pea can be chopped up and reassembled into the Sun" and called the "pea and the Sun paradox".
p2468
aVThe reason the Banach\u2013Tarski theorem is called a paradox is that it contradicts basic geometric intuition. "Doubling the ball" by dividing it into parts and moving them around by rotations and translations, without any stretching, bending, or adding new points, seems to be impossible, since all these operations "ought to", intuitively speaking, preserve the volume, but they don't necessarily all do that, and the volume is doubled in the end.
p2469
aVUnlike with most theorems in geometry, the proof of this result depends in a critical way on the choice of axioms for set theory. It can be proven using the axiom of choice, which allows for the construction of nonmeasurable sets, i.e., collections of points that do not have a volume in the ordinary sense, and whose construction requires an uncountable number of choices.
p2470
aVIt was shown in 2005 that the pieces in the decomposition can be chosen in such a way that they can be moved continuously into place without running into one another.
p2471
aVBanach and Tarski publication.
p2472
aVIn a paper published in 1924, Stefan Banach and Alfred Tarski gave a construction of such a paradoxical decomposition, based on earlier work by Giuseppe Vitali concerning the unit interval and on the paradoxical decompositions of the sphere by Felix Hausdorff, and discussed a number of related questions concerning decompositions of subsets of Euclidean spaces in various dimensions. They proved the following more general statement, the strong form of the Banach\u2013Tarski paradox:
p2473
aV Given any two bounded subsets and of an Euclidean space in at least three dimensions, both of which have a nonempty interior, there are partitions of and into a finite number of disjoint subsets, , such that for each between and , the sets and are congruent.
p2474
aVNow let be the original ball and be the union of two translated copies of the original ball. Then the proposition means that you can divide the original ball into a certain number of pieces and then rotate and translate these pieces in such a way that the result is the whole set , which contains two copies of .
p2475
aVThe strong form of the Banach\u2013Tarski paradox is false in dimensions one and two, but Banach and Tarski showed that an analogous statement remains true if countably many subsets are allowed. The difference between the dimensions 1 and 2 on the one hand, and three and higher, on the other hand, is due to the richer structure of the group of the Euclidean motions in the higher dimensions, which is solvable for and contains a free group with two generators for . John von Neumann studied the properties of the group of equivalences that make a paradoxical decomposition possible and introduced the notion of amenable groups. He also found a form of the paradox in the plane which uses area-preserving affine transformations in place of the usual congruences.
p2476
aVTarski proved that amenable groups are precisely those for which no paradoxical decompositions exist. Since only free subgroups are needed in the Banach\u2013Tarski paradox, this led to the long-standing Von Neumann conjecture.
p2477
aVFormal treatment.
p2478
aVThe Banach\u2013Tarski paradox states that a ball in the ordinary Euclidean space can be doubled using only the operations of partitioning into subsets, replacing a set with a congruent set, and reassembly. Its mathematical structure is greatly elucidated by emphasizing the role played by the group of Euclidean motions and introducing the notions of equidecomposable sets and paradoxical set. Suppose that is a group acting on a set . In the most important special case, is an -dimensional Euclidean space, and consists of all isometries of , i.e. the transformations of into itself that preserve the distances, usually denoted . Two geometric figures that can be transformed into each other are called congruent, and this terminology will be extended to the general -action. Two subsets and of are called -equidecomposable, or equidecomposable with respect to , if and can be partitioned into the same finite number of respectively -congruent pieces. This defines an equivalence relation among all subsets of . Formally, if
p2479
aV formula_1
p2480
aVthen we will say that and are -equidecomposable using pieces. If a set has two disjoint subsets and such that and , as well as and , are -equidecomposable then is called paradoxical.
p2481
aVUsing this terminology, the Banach\u2013Tarski paradox can be reformulated as follows:
p2482
aV A three-dimensional Euclidean ball is equidecomposable with two copies of itself.
p2483
aVIn fact, there is a sharp result in this case, due to R. M. Robinson: doubling the ball can be accomplished with five pieces, and fewer than five pieces will not suffice.
p2484
aVThe strong version of the paradox claims:
p2485
aV Any two bounded subsets of 3-dimensional Euclidean space with non-empty interiors are equidecomposable.
p2486
aVWhile apparently more general, this statement is derived in a simple way from the doubling of a ball by using a generalization of the Bernstein\u2013Schroeder theorem due to Banach that implies that if is equidecomposable with a subset of and is equidecomposable with a subset of , then and are equidecomposable.
p2487
aVThe Banach\u2013Tarski paradox can be put in context by pointing out that for two sets in the strong form of the paradox, there is always a bijective function that can map the points in one shape into the other in a one-to-one fashion. In the language of Georg Cantor's set theory, these two sets have equal cardinality. Thus, if one enlarges the group to allow arbitrary bijections of then all sets with non-empty interior become congruent. Likewise, we can make one ball into a larger or smaller ball by stretching, in other words, by applying similarity transformations. Hence if the group is large enough, we may find -equidecomposable sets whose "size" varies. Moreover, since a countable set can be made into two copies of itself, one might expect that somehow, using countably many pieces could do the trick.
p2488
aVOn the other hand, in the Banach\u2013Tarski paradox the number of pieces is finite and the allowed equivalences are Euclidean congruences, which preserve the volumes. Yet, somehow, they end up doubling the volume of the ball! While this is certainly surprising, some of the pieces used in the paradoxical decomposition are non-measurable sets, so the notion of volume (more precisely, Lebesgue measure) is not defined for them, and the partitioning cannot be accomplished in a practical way. In fact, the Banach\u2013Tarski paradox demonstrates that it is impossible to find a finitely-additive measure (or a Banach measure) defined on all subsets of a Euclidean space of three (and greater) dimensions that is invariant with respect to Euclidean motions and takes the value one on a unit cube. In his later work, Tarski showed that, conversely, non-existence of paradoxical decompositions of this type implies the existence of a finitely-additive invariant measure.
p2489
aVThe heart of the proof of the "doubling the ball" form of the paradox presented below is the remarkable fact that by a Euclidean isometry (and renaming of elements), one can divide a certain set (essentially, the surface of a unit sphere) into four parts, then rotate one of them to become itself plus two of the other parts. This follows rather easily from a -paradoxical decomposition of , the free group with two generators. Banach and Tarski's proof relied on an analogous fact discovered by Hausdorff some years earlier: the surface of a unit sphere in space is a disjoint union of three sets and a countable set such that, on the one hand, are pairwise congruent, and, on the other hand, is congruent with the union of and . This is often called the Hausdorff paradox.
p2490
aVConnection with earlier work and the role of the axiom of choice.
p2491
aVBanach and Tarski explicitly acknowledge Giuseppe Vitali's 1905 construction of the set bearing his name, Hausdorff's paradox (1914), and an earlier (1923) paper of Banach as the precursors to their work. Vitali's and Hausdorff's constructions depend on Zermelo's axiom of choice ("AC"), which is also crucial to the Banach\u2013Tarski paper, both for proving their paradox and for the proof of another result:
p2492
aV Two Euclidean polygons, one of which strictly contains the other, are not equidecomposable.
p2493
aVThey remark:
p2494
aV "Le rôle que joue cet axiome dans nos raisonnements nous semble mériter l'attention"
p2495
aV (The role this axiom plays in our reasoning seems to us to deserve attention)
p2496
aVand point out that while the second result fully agrees with our geometric intuition, its proof uses AC in an even more substantial way than the proof of the paradox. Thus Banach and Tarski imply that AC should not be rejected simply because it produces a paradoxical decomposition, for such an argument also undermines proofs of geometrically intuitive statements.
p2497
aVHowever, in 1949 A.P. Morse showed that the statement about Euclidean polygons can be proved in ZF set theory and thus does not require the axiom of choice. In 1964, Paul Cohen proved that the axiom of choice cannot be proved from ZF. A weaker version of an axiom of choice is the axiom of dependent choice, DC. It has been shown that
p2498
aV The Banach\u2013Tarski paradox is not a theorem of ZF, nor of ZF+DC.
p2499
aVLarge amounts of mathematics use AC. As Stan Wagon points out at the end of his monograph, the Banach\u2013Tarski paradox has been more significant for its role in pure mathematics than for foundational questions: it motivated a fruitful new direction for research, the amenability of groups, which has nothing to do with the foundational questions.
p2500
aVIn 1991, using then-recent results by Matthew Foreman and Friedrich Wehrung, Janusz Pawlikowski proved that the Banach\u2013Tarski paradox follows from ZF plus the Hahn\u2013Banach theorem. The Hahn\u2013Banach theorem doesn't rely on the full axiom of choice but can be proved using a weaker version of AC called the ultrafilter lemma. So Pawlikowski proved that the set theory needed to prove the Banach\u2013Tarski paradox, while stronger than ZF, is weaker than full ZFC.
p2501
aVA sketch of the proof.
p2502
aVHere we sketch a proof which is similar but not identical to that given by Banach and Tarski. Essentially, the paradoxical decomposition of the ball is achieved in four steps:
p2503
aVWe now discuss each of these steps in more detail.
p2504
aVStep 1.
p2505
aVThe free group with two generators "a" and "b" consists of all finite strings that can be formed from the four symbols "a", "a"\u22121, "b" and "b"\u22121 such that no "a" appears directly next to an "a"\u22121 and no "b" appears directly next to a "b"\u22121. Two such strings can be concatenated and converted into a string of this type by repeatedly replacing the "forbidden" substrings with the empty string. For instance: "abab"\u22121"a"\u22121 concatenated with "abab"\u22121"a" yields "abab"\u22121"a"\u22121"abab"\u22121"a", which contains the substring "a"\u22121"a", and so gets reduced to "abab"\u22121"bab"\u22121"a", which contains the substring "b"\u22121"b", which gets reduced to "abaab"\u22121"a". One can check that the set of those strings with this operation forms a group with identity element the empty string "e". We will call this group "F"2.
p2506
aVThe group formula_2 can be "paradoxically decomposed" as follows: let "S"("a") be the set of all non-forbidden strings that start with "a" and define "S"("a"\u22121), "S"("b") and "S"("b"\u22121) similarly. Clearly,
p2507
aVformula_3
p2508
aVbut also
p2509
aVformula_4
p2510
aVand
p2511
aVformula_5
p2512
aVwhere the notation "aS"("a"\u22121) means take all the strings in "S"("a"\u22121) and concatenate them on the left with "a".
p2513
aVThis is at the core of the proof. For example, there may be a string formula_6 in the set formula_7 which, because of the rule that formula_8 must not appear next to formula_9, reduces to the string formula_10. Similarly, it contains all the strings that start with formula_9 (for example the string formula_12 which reduces to formula_9). In this way, formula_7 contains all the strings that start with formula_10, formula_16 and formula_9.
p2514
aVWe have cut our group "F"2 into four pieces (plus the singleton {"e"}), then "shifted" two of them by multiplying with "a" or "b", then "reassembled" two pieces to make one copy of formula_2 and the other two to make another copy of formula_2. That is exactly what we want to do to the ball.
p2515
aVStep 2.
p2516
aVIn order to find a free group of rotations of 3D space, i.e. that behaves just like (or "is isomorphic to") the free group "F"2, we take two orthogonal axes, e.g. the "x" and "z" axes, and let "A" be a rotation of formula_20 about the first, x axis, and "B" be a rotation of formula_21 about the "z" axis (there are many other suitable pairs of irrational multiples of \u03c0, that could be used here as well).
p2517
aVThe group of rotations generated by "A" and "B" will be called H. 
p2518
aVLet formula_22 be an element of H which starts with a rotation on the "z" axis, of the form formula_23.
p2519
aVIt can be shown by induction that formula_22 maps the point formula_25 to formula_26, for some formula_27. Analysing formula_28 and formula_29 modulo 3, one can show that formula_30. The same argument repeated (by symmetry of the problem) is valid for the opposite rotation about the "z" axis, as well as rotations about the "x" axis. This shows that for any non trivial word formula_31 H, then formula_32. Therefore the group H is a free group, isomorphic to "F"2.
p2520
aVThe two rotations behave just like the elements "a" and "b" in the group "F"2: we now have a paradoxical decomposition of H.
p2521
aVThis step cannot be performed in two dimensions since it involves rotations in three dimensions. If we take two rotations about the same axis, the resulting group is commutative and doesn't have the property required in step 1.
p2522
aVAn alternate arithmetic proof of the existence of free groups in some special orthogonal groups using integral quaternions leads to paradoxical decompositions of the rotation group.
p2523
aVStep 3.
p2524
aVThe unit sphere "S"2 is partitioned into orbits by the action of our group H: two points belong to the same orbit if and only if there's a rotation in H which moves the first point into the second. (Note that the orbit of a point is a dense set in "S"2.) We can use the axiom of choice to pick exactly one point from every orbit; collect these points into a set "M". Now (almost) every point in "S"2 can be reached in exactly one way by applying the proper rotation from H to the proper element from "M", and because of this, the paradoxical decomposition of H then yields a paradoxical decomposition of "S"2 into four pieces "A1", "A2", "A3", "A4" as follows:
p2525
aVformula_33
p2526
aVformula_34
p2527
aVformula_35
p2528
aVformula_36
p2529
aVwhere we use the notation
p2530
aVformula_37
p2531
aVand likewise for the other sets and define
p2532
aVformula_38
p2533
aVThe (majority of the) sphere has now been divided into four sets (each one dense on the sphere), and when two of these are rotated, we end up with double what we had before:
p2534
aVformula_39
p2535
aVformula_40
p2536
aVStep 4.
p2537
aVFinally, connect every point on "S"2 with a ray to the origin; the paradoxical decomposition of "S"2 then yields a paradoxical decomposition of the solid unit ball minus the point at the ball's centre (this center point needs a bit more care, see below).
p2538
aVN.B. This sketch glosses over some details. One has to be careful about the set of points on the sphere which happen to lie on the axis of some rotation in H. However, there are only countably many such points, and like the point at the centre of the ball, it is possible to patch the proof to account for them all (see below).
p2539
aVSome details, fleshed out.
p2540
aVIn Step 3, we partitioned the sphere into orbits of our group H. To streamline the proof, we omitted the discussion of points that are fixed by some rotation; since the paradoxical decomposition of "F"2 relies on shifting certain subsets, the fact that some points are fixed might cause some trouble. Since any rotation of "S"2 (other than the null rotation) has exactly two fixed points, and since H, which is isomorphic to "F"2, is countable, there are countably many points of "S"2 that are fixed by some rotation in H, denote this set of fixed points "D". Step 3 proves that "S"2 \u2212 "D" admits a paradoxical decomposition.
p2541
aVWhat remains to be shown is the Claim: "S"2 \u2212 "D" is equidecomposable with "S"2.
p2542
aV"Proof." Let \u03bb be some line through the origin that does not intersect any point in "D" \u2013 this is possible since "D" is countable. Let "J" be the set of angles, \u03b1, such that for some natural number "n", and some "P" in "D", r("n"\u03b1)P is also in "D", where r("n"\u03b1) is a rotation about \u03bb of "n"\u03b1. Then "J" is countable so there exists an angle \u03b8 not in "J". Let \u03c1 be the rotation about \u03bb by \u03b8, then \u03c1 acts on "S"2 with no fixed points in "D", i.e., \u03c1"n"("D") is disjoint from "D", and for natural "m"<"n", \u03c1"n"("D") is disjoint from \u03c1"m"("D"). Let "E" be the disjoint union of \u03c1"n"("D") over "n" = 0, 1, 2, ... Then "S"2 = "E" \u222a ("S"2 \u2212 "E") ~ \u03c1("E") \u222a ("S"2 \u2212 "E") = ("E" \u2212 "D") \u222a ("S"2 \u2212 "E") = "S"2 \u2212 "D", where ~ denotes "is equidecomposable to".
p2543
aVFor step 4, it has already been shown that the ball minus a point admits a paradoxical decomposition; it remains to be shown that the ball minus a point is equidecomposable with the ball. Consider a circle within the ball, containing the point at the centre of the ball. Using an argument like that used to prove the Claim, one can see that the full circle is equidecomposable with the circle minus the point at the ball's centre. (Basically, a countable set of points on the circle can be rotated to give itself plus one more point.) Note that this involves the rotation about a point other than the origin, so the Banach\u2013Tarski paradox involves isometries of Euclidean 3-space rather than just SO(3).
p2544
aVWe are using the fact that if "A" ~ "B" and "B" ~ "C", then "A" ~ "C". The decomposition of "A" into "C" can be done using number of pieces equal to the product of the numbers needed for taking "A" into "B" and for taking "B" into "C".
p2545
aVThe proof sketched above requires 2 × 4 × 2 + 8 = 24 pieces, a factor of 2 to remove fixed points, a factor 4 from step 1, a factor 2 to recreate fixed points, and 8 for the center point of the second ball. But in step 1 when moving {"e"} and all strings of the form "an" into "S"("a"\u22121), do this to all orbits except one. Move {"e"} of this last orbit to the center point of the second ball. This brings the total down to 16 + 1 pieces. With more algebra one can also decompose fixed orbits into 4 sets as in step 1. This gives 5 pieces and is the best possible.
p2546
aVObtaining infinitely many balls from one.
p2547
aVUsing the Banach\u2013Tarski paradox, it is possible to obtain "k" copies of a ball in the Euclidean "n"-space from one, for any integers "n" \u2265 3 and "k" \u2265 1, i.e. a ball can be cut into "k" pieces so that each of them is equidecomposable to a ball of the same size as the original. Using the fact that the free group "F"2 of rank 2 admits a free subgroup of countably infinite rank, a similar proof yields that the unit sphere "S""n"\u22121 can be partitioned into countably infinitely many pieces, each of which is equidecomposable (with two pieces) to the "S""n"\u22121 using rotations. By using analytic properties of the rotation group SO("n"), which is a connected analytic Lie group, one can further prove that the sphere "S""n"\u22121 can be partitioned into as many pieces as there are real numbers (that is, formula_41 pieces), so that each piece is equidecomposable with two pieces to "S""n"\u22121 using rotations. These results then extend to the unit ball deprived of the origin. A 2010 article by Valeriy Churkin gives a new proof of the continuous version of the Banach\u2013Tarski paradox.
p2548
aVThe von Neumann paradox in the Euclidean plane.
p2549
aVIn the Euclidean plane, two figures that are equidecomposable with respect to the group of Euclidean motions are necessarily of the same area, therefore, a paradoxical decomposition of a square or disk of Banach\u2013Tarski type that uses only Euclidean congruences is impossible. A conceptual explanation of the distinction between the planar and higher-dimensional cases was given by John von Neumann: unlike the group SO(3) of rotations in three dimensions, the group "E"(2) of Euclidean motions of the plane is solvable, which implies the existence of a finitely-additive measure on "E"(2) and R2 which is invariant under translations and rotations, and rules out paradoxical decompositions of non-negligible sets. Von Neumann then posed the following question: can such a paradoxical decomposition be constructed if one allowed a larger group of equivalences?
p2550
aVIt is clear that if one permits similarities, any two squares in the plane become equivalent even without further subdivision. This motivates restricting one's attention to the group "SA"2 of area-preserving affine transformations. Since the area is preserved, any paradoxical decomposition of a square with respect to this group would be counterintuitive for the same reasons as the Banach\u2013Tarski decomposition of a ball. In fact, the group "SA"2 contains as a subgroup the special linear group "SL"(2,R), which in its turn contains the free group "F"2 with two generators as a subgroup. This makes it plausible that the proof of Banach\u2013Tarski paradox can be imitated in the plane. The main difficulty here lies in the fact that the unit square is not invariant under the action of the linear group "SL"(2, R), hence one cannot simply transfer a paradoxical decomposition from the group to the square, as in the third step of the above proof of the Banach\u2013Tarski paradox. Moreover, the fixed points of the group present difficulties (for example, the origin is fixed under all linear transformations). This is why von Neumann used the larger group "SA"2 including the translations, and he constructed a paradoxical decomposition of the unit square with respect to the enlarged group (in 1929). Applying the Banach\u2013Tarski method, the paradox for the square can be strengthened as follows:
p2551
aV Any two bounded subsets of the Euclidean plane with non-empty interiors are equidecomposable with respect to the area-preserving affine maps.
p2552
aVAs von Neumann notes,
p2553
aV"Infolgedessen gibt es bereits in der Ebene kein nichtnegatives additives Maß (wo das Einheitsquadrat das Maß 1 hat), das gegenüber allen Abbildungen von "A"2 invariant wäre."
p2554
aV"In accordance with this, already in the plane there is no nonnegative additive measure (for which the unit square has a measure of 1), which is invariant with respect to all transformations belonging to "A"2 group of area-preserving affine transformations."
p2555
aVTo explain this a bit more, the question of whether a finitely additive measure exists, that is preserved under certain transformations, depends on what transformations are allowed. The Banach measure of sets in the plane, which is preserved by translations and rotations, is not preserved by non-isometric transformations even when they do preserve the area of polygons. The points of the plane (other than the origin) can be divided into two dense sets which we may call "A" and "B". If the "A" points of a given polygon are transformed by a certain area-preserving transformation and the "B" points by another, both sets can become subsets of the "A" points in two new polygons. The new polygons have the same area as the old polygon, but the two transformed sets cannot have the same measure as before (since they contain only part of the "A" points), and therefore there is no measure that "works".
p2556
aVThe class of groups isolated by von Neumann in the course of study of Banach\u2013Tarski phenomenon turned out to be very important for many areas of mathematics: these are amenable groups, or groups with an invariant mean, and include all finite and all solvable groups. Generally speaking, paradoxical decompositions arise when the group used for equivalences in the definition of equidecomposability is "not" amenable.
p2557
asS'Square root'
p2558
(lp2559
VIn mathematics, a square root of a number "a" is a number "y" such that , in other words, a number "y" whose "square" (the result of multiplying the number by itself, or ) is "a". For example, 4 and \u22124 are square roots of 16 because .
p2560
aVEvery non-negative real number "a" has a unique non-negative square root, called the "principal square root", which is denoted by , where \u221a is called the "radical sign" or "radix". For example, the principal square root of 9 is 3, denoted = 3, because and 3 is non-negative. The term whose root is being considered is known as the "radicand". The radicand is the number or expression underneath the radical sign, in this example 9.
p2561
aVEvery positive number "a" has two square roots: , which is positive, and \u2212, which is negative. Together, these two roots are denoted ± (see ± shorthand). Although the principal square root of a positive number is only one of its two square roots, the designation ""the" square root" is often used to refer to the "principal" square root. For positive "a", the principal square root can also be written in exponent notation, as "a"1/2.
p2562
aVSquare roots of negative numbers can be discussed within the framework of complex numbers. More generally, square roots can be considered in any context in which a notion of "squaring" of some mathematical objects is defined (including algebras of matrices, endomorphism rings, etc.)
p2563
aVHistory.
p2564
aVThe Yale Babylonian Collection YBC 7289 clay tablet was created between 1800 BC and 1600 BC, showing and 30 as 1;24,51,10 and 42;25,35 base 60 numbers on a square crossed by two diagonals.
p2565
aVThe Rhind Mathematical Papyrus is a copy from 1650 BC of an earlier Berlin Papyrus and other texts possible the Kahun Papyrus that shows how the Egyptians extracted square roots by an inverse proportion method.
p2566
aVIn Ancient India, the knowledge of theoretical and applied aspects of square and square root was at least as old as the "Sulba Sutras", dated around 800\u2013500 BC (possibly much earlier). A method for finding very good approximations to the square roots of 2 and 3 are given in the "Baudhayana Sulba Sutra". Aryabhata in the "Aryabhatiya" (section 2.4), has given a method for finding the square root of numbers having many digits.
p2567
aVIt was known to the ancient Greeks that square roots of positive whole numbers that are not perfect squares are always irrational numbers: numbers not expressible as a ratio of two integers (that is to say they cannot be written exactly as "m/n", where "m" and "n" are integers). This is the theorem "Euclid X, 9" almost certainly due to Theaetetus dating back to circa 380 BC.
p2568
aVThe particular case Square root of 2 is assumed to date back earlier to the Pythagoreans and is traditionally attributed to Hippasus. It is exactly the length of the diagonal of a square with side length 1.
p2569
aVIn the Chinese mathematical work "Writings on Reckoning", written between 202 BC and 186 BC during the early Han Dynasty, the square root is approximated by using an "excess and deficiency" method, which says to "...combine the excess and deficiency as the divisor; (taking) the deficiency numerator multiplied by the excess denominator and the excess numerator times the deficiency denominator, combine them as the dividend."
p2570
aVMah\u0101v\u012bra, a 9th-century Indian mathematician, was the first to state that square roots of negative numbers do not exist.
p2571
aVA symbol for square roots, written as an elaborate R, was invented by Regiomontanus (1436\u20131476). An R was also used for Radix to indicate square roots in Giralamo Cardano's Ars Magna.
p2572
aVAccording to historian of mathematics D.E. Smith, Aryabhata's method for finding the square root was first introduced in Europe by Cataneo in 1546.
p2573
aVThe symbol '\u221a' for the square root was first used in print in 1525 in Christoph Rudolff's "Coss", which was also the first to use the then-new signs '+' and '\u2212'.
p2574
aVProperties and uses.
p2575
aVThe principal square root function "f"("x") = (usually just referred to as the "square root function") is a function that maps the set of non-negative real numbers onto itself. In geometrical terms, the square root function maps the area of a square to its side length.
p2576
aVThe square root of "x" is rational if and only if "x" is a rational number that can be represented as a ratio of two perfect squares. (See square root of 2 for proofs that this is an irrational number, and quadratic irrational for a proof for all non-square natural numbers.) The square root function maps rational numbers into algebraic numbers (a superset of the rational numbers).
p2577
aVFor all real numbers "x" 
p2578
aVformula_1     (see absolute value)
p2579
aVFor all non-negative real numbers "x" and "y",
p2580
aVformula_2
p2581
aVand
p2582
aVformula_3
p2583
aVThe square root function is continuous for all non-negative "x" and differentiable for all positive "x". If "f" denotes the square-root function, its derivative is given by:
p2584
aVformula_4
p2585
aVThe Taylor series of about "x" = 0 converges for \u2264 1 and is given by
p2586
aVformula_5
p2587
aVThe square root of a non-negative number is used in the definition of Euclidean norm (and distance), as well as in generalizations such as Hilbert spaces. It defines an important concept of standard deviation used in probability theory and statistics. It has a major use in the formula for roots of a quadratic equation; quadratic fields and rings of quadratic integers, which are based on square roots, are important in algebra and have uses in geometry. Square roots frequently appear in mathematical formulas elsewhere, as well as in many physical laws.
p2588
aVComputation.
p2589
aVMost pocket calculators have a square root key. Computer spreadsheets and other software are also frequently used to calculate square roots. Pocket calculators typically implement efficient routines, such as the Newton's method (frequently with an initial guess of 1), to compute the square root of a positive real number. When computing square roots with logarithm tables or slide rules, one can exploit the identity
p2590
aVformula_6 or formula_7
p2591
aVwhere formula_8 and formula_9 are the natural and base-10 logarithms.
p2592
aVBy trial-and-error, one can square an estimate for and raise or lower the estimate until it agrees to sufficient accuracy. For this technique it's prudent to use the identity
p2593
aVformula_10
p2594
aVas it allows one to adjust the estimate "x" by some amount "c" and measure the square of the adjustment in terms of the original estimate and its square. Furthermore, formula_11 when "c" is close to 0, because the tangent line to the graph of formula_12 at "c"=0, as a function of "c" alone, is formula_13. Thus, small adjustments to "x" can be planned out by setting formula_14 to formula_15, or formula_16.
p2595
aVThe most common iterative method of square root calculation by hand is known as the "Babylonian method" or "Heron's method" after the first-century Greek philosopher Heron of Alexandria, who first described it.
p2596
aVThe method uses the same iterative scheme as the Newton\u2013Raphson method yields when applied to the function y = f("x")="x"2 \u2212 "a", using the fact that its slope at any point is formula_17 but predates it by many centuries.
p2597
aVThe algorithm is to repeat a simple calculation that results in a number closer to the actual square root each time it is repeated with its result as the new input. The motivation is that if "x" is an overestimate to the square root of a non-negative real number "a" then "a/x" will be an underestimate and so the average of these two numbers is a better approximation than either of them. However, the inequality of arithmetic and geometric means shows this average is always an overestimate of the square root (as noted below), and so it can serve as a new overestimate with which to repeat the process, which converges as a consequence of the successive overestimates and underestimates being closer to each other after each iteration. To find "x" :
p2598
aVThat is, if an arbitrary guess for is formula_18, and , then each xn is an approximation of which is better for large "n" than for small "n". If "a" is positive, the convergence is quadratic, which means that in approaching the limit, the number of correct digits roughly doubles in each next iteration. If , the convergence is only linear.
p2599
aVUsing the identity
p2600
aVformula_19
p2601
aVthe computation of the square root of a positive number can be reduced to that of a number in the range . This simplifies finding a start value for the iterative method that is close to the square root, for which a polynomial or piecewise-linear approximation can be used.
p2602
aVThe time complexity for computing a square root with "n" digits of precision is equivalent to that of multiplying two "n"-digit numbers.
p2603
aVAnother useful method for calculating the square root is the Shifting nth root algorithm, applied for .
p2604
aVSquare roots of negative and complex numbers.
p2605
aVThe square of any positive or negative number is positive, and the square of 0 is 0. Therefore, no negative number can have a real square root. However, it is possible to work with a more inclusive set of numbers, called the complex numbers, that does contain solutions to the square root of a negative number. This is done by introducing a new number, denoted by "i" (sometimes "j", especially in the context of electricity where ""i"" traditionally represents electric current) and called the imaginary unit, which is "defined" such that . Using this notation, we can think of "i" as the square root of \u22121, but notice that we also have and so \u2212"i" is also a square root of \u22121. By convention, the principal square root of \u22121 is "i", or more generally, if "x" is any non-negative number, then the principal square root of \u2212"x" is
p2606
aVformula_20
p2607
aVThe right side (as well as its negative) is indeed a square root of \u2212"x", since
p2608
aVformula_21
p2609
aVFor every non-zero complex number "z" there exist precisely two numbers "w" such that : the principal square root of "z" (defined below), and its negative.
p2610
aVSquare root of an imaginary number.
p2611
aVThe square root of i is given by
p2612
aVformula_22
p2613
aVThis result can be obtained algebraically by finding "a" and "b" such that
p2614
aVformula_23
p2615
aVor equivalently
p2616
aVformula_24
p2617
aVThis gives the two simultaneous equations
p2618
aVformula_25
p2619
aVwith solutions
p2620
aVformula_26
p2621
aVThe choice of the principal root then gives
p2622
aVformula_27
p2623
aVThe result can also be obtained by using de Moivre's formula and setting
p2624
aVformula_28
p2625
aVwhich produces
p2626
aVformula_29
p2627
aVPrincipal square root of a complex number.
p2628
aVTo find a definition for the square root that allows us to consistently choose a single value, called the principal value, we start by observing that any complex number "x" + "iy" can be viewed as a point in the plane, ("x", "y"), expressed using Cartesian coordinates. The same point may be reinterpreted using polar coordinates as the pair ("r", \u03c6), where "r" \u2265 0 is the distance of the point from the origin, and \u03c6 is the angle that the line from the origin to the point makes with the positive real ("x") axis. In complex analysis, this value is conventionally written "r"\u2009"e""i\u03c6". If 
p2629
aVformula_30
p2630
aVthen we define the principal square root of "z" as follows:
p2631
aVformula_31
p2632
aVThe principal square root function is thus defined using the nonpositive real axis as a branch cut. The principal square root function is holomorphic everywhere except on the set of non-positive real numbers (on strictly negative reals it isn't even continuous). The above Taylor series for remains valid for complex numbers "x" with .
p2633
aVThe above can also be expressed in terms of trigonometric functions:
p2634
aVformula_32
p2635
aVAlgebraic formula.
p2636
aVWhen the number is expressed using Cartesian coordinates the following formula can be used for the principal square root:
p2637
aVformula_33
p2638
aVwhere the two-digit pattern {3, 6} repeats over and over again in the partial denominators. Since , the above is also identical to the following generalized continued fractions:
p2639
aVformula_34
p2640
aVGeometric construction of the square root.
p2641
aVThe square root of a positive number is usually defined as the side length of a square with the area equal to the given number. But the square shape is not necessary for it: if one of two similar planar Euclidean objects has the area "a" times greater than another, then the ratio of their linear sizes is .
p2642
aVA square root can be constructed with a compass and straightedge. In his Elements, Euclid (fl. 300 BC) gave the construction of the geometric mean of two quantities in two different places: Proposition II.14 and Proposition VI.13. Since the geometric mean of "a" and "b" is formula_35, one can construct formula_36 simply by taking .
p2643
aVThe construction is also given by Descartes in his "La Géométrie", see figure 2 on page 2. However, Descartes made no claim to originality and his audience would have been quite familiar with Euclid.
p2644
aVEuclid's second proof in Book VI depends on the theory of similar triangles. Let AHB be a line segment of length with and . Construct the circle with AB as diameter and let C be one of the two intersections of the perpendicular chord at H with the circle and denote the length CH as "h". Then, using Thales' theorem and, as in the proof of Pythagoras' theorem by similar triangles, triangle AHC is similar to triangle CHB (as indeed both are to triangle ACB, though we don't need that, but it is the essence of the proof of Pythagoras' theorem) so that AH:CH is as HC:HB, i.e. formula_37 from which we conclude by cross-multiplication that formula_38 and finally that formula_39. Note further that if you were to mark the midpoint O of the line segment AB and draw the radius OC of length formula_40 then clearly OC > CH, i.e. formula_41 (with equality if and only if ), which is the arithmetic\u2013geometric mean inequality for two variables and, as noted above, is the basis of the Ancient Greek understanding of "Heron's method".
p2645
aVAnother method of geometric construction uses right triangles and induction: can, of course, be constructed, and once has been constructed, the right triangle with 1 and for its legs has a hypotenuse of . The Spiral of Theodorus is constructed using successive square roots in this manner.
p2646
asS'Surface area'
p2647
(lp2648
VThe surface area of a solid object is a measure of the total area that the surface of an object occupies. The mathematical definition of surface area in the presence of curved surfaces is considerably more involved than the definition of arc length of one-dimensional curves, or of the surface area for polyhedra (i.e., objects with flat polygonal faces), for which the surface area is the sum of the areas of its faces. Smooth surfaces, such as a sphere, are assigned surface area using their representation as parametric surfaces. This definition of surface area is based on methods of infinitesimal calculus and involves partial derivatives and double integration. 
p2649
aVA general definition of surface area was sought by Henri Lebesgue and Hermann Minkowski at the turn of the twentieth century. Their work led to the development of geometric measure theory, which studies various notions of surface area for irregular objects of any dimension. An important example is the Minkowski content of a surface.
p2650
aVDefinition.
p2651
aVWhile the areas of many simple surfaces have been known since antiquity, a rigorous mathematical "definition" of area requires a great deal of care. 
p2652
aVThis should provide a function
p2653
aV formula_1
p2654
aVwhich assigns a positive real number to a certain class of surfaces that satisfies several natural requirements. The most fundamental property of the surface area is its additivity: "the area of the whole is the sum of the areas of the parts". More rigorously, if a surface "S" is a union of finitely many pieces "S"1, \u2026, "S""r" which do not overlap except at their boundaries, then 
p2655
aV formula_2
p2656
aVSurface areas of flat polygonal shapes must agree with their geometrically defined area. Since surface area is a geometric notion, areas of congruent surfaces must be the same and the area must depend only on the shape of the surface, but not on its position and orientation in space. This means that surface area is invariant under the group of Euclidean motions. These properties uniquely characterize surface area for a wide class of geometric surfaces called "piecewise smooth". Such surfaces consist of finitely many pieces that can be represented in the parametric form
p2657
aV formula_3
p2658
aVwith a continuously differentiable function formula_4 The area of an individual piece is defined by the formula 
p2659
aV formula_5
p2660
aVThus the area of "S""D" is obtained by integrating the length of the normal vector formula_6 to the surface over the appropriate region "D" in the parametric "uv" plane. The area of the whole surface is then obtained by adding together the areas of the pieces, using additivity of surface area. The main formula can be specialized to different classes of surfaces, giving, in particular, formulas for areas of graphs "z" = "f"("x","y") and surfaces of revolution.
p2661
aVOne of the subtleties of surface area, as compared to arc length of curves, is that surface area cannot be defined simply as the limit of areas of polyhedral shapes approximating a given smooth surface. It was demonstrated by Hermann Schwarz that already for the cylinder, different choices of approximating flat surfaces can lead to different limiting values of the area (Known as Schwarz's paradox.)
p2662
aVVarious approaches to a general definition of surface area were developed in the late nineteenth and the early twentieth century by Henri Lebesgue and Hermann Minkowski. While for piecewise smooth surfaces there is a unique natural notion of surface area, if a surface is very irregular, or rough, then it may not be possible to assign an area to it at all. A typical example is given by a surface with spikes spread throughout in a dense fashion. Many surfaces of this type occur in the study of fractals. Extensions of the notion of area which partially fulfill its function and may be defined even for very badly irregular surfaces are studied in geometric measure theory. A specific example of such an extension is the Minkowski content of the surface.
p2663
aVCommon formulas.
p2664
aVRatio of surface areas of a sphere and cylinder of the same radius and height.
p2665
aVThe below given formulas can be used to show that the surface area of a sphere and cylinder of the same radius and height are in the ratio 2 : 3, as follows.
p2666
aVLet the radius be "r" and the height be "h" (which is 2"r" for the sphere).
p2667
aVformula_7
p2668
aVThe discovery of this ratio is credited to Archimedes.
p2669
aVIn chemistry.
p2670
aVSurface area is important in chemical kinetics. Increasing the surface area of a substance generally increases the rate of a chemical reaction. For example, iron in a fine powder will combust, while in solid blocks it is stable enough to use in structures. For different applications a minimal or maximal surface area may be desired.
p2671
aVIn biology.
p2672
aVThe surface area of an organism is important in several considerations, such as regulation of body temperature and digestion. Animals use their teeth to grind food down into smaller particles, increasing the surface area available for digestion. The epithelial tissue lining the digestive tract contains microvilli, greatly increasing the area available for absorption. Elephants have large ears, allowing them to regulate their own body temperature. In other instances, animals will need to minimize surface area; for example, people will fold their arms over their chest when cold to minimize heat loss. 
p2673
aVThe surface area to volume ratio (SA:V) of a cell imposes upper limits on size, as the volume increases much faster than does the surface area, thus limiting the rate at which substances diffuse from the interior across the cell membrane to interstitial spaces or to other cells. Indeed, representing a cell as an idealized sphere of radius "r", the volume and surface area are, respectively, "V" = 4/3 \u03c0 "r"3; "SA" = 4 \u03c0 "r"2. The resulting surface area to volume ratio is therefore 3/"r". Thus, if a cell has a radius of 1 \u03bcm, the SA:V ratio is 3; whereas if the radius of the cell is instead 10 \u03bcm, then the SA:V ratio becomes 0.3. With a cell radius of 100, SA:V ratio is 0.03. Thus, the surface area falls off steeply with increasing volume.
p2674
asS'Theory of computation'
p2675
(lp2676
VIn theoretical computer science and mathematics, the theory of computation is the branch that deals with how efficiently problems can be solved on a model of computation, using an algorithm. The field is divided into three major branches: automata theory and language, computability theory, and computational complexity theory, which are linked by the question: "What are the fundamental capabilities and limitations of computers?."
p2677
aVIn order to perform a rigorous study of computation, computer scientists work with a mathematical abstraction of computers called a model of computation. There are several models in use, but the most commonly examined is the Turing machine. Computer scientists study the Turing machine because it is simple to formulate, can be analyzed and used to prove results, and because it represents what many consider the most powerful possible "reasonable" model of computation (see Church\u2013Turing thesis). It might seem that the potentially infinite memory capacity is an unrealizable attribute, but any decidable problem solved by a Turing machine will always require only a finite amount of memory. So in principle, any problem that can be solved (decided) by a Turing machine can be solved by a computer that has a bounded amount of memory.
p2678
aVHistory.
p2679
aVThe theory of computation can be considered the creation of models of all kinds in the field of computer science. Therefore, mathematics and logic are used. In the last century it became an independent academic discipline and was separated from mathematics.
p2680
aVSome pioneers of the theory of computation were Alonzo Church, Kurt Gödel, Alan Turing, Stephen Kleene, John von Neumann and Claude Shannon.
p2681
aVBranches.
p2682
aVAutomata theory.
p2683
aVAutomata theory is the study of abstract machines (or more appropriately, abstract 'mathematical' machines or systems) and the computational problems that can be solved using these machines. These abstract machines are called automata. Automata comes from the Greek word (\u0391\u03c5\u03c4\u03cc\u03bc\u03b1\u03c4\u03b1) which means that something is doing something by itself.
p2684
aVAutomata theory is also closely related to formal language theory, as the automata are often classified by the class of formal languages they are able to recognize. An automaton can be a finite representation of a formal language that may be an infinite set. Automata are used as theoretical models for computing machines, and are used for proofs about computability.
p2685
aVFormal Language Theory.
p2686
aVLanguage theory is a branch of mathematics concerned with describing languages as a set of operations over an alphabet. It is closely linked with automata theory, as automata are used to generate and recognize formal languages. There are several classes of formal languages, each allowing more complex language specification than the one before it, i.e. Chomsky hierarchy, and each corresponding to a class of automata which recognizes it. Because automata are used as models for computation, formal languages are the preferred mode of specification for any problem that must be computed.
p2687
aVComputability theory.
p2688
aVComputability theory deals primarily with the question of the extent to which a problem is solvable on a computer. The statement that the halting problem cannot be solved by a Turing machine is one of the most important results in computability theory, as it is an example of a concrete problem that is both easy to formulate and impossible to solve using a Turing machine. Much of computability theory builds on the halting problem result.
p2689
aVAnother important step in computability theory was Rice's theorem, which states that for all non-trivial properties of partial functions, it is undecidable whether a Turing machine computes a partial function with that property.
p2690
aVComputability theory is closely related to the branch of mathematical logic called recursion theory, which removes the restriction of studying only models of computation which are reducible to the Turing model. Many mathematicians and computational theorists who study recursion theory will refer to it as computability theory.
p2691
aVComputational complexity theory.
p2692
aVComplexity theory considers not only whether a problem can be solved at all on a computer, but also how efficiently the problem can be solved. Two major aspects are considered: time complexity and space complexity, which are respectively how many steps does it take to perform a computation, and how much memory is required to perform that computation.
p2693
aVIn order to analyze how much time and space a given algorithm requires, computer scientists express the time or space required to solve the problem as a function of the size of the input problem. For example, finding a particular number in a long list of numbers becomes harder as the list of numbers grows larger. If we say there are "n" numbers in the list, then if the list is not sorted or indexed in any way we may have to look at every number in order to find the number we're seeking. We thus say that in order to solve this problem, the computer needs to perform a number of steps that grows linearly in the size of the problem.
p2694
aVTo simplify this problem, computer scientists have adopted Big O notation, which allows functions to be compared in a way that ensures that particular aspects of a machine's construction do not need to be considered, but rather only the asymptotic behavior as problems become large. So in our previous example we might say that the problem requires formula_1 steps to solve.
p2695
aVPerhaps the most important open problem in all of computer science is the question of whether a certain broad class of problems denoted NP can be solved efficiently. This is discussed further at Complexity classes P and NP, and P versus NP problem is one of the seven Millennium Prize Problems stated by the Clay Mathematics Institute in 2000. The Official Problem Description was given by Turing Award winner Stephen Cook.
p2696
aVModels of computation.
p2697
aVAside from a Turing machine, other equivalent (See: Church\u2013Turing thesis) models of computation are in use.
p2698
aVis a concept which has many similarities to formula_2-calculus, but also important differences exist (e.g. fixed point combinator Y has normal form in combinatory logic but not in formula_2-calculus). Combinatory logic was developed with great ambitions: understanding the nature of paradoxes, making foundations of mathematics more economic (conceptually), eliminating the notion of variables (thus clarifying their role in mathematics).
p2699
aVis a theoretically interesting idealization of a computer. There are several variants. In most of them, each register can hold a natural number (of unlimited size), and the instructions are simple (and few in number), e.g. only decrementation (combined with conditional jump) and incrementation exist (and halting). The lack of the infinite (or dynamically growing) external store (seen at Turing machines) can be understood by replacing its role with Gödel numbering techniques: the fact that each register holds a natural number allows the possibility of representing a complicated thing (e.g. a sequence, or a matrix etc.) by an appropriate huge natural number \u2014 unambiguity of both representation and interpretation can be established by number theoretical foundations of these techniques.
p2700
aVIn addition to the general computational models, some simpler computational models are useful for special, restricted applications. Regular expressions, for example, specify string patterns in many contexts, from office productivity software to programming languages. Another formalism mathematically equivalent to regular expressions, Finite automata are used in circuit design and in some kinds of problem-solving. Context-free grammars specify programming language syntax. Non-deterministic pushdown automata are another formalism equivalent to context-free grammars. Primitive recursive functions are a defined subclass of the recursive functions.
p2701
aVDifferent models of computation have the ability to do different tasks. One way to measure the power of a computational model is to study the class of formal languages that the model can generate; in such a way to the Chomsky hierarchy of languages is obtained.
p2702
asS'Estimation'
p2703
(lp2704
VEstimation (or estimating) is the process of finding an estimate, or approximation, which is a value that is usable for some purpose even if input data may be incomplete, uncertain, or unstable. The value is nonetheless usable because it is derived from the best information available. Typically, estimation involves "using the value of a statistic derived from a sample to estimate the value of a corresponding population parameter". The sample provides information that can be projected, through various formal or informal processes, to determine a range most likely to describe the missing information. An estimate that turns out to be incorrect will be an overestimate if the estimate exceeded the actual result, and an underestimate if the estimate fell short of the actual result.
p2705
aVHow estimation is done.
p2706
aVEstimation is often done by sampling, which is counting a small number of examples something, and projecting that number onto a larger population. An example of estimation would be determining how many candies of a given size are in a glass jar. Because the distribution of candies inside the jar may vary, the observer can count the number of candies visible through the glass, consider the size of the jar, and presume that a similar distribution can be found in the parts that can not be seen, thereby making an estimate of the total number of candies that could be in the jar if that presumption were true. Estimates can similarly be generated by projecting results from polls or surveys onto the entire population.
p2707
aVIn making an estimate, the goal is often most useful to generate a range of possible outcomes that is precise enough to be useful, but not so precise that it is likely to be inaccurate. For example, in trying to guess the number of candies in the jar, if fifty were visible, and the total volume of the jar seemed to be about twenty times as large as the volume containing the visible candies, then one might simply project that there were a thousand candies in the jar. Such a projection, intended to pick the single value that is believed to be closest to the actual value, is called a point estimate. However, a point estimation is likely to be incorrect, because the sample size - in this case, the number of candies that are visible - is too small a number to be sure that it does not contain anomalies that differ from the population as a whole. A corresponding concept is an interval estimate, which captures a much larger range of possibilities, but is too broad to be useful. For example, if one were asked to estimate the percentage of people who like candy, it would clearly be correct that the number falls between zero and one hundred percent. Such an estimate would provide no guidance, however, to somebody who is trying to determine how many candies to buy for a party to be attended by a hundred people.
p2708
aVUses of estimation.
p2709
aVIn mathematics, approximation describes the process of finding estimates in the form of upper or lower bounds for a quantity that cannot readily be evaluated precisely, and approximation theory deals with finding simpler functions that are close to some complicated function and that can provide useful estimates. In statistics, an estimator is the formal name for the rule by which an estimate is calculated from data, and estimation theory deals with finding estimates with good properties. This process is used in signal processing, for approximating an unobserved signal on the basis of an observed signal containing noise. For estimation of yet-to-be observed quantities, forecasting and prediction are applied. A Fermi problem, in physics, is one concerning estimation in problems which typically involve making justified guesses about quantities that seem impossible to compute given limited available information.
p2710
aVEstimation is important in business and economics, because too many variables exist to figure out how large-scale activities will develop. Estimation in project planning can be particularly significant, because plans for the distribution of labor and for purchases of raw materials must be made, despite the inability to know every possible problem that may come up. A certain amount of resources will be available for carrying out a particular project, making it important to obtain or generate a cost estimate as one of the vital elements of entering into the project. The U.S. Government Accountability Office defines a cost estimate as, "the summation of individual cost elements, using established methods and valid data, to estimate the future costs of a program, based on what is known today", and reports that "realistic cost estimating was imperative when making wise decisions in acquiring new systems". Furthermore, project plans must not underestimate the needs of the project, which can result in delays while unmet needs are fulfilled, nor must they greatly overestimate the needs of the project, or else the unneeded resources may go to waste.
p2711
aVAn informal estimate when little information is available is called a guesstimate, because the inquiry becomes closer to purely guessing the answer. The "estimated" sign, \u212e, is used to designate that package contents are close to the nominal contents.
p2712
asS'Transitivity (mathematics)'
p2713
(lp2714
sS'Empty string'
p2715
(lp2716
VIn formal language theory, the empty string is the unique string of length zero.
p2717
aVFormal theory.
p2718
aVFormally, a string is a finite, ordered sequence of characters such as letters, digits or spaces. The empty string is the special case where the sequence has length zero, so there are no symbols in the string.
p2719
aVThere is only one empty string, because two strings are only different if they have different lengths or a different sequence of symbols.
p2720
aVIn formal treatments, the empty string is denoted with "\u03b5" or sometimes \u039b or \u03bb.
p2721
aVThe empty string should not be confused with the empty language \u2205, which is a formal language (i.e. a set of strings) that contains no strings, not even the empty string.
p2722
aVThe empty string has several properties:
p2723
aVUse in programming languages.
p2724
aVIn most programming languages, strings are a data type. Individual strings are typically stored in consecutive memory locations.
p2725
aVThis means that the same string (for example, the empty string) could be stored in two different places in memory.
p2726
aVIn this way there could be multiple empty strings in memory, in contrast with the formal theory definition, for which there is only one possible empty string.
p2727
aVHowever, a string comparison function would indicate that all of these empty strings are equal to each other.
p2728
aVIn most programming languages, the empty string is distinct from a null reference (or null pointer) because a null reference does not point to any string at all, not even the empty string.
p2729
aVThe empty string is a legitimate string, upon which most string operations should work. Some languages treat some or all of the following in similar ways, which can lessen the danger: empty strings, null references, the integer 0, the floating point number 0, the boolean value false, the ASCII character NUL, or other such values.
p2730
aVThe empty string is usually represented similarly to other strings. In implementations with string terminating character (null-terminated strings or plain text lines), the empty string is indicated by the immediate use of this terminating character.
p2731
aVExamples of empty strings.
p2732
aVThe empty string is a syntactically valid representation of zero in positional notation (in any base), which does not contain leading zeros. Since the empty string does not have a standard visual representation outside of formal language theory, the number zero is traditionally represented by a single decimal digit 0 instead.
p2733
aVZero-filled memory area, interpreted as a null-terminated string, is an empty string.
p2734
aVEmpty lines of text show the empty string. This can occur from two consecutive EOLs, as often occur in text files, and this is sometimes used in text processing to separate paragraphs, e.g. in MediaWiki.
p2735
asS'Big O notation'
p2736
(lp2737
VIn mathematics, big O notation describes the limiting behavior of a function when the argument tends towards a particular value or infinity, usually in terms of simpler functions. It is a member of a larger family of notations that is called Landau notation, Bachmann\u2013Landau notation (after Edmund Landau and Paul Bachmann), or asymptotic notation. In computer science, big O notation is used to classify algorithms by how they respond ("e.g.," in their processing time or working space requirements) to changes in input size. In analytic number theory, it is used to estimate the "error committed" while replacing the asymptotic size, or asymptotic mean size, of an arithmetical function, by the value, or mean value, it takes at a large finite argument. A famous example is the problem of estimating the remainder term in the prime number theorem.
p2738
aVBig O notation characterizes functions according to their growth rates: different functions with the same growth rate may be represented using the same O notation. The letter O is used because the growth rate of a function is also referred to as order of the function. A description of a function in terms of big O notation usually only provides an upper bound on the growth rate of the function. Associated with big O notation are several related notations, using the symbols "o", \u03a9, \u03c9, and \u0398, to describe other kinds of bounds on asymptotic growth rates.
p2739
aVBig O notation is also used in many other fields to provide similar estimates.
p2740
aVFormal definition.
p2741
aVLet "f" and "g" be two functions defined on some subset of the real numbers. One writes
p2742
aVformula_1
p2743
aVif and only if there is a positive constant M such that for all sufficiently large values of "x", the absolute value of "f"("x") is at most M multiplied by the absolute value of "g"("x"). That is, "f"("x") = "O"("g"("x")) if and only if there exists a positive real number "M" and a real number "x"0 such that
p2744
aVformula_2
p2745
aVIn many contexts, the assumption that we are interested in the growth rate as the variable "x" goes to infinity is left unstated, and one writes more simply that "f"("x") = "O"("g"("x")).
p2746
aVThe notation can also be used to describe the behavior of "f" near some real number "a" (often, "a" = 0): we say
p2747
aVformula_3
p2748
aVif and only if there exist positive numbers "\u03b4" and "M" such that
p2749
aVformula_4
p2750
aVIf "g"("x") is non-zero for values of "x" sufficiently close to "a", both of these definitions can be unified using the limit superior:
p2751
aVformula_5
p2752
aVif and only if
p2753
aVformula_6
p2754
aVExample.
p2755
aVIn typical usage, the formal definition of "O" notation is not used directly; rather, the "O" notation for a function "f" is derived by the following simplification rules:
p2756
aVFor example, let formula_7, and suppose we wish to simplify this function, using "O" notation, to describe its growth rate as "x" approaches infinity. This function is the sum of three terms: 6"x"4, \u22122"x"3, and 5. Of these three terms, the one with the highest growth rate is the one with the largest exponent as a function of "x", namely 6"x"4. Now one may apply the second rule: 6"x"4 is a product of 6 and "x"4 in which the first factor does not depend on "x". Omitting this factor results in the simplified form "x"4. Thus, we say that "f"("x") is a "big-oh" of ("x"4). Mathematically, we can write "f"("x") = "O"("x"4).
p2757
aVOne may confirm this calculation using the formal definition: let "f"("x") = 6"x"4 \u2212 2"x"3 + 5 and "g"("x") = "x"4. Applying the formal definition from above, the statement that "f"("x") = "O"("x"4) is equivalent to its expansion,
p2758
aVformula_8
p2759
aVfor some suitable choice of "x"0 and "M" and for all "x" > "x"0. To prove this, let "x"0 = 1 and "M" = 13. Then, for all "x" > "x"0:
p2760
aVformula_9
p2761
aVUsage.
p2762
aVBig O notation has two main areas of application. In mathematics, it is commonly used to describe how closely a finite series approximates a given function, especially in the case of a truncated Taylor series or asymptotic expansion. In computer science, it is useful in the analysis of algorithms. In both applications, the function "g"("x") appearing within the "O"(...) is typically chosen to be as simple as possible, omitting constant factors and lower order terms.
p2763
aVThere are two formally close, but noticeably different, usages of this notation: infinite asymptotics and infinitesimal asymptotics. This distinction is only in application and not in principle, however\u2014the formal definition for the "big O" is the same for both cases, only with different limits for the function argument.
p2764
aVInfinite asymptotics.
p2765
aVBig O notation is useful when analyzing algorithms for efficiency. For example, the time (or the number of steps) it takes to complete a problem of size "n" might be found to be "T"("n") = 4"n"2 \u2212 2"n" + 2.
p2766
aVAs "n" grows large, the "n"2 term will come to dominate, so that all other terms can be neglected\u2014for instance when "n" = 500, the term 4"n"2 is 1000 times as large as the 2"n" term. Ignoring the latter would have negligible effect on the expression's value for most purposes.
p2767
aVFurther, the coefficients become irrelevant if we compare to any other order of expression, such as an expression containing a term n3 or n4. Even if "T"("n") = 1,000,000"n"2, if "U"("n") = "n"3, the latter will always exceed the former once "n" grows larger than 1,000,000 ("T"(1,000,000) = 1,000,0003= "U"(1,000,000)). Additionally, the number of steps depends on the details of the machine model on which the algorithm runs, but different types of machines typically vary by only a constant factor in the number of steps needed to execute an algorithm.
p2768
aVSo the big O notation captures what remains: we write either
p2769
aVformula_10
p2770
aVor
p2771
aVformula_11
p2772
aVand say that the algorithm has "order of n2" time complexity.
p2773
aVNote that "=" is not meant to express "is equal to" in its normal mathematical sense, but rather a more colloquial "is", so the second expression is technically accurate (see the "Equals sign" discussion below) while the first is a common abuse of notation.
p2774
aVInfinitesimal asymptotics.
p2775
aVBig can also be used to describe the error term in an approximation to a mathematical function. The most significant terms are written explicitly, and then the least-significant terms are summarized in a single big term. Consider, for example, the exponential series and two expressions of it that are valid when is small:
p2776
aVformula_12
p2777
aVThe second expression (the one with ) means the absolute-value of the error is smaller than some constant times when is close enough to 0.
p2778
aVProperties.
p2779
aVIf the function "f" can be written as a finite sum of other functions, then the fastest growing one determines the order of
p2780
aV"f"("n"). For example
p2781
aVformula_13 
p2782
aVIn particular, if a function may be bounded by a polynomial in "n", then as "n" tends to "infinity", one may disregard "lower-order" terms of the polynomial. 
p2783
aV"O"("n""c") and "O"("c""n") are very different. If "c" is greater than one, then the latter grows much faster. A function that grows faster than "n""c" for any "c" is called "superpolynomial". One that grows more slowly than any exponential function of the form formula_14 is called "subexponential". An algorithm can require time that is both superpolynomial and subexponential; examples of this include the fastest known algorithms for integer factorization.
p2784
aV"O"(log "n") is exactly the same as "O"(log("n""c")). The logarithms differ only by a constant factor (since
p2785
aVformula_15) and thus the big O notation ignores that. Similarly, logs with different constant bases are equivalent.
p2786
aVExponentials with different bases, on the other hand, are not of the same order. For example, formula_16 and formula_17 are not of the same order.
p2787
aVChanging units may or may not affect the order of the resulting algorithm. Changing units is equivalent to multiplying the appropriate variable by a constant wherever it appears. For example, if an algorithm runs in the order of "n"2, replacing "n" by "cn" means the algorithm runs in the order of formula_18, and the big O notation ignores the constant formula_19. This can be written as formula_20. If, however, an algorithm runs in the order of formula_16, replacing n with cn gives formula_22. This is not equivalent to formula_16 in general.
p2788
aVChanging of variable may affect the order of the resulting algorithm. For example, if an algorithm's running time is "O"("n") when measured in terms of the number "n" of "digits" of an input number "x", then its running time is "O"(log "x") when measured as a function of the input number "x" itself, because "n" = \u0398(log "x").
p2789
aVformula_24
p2790
aVformula_25
p2791
aVformula_26, which means that formula_27 is a convex cone.
p2792
aVIf "f" and "g" are positive functions, formula_28
p2793
aVLet "k" be a constant. Then:
p2794
aVformula_29 if "k" is nonzero.
p2795
aVformula_30
p2796
aVMultiple variables.
p2797
aVBig "O" (and little o, and \u03a9...) can also be used with multiple variables.
p2798
aVTo define Big "O" formally for multiple variables, suppose formula_31 and formula_32 are two functions defined on some subset of formula_33. We say
p2799
aVformula_34
p2800
aVif and only if
p2801
aVformula_35
p2802
aVFor example, the statement
p2803
aVformula_36
p2804
aVasserts that there exist constants "C" and "M" such that
p2805
aVformula_37
p2806
aVwhere "g"("n","m") is defined by
p2807
aVformula_38
p2808
aVNote that this definition allows all of the coordinates of formula_39 to increase to infinity. In particular, the statement
p2809
aVformula_40
p2810
aV(i.e., formula_41) is quite different from
p2811
aVformula_42
p2812
aV(i.e., formula_43).
p2813
aVMatters of notation.
p2814
aVEquals sign.
p2815
aVThe statement ""f"("x") is "O"("g"("x"))" as defined above is usually written as "f"("x") = "O"("g"("x")). Some consider this to be an abuse of notation, since the use of the equals sign could be misleading as it suggests a symmetry that this statement does not have. As de Bruijn says, "O"("x") = "O"("x"2) is true but "O"("x"2) = "O"("x") is not. Knuth describes such statements as "one-way equalities", since if the sides could be reversed, "we could deduce ridiculous things like "n" = "n"2 from the identities "n" = "O"("n"2) and "n"2 = "O"("n"2)."
p2816
aVFor these reasons, it would be more precise to use set notation and write "f"("x") \u2208 "O"("g"("x")), thinking of "O"("g"("x")) as the class of all functions "h"("x") such that |"h"("x")| \u2264 "C"|"g"("x")| for some constant "C". However, the use of the equals sign is customary. Knuth pointed out that "mathematicians customarily use the = sign as they use the word 'is' in English: Aristotle is a man, but a man isn't necessarily Aristotle."
p2817
aVOther arithmetic operators.
p2818
aVBig O notation can also be used in conjunction with other arithmetic operators in more complicated equations. For example, "h"("x") + "O"("f"("x")) denotes the collection of functions having the growth of "h"("x") plus a part whose growth is limited to that of "f"("x"). Thus,
p2819
aVformula_44
p2820
aVexpresses the same as
p2821
aVformula_45
p2822
aVExample.
p2823
aVSuppose an algorithm is being developed to operate on a set of "n" elements. Its developers are interested in finding a function "T"("n") that will express how long the algorithm will take to run (in some arbitrary measurement of time) in terms of the number of elements in the input set. The algorithm works by first calling a subroutine to sort the elements in the set and then perform its own operations. The sort has a known time complexity of "O"("n"2), and after the subroutine runs the algorithm must take an additional formula_46 time before it terminates. Thus the overall time complexity of the algorithm can be expressed as
p2824
aVformula_47
p2825
aVHere the terms 2"n"+10 are subsumed within the faster-growing "O"("n"2). Again, this usage disregards some of the formal meaning of the "=" symbol, but it does allow one to use the big O notation as a kind of convenient placeholder.
p2826
aVDeclaration of variables.
p2827
aVAnother feature of the notation, although less exceptional, is that function arguments may need to be inferred from the context when several variables are involved. The following two right-hand side big O notations have dramatically different meanings:
p2828
aVformula_48
p2829
aVformula_49
p2830
aVThe first case states that "f"("m") exhibits polynomial growth, while the second, assuming "m" > 1, states that "g"("n") exhibits exponential growth.
p2831
aVTo avoid confusion, some authors use the notation
p2832
aVformula_50
p2833
aVrather than the less explicit
p2834
aVformula_51
p2835
aVMultiple usages.
p2836
aVIn more complicated usage, "O"(...) can appear in different places in an equation, even several times on each side. For example, the following are true for formula_52
p2837
aVformula_53
p2838
aVformula_54
p2839
aVformula_55
p2840
aVThe meaning of such statements is as follows: for "any" functions which satisfy each "O"(...) on the left side, there are "some" functions satisfying each "O"(...) on the right side, such that substituting all these functions into the equation makes the two sides equal. For example, the third equation above means: "For any function formula_56, there is some function formula_57 such that formula_58." In terms of the "set notation" above, the meaning is that the class of functions represented by the left side is a subset of the class of functions represented by the right side. In this use the "=" is a formal symbol that unlike the usual use of "=" is not a symmetric relation. Thus for example formula_59 does not imply the false statement formula_60.
p2841
aVOrders of common functions.
p2842
aVHere is a list of classes of functions that are commonly encountered when analyzing the running time of an algorithm. In each case, "c" is a constant and "n" increases without bound. The slower-growing functions are generally listed first.
p2843
aVThe statement formula_61 is sometimes weakened to formula_62 to derive simpler formulas for asymptotic complexity.
p2844
aVFor any formula_63 and formula_64, formula_65 is a subset of formula_66 for any formula_67, so may be considered as a polynomial with some bigger order.
p2845
aVRelated asymptotic notations.
p2846
aVBig "O" is the most commonly used asymptotic notation for comparing functions, although in many cases Big "O" may be replaced with Big Theta \u0398 for asymptotically tighter bounds. Here, we define some related notations in terms of Big "O", progressing up to the family of Bachmann\u2013Landau notations to which Big "O" notation belongs.
p2847
aVLittle-o notation.
p2848
aVThe relation formula_68 is read as "formula_69 is little-o of formula_70". Intuitively, it means that formula_70 grows much faster than formula_69, or similarly, the growth of formula_69 is nothing compared to that of formula_70. It assumes that "f" and "g" are both functions of one variable. Formally, "f"("n") \u2208 "o"("g"("n")) as means that for every positive constant formula_75 there exists a constant "N" such that
p2849
aVformula_76
p2850
aVNote the difference between the earlier formal definition for the big-O notation, and the present definition of little-o: while the former has to be true for "at least one" constant "M" the latter must hold for "every" positive constant formula_75, however small. In this way little-o notation makes a stronger statement than the corresponding big-O notation: every function that is little-o of "g" is also big-O of "g", but not every function that is big-O "g" is also little-o of "g" (for instance "g" itself is not, unless it is identically zero near \u221e).
p2851
aVIf "g"("x") is nonzero, or at least becomes nonzero beyond a certain point, the relation "f"("x") = "o"("g"("x")) is equivalent to
p2852
aVformula_78
p2853
aVFor example,
p2854
aVLittle-o notation is common in mathematics but rarer in computer science. In computer science the variable (and function value) is most often a natural number. In mathematics, the variable and function values are often real numbers. The following properties can be useful:
p2855
aVAs with big O notation, the statement "formula_69 is formula_87" is usually written as formula_88, which is a slight abuse of notation.
p2856
aVBig Omega notation.
p2857
aVThere are two very widespread and incompatible definitions of the statement
p2858
aVformula_89
p2859
aVwhere formula_90 is some real number, formula_91, or formula_92, where formula_93 and formula_94 are real functions defined in a neighbourhood of formula_90, and where formula_94 is positive in this neighbourhood.
p2860
aVThe first one (chronologically) is used in analytic number theory, and the other one in computational complexity theory. When the two subjects meet, this situation is bound to generate confusion.
p2861
aVThe Hardy\u2013Littlewood definition.
p2862
aVIn 1914 G.H. Hardy and J.E. Littlewood introduced the new symbol formula_97, which is defined as follows:
p2863
aVformula_98.
p2864
aVThus formula_99 is the negation of formula_100.
p2865
aVIn 1918 the same authors introduced the two new symbols formula_101 and formula_102, thus defined:
p2866
aVformula_103;
p2867
aVformula_104.
p2868
aVHence formula_105 is the negation of formula_106, and formula_107 the negation of formula_108.
p2869
aVContrary to a later assertion of D.E. Knuth, Edmund Landau did use these three symbols, with the same meanings, in 1924.
p2870
aVThese Hardy-Littlewood symbols are prototypes, which after Landau were never used again exactly thus.
p2871
aVformula_101 became formula_110, and formula_102 became formula_112.
p2872
aVThese three symbols formula_113, as well as formula_114 (meaning that formula_115 and formula_116 are both satisfied), are now currently used in analytic number theory.
p2873
aVSimple examples.
p2874
aVWe have
p2875
aVformula_117
p2876
aVand more precisely
p2877
aVformula_118
p2878
aVWe have
p2879
aVformula_119
p2880
aVand more precisely
p2881
aVformula_120
p2882
aVhowever
p2883
aVformula_121
p2884
aVThe Knuth definition.
p2885
aVIn 1976 D.E. Knuth published a paper to justify his use of the formula_97-symbol to describe a stronger property. Knuth wrote: "For all the applications I have seen so far in computer science, a stronger requirement [\u2026] is much more appropriate". He defined
p2886
aVformula_123
p2887
aVwith the comment: "Although I have changed Hardy and Littlewood's definition of formula_97, I feel justified in doing so because their definition is by no means in wide use, and because there are other ways to say what they want to say in the comparatively rare cases when their definition applies". However, the Hardy\u2013Littlewood definition had been used for at least 25 years.
p2888
aVFamily of Bachmann\u2013Landau notations.
p2889
aVAside from the Big "O" notation, the Big Theta \u0398 and Big Omega \u03a9 notations are the two most often used in computer science; the small omega \u03c9 notation is occasionally used in computer science.
p2890
aVAside from the Big "O" notation, the small "o", Big Omega \u03a9 and formula_125 notations are the three most often used in number theory; the small omega \u03c9 notation is never used in number theory.
p2891
aVUse in computer science.
p2892
aVInformally, especially in computer science, the Big "O" notation often is permitted to be somewhat abused to describe an asymptotic tight bound where using Big Theta \u0398 notation might be more factually appropriate in a given context. For example, when considering a function formula_126, all of the following are generally acceptable, but tightnesses of bound (i.e., numbers 2 and 3 below) are usually strongly preferred over laxness of bound (i.e., number 1 below).
p2893
aVThe equivalent English statements are respectively:
p2894
aVSo while all three statements are true, progressively more information is contained in each. In some fields, however, the Big O notation (number 2 in the lists above) would be used more commonly than the Big Theta notation (bullets number 3 in the lists above) because functions that grow more slowly are more desirable. For example, if formula_127 represents the running time of a newly developed algorithm for input size formula_128, the inventors and users of the algorithm might be more inclined to put an upper asymptotic bound on how long it will take to run without making an explicit statement about the lower asymptotic bound.
p2895
aVExtensions to the Bachmann\u2013Landau notations.
p2896
aVAnother notation sometimes used in computer science is Õ (read "soft-O"): "f"("n") = "Õ"("g"("n")) is shorthand
p2897
aVfor "f"("n") = "O"("g"("n") log"k" "g"("n")) for some "k". Essentially, it is Big O notation, ignoring logarithmic factors because the growth-rate effects of some other super-logarithmic function indicate a growth-rate explosion for large-sized input parameters that is more important to predicting bad run-time performance than the finer-point effects contributed by the logarithmic-growth factor(s). This notation is often used to obviate the "nitpicking" within growth-rates that are stated as too tightly bounded for the matters at hand (since log"k" "n" is always "o"("n"\u03b5) for any constant "k" and any \u03b5 > 0).
p2898
aVAlso the L notation, defined as
p2899
aVformula_129
p2900
aVis convenient for functions that are between polynomial and exponential.
p2901
aVGeneralizations and related usages.
p2902
aVThe generalization to functions taking values in any normed vector space is straightforward (replacing absolute values by norms), where "f" and "g" need not take their values in the same space. A generalization to functions "g" taking values in any topological group is also possible.
p2903
aVThe "limiting process" "x\u2192xo" can also be generalized by introducing an arbitrary filter base, i.e. to directed nets "f" and "g".
p2904
aVThe "o" notation can be used to define derivatives and differentiability in quite general spaces, and also (asymptotical) equivalence of functions,
p2905
aVformula_130
p2906
aVwhich is an equivalence relation and a more restrictive notion than the relationship ""f" is \u0398("g")" from above. (It reduces to formula_131 if "f" and "g" are positive real valued functions.) For example, 2"x" is \u0398("x"), but 2"x" \u2212 "x" is not "o"("x").
p2907
aVHistory (Bachmann\u2013Landau, Hardy, and Vinogradov notations).
p2908
aVThe symbol O was first introduced by number theorist Paul Bachmann in 1894, in the second volume of his book "Analytische Zahlentheorie" ("analytic number theory"), the first volume of which (not yet containing big O notation) was published in 1892. The number theorist Edmund Landau adopted it, and was thus inspired to introduce in 1909 the notation o; hence both are now called Landau symbols. These notations were used in applied mathematics during the 1950s for asymptotic analysis. The big O was popularized in computer science by Donald Knuth, who re-introduced the related Omega and Theta notations. Knuth also noted that the Omega notation had been introduced by Hardy and Littlewood under a different meaning "\u2260"o"" (i.e. "is not an "o" of"), and proposed the above definition. Hardy and Littlewood's original definition (which was also used in one paper by Landau) is still used in number theory (where Knuth's definition is never used). In fact, Landau also used in 1924, in the paper just mentioned, the symbols formula_101 ("right") and formula_102 ("left"), which were introduced in 1918 by Hardy and Littlewood, and which were precursors for the modern symbols formula_110 ("is not smaller than a small o of") and formula_112 ("is not larger than a small o of"). Thus the Omega symbols (with their original meanings) are sometimes also referred to as "Landau symbols".
p2909
aVAlso, Landau never used the Big Theta and small omega symbols.
p2910
aVHardy's symbols were (in terms of the modern "O" notation)
p2911
aVformula_136   and   formula_137
p2912
aV(Hardy however never defined or used the notation formula_138, nor formula_139, as it has been sometimes reported).
p2913
aVIt should also be noted that Hardy introduces the symbols formula_140 and formula_141 (as well as some other symbols) in his 1910 tract "Orders of Infinity", and makes use of it only in three papers (1910\u20131913). In his nearly 400 remaining papers and books he consistently uses the Landau symbols O and o.
p2914
aVHardy's notation is not used anymore. On the other hand, in the 1930s, the Russian number theorist Ivan Matveyevich Vinogradov introduced his notation
p2915
aVformula_139, which has been increasingly used in number theory instead of the formula_143 notation. We have
p2916
aVformula_144
p2917
aVand frequently both notations are used in the same paper.
p2918
aVThe big-O originally stands for "order of" ("Ordnung", Bachmann 1894), and is thus a roman letter. Neither Bachmann nor Landau ever call it "Omicron". The symbol was much later on (1976) viewed by Knuth as a capital omicron, probably in reference to his definition of the symbol Omega. The digit zero should not be used.
p2919
asS'Lambda calculus'
p2920
(lp2921
VLambda calculus (also written as \u03bb-calculus) is a formal system in mathematical logic for expressing computation based on function abstraction and application using variable binding and substitution. First formulated by Alonzo Church to formalize the concept of effective computability, lambda calculus found early successes in the area of computability theory, such as a negative answer to Hilbert's Entscheidungsproblem. Lambda calculus is a conceptually simple universal model of computation (Turing showed in 1937 that Turing machines equated the lambda calculus in expressiveness). The name derives from the Greek letter lambda (\u03bb) used to denote binding a variable in a function. The letter itself is arbitrary and has no special meaning. Lambda calculus is taught and used in computer science because of its usefulness.
p2922
aVBecause of the importance of the notion of variable binding and substitution, there is not just one system of lambda calculus, and in particular there are "typed" and "untyped" variants. Historically, the most important system was the untyped lambda calculus, in which function application has no restrictions (so the notion of the domain of a function is not built into the system). In the Church\u2013Turing Thesis, the untyped lambda calculus is claimed to be capable of computing all effectively calculable functions. The typed lambda calculus is a variety that restricts function application, so that functions can only be applied if they are capable of accepting the given input's "type" of data.
p2923
aVToday, the lambda calculus has applications in many different areas in mathematics, philosophy, linguistics, and computer science. It is still used in the area of computability theory, although Turing machines are also an important model for computation. Lambda calculus has played an important role in the development of the theory of programming languages. Counterparts to lambda calculus in computer science are functional programming languages, which essentially implement the lambda calculus (augmented with some constants and datatypes). Beyond programming languages, the lambda calculus also has many applications in proof theory. A major example of this is the Curry\u2013Howard correspondence, which gives a correspondence between different systems of typed lambda calculus and systems of formal logic.
p2924
aVLambda calculus in history of mathematics.
p2925
aVThe lambda calculus was introduced by mathematician Alonzo Church in the 1930s as part of an investigation into the foundations of mathematics. The original system was shown to be logically inconsistent in 1935 when Stephen Kleene and J. B. Rosser developed the Kleene\u2013Rosser paradox.
p2926
aVSubsequently, in 1936 Church isolated and published just the portion relevant to computation, what is now called the untyped lambda calculus. In 1940, he also introduced a computationally weaker, but logically consistent system, known as the simply typed lambda calculus.
p2927
aVInformal description.
p2928
aVMotivation.
p2929
aVComputable functions are a fundamental concept within computer science and mathematics. The \u03bb-calculus provides a simple semantics for computation, enabling properties of computation to be studied formally. The \u03bb-calculus incorporates two simplifications that make this semantics simple.
p2930
aVThe first simplification is that the \u03bb-calculus treats functions "anonymously", without giving them explicit names. For example, the function 
p2931
aVformula_1
p2932
aVcan be rewritten in "anonymous form" as 
p2933
aVformula_2
p2934
aV(read as "the pair of formula_3 and formula_4 is mapped to formula_5"). Similarly, 
p2935
aVformula_6
p2936
aVcan be rewritten in anonymous form as formula_7, where the input is simply mapped to itself.
p2937
aVThe second simplification is that the \u03bb-calculus only uses functions of a single input. An ordinary function that requires two inputs, for instance the formula_8 function, can be reworked into an equivalent function that accepts a single input, and as output returns "another" function, that in turn accepts a single input. For example, 
p2938
aVformula_2
p2939
aVcan be reworked into 
p2940
aVformula_10
p2941
aVThis method, known as currying, transforms a function that takes multiple arguments into a chain of functions each with a single argument.
p2942
aVFunction application of the formula_8 function to the arguments (5, 2), yields at once
p2943
aVformula_12
p2944
aVformula_13
p2945
aVformula_14,
p2946
aVwhereas evaluation of the curried version requires one more step
p2947
aVformula_15
p2948
aVformula_16
p2949
aVformula_17
p2950
aVformula_14
p2951
aVto arrive at the same result.
p2952
aVThe lambda calculus.
p2953
aVThe lambda calculus consists of a language of lambda terms, which is defined by a certain formal syntax, and a set of transformation rules, which allow manipulation of the lambda terms. These transformation rules can be viewed as an equational theory or as an operational definition.
p2954
aVAs described above, all functions in the lambda calculus are anonymous functions, having no names. They only accept one input variable, with currying used to implement functions with several variables.
p2955
aVLambda terms.
p2956
aVThe syntax of the lambda calculus defines some expressions as valid lambda calculus expression and some as invalid, just as some strings of characters are valid C programs and some are not. A valid lambda calculus expression is called a "lambda term".
p2957
aVThe following three rules give an inductive definition that can be applied to build all syntactically valid lambda terms:
p2958
aVNothing else is a lambda term. Thus a lambda term is valid if and only if it can be obtained by repeated application of these three rules. However, some parentheses can be omitted according to certain rules. For example, the outermost parentheses are usually not written. "See" #Notation, below.
p2959
aVA lambda abstraction formula_26 is a definition of an anonymous function that is capable of taking a single input formula_3 and substituting it into the expression formula_20. 
p2960
aVIt thus defines an anonymous function that takes x and returns t. For example formula_29 is a lambda abstraction for the function formula_30 using the term formula_31 for formula_20. The definition of a function with a lambda abstraction merely "sets up" the function but does not invoke it. The abstraction binds the variable formula_3 in the term formula_20.
p2961
aVAn application formula_35 represents the application of a function formula_20 to an input formula_24, that is, it represents the act of calling function formula_20 on input formula_24 to produce formula_40.
p2962
aVThere is no concept in lambda calculus of variable declaration. In a definition such as formula_41 (i.e. formula_42), the lambda calculus treats formula_4 as a variable that is not yet defined. The lambda abstraction formula_41 is syntactically valid, and represents a function that adds its input to the yet-unknown formula_4.
p2963
aVBracketing may be used and may be needed to disambiguate terms. For example, formula_46 and formula_47 denote different terms (although coincidentally reduce to the same value.)
p2964
aVFunctions that operate on functions.
p2965
aVIn lambda calculus, functions are taken to be 'first class values', so functions may be used as the inputs, or be returned as outputs from other functions.
p2966
aVFor example, formula_48 represents the identity function, formula_49, and formula_50 represents the identity function applied to formula_4. Further, formula_52 represents the constant function formula_53, the function that always returns formula_4, no matter the input. In lambda calculus, function application is regarded as left-associative, so that formula_55 means formula_56.
p2967
aVThere are several notions of "equivalence" and "reduction" that allow lambda terms to be "reduced" to "equivalent" lambda terms.
p2968
aVAlpha equivalence.
p2969
aVA basic form of equivalence, definable on lambda terms, is alpha equivalence. It captures the intuition that the particular choice of a bound variable, in a lambda abstraction, does not (usually) matter.
p2970
aVFor instance, formula_48 and formula_58 are alpha-equivalent lambda terms, and they both represent the same function (the identity function). 
p2971
aVThe terms formula_3 and formula_4 are not alpha-equivalent, because they are not bound in a lambda abstraction.
p2972
aVIn many presentations, it is usual to identify alpha-equivalent lambda terms.
p2973
aVThe following definitions are necessary in order to be able to define beta reduction.
p2974
aVFree variables.
p2975
aVThe free variables of a term are those variables not bound by a lambda abstraction. The set of free variables of an expression is defined inductively:
p2976
aVFor example, the lambda term representing the identity formula_48 has no free variables, but the function formula_41 has a single free variable, formula_4.
p2977
aVCapture-avoiding substitutions.
p2978
aVSuppose formula_20, formula_24 and formula_74 are lambda terms and formula_3 and formula_4 are variables.
p2979
aVThe notation formula_77 indicates substitution of formula_74 for formula_3 in formula_20 in a "capture-avoiding" manner. This is defined so that:
p2980
aVFor example, formula_92, and formula_93.
p2981
aVThe freshness condition (requiring that formula_4 is not in the free variables of formula_74) is crucial in order to ensure that substitution does not change the meaning of functions.
p2982
aVFor example, a substitution is made that ignores the freshness condition: formula_96. This substitution turns the constant function formula_97 into the identity formula_48 by substitution.
p2983
aVIn general, failure to meet the freshness condition can be remedied by alpha-renaming with a suitable fresh variable.
p2984
aVFor example, switching back to our correct notion of substitution, in formula_99 the lambda abstraction can be renamed with a fresh variable formula_100, to obtain formula_101, and the meaning of the function is preserved by substitution.
p2985
aVBeta reduction.
p2986
aVThe beta reduction rule states that an application of the form formula_102 reduces to the term formula_103. The notation formula_104 is used to indicate that formula_105 beta reduces to formula_106.
p2987
aVFor example, for every formula_24, formula_108. This demonstrates that formula_109 really is the identity.
p2988
aVSimilarly, formula_110, which demonstrates that formula_111 is a constant function.
p2989
aVThe lambda calculus may be seen as an idealised functional programming language, like Haskell or Standard ML.
p2990
aVUnder this view, beta reduction corresponds to a computational step. This step can be repeated by additional beta conversions until there are no more applications left to reduce. In the untyped lambda calculus, as presented here, this reduction process may not terminate.
p2991
aVFor instance, consider the term formula_112.
p2992
aVHere formula_113.
p2993
aVThat is, the term reduces to itself in a single beta reduction, and therefore the reduction process will never terminate.
p2994
aVAnother aspect of the untyped lambda calculus is that it does not distinguish between different kinds of data.
p2995
aVFor instance, it may be desirable to write a function that only operates on numbers. However, in the untyped lambda calculus, there is no way to prevent a function from being applied to truth values, strings, or other non-number objects.
p2996
aVFormal definition.
p2997
aVDefinition.
p2998
aVLambda expressions are composed of
p2999
aVThe set of lambda expressions, \u039b, can be defined inductively:
p3000
aVInstances of rule 2 are known as abstractions and instances of rule 3 are known as applications.
p3001
aVNotation.
p3002
aVTo keep the notation of lambda expressions uncluttered, the following conventions are usually applied.
p3003
aVFree and bound variables.
p3004
aVThe abstraction operator, \u03bb, is said to bind its variable wherever it occurs in the body of the abstraction. Variables that fall within the scope of an abstraction are said to be "bound". All other variables are called "free". For example, in the following expression y is a bound variable and x is free: \u03bb"y"."x" "x" "y". Also note that a variable is bound by its "nearest" abstraction. In the following example the single occurrence of x in the expression is bound by the second lambda: \u03bb"x"."y" (\u03bb"x"."z" "x")
p3005
aVThe set of "free variables" of a lambda expression, M, is denoted as FV(M) and is defined by recursion on the structure of the terms, as follows:
p3006
aVAn expression that contains no free variables is said to be "closed". Closed lambda expressions are also known as combinators and are equivalent to terms in combinatory logic.
p3007
aVReduction.
p3008
aVThe meaning of lambda expressions is defined by how expressions can be reduced.
p3009
aVThere are three kinds of reduction:
p3010
aVWe also speak of the resulting equivalences: two expressions are "\u03b2-equivalent", if they can be \u03b2-converted into the same expression, and \u03b1/\u03b7-equivalence are defined similarly.
p3011
aVThe term "redex", short for "reducible expression", refers to subterms that can be reduced by one of the reduction rules. For example, (\u03bb"x".M) N is a beta-redex in expressing the substitution of N for x in M; if "x" is not free in M, \u03bb"x".M "x" is an eta-redex. The expression to which a redex reduces is called its reduct; using the previous example, the reducts of these expressions are respectively M["x":=N] and M.
p3012
aV\u03b1-conversion.
p3013
aVAlpha-conversion, sometimes known as alpha-renaming, allows bound variable names to be changed. For example, alpha-conversion of \u03bb"x"."x" might yield \u03bb"y"."y". Terms that differ only by alpha-conversion are called "\u03b1-equivalent". Frequently in uses of lambda calculus, \u03b1-equivalent terms are considered to be equivalent.
p3014
aVThe precise rules for alpha-conversion are not completely trivial. First, when alpha-converting an abstraction, the only variable occurrences that are renamed are those that are bound to the same abstraction. For example, an alpha-conversion of \u03bb"x".\u03bb"x"."x" could result in \u03bb"y".\u03bb"x"."x", but it could "not" result in \u03bb"y".\u03bb"x"."y". The latter has a different meaning from the original.
p3015
aVSecond, alpha-conversion is not possible if it would result in a variable getting captured by a different abstraction. For example, if we replace "x" with "y" in \u03bb"x".\u03bb"y"."x", we get \u03bb"y".\u03bb"y"."y", which is not at all the same.
p3016
aVIn programming languages with static scope, alpha-conversion can be used to make name resolution simpler by ensuring that no variable name masks a name in a containing scope (see alpha renaming to make name resolution trivial).
p3017
aVIn the De Bruijn index notation, any two alpha-equivalent terms are literally identical.
p3018
aVSubstitution.
p3019
aVSubstitution, written "E"["V" := "R"], is the process of replacing all free occurrences of the variable "V" in the expression "E" with expression "R".
p3020
aVSubstitution on terms of the \u03bb-calculus is defined by recursion on the structure of terms, as follows (note: x and y are only variables while M and N are any \u03bb expression).
p3021
aV "x"["x" := N]        \u2261 N
p3022
aV "y"["x" := N]        \u2261 "y", if "x" \u2260 "y"
p3023
aV (M1 M2)["x" := N]  \u2261 (M1["x" := N]) (M2["x" := N])
p3024
aV (\u03bb"x".M)["x" := N]   \u2261 \u03bb"x".M
p3025
aV (\u03bb"y".M)["x" := N]   \u2261 \u03bb"y".(M["x" := N]), if "x" \u2260 "y", "provided" "y" \u2209 FV(N)
p3026
aVTo substitute into a lambda abstraction, it is sometimes necessary to \u03b1-convert the expression. For example, it is not correct for (\u03bb"x"."y")["y" := "x"] to result in (\u03bb"x"."x"), because the substituted "x" was supposed to be free but ended up being bound. The correct substitution in this case is (\u03bb"z"."x"), up to \u03b1-equivalence. Notice that substitution is defined uniquely up to \u03b1-equivalence.
p3027
aV\u03b2-reduction.
p3028
aVBeta-reduction captures the idea of function application. Beta-reduction is defined in terms of substitution: the beta-reduction of  ((\u03bb"V"."E") "E\u2032")  is "E"["V" := "E\u2032"].
p3029
aVFor example, assuming some encoding of 2, 7, ×, we have the following \u03b2-reduction: ((\u03bb"n"."n"×2) 7) \u2192 7×2.
p3030
aV\u03b7-conversion.
p3031
aVEta-conversion expresses the idea of extensionality, which in this context is that two functions are the same if and only if they give the same result for all arguments. Eta-conversion converts between \u03bb"x".("f" "x") and "f" whenever "x" does not appear free in "f".
p3032
aVNormal forms and confluence.
p3033
aVFor the untyped lambda calculus, \u03b2-reduction as a rewriting rule is neither strongly normalising nor weakly normalising.
p3034
aVHowever, it can be shown that \u03b2-reduction is confluent. (Of course, we are working up to \u03b1-conversion, i.e. we consider two normal forms to be equal, if it is possible to \u03b1-convert one into the other.)
p3035
aVTherefore, both strongly normalising terms and weakly normalising terms have a unique normal form. For strongly normalising terms, any reduction strategy is guaranteed to yield the normal form, whereas for weakly normalising terms, some reduction strategies may fail to find it.
p3036
aVEncoding datatypes.
p3037
aVThe basic lambda calculus may be used to model booleans, arithmetic, data structures and recursion, as illustrated in the following sub-sections.
p3038
aVArithmetic in lambda calculus.
p3039
aVThere are several possible ways to define the natural numbers in lambda calculus, but by far the most common are the Church numerals, which can be defined as follows:
p3040
aV 0 := \u03bb"f".\u03bb"x"."x"
p3041
aV 1 := \u03bb"f".\u03bb"x"."f" "x"
p3042
aV 2 := \u03bb"f".\u03bb"x"."f" ("f" "x")
p3043
aV 3 := \u03bb"f".\u03bb"x"."f" ("f" ("f" "x"))
p3044
aVand so on. Or using the alternative syntax presented above in "Notation":
p3045
aV 0 := \u03bb"fx"."x"
p3046
aV 1 := \u03bb"fx"."f" "x"
p3047
aV 2 := \u03bb"fx"."f" ("f" "x")
p3048
aV 3 := \u03bb"fx"."f" ("f" ("f" "x"))
p3049
aVA Church numeral is a higher-order function\u2014it takes a single-argument function "f", and returns another single-argument function. The Church numeral "n" is a function that takes a function "f" as argument and returns the "n"-th composition of "f", i.e. the function "f" composed with itself "n" times. This is denoted "f"("n") and is in fact the "n"-th power of "f" (considered as an operator); "f"(0) is defined to be the identity function. Such repeated compositions (of a single function "f") obey the laws of exponents, which is why these numerals can be used for arithmetic. (In Church's original lambda calculus, the formal parameter of a lambda expression was required to occur at least once in the function body, which made the above definition of 0 impossible.)
p3050
aVWe can define a successor function, which takes a number "n" and returns "n" + 1 by adding another application of "f",where '(mf)x' means the function 'f' is applied 'm' times on 'x':
p3051
aV SUCC := \u03bb"n".\u03bb"f".\u03bb"x"."f" ("n" "f" "x")
p3052
aVBecause the "m"-th composition of "f" composed with the "n"-th composition of "f" gives the "m"+"n"-th composition of "f", addition can be defined as follows:
p3053
aV PLUS := \u03bb"m".\u03bb"n".\u03bb"f".\u03bb"x"."m" "f" ("n" "f" "x")
p3054
aVPLUS can be thought of as a function taking two natural numbers as arguments and returning a natural number; it can be verified that
p3055
aV PLUS 2 3
p3056
aVand
p3057
aV 5
p3058
aVare \u03b2-equivalent lambda expressions. Since adding "m" to a number "n" can be accomplished by adding 1 "m" times, an equivalent definition is:
p3059
aV PLUS := \u03bb"m".\u03bb"n"."m" SUCC "n\u2009"
p3060
aVSimilarly, multiplication can be defined as
p3061
aV MULT := \u03bb"m".\u03bb"n".\u03bb"f"."m" ("n" "f")
p3062
aVAlternatively
p3063
aV MULT := \u03bb"m".\u03bb"n"."m" (PLUS "n") 0
p3064
aVsince multiplying "m" and "n" is the same as repeating the add "n" function "m" times and then applying it to zero.
p3065
aVExponentiation has a rather simple rendering in Church numerals, namely
p3066
aV POW := \u03bb"b".\u03bb"e"."e" "b"
p3067
aVThe predecessor function defined by PRED "n" = "n" \u2212 1 for a positive integer "n" and PRED 0 = 0 is considerably more difficult. The formula
p3068
aV PRED := \u03bb"n".\u03bb"f".\u03bb"x"."n" (\u03bb"g".\u03bb"h"."h" ("g" "f")) (\u03bb"u"."x") (\u03bb"u"."u")
p3069
aVcan be validated by showing inductively that if "T" denotes (\u03bb"g".\u03bb"h"."h" ("g" "f")), then T("n")(\u03bb"u"."x") = (\u03bb"h"."h"("f"("n"\u22121)("x"))) for "n" > 0. Two other definitions of PRED are given below, one using conditionals and the other using pairs. With the predecessor function, subtraction is straightforward. Defining
p3070
aV SUB := \u03bb"m".\u03bb"n"."n" PRED "m",
p3071
aVSUB "m" "n" yields "m" \u2212 "n" when "m" > "n" and 0 otherwise.
p3072
aVLogic and predicates.
p3073
aVBy convention, the following two definitions (known as Church booleans) are used for the boolean values TRUE and FALSE:
p3074
aV TRUE := \u03bb"x".\u03bb"y"."x"
p3075
aV FALSE := \u03bb"x".\u03bb"y"."y"
p3076
aV:(Note that FALSE is equivalent to the Church numeral zero defined above)
p3077
aVThen, with these two \u03bb-terms, we can define some logic operators (these are just possible formulations; other expressions are equally correct):
p3078
aV AND := \u03bb"p".\u03bb"q"."p" "q" "p"
p3079
aV OR := \u03bb"p".\u03bb"q"."p" "p" "q"
p3080
aV NOT := \u03bb"p".\u03bb"a".\u03bb"b"."p" "b" "a"
p3081
aV IFTHENELSE := \u03bb"p".\u03bb"a".\u03bb"b"."p" "a" "b"
p3082
aVWe are now able to compute some logic functions, for example:
p3083
aV AND TRUE FALSE
p3084
aV:\u2261 (\u03bb"p".\u03bb"q"."p" "q" "p") TRUE FALSE \u2192\u03b2 TRUE FALSE TRUE
p3085
aV:\u2261 (\u03bb"x".\u03bb"y"."x") FALSE TRUE \u2192\u03b2 FALSE
p3086
aVand we see that AND TRUE FALSE is equivalent to FALSE.
p3087
aVA "predicate" is a function that returns a boolean value. The most fundamental predicate is ISZERO, which returns TRUE if its argument is the Church numeral 0, and FALSE if its argument is any other Church numeral:
p3088
aV ISZERO := \u03bb"n"."n" (\u03bb"x".FALSE) TRUE
p3089
aVThe following predicate tests whether the first argument is less-than-or-equal-to the second:
p3090
aV LEQ := \u03bb"m".\u03bb"n".ISZERO (SUB "m" "n"),
p3091
aVand since "m" = "n", if LEQ "m" "n" and LEQ "n" "m", it is straightforward to build a predicate for numerical equality.
p3092
aVThe availability of predicates and the above definition of TRUE and FALSE make it convenient to write "if-then-else" expressions in lambda calculus. For example, the predecessor function can be defined as:
p3093
aV PRED := \u03bb"n"."n" (\u03bb"g".\u03bb"k".ISZERO ("g" 1) "k" (PLUS ("g" "k") 1)) (\u03bb"v".0) 0 
p3094
aVwhich can be verified by showing inductively that "n" (\u03bb"g".\u03bb"k".ISZERO ("g" 1) "k" (PLUS ("g" "k") 1)) (\u03bb"v".0) is the add "n" \u2212 1 function for "n" > 0.
p3095
aVPairs.
p3096
aVA pair (2-tuple) can be defined in terms of TRUE and FALSE, by using the Church encoding for pairs. For example, PAIR encapsulates the pair ("x","y"), FIRST returns the first element of the pair, and SECOND returns the second.
p3097
aV PAIR := \u03bb"x".\u03bb"y".\u03bb"f"."f" "x" "y"
p3098
aV FIRST := \u03bb"p"."p" TRUE
p3099
aV SECOND := \u03bb"p"."p" FALSE
p3100
aV NIL := \u03bb"x".TRUE 
p3101
aV NULL := \u03bb"p"."p" (\u03bb"x".\u03bb"y".FALSE)
p3102
aVA linked list can be defined as either NIL for the empty list, or the PAIR of an element and a smaller list. The predicate NULL tests for the value NIL. (Alternatively, with NIL := FALSE, the construct "l" (\u03bb"h".\u03bb"t".\u03bb"z".deal_with_head_"h"_and_tail_"t") (deal_with_nil) obviates the need for an explicit NULL test).
p3103
aVAs an example of the use of pairs, the shift-and-increment function that maps ("m", "n") to ("n", "n" + 1) can be defined as
p3104
aV \u03a6 := \u03bb"x".PAIR (SECOND "x") (SUCC (SECOND "x"))
p3105
aVwhich allows us to give perhaps the most transparent version of the predecessor function:
p3106
aV PRED := \u03bb"n".FIRST ("n" \u03a6 (PAIR 0 0)).
p3107
aVRecursion and fixed points.
p3108
aVRecursion is the definition of a function using the function itself; on the face of it, lambda calculus does not allow this (we can't refer to a value which is yet to be defined, inside the lambda term defining that same value, as all functions are anonymous in lambda calculus). However, this impression is misleading: in\u2002 (\u03bb"x"."x" "x") "y" \u2002both "x"\u200d\u2009\u200d's refer to the same lambda term, "y", so it is possible for a lambda expression \u2013 here "y" \u2013 to be arranged to receive itself as its argument value, through self-application.
p3109
aVConsider for instance the factorial function F("n") recursively defined by
p3110
aVF("n") = 1, if "n" = 0; else "n" × F("n" \u2212 1).
p3111
aVIn the lambda expression which is to represent this function, a "parameter" (typically the first one) will be assumed to receive the lambda expression itself as its value, so that calling it \u2013 applying it to an argument \u2013 will amount to recursion. Thus to achieve recursion, the intended-as-self-referencing argument (called "r" here) must always be passed to itself within the function body, at a call point:
p3112
aVG := \u03bb"r". \u03bb"n".(1, if "n" = 0; else "n" × ("r" "r" ("n"\u22121)))
p3113
aV:: with\u2002 "r" "r" "x" = F "x" = G "r" "x" \u2002to hold, so\u2002 "r" = G \u2002and
p3114
aVF := G G = (\u03bb"x"."x" "x") G
p3115
aVThe self-application achieves replication here, passing the function's lambda expression on to the next invocation as an argument value, making it available to be referenced and called there.
p3116
aVThis solves it but requires re-writing each recursive call as self-application. We would like to have a generic solution, without a need for any re-writes:
p3117
aVG := \u03bb"r". \u03bb"n".(1, if "n" = 0; else "n" × ("r" ("n"\u22121)))
p3118
aV:: with\u2002 "r" "x" = F "x" = G "r" "x" \u2002to hold, so\u2002 "r" = G "r" =: FIX G \u2002and
p3119
aVF := FIX G \u2002where\u2002 FIX "g" := ("r" where "r" = "g" "r") = "g" (FIX "g")
p3120
aV:: so that\u2002 FIX G = G (FIX G) = (\u03bb"n".(1, if "n" = 0; else "n" × ((FIX G) ("n"\u22121)))) 
p3121
aVGiven a lambda term with first argument representing recursive call (e.g. G here), the "fixed-point" combinator FIX will return a self-replicating lambda expression representing the recursive function (here, F). The function does not need to be explicitly passed to itself at any point, for the self-replication is arranged in advance, when it is created, to be done each time it is called. Thus the original lambda expression (FIX G) is re-created inside itself, at call-point, achieving self-reference.
p3122
aVIn fact, there are many possible definitions for this FIX operator, the simplest of them being:
p3123
aVY := \u03bb"g".(\u03bb"x"."g" ("x" "x")) (\u03bb"x"."g" ("x" "x"))
p3124
aVIn the lambda calculus, Y "g"\u2009 is a fixed-point of "g", as it expands to:
p3125
aVY "g"
p3126
aV\u03bb"h".((\u03bb"x"."h" ("x" "x")) (\u03bb"x"."h" ("x" "x"))) "g"
p3127
aV(\u03bb"x"."g" ("x" "x")) (\u03bb"x"."g" ("x" "x"))
p3128
aV"g" ((\u03bb"x"."g" ("x" "x")) (\u03bb"x"."g" ("x" "x")))
p3129
aV"g" (Y "g")
p3130
aVNow, to perform our recursive call to the factorial function, we would simply call (Y G) "n",  where "n" is the number we are calculating the factorial of. Given "n" = 4, for example, this gives:
p3131
aV(Y G) 4 
p3132
aVG (Y G) 4 
p3133
aV(\u03bb"r".\u03bb"n".(1, if "n" = 0; else "n" × ("r" ("n"\u22121)))) (Y G) 4
p3134
aV(\u03bb"n".(1, if "n" = 0; else "n" × ((Y G) ("n"\u22121)))) 4
p3135
aV1, if 4 = 0; else 4 × ((Y G) (4\u22121))
p3136
aV4 × (G (Y G) (4\u22121))
p3137
aV4 × ((\u03bb"n".(1, if "n" = 0; else "n" × ((Y G) ("n"\u22121)))) (4\u22121))
p3138
aV4 × (1, if 3 = 0; else 3 × ((Y G) (3\u22121)))
p3139
aV4 × (3 × (G (Y G) (3\u22121)))
p3140
aV4 × (3 × ((\u03bb"n".(1, if "n" = 0; else "n" × ((Y G) ("n"\u22121)))) (3\u22121)))
p3141
aV4 × (3 × (1, if 2 = 0; else 2 × ((Y G) (2\u22121))))
p3142
aV4 × (3 × (2 × (G (Y G) (2\u22121))))
p3143
aV4 × (3 × (2 × ((\u03bb"n".(1, if "n" = 0; else "n" × ((Y G) ("n"\u22121)))) (2\u22121))))
p3144
aV4 × (3 × (2 × (1, if 1 = 0; else 1 × ((Y G) (1\u22121)))))
p3145
aV4 × (3 × (2 × (1 × (G (Y G) (1\u22121)))))
p3146
aV4 × (3 × (2 × (1 × ((\u03bb"n".(1, if "n" = 0; else "n" × ((Y G) ("n"\u22121)))) (1\u22121)))))
p3147
aV4 × (3 × (2 × (1 × (1, if 0 = 0; else 0 × ((Y G) (0\u22121))))))
p3148
aV4 × (3 × (2 × (1 × (1))))
p3149
aV24
p3150
aVEvery recursively defined function can be seen as a fixed point of some suitably defined function closing over the recursive call with an extra argument, and therefore, using Y, every recursively defined function can be expressed as a lambda expression. In particular, we can now cleanly define the subtraction, multiplication and comparison predicate of natural numbers recursively.
p3151
aVStandard terms.
p3152
aVCertain terms have commonly accepted names:
p3153
aV I := \u03bb"x"."x"
p3154
aV K := \u03bb"x".\u03bb"y"."x"
p3155
aV S := \u03bb"x".\u03bb"y".\u03bb"z"."x" "z" ("y" "z") 
p3156
aV B := \u03bb"x".\u03bb"y".\u03bb"z"."x" ("y" "z") 
p3157
aV C := \u03bb"x".\u03bb"y".\u03bb"z"."x" "z" "y"
p3158
aV W := \u03bb"x".\u03bb"y"."x" "y" "y"
p3159
aV U := \u03bb"x"."x" "x" 
p3160
aV \u03c9 := \u03bb"x"."x" "x" 
p3161
aV Y := \u03bb"g".(\u03bb"x"."g" ("x" "x")) (\u03bb"x"."g" ("x" "x"))
p3162
aVTyped lambda calculus.
p3163
aVA typed lambda calculus is a typed formalism that uses the lambda-symbol (formula_114) to denote anonymous function abstraction. In this context, types are usually objects of a syntactic nature that are assigned to lambda terms; the exact nature of a type depends on the calculus considered (see kinds below). From a certain point of view, typed lambda calculi can be seen as refinements of the untyped lambda calculus but from another point of view, they can also be considered the more fundamental theory and "untyped lambda calculus" a special case with only one type.
p3164
aVTyped lambda calculi are foundational programming languages and are the base of typed functional programming languages such as ML and Haskell and, more indirectly, typed imperative programming languages. Typed lambda calculi play an important role in the design of type systems for programming languages; here typability usually captures desirable properties of the program, e.g. the program will not cause a memory access violation.
p3165
aVTyped lambda calculi are closely related to mathematical logic and proof theory via the Curry\u2013Howard isomorphism and they can be considered as the internal language of classes of categories, e.g. the simply typed lambda calculus is the language of Cartesian closed categories (CCCs).
p3166
aVComputable functions and lambda calculus.
p3167
aVA function "F": N \u2192 N of natural numbers is a computable function if and only if there exists a lambda expression "f" such that for every pair of "x", "y" in N, "F"("x")="y" if and only if "f" "x" =\u03b2 "y",  where "x" and "y" are the Church numerals corresponding to "x" and "y", respectively and =\u03b2 meaning equivalence with beta reduction. This is one of the many ways to define computability; see the Church-Turing thesis for a discussion of other approaches and their equivalence.
p3168
aVUndecidability of equivalence.
p3169
aVThere is no algorithm that takes as input two lambda expressions and outputs TRUE or FALSE depending on whether or not the two expressions are equivalent. This was historically the first problem for which undecidability could be proven. As is common for a proof of undecidability, the proof shows that no computable function can decide the equivalence. Church's thesis is then invoked to show that no algorithm can do so.
p3170
aVChurch's proof first reduces the problem to determining whether a given lambda expression has a "normal form". A normal form is an equivalent expression that cannot be reduced any further under the rules imposed by the form. Then he assumes that this predicate is computable, and can hence be expressed in lambda calculus. Building on earlier work by Kleene and constructing a Gödel numbering for lambda expressions, he constructs a lambda expression "e" that closely follows the proof of Gödel's first incompleteness theorem. If "e" is applied to its own Gödel number, a contradiction results.
p3171
aVLambda calculus and programming languages.
p3172
aVAs pointed out by Peter Landin's 1965 paper A Correspondence between ALGOL 60 and Church's Lambda-notation, sequential procedural programming languages can be understood in terms of the lambda calculus, which provides the basic mechanisms for procedural abstraction and procedure (subprogram) application.
p3173
aVLambda calculus reifies "functions" and makes them first-class objects, which raises implementation complexity when it is implemented.
p3174
aVAnonymous functions.
p3175
aVFor example in Lisp the 'square' function can be expressed as a lambda expression as follows:
p3176
aVThe above example is an expression that evaluates to a first-class function. The symbol codice_1 creates an anonymous function, given a list of parameter names, codice_2 \u2014 just a single argument in this case, and an expression that is evaluated as the body of the function, codice_3. The Haskell example is identical. Anonymous functions are sometimes called lambda expressions.
p3177
aVFor example Pascal and many other imperative languages have long supported passing subprograms as arguments to other subprograms through the mechanism of function pointers. However, function pointers are not a sufficient condition for functions to be first class datatypes, because a function is a first class datatype if and only if new instances of the function can be created at run-time. And this run-time creation of functions is supported in Smalltalk, Javascript, and more recently in Scala, Eiffel ("agents"), C# ("delegates") and C++11, among others.
p3178
aVReduction strategies.
p3179
aVWhether a term is normalising or not, and how much work needs to be done in normalising it if it is, depends to a large extent on the reduction strategy used. The distinction between reduction strategies relates to the distinction in functional programming languages between eager evaluation and lazy evaluation.
p3180
aVMost programming languages (including Lisp, ML and imperative languages like C and Java) are described as "strict", meaning that functions applied to non-normalising arguments are non-normalising. This is done essentially using applicative order, call by value reduction (see below), but usually called "eager evaluation".
p3181
aVApplicative order is not a normalising strategy. The usual counterexample is as follows: define \u03a9 = \u03c9\u03c9 where \u03c9 = \u03bb"x"."xx". This entire expression contains only one redex, namely the whole expression; its reduct is again \u03a9. Since this is the only available reduction, \u03a9 has no normal form (under any evaluation strategy). Using applicative order, the expression KI\u03a9 = (\u03bb"x".\u03bb"y"."x") (\u03bb"x"."x")\u03a9 is reduced by first reducing \u03a9 to normal form (since it is the rightmost redex), but since \u03a9 has no normal form, applicative order fails to find a normal form for KI\u03a9.
p3182
aVIn contrast, normal order is so called because it always finds a normalising reduction, if one exists. In the above example, KI\u03a9 reduces under normal order to "I", a normal form. A drawback is that redexes in the arguments may be copied, resulting in duplicated computation (for example, (\u03bb"x"."xx") ((\u03bb"x"."x")"y") reduces to ((\u03bb"x"."x")"y") ((\u03bb"x"."x")"y") using this strategy; now there are two redexes, so full evaluation needs two more steps, but if the argument had been reduced first, there would now be none).
p3183
aVThe positive tradeoff of using applicative order is that it does not cause unnecessary computation, if all arguments are used, because it never substitutes arguments containing redexes and hence never needs to copy them (which would duplicate work). In the above example, in applicative order (\u03bb"x"."xx") ((\u03bb"x"."x")"y") reduces first to (\u03bb"x"."xx")"y" and then to the normal order "yy", taking two steps instead of three.
p3184
aVMost "purely" functional programming languages (notably Miranda and its descendents, including Haskell), and the proof languages of theorem provers, use "lazy evaluation", which is essentially the same as call by need. This is like normal order reduction, but call by need manages to avoid the duplication of work inherent in normal order reduction using "sharing". In the example given above, (\u03bb"x"."xx") ((\u03bb"x"."x")"y") reduces to ((\u03bb"x"."x")"y") ((\u03bb"x"."x")"y"), which has two redexes, but in call by need they are represented using the same object rather than copied, so when one is reduced the other is too.
p3185
aVA note about complexity.
p3186
aVWhile the idea of beta reduction seems simple enough, it is not an atomic step, in that it must have a non-trivial cost when estimating computational complexity. To be precise, one must somehow find the location of all of the occurrences of the bound variable "V" in the expression "E", implying a time cost, or one must keep track of these locations in some way, implying a space cost. A naïve search for the locations of "V" in "E" is "O"("n") in the length "n" of "E". This has led to the study of systems that use explicit substitution. Sinot's director strings offer a way of tracking the locations of free variables in expressions.
p3187
aVParallelism and concurrency.
p3188
aVThe Church\u2013Rosser property of the lambda calculus means that evaluation (\u03b2-reduction) can be carried out in "any order", even in parallel. This means that various nondeterministic evaluation strategies are relevant. However, the lambda calculus does not offer any explicit constructs for parallelism. One can add constructs such as Futures to the lambda calculus. Other process calculi have been developed for describing communication and concurrency.
p3189
aVSemantics.
p3190
aVThe fact that lambda calculus terms act as functions on other lambda calculus terms, and even on themselves, led to questions about the semantics of the lambda calculus. Could a sensible meaning be assigned to lambda calculus terms? The natural semantics was to find a set "D" isomorphic to the function space "D" \u2192 "D", of functions on itself. However, no nontrivial such "D" can exist, by cardinality constraints because the set of all functions from "D" to "D" has greater cardinality than "D", unless "D" is a singleton set.
p3191
aVIn the 1970s, Dana Scott showed that, if only continuous functions were considered, a set or domain "D" with the required property could be found, thus providing a model for the lambda calculus.
p3192
aVThis work also formed the basis for the denotational semantics of programming languages.
p3193
aVFurther reading.
p3194
aVMonographs/textbooks for graduate students:
p3195
aV"Some parts of this article are based on material from FOLDOC, used with ."
p3196
asS'Manifold'
p3197
(lp3198
VIn mathematics, a manifold is a topological space that resembles Euclidean space near each point. More precisely, each point of an "n"-dimensional manifold has a neighbourhood that is homeomorphic to the Euclidean space of dimension "n". Lines and circles, but not figure eights, are one-dimensional manifolds. Two-dimensional manifolds are also called surfaces. Examples include the plane, the sphere, and the torus, which can all be realized in three dimensions, but also the Klein bottle and real projective plane which cannot.
p3199
aVAlthough a manifold resembles Euclidean space near each point, globally it may not. For example, the surface of the sphere is not a Euclidean space, but in a region it can be charted by means of map projections of the region into the Euclidean plane (in the context of manifolds they are called "charts"). When a region appears in two neighbouring charts, the two representations do not coincide exactly and a transformation is needed to pass from one to the other, called a "transition map".
p3200
aVThe concept of a manifold is central to many parts of geometry and modern mathematical physics because it allows more complicated structures to be described and understood in terms of the relatively well-understood properties of Euclidean space. Manifolds naturally arise as solution sets of systems of equations and as graphs of functions. Manifolds may have additional features. One important class of manifolds is the class of differentiable manifolds.
p3201
aVThis differentiable structure allows calculus to be done on manifolds. A Riemannian metric on a manifold allows distances and angles to be measured. Symplectic manifolds serve as the phase spaces in the Hamiltonian formalism of classical mechanics, while four-dimensional Lorentzian manifolds model spacetime in general relativity.
p3202
aVMotivational examples.
p3203
aVCircle.
p3204
aVAfter a line, the circle is the simplest example of a topological manifold. Topology ignores bending, so a small piece of a circle is treated exactly the same as a small piece of a line. Consider, for instance, the top part of the unit circle, "x"2 + "y"2 = 1, where the "y"-coordinate is positive (indicated by the yellow circular arc in "Figure 1"). Any point of this arc can be uniquely described by its "x"-coordinate. So, projection onto the first coordinate is a continuous, and invertible, mapping from the upper arc to the open interval (\u22121,1):
p3205
aV formula_1
p3206
aVSuch functions along with the open regions they map are called "charts". Similarly, there are charts for the bottom (red), left (blue), and right (green) parts of the circle:
p3207
aV formula_2
p3208
aV formula_3
p3209
aV formula_4
p3210
aVTogether, these parts cover the whole circle and the four charts form an atlas for the circle.
p3211
aVThe top and right charts overlap: their intersection lies in the quarter of the circle where both the "x"- and the "y"-coordinates are positive. The two charts \u03c7top and \u03c7right each map this part into the interval (0, 1). Thus a function "T" from (0, 1) to itself can be constructed, which first uses the inverse of the top chart to reach the circle and then follows the right chart back to the interval. Let "a" be any number in (0, 1), then:
p3212
aV formula_5
p3213
aVSuch a function is called a "transition map".
p3214
aVThe top, bottom, left, and right charts show that the circle is a manifold, but they do not form the only possible atlas. Charts need not be geometric projections, and the number of charts is a matter of some choice. Consider the charts
p3215
aV formula_6
p3216
aVand
p3217
aV formula_7
p3218
aVHere "s" is the slope of the line through the point at coordinates ("x","y") and the fixed pivot point (\u22121, 0); "t" follows similarly, but with pivot point (+1, 0). The inverse mapping from "s" to ("x", "y") is given by
p3219
aV formula_8
p3220
aVIt can easily be confirmed that "x"2 + "y"2 = 1 for all values of the slope "s". These two charts provide a second atlas for the circle, with
p3221
aV formula_9
p3222
aVEach chart omits a single point, either (\u22121, 0) for "s" or (+1, 0) for "t", so neither chart alone is sufficient to cover the whole circle. It can be proved that it is not possible to cover the full circle with a single chart. For example, although it is possible to construct a circle from a single line interval by overlapping and "gluing" the ends, this does not produce a chart; a portion of the circle will be mapped to both ends at once, losing invertibility.
p3223
aVOther curves.
p3224
aVManifolds need not be connected (all in "one piece"); an example is a pair of separate circles.
p3225
aVManifolds need not be closed; thus a line segment without its end points is a manifold. And they are never countable, unless the dimension of the manifold is 0. Putting these freedoms together, other examples of manifolds are a parabola, a hyperbola (two open, infinite pieces), and the locus of points on a cubic curve "y"2 = "x"3\u2212"x" (a closed loop piece and an open, infinite piece).
p3226
aVHowever, excluded are examples like two touching circles that share a point to form a figure-8; at the shared point a satisfactory chart cannot be created. Even with the bending allowed by topology, the vicinity of the shared point looks like a "+", not a line. A "+" is not homeomorphic to a closed interval (line segment), since deleting the center point from the "+" gives a space with four components (i.e. pieces), whereas deleting a point from a closed interval gives a space with at most two pieces; topological operations always preserve the number of pieces.
p3227
aVEnriched circle.
p3228
aVViewed using calculus, the circle transition function "T" is simply a function between open intervals, which gives a meaning to the statement that "T" is differentiable. The transition map "T", and all the others, are differentiable on (0, 1); therefore, with this atlas the circle is a "differentiable manifold". It is also "smooth" and "analytic" because the transition functions have these properties as well.
p3229
aVOther circle properties allow it to meet the requirements of more specialized types of manifold. For example, the circle has a notion of distance between two points, the arc-length between the points; hence it is a "Riemannian manifold".
p3230
aVHistory.
p3231
aVThe study of manifolds combines many important areas of mathematics: it generalizes concepts such as curves and surfaces as well as ideas from linear algebra and topology.
p3232
aVEarly development.
p3233
aVBefore the modern concept of a manifold there were several important results.
p3234
aVNon-Euclidean geometry considers spaces where Euclid's parallel postulate fails. Saccheri first studied them in 1733. Lobachevsky, Bolyai, and Riemann developed them 100 years later. Their research uncovered two types of spaces whose geometric structures differ from that of classical Euclidean space; these gave rise to hyperbolic geometry and elliptic geometry. In the modern theory of manifolds, these notions correspond to Riemannian manifolds with constant negative and positive curvature, respectively.
p3235
aVCarl Friedrich Gauss may have been the first to consider abstract spaces as mathematical objects in their own right. His theorema egregium gives a method for computing the curvature of a surface without considering the ambient space in which the surface lies. Such a surface would, in modern terminology, be called a manifold; and in modern terms, the theorem proved that the curvature of the surface is an intrinsic property. Manifold theory has come to focus exclusively on these intrinsic properties (or invariants), while largely ignoring the extrinsic properties of the ambient space.
p3236
aVAnother, more topological example of an intrinsic property of a manifold is its Euler characteristic. Leonhard Euler showed that for a convex polytope in the three-dimensional Euclidean space with "V" vertices (or corners), "E" edges, and "F" faces,
p3237
aVformula_10
p3238
aVThe same formula will hold if we project the vertices and edges of the polytope onto a sphere, creating a topological map with "V" vertices, "E" edges, and "F" faces, and in fact, will remain true for any spherical map, even if it does not arise from any convex polytope. Thus 2 is a topological invariant of the sphere, called its Euler characteristic. On the other hand, a torus can be sliced open by its 'parallel' and 'meridian' circles, creating a map with "V" = 1 vertex, "E" = 2 edges, and "F" = 1 face. Thus the Euler characteristic of the torus is 1 \u2212 2 + 1 = 0. The Euler characteristic of other surfaces is a useful topological invariant, which can be extended to higher dimensions using Betti numbers. In the mid nineteenth century, the Gauss\u2013Bonnet theorem linked the Euler characteristic to the Gaussian curvature.
p3239
aVSynthesis.
p3240
aVInvestigations of Niels Henrik Abel and Carl Gustav Jacobi on inversion of elliptic integrals in the first half of 19th century led them to consider special types of complex manifolds, now known as Jacobians. Bernhard Riemann further contributed to their theory, clarifying the geometric meaning of the process of analytic continuation of functions of complex variables.
p3241
aVAnother important source of manifolds in 19th century mathematics was analytical mechanics, as developed by Siméon Poisson, Jacobi, and William Rowan Hamilton. The possible states of a mechanical system are thought to be points of an abstract space, phase space in Lagrangian and Hamiltonian formalisms of classical mechanics. This space is, in fact, a high-dimensional manifold, whose dimension corresponds to the degrees of freedom of the system and where the points are specified by their generalized coordinates. For an unconstrained movement of free particles the manifold is equivalent to the Euclidean space, but various conservation laws constrain it to more complicated formations, e.g. Liouville tori. The theory of a rotating solid body, developed in the 18th century by Leonhard Euler and Joseph-Louis Lagrange, gives another example where the manifold is nontrivial. Geometrical and topological aspects of classical mechanics were emphasized by Henri Poincaré, one of the founders of topology.
p3242
aVRiemann was the first one to do extensive work generalizing the idea of a surface to higher dimensions. The name "manifold" comes from Riemann's original German term, "Mannigfaltigkeit", which William Kingdon Clifford translated as "manifoldness". In his Göttingen inaugural lecture, Riemann described the set of all possible values of a variable with certain constraints as a "Mannigfaltigkeit", because the variable can have "many" values. He distinguishes between "stetige Mannigfaltigkeit" and "diskrete" "Mannigfaltigkeit" ("continuous manifoldness" and "discontinuous manifoldness"), depending on whether the value changes continuously or not. As continuous examples, Riemann refers to not only colors and the locations of objects in space, but also the possible shapes of a spatial figure. Using induction, Riemann constructs an "n-fach ausgedehnte Mannigfaltigkeit" ("n times extended manifoldness" or "n-dimensional manifoldness") as a continuous stack of (n\u22121) dimensional manifoldnesses. Riemann's intuitive notion of a "Mannigfaltigkeit" evolved into what is today formalized as a manifold. Riemannian manifolds and Riemann surfaces are named after Riemann.
p3243
aVPoincaré's definition.
p3244
aVIn his very influential paper, Analysis Situs, Henri Poincaré gave a definition of a (differentiable) manifold ("variété") which served as a precursor to the modern concept of a manifold.
p3245
aVIn the first section of Analysis Situs, Poincaré defines a manifold as the level set of a continuously differentiable function between Euclidean spaces that satisfies the nondegeneracy hypothesis of the implicit function theorem. In the third section, he begins by remarking that the graph of a continuously differentiable function is a manifold in the latter sense. He then proposes a new, more general, definition of manifold based on a 'chain of manifolds' ("une chaîne des variétés").
p3246
aVPoincaré's notion of a 'chain of manifolds' is a precursor to the modern notion of atlas. In particular, he considers two manifolds defined respectively as graphs of functions formula_11 and formula_12. If these manifolds overlap ("a une partie commune"), then he requires that the coordinates formula_13 depend continuously differentiably on the coordinates formula_14 and vice versa ('<nowiki/>"...les formula_15 sont fonctions analytiques des formula_16 et inversement"<nowiki/>'). In this way he introduces a precursor to the notion of a chart and of a transition map. Note that it is implicit in Analysis Situs that a manifold obtained as a 'chain' is a subset of Euclidean space.
p3247
aVFor example, the unit circle in the plane can be thought of as the graph of the function formula_17 or else the function formula_18 in a neighborhood of every point except the points (1,0) and (\u22121,0); and in a neighborhood of those points, it can be thought of as the graph of, respectively, formula_19 and formula_20. The reason the circle can be represented by a graph in the neighborhood of every point is because the left hand side of its defining equation formula_21 has nonzero gradient at every point of the circle. By the implicit function theorem, every submanifold of Euclidean space is locally the graph of a function.
p3248
aVHermann Weyl gave an intrinsic definition for differentiable manifolds in his lecture course on Riemann surfaces in 1911\u20131912, opening the road to the general concept of a topological space that followed shortly. During the 1930s Hassler Whitney and others clarified the foundational aspects of the subject, and thus intuitions dating back to the latter half of the 19th century became precise, and developed through differential geometry and Lie group theory. Notably, the Whitney embedding theorem showed that the intrinsic definition in terms of charts was equivalent to Poincaré's definition in terms of subsets of Euclidean space.
p3249
aVTopology of manifolds: highlights.
p3250
aVTwo-dimensional manifolds, also known as a 2D "surfaces" embedded in our common 3D space, were considered by Riemann under the guise of Riemann surfaces, and rigorously classified in the beginning of the 20th century by Poul Heegaard and Max Dehn. Henri Poincaré pioneered the study of three-dimensional manifolds and raised a fundamental question about them, today known as the Poincaré conjecture. After nearly a century of effort by many mathematicians, starting with Poincaré himself, a consensus among experts (as of 2006) is that Grigori Perelman has proved the Poincaré conjecture (see the Solution of the Poincaré conjecture). William Thurston's geometrization program, formulated in the 1970s, provided a far-reaching extension of the Poincaré conjecture to the general three-dimensional manifolds. Four-dimensional manifolds were brought to the forefront of mathematical research in the 1980s by Michael Freedman and in a different setting, by Simon Donaldson, who was motivated by the then recent progress in theoretical physics (Yang\u2013Mills theory), where they serve as a substitute for ordinary 'flat' spacetime. Andrey Markov Jr. showed in 1960 that no algorithm exists for classifying four-dimensional manifolds. Important work on higher-dimensional manifolds, including analogues of the Poincaré conjecture, had been done earlier by René Thom, John Milnor, Stephen Smale and Sergei Novikov. One of the most pervasive and flexible techniques underlying much work on the topology of manifolds is Morse theory.
p3251
aVMathematical definition.
p3252
aVInformally, a manifold is a space that is "modeled on" Euclidean space.
p3253
aVThere are many different kinds of manifolds and generalizations.
p3254
aVIn geometry and topology, all manifolds are topological manifolds, possibly with additional structure, most often a differentiable structure. In terms of constructing manifolds via patching, a manifold has an additional structure if the transition maps between different patches satisfy axioms beyond just continuity. For instance, differentiable manifolds have homeomorphisms on overlapping neighborhoods diffeomorphic with each other, so that the manifold has a well-defined set of functions which are differentiable in each neighborhood, and so differentiable on the manifold as a whole.
p3255
aVFormally, a topological manifold is a second countable Hausdorff space that is locally homeomorphic to Euclidean space.
p3256
aV"Second countable" and "Hausdorff" are point-set conditions;
p3257
aV"second countable" excludes spaces which are in some sense 'too large' such as the long line, while "Hausdorff" excludes spaces such as "the line with two origins" (these generalizations of manifolds are discussed in non-Hausdorff manifolds).
p3258
aV"Locally homeomorphic" to Euclidean space means that every point has a neighborhood homeomorphic to an open Euclidean "n"-ball,
p3259
aVformula_22
p3260
aVGenerally manifolds are taken to have a fixed dimension (the space must be locally homeomorphic to a fixed "n"-ball), and such a space is called an ""'n"-manifold; however, some authors admit manifolds where different points can have different dimensions. If a manifold has a fixed dimension, it is called a pure manifold"'. For example, the sphere has a constant dimension of 2 and is therefore a pure manifold whereas the disjoint union of a sphere and a line in three-dimensional space is "not" a pure manifold. Since dimension is a local invariant (i.e. the map sending each point to the dimension of its neighbourhood over which a chart is defined, is locally constant), each connected component has a fixed dimension.
p3261
aVScheme-theoretically, a manifold is a locally ringed space, whose structure sheaf is locally isomorphic to the sheaf of continuous (or differentiable, or complex-analytic, etc.) functions on Euclidean space. This definition is mostly used when discussing analytic manifolds in algebraic geometry.
p3262
aVBroad definition.
p3263
aVThe broadest common definition of manifold is a topological space locally homeomorphic to a topological vector space over the reals. This omits the point-set axioms, allowing higher cardinalities and non-Hausdorff manifolds; and it omits finite dimension, allowing structures such as Hilbert manifolds to be modeled on Hilbert spaces, Banach manifolds to be modeled on Banach spaces, and Fréchet manifolds to be modeled on Fréchet spaces. Usually one relaxes one or the other condition: manifolds with the point-set axioms are studied in general topology, while infinite-dimensional manifolds are studied in functional analysis.
p3264
aVCharts, atlases, and transition maps.
p3265
aVThe spherical Earth is navigated using flat maps or charts, collected in an atlas. Similarly, a differentiable manifold can be described using mathematical maps, called "coordinate charts", collected in a mathematical "atlas". It is not generally possible to describe a manifold with just one chart, because the global structure of the manifold is different from the simple structure of the charts. For example, no single flat map can represent the entire Earth without separation of adjacent features across the map's boundaries or duplication of coverage. When a manifold is constructed from multiple overlapping charts, the regions where they overlap carry information essential to understanding the global structure.
p3266
aVCharts.
p3267
aVA coordinate map, a coordinate chart, or simply a chart, of a manifold is an invertible map between a subset of the manifold and a simple space such that both the map and its inverse preserve the desired structure. For a topological manifold, the simple space is some Euclidean space R"n" and interest focuses on the topological structure. This structure is preserved by homeomorphisms, invertible maps that are continuous in both directions.
p3268
aVIn the case of a differentiable manifold, a set of charts called an atlas allows us to do calculus on manifolds. Polar coordinates, for example, form a chart for the plane R2 minus the positive "x"-axis and the origin. Another example of a chart is the map \u03c7top mentioned in the section above, a chart for the circle.
p3269
aVAtlases.
p3270
aVThe description of most manifolds requires more than one chart (a single chart is adequate for only the simplest manifolds). A specific collection of charts which covers a manifold is called an atlas. An atlas is not unique as all manifolds can be covered multiple ways using different combinations of charts. Two atlases are said to be Ck equivalent if their union is also a Ck atlas.
p3271
aVThe atlas containing all possible charts consistent with a given atlas is called the maximal atlas (i.e. an equivalence class containing that given atlas (under the already defined equivalence relation given in the previous paragraph)). Unlike an ordinary atlas, the maximal atlas of a given manifold is unique. Though it is useful for definitions, it is an abstract object and not used directly (e.g. in calculations).
p3272
aVTransition maps.
p3273
aVCharts in an atlas may overlap and a single point of a manifold may be represented in several charts. If two charts overlap, parts of them represent the same region of the manifold, just as a map of Europe and a map of Asia may both contain Moscow. Given two overlapping charts, a transition function can be defined which goes from an open ball in R"n" to the manifold and then back to another (or perhaps the same) open ball in R"n". The resultant map, like the map "T" in the circle example above, is called a change of coordinates, a coordinate transformation, a transition function, or a transition map.
p3274
aVAdditional structure.
p3275
aVAn atlas can also be used to define additional structure on the manifold. The structure is first defined on each chart separately. If all the transition maps are compatible with this structure, the structure transfers to the manifold.
p3276
aVThis is the standard way differentiable manifolds are defined. If the transition functions of an atlas for a topological manifold preserve the natural differential structure of R"n" (that is, if they are diffeomorphisms), the differential structure transfers to the manifold and turns it into a differentiable manifold. Complex manifolds are introduced in an analogous way by requiring that the transition functions of an atlas are holomorphic functions. For symplectic manifolds, the transition functions must be symplectomorphisms.
p3277
aVThe structure on the manifold depends on the atlas, but sometimes different atlases can be said to give rise to the same structure. Such atlases are called compatible.
p3278
aVThese notions are made precise in general through the use of pseudogroups.
p3279
aVManifold with boundary.
p3280
aVA manifold with boundary is a manifold with an edge. For example a sheet of paper is a 2-manifold with a 1-dimensional boundary. The boundary of an "n"-manifold with boundary is an ("n" \u2212 1)-manifold. A disk (circle plus interior) is a 2-manifold with boundary. Its boundary is a circle, a 1-manifold. A square with interior is also a 2-manifold with boundary. A ball (sphere plus interior) is a 3-manifold with boundary. Its boundary is a sphere, a 2-manifold. (See also Boundary (topology)).
p3281
aVIn technical language, a manifold with boundary is a space containing both interior points and boundary points. Every interior point has a neighborhood homeomorphic to the open "n"-ball {("x"1, "x"2, \u2026, "x""n") | \u03a3 "x""i"2 < 1}. Every boundary point has a neighborhood homeomorphic to the "half" "n"-ball {("x"1, "x"2, \u2026, "x""n") | \u03a3 "x""i"2 < 1 and "x"1 \u2265 0}. The homeomorphism must send each boundary point to a point with "x"1 = 0.
p3282
aVBoundary and interior.
p3283
aVLet "M" be a manifold with boundary. The interior of "M", denoted Int "M", is the set of points in "M" which have neighborhoods homeomorphic to an open subset of R"n". The boundary of "M", denoted \u2202"M", is the complement of Int "M" in "M". The boundary points can be characterized as those points which land on the boundary hyperplane ("x""n" = 0) of R"n"+ under some coordinate chart.
p3284
aVIf "M" is a manifold with boundary of dimension "n", then Int "M" is a manifold (without boundary) of dimension "n" and \u2202"M" is a manifold (without boundary) of dimension "n" \u2212 1.
p3285
aVConstruction.
p3286
aVA single manifold can be constructed in different ways, each stressing a different aspect of the manifold, thereby leading to a slightly different viewpoint.
p3287
aVCharts.
p3288
aVPerhaps the simplest way to construct a manifold is the one used in the example above of the circle. First, a subset of R2 is identified, and then an atlas covering this subset is constructed. The concept of "manifold" grew historically from constructions like this. Here is another example, applying this method to the construction of a sphere:
p3289
aVSphere with charts.
p3290
aVA sphere can be treated in almost the same way as the circle. In mathematics a sphere is just the surface (not the solid interior), which can be defined as a subset of R3:
p3291
aV formula_23
p3292
aVThe sphere is two-dimensional, so each chart will map part of the sphere to an open subset of R2. Consider the northern hemisphere, which is the part with positive "z" coordinate (coloured red in the picture on the right). The function \u03c7 defined by
p3293
aVformula_24
p3294
aVmaps the northern hemisphere to the open unit disc by projecting it on the ("x", "y") plane. A similar chart exists for the southern hemisphere. Together with two charts projecting on the ("x", "z") plane and two charts projecting on the ("y", "z") plane, an atlas of six charts is obtained which covers the entire sphere.
p3295
aVThis can be easily generalized to higher-dimensional spheres.
p3296
aVPatchwork.
p3297
aVA manifold can be constructed by gluing together pieces in a consistent manner, making them into overlapping charts. This construction is possible for any manifold and hence it is often used as a characterisation, especially for differentiable and Riemannian manifolds. It focuses on an atlas, as the patches naturally provide charts, and since there is no exterior space involved it leads to an intrinsic view of the manifold.
p3298
aVThe manifold is constructed by specifying an atlas, which is itself defined by transition maps. A point of the manifold is therefore an equivalence class of points which are mapped to each other by transition maps. Charts map equivalence classes to points of a single patch. There are usually strong demands on the consistency of the transition maps. For topological manifolds they are required to be homeomorphisms; if they are also diffeomorphisms, the resulting manifold is a differentiable manifold.
p3299
aVThis can be illustrated with the transition map "t" = 1\u2044"s" from the second half of the circle example. Start with two copies of the line. Use the coordinate "s" for the first copy, and "t" for the second copy. Now, glue both copies together by identifying the point "t" on the second copy with the point "s" = 1\u2044"t" on the first copy (the points "t" = 0 and "s" = 0 are not identified with any point on the first and second copy, respectively). This gives a circle.
p3300
aVIntrinsic and extrinsic view.
p3301
aVThe first construction and this construction are very similar, but they represent rather different points of view. In the first construction, the manifold is seen as embedded in some Euclidean space. This is the "extrinsic view". When a manifold is viewed in this way, it is easy to use intuition from Euclidean spaces to define additional structure. For example, in a Euclidean space it is always clear whether a vector at some point is tangential or normal to some surface through that point.
p3302
aVThe patchwork construction does not use any embedding, but simply views the manifold as a topological space by itself. This abstract point of view is called the "intrinsic view". It can make it harder to imagine what a tangent vector might be, and there is no intrinsic notion of a normal bundle, but instead there is an intrinsic stable normal bundle.
p3303
aV"n"-Sphere as a patchwork.
p3304
aVThe "n"-sphere S"n" is a generalisation of the idea of a circle (1-sphere) and sphere (2-sphere) to higher dimensions. An "n"-sphere S"n" can be constructed by gluing together two copies of R"n". The transition map between them is defined as
p3305
aVformula_25
p3306
aVThis function is its own inverse and thus can be used in both directions. As the transition map is a smooth function, this atlas defines a smooth manifold.
p3307
aVIn the case "n" = 1, the example simplifies to the circle example given earlier.
p3308
aVIdentifying points of a manifold.
p3309
aVIt is possible to define different points of a manifold to be same. This can be visualized as gluing these points together in a single point, forming a quotient space. There is, however, no reason to expect such quotient spaces to be manifolds. Among the possible quotient spaces that are not necessarily manifolds, orbifolds and CW complexes are considered to be relatively well-behaved. An example of a quotient space of a manifold that is also a manifold is the real projective space identified as a quotient space of the corresponding sphere.
p3310
aVOne method of identifying points (gluing them together) is through a right (or left) action of a group, which acts on the manifold. Two points are identified if one is moved onto the other by some group element. If "M" is the manifold and "G" is the group, the resulting quotient space is denoted by "M" / "G" (or "G" \u005c "M").
p3311
aVManifolds which can be constructed by identifying points include tori and real projective spaces (starting with a plane and a sphere, respectively).
p3312
aVGluing along boundaries.
p3313
aVTwo manifolds with boundaries can be glued together along a boundary. If this is done the right way, the result is also a manifold. Similarly, two boundaries of a single manifold can be glued together.
p3314
aVFormally, the gluing is defined by a bijection between the two boundaries. Two points are identified when they are mapped onto each other. For a topological manifold this bijection should be a homeomorphism, otherwise the result will not be a topological manifold. Similarly for a differentiable manifold it has to be a diffeomorphism. For other manifolds other structures should be preserved.
p3315
aVA finite cylinder may be constructed as a manifold by starting with a strip 1 × 1 and gluing a pair of opposite edges on the boundary by a suitable diffeomorphism. A projective plane may be obtained by gluing a sphere with a hole in it to a Möbius strip along their respective circular boundaries.
p3316
aVCartesian products.
p3317
aVThe Cartesian product of manifolds is also a manifold.
p3318
aVThe dimension of the product manifold is the sum of the dimensions of its factors. Its topology is the product topology, and a Cartesian product of charts is a chart for the product manifold. Thus, an atlas for the product manifold can be constructed using atlases for its factors. If these atlases define a differential structure on the factors, the corresponding atlas defines a differential structure on the product manifold. The same is true for any other structure defined on the factors. If one of the factors has a boundary, the product manifold also has a boundary. Cartesian products may be used to construct tori and finite cylinders, for example, as S1 × S1 and S1 × [0, 1], respectively.
p3319
aVManifolds with additional structure.
p3320
aVTopological manifolds.
p3321
aVThe simplest kind of manifold to define is the topological manifold, which looks locally like some "ordinary" Euclidean space R"n". Formally, a topological manifold is a topological space locally homeomorphic to a Euclidean space. This means that every point has a neighbourhood for which there exists a homeomorphism (a bijective continuous function whose inverse is also continuous) mapping that neighbourhood to R"n". These homeomorphisms are the charts of the manifold.
p3322
aVIt is to be noted that a "topological" manifold looks locally like a Euclidean space in a rather weak manner: while for each individual chart it is possible to distinguish differentiable functions or measure distances and angles, merely by virtue of being a topological manifold a space does not have any "particular" and "consistent" choice of such concepts. In order to discuss such properties for a manifold, one needs to specify further structure and consider differentiable manifolds and Riemannian manifolds discussed below. In particular, the same underlying topological manifold can have several mutually incompatible classes of differentiable functions and an infinite number of ways to specify distances and angles.
p3323
aVUsually additional technical assumptions on the topological space are made to exclude pathological cases. It is customary to require that the space be Hausdorff and second countable.
p3324
aVThe "dimension" of the manifold at a certain point is the dimension of the Euclidean space that the charts at that point map to (number "n" in the definition). All points in a connected manifold have the same dimension. Some authors require that all charts of a topological manifold map to Euclidean spaces of same dimension. In that case every topological manifold has a topological invariant, its dimension. Other authors allow disjoint unions of topological manifolds with differing dimensions to be called manifolds.
p3325
aVDifferentiable manifolds.
p3326
aVFor most applications a special kind of topological manifold, namely a differentiable manifold, is used. If the local charts on a manifold are compatible in a certain sense, one can define directions, tangent spaces, and differentiable functions on that manifold. In particular it is possible to use calculus on a differentiable manifold. Each point of an "n"-dimensional differentiable manifold has a tangent space. This is an "n"-dimensional Euclidean space consisting of the tangent vectors of the curves through the point.
p3327
aVTwo important classes of differentiable manifolds are smooth and analytic manifolds. For smooth manifolds the transition maps are smooth, that is infinitely differentiable. Analytic manifolds are smooth manifolds with the additional condition that the transition maps are analytic (they can be expressed as power series). The sphere can be given analytic structure, as can most familiar curves and surfaces.
p3328
aVThere are also topological manifolds, i.e., locally Euclidean spaces, which possess no differentiable structures at all.
p3329
aVA rectifiable set generalizes the idea of a piecewise smooth or rectifiable curve to higher dimensions; however, rectifiable sets are not in general manifolds.
p3330
aVRiemannian manifolds.
p3331
aVTo measure distances and angles on manifolds, the manifold must be Riemannian. A 'Riemannian manifold' is a differentiable manifold in which each tangent space is equipped with an inner product \u27e8\u22c5,\u22c5\u27e9 in a manner which varies smoothly from point to point. Given two tangent vectors u and v, the inner product \u27e8u,v\u27e9 gives a real number. The dot (or scalar) product is a typical example of an inner product. This allows one to define various notions such as length, angles, areas (or volumes), curvature, gradients of functions and divergence of vector fields.
p3332
aVAll differentiable manifolds (of constant dimension) can be given the structure of a Riemannian manifold. The Euclidean space itself carries a natural structure of Riemannian manifold (the tangent spaces are naturally identified with the Euclidean space itself and carry the standard scalar product of the space). Many familiar curves and surfaces, including for example all "n"-spheres, are specified as subspaces of a Euclidean space and inherit a metric from their embedding in it.
p3333
aVFinsler manifolds.
p3334
aVA Finsler manifold allows the definition of distance but does not require the concept of angle; it is an analytic manifold in which each tangent space is equipped with a norm, ||·||, in a manner which varies smoothly from point to point. This norm can be extended to a metric, defining the length of a curve; but it cannot in general be used to define an inner product.
p3335
aVAny Riemannian manifold is a Finsler manifold.
p3336
aVLie groups.
p3337
aVLie groups, named after Sophus Lie, are differentiable manifolds that carry also the structure of a group which is such that the group operations are defined by smooth maps.
p3338
aVA Euclidean vector space with the group operation of vector addition is an example of a non-compact Lie group. 
p3339
aVA simple example of a compact Lie group is the circle: the group operation is simply rotation. This group, known as U(1), can be also characterised as the group of complex numbers of modulus 1 with multiplication as the group operation.
p3340
aVOther examples of Lie groups include special groups of matrices, which are all subgroups of the general linear group, the group of "n" by "n" matrices with non-zero determinant. If the matrix entries are real numbers, this will be an "n"2-dimensional disconnected manifold. The orthogonal groups, the symmetry groups of the sphere and hyperspheres, are "n"("n"\u22121)/2 dimensional manifolds, where "n"\u22121 is the dimension of the sphere. Further examples can be found in the table of Lie groups.
p3341
aVClassification and invariants.
p3342
aVDifferent notions of manifolds have different notions of classification and invariant; in this section we focus on smooth closed manifolds.
p3343
aVThe classification of smooth closed manifolds is well-understood "in principle", except in dimension 4: in low dimensions (2 and 3) it is geometric, via the uniformization theorem and the solution of the Poincaré conjecture, and in high dimension (5 and above) it is algebraic, via surgery theory. This is a classification in principle: the general question of whether two smooth manifolds are diffeomorphic is not computable in general. Further, specific computations remain difficult, and there are many open questions.
p3344
aVOrientable surfaces can be visualized, and their diffeomorphism classes enumerated, by genus. Given two orientable surfaces, one can determine if they are diffeomorphic by computing their respective genera and comparing: they are diffeomorphic if and only if the genera are equal, so the genus forms a complete set of invariants.
p3345
aVThis is much harder in higher dimensions: higher-dimensional manifolds cannot be directly visualized (though visual intuition is useful in understanding them), nor can their diffeomorphism classes be enumerated, nor can one in general determine if two different descriptions of a higher-dimensional manifold refer to the same object.
p3346
aVHowever, one can determine if two manifolds are "different" if there is some intrinsic characteristic that differentiates them. Such criteria are commonly referred to as invariants, because, while they may be defined in terms of some presentation (such as the genus in terms of a triangulation), they are the same relative to all possible descriptions of a particular manifold: they are "invariant" under different descriptions.
p3347
aVNaively, one could hope to develop an arsenal of invariant criteria that would definitively classify all manifolds up to isomorphism. Unfortunately, it is known that for manifolds of dimension 4 and higher, no program exists that can decide whether two manifolds are diffeomorphic.
p3348
aVSmooth manifolds have a rich set of invariants, coming from point-set topology, 
p3349
aVclassic algebraic topology, and geometric topology. The most familiar invariants, which are visible for surfaces, are orientability (a normal invariant, also detected by homology) and genus (a homological invariant).
p3350
aVSmooth closed manifolds have no local invariants (other than dimension), though geometric manifolds have local invariants, notably the curvature of a Riemannian manifold and the torsion of a manifold equipped with an affine connection.
p3351
aVThis distinction between local invariants and no local invariants is a common way to distinguish between geometry and topology. All invariants of a smooth closed manifold are thus global.
p3352
aVAlgebraic topology is a source of a number of important global invariant properties. Some key criteria include the "simply connected" property and orientability (see below). Indeed several branches of mathematics, such as homology and homotopy theory, and the theory of characteristic classes were founded in order to study invariant properties of manifolds.
p3353
aVExamples of surfaces.
p3354
aVOrientability.
p3355
aVIn dimensions two and higher, a simple but important invariant criterion is the question of whether a manifold admits a meaningful orientation. 
p3356
aVConsider a topological manifold with charts mapping to R"n". Given an ordered basis for R"n", a chart causes its piece of the manifold to itself acquire a sense of ordering, which in 3-dimensions can be viewed as either right-handed or left-handed. Overlapping charts are not required to agree in their sense of ordering, which gives manifolds an important freedom. For some manifolds, like the sphere, charts can be chosen so that overlapping regions agree on their "handedness"; these are "orientable" manifolds. For others, this is impossible. The latter possibility is easy to overlook, because any closed surface embedded (without self-intersection) in three-dimensional space is orientable.
p3357
aVSome illustrative examples of non-orientable manifolds include: (1) the Möbius strip, which is a manifold with boundary, (2) the Klein bottle, which must intersect itself in its 3-space representation, and (3) the real projective plane, which arises naturally in geometry. 
p3358
aVMöbius strip.
p3359
aVBegin with an infinite circular cylinder standing vertically, a manifold without boundary. Slice across it high and low to produce two circular boundaries, and the cylindrical strip between them. This is an orientable manifold with boundary, upon which "surgery" will be performed. Slice the strip open, so that it could unroll to become a rectangle, but keep a grasp on the cut ends. Twist one end 180°, making the inner surface face out, and glue the ends back together seamlessly. This results in a strip with a permanent half-twist: the Möbius strip. Its boundary is no longer a pair of circles, but (topologically) a single circle; and what was once its "inside" has merged with its "outside", so that it now has only a "single" side.
p3360
aVKlein bottle.
p3361
aVTake two Möbius strips; each has a single loop as a boundary. Straighten out those loops into circles, and let the strips distort into cross-caps. Gluing the circles together will produce a new, closed manifold without boundary, the Klein bottle. Closing the surface does nothing to improve the lack of orientability, it merely removes the boundary. Thus, the Klein bottle is a closed surface with no distinction between inside and outside. Note that in three-dimensional space, a Klein bottle's surface must pass through itself. Building a Klein bottle which is not self-intersecting requires four or more dimensions of space.
p3362
aVReal projective plane.
p3363
aVBegin with a sphere centered on the origin. Every line through the origin pierces the sphere in two opposite points called "antipodes". Although there is no way to do so physically, it is possible (by considering a quotient space) to mathematically merge each antipode pair into a single point. The closed surface so produced is the real projective plane, yet another non-orientable surface. It has a number of equivalent descriptions and constructions, but this route explains its name: all the points on any given line through the origin project to the same "point" on this "plane".
p3364
aVGenus and the Euler characteristic.
p3365
aVFor two dimensional manifolds a key invariant property is the genus, or the "number of handles" present in a surface. A torus is a sphere with one handle, a double torus is a sphere with two handles, and so on. Indeed it is possible to fully characterize compact, two-dimensional manifolds on the basis of genus and orientability. In higher-dimensional manifolds genus is replaced by the notion of Euler characteristic, and more generally Betti numbers and homology and cohomology.
p3366
aVMaps of manifolds.
p3367
aVJust as there are various types of manifolds, there are various types of maps of manifolds. In addition to continuous functions and smooth functions generally, there are maps with special properties. In geometric topology a basic type are embeddings, of which knot theory is a central example, and generalizations such as immersions, submersions, covering spaces, and ramified covering spaces.
p3368
aVBasic results include the Whitney embedding theorem and Whitney immersion theorem.
p3369
aVIn Riemannian geometry, one may ask for maps to preserve the Riemannian metric, leading to notions of isometric embeddings, isometric immersions, and Riemannian submersions; a basic result is the Nash embedding theorem.
p3370
aVScalar-valued functions.
p3371
aVA basic example of maps between manifolds are scalar-valued functions on a manifold,
p3372
aVformula_28 or formula_29
p3373
aVsometimes called regular functions or functionals, by analogy with algebraic geometry or linear algebra. These are of interest both in their own right, and to study the underlying manifold.
p3374
aVIn geometric topology, most commonly studied are Morse functions, which yield handlebody decompositions, while in mathematical analysis, one often studies solution to partial differential equations, an important example of which is harmonic analysis, where one studies harmonic functions: the kernel of the Laplace operator. This leads to such functions as the spherical harmonics, and to heat kernel methods of studying manifolds, such as hearing the shape of a drum and some proofs of the Atiyah\u2013Singer index theorem.
p3375
aVBecause of singular points, a variety is in general not a manifold, though linguistically the French "variété", German "Mannigfaltigkeit" and English "manifold" are largely synonymous. In French an algebraic variety is called "une variété algébrique" (an "algebraic variety"), while a smooth manifold is called "une variété différentielle" (a "differential variety").
p3376
aVGeneralizations of manifolds.
p3377
aVCentrality of manifolds.
p3378
aVWhy does one study manifolds? Manifolds, and generalized spaces composed of manifolds such as stratified spaces, occupy a central role in topology. This is for a variety of reasons, including that they often arise in practice, as solution sets of equations (elaborated above by the fact that algebraic varieties, analytic varieties, etc. can be stratified into manifold pieces), and that they are the space "modeled on" Euclidean space (a space that looks locally like Euclidean space) \u2013 i.e., they arise naturally when considering "subsets" and "quotients" of Euclidean space.
p3379
aVMore abstractly, a natural class of objects to study in topology are objects that are "homogeneous" (all points are topologically the same: the group of self-homeomorphisms acts transitively) and "finite type" or "tame" (to rule out spaces such as the Cantor set, where each open set contains uncountably many connected components); more generally, a space of "finite type" where the self-homeomorphism group has finitely many orbits, forming the strata. Manifolds are homogeneous and tame (locally isomorphic to Euclidean space) in this manner, and one may ask if all "tame" homogeneous spaces are manifolds, or whether there is a natural class where more general spaces are also included. As stated, this is a meta-mathematical question; the Bing\u2013Borsuk conjecture gives a concrete statement, conjecturing that a homogeneous ENR is a manifold, where ENR, a tameness condition, means a Euclidean neighborhood retract \u2013 a retract of an open subset of Euclidean space, or equivalently an absolute neighborhood retract (ANR) that embeds in Euclidean space. This is an open question; a candidate counterexample is given by generalizing to homology manifolds (that are finite-dimensional ANRs), in which case certain such spaces are not manifolds, but have not been shown to be homogeneous, hence may not be a counterexample.
p3380
asS'Map coloring'
p3381
(lp3382
VMap coloring is the act of assigning different colors to different features on a map. There are two very different uses of this term. The first is in cartography, choosing the colors to be used when producing a map. The second is in mathematics, where the problem is to determine the minimum number of colors needed to color a map so that no two adjacent features have the same color.
p3383
aVCartography.
p3384
aVColor is a very useful attribute to depict different features on a map. Typical uses of color include displaying different political divisions, different elevations, or different kinds of roads. A choropleth map is a thematic map in which areas are colored differently to show the measurement of a statistical variable being displayed on the map. The choropleth map provides an easy way to visualize how a measurement varies across a geographic area or it shows the level of variability within a region.
p3385
aVDisplaying the data in different hues can greatly affect the understanding or feel of the map. Also, the cartographer must take into account that many people have impaired color vision, and use colors that are easily distinguishable by these readers.
p3386
aVColors can also be used to produce three-dimensional effects from two-dimensional maps, either by explicit color-coding of the two images intended for different eyes, or by using the characteristics of the human visual system to make the map look three-dimensional.
p3387
aVMathematics.
p3388
aVIn mathematics there is a very strong link between map coloring and graph coloring, since every map showing different areas has a corresponding graph. By far the most famous result in this area is the four color theorem, which states that any planar map can be colored with at most four colors.
p3389
asS'Exponentiation'
p3390
(lp3391
VExponentiation is a mathematical operation, written as ""'b""n", involving two numbers, the base"' "b" and the exponent (or power) "n". When "n" is a positive integer, exponentiation corresponds to repeated multiplication of the base: that is, "bn" is the product of multiplying "n" bases:
p3392
aVformula_1
p3393
aVThe exponent is usually shown as a superscript to the right of the base. Some common exponents have their own names: the exponent 2 (or 2nd power) is called the "square" of "b" ("b"2) or "b squared"; the exponent 3 (or 3rd power) is called the "cube" of "b" ("b"3) or "b cubed". The exponent \u22121 of "b", or 1 / "b", is called the "reciprocal" of "b".
p3394
aVWhen "n" is a negative integer and "b" is not zero, "b""n" is naturally defined as 1/"b"\u2212"n", preserving the property .
p3395
aVExponentiation for integer exponents can be defined for a wide variety of algebraic structures, including matrices.
p3396
aVExponentiation is used extensively in many fields, including economics, biology, chemistry, physics, and computer science, with applications such as compound interest, population growth, chemical reaction kinetics, wave behavior, and public-key cryptography.
p3397
aVBackground and terminology.
p3398
aVThe expression "b"2 = "b"·"b" is called the square of "b" because the area of a square with side-length "b" is "b"2. It is pronounced "b squared".
p3399
aVThe expression "b"3 = "b"·"b"·"b" is called the cube of "b" because the volume of a cube with side-length "b" is "b"3. It is pronounced "b cubed".
p3400
aVThe exponent says how many copies of the base are multiplied together. For example, 35 = 3·3·3·3·3 = 243. The base 3 appears 5 times in the repeated multiplication, because the exponent is 5. Here, 3 is the "base", 5 is the "exponent", and 243 is the "power" or, more specifically, "the fifth power of 3", "3 raised to the fifth power", or "3 to the power of 5".
p3401
aVThe word "raised" is usually omitted, and very often "power" as well, so 35 is typically pronounced "three to the fifth" or "three to the five". The exponentiation "b""n" can be read as "b raised to the n-th power", or "b raised to the power of n", or "b raised by the exponent of n", or most briefly as "b to the n".
p3402
aVExponentiation may be generalized from integer exponents to more general types of numbers.
p3403
aVThe word "exponent" was coined in 1544 by Michael Stifel.
p3404
aVThe modern notation for exponentiation was introduced by René Descartes in his "Géométrie" of 1637.
p3405
aVInteger exponents.
p3406
aVThe exponentiation operation with integer exponents requires only elementary algebra.
p3407
aVPositive integer exponents.
p3408
aVFormally, powers with positive integer exponents may be defined by the initial condition
p3409
aVformula_2
p3410
aVand the recurrence relation
p3411
aVformula_3
p3412
aVFrom the associativity of multiplication, it follows that for any positive integers "m" and "n",
p3413
aVformula_4
p3414
aVZero exponent.
p3415
aVAny nonzero number raised by the exponent 0 is 1; one interpretation of such a power is as an empty product. The case of 00 is discussed below.
p3416
aVNegative exponents.
p3417
aVThe following identity holds for an arbitrary integer "n" and nonzero "b":
p3418
aVformula_5
p3419
aVRaising 0 by a negative exponent is left undefined.
p3420
aVThe identity above may be derived through a definition aimed at extending the range of exponents to negative integers.
p3421
aVFor non-zero "b" and positive "n", the recurrence relation from the previous subsection can be rewritten as
p3422
aVformula_6
p3423
aVBy defining this relation as valid for all integer "n" and nonzero "b", it follows that
p3424
aVformula_7
p3425
aVThis is then readily shown to be true for every integer "n".
p3426
aVCombinatorial interpretation.
p3427
aVFor nonnegative integers "n" and "m", the power "n""m" equals the cardinality of the set of "m"-tuples from an "n"-element set, or the number of "m"-letter words from an "n"-letter alphabet.
p3428
aVIdentities and properties.
p3429
aVThe following identities hold for all integer exponents, provided that the base is non-zero:
p3430
aVformula_8
p3431
aVExponentiation is not commutative. This contrasts with addition and multiplication, which are. For example, and , but , whereas .
p3432
aVExponentiation is not associative either. Addition and multiplication are. For example,
p3433
aVformula_9
p3434
aVParticular bases.
p3435
aVPowers of ten.
p3436
aVIn the base ten (decimal) number system, integer powers of 10 are written as the digit 1 followed or preceded by a number of zeroes determined by the sign and magnitude of the exponent. For example, = 1,000 and = 0.0001.
p3437
aVExponentiation with base 10 is used in scientific notation to denote large or small numbers. For instance, 299,792,458 m/s (the speed of light in vacuum, in metre per second) can be written as and then approximated as .
p3438
aVSI prefixes based on powers of 10 are also used to describe small or large quantities. For example, the prefix kilo means , so a kilometre is 1,000 metres.
p3439
aVPowers of two.
p3440
aVThe positive powers of 2 are important in computer science because there are 2"n" possible values for an "n"-bit binary register.
p3441
aVPowers of 2 are important in set theory since a set with "n" members has a power set, or set of all subsets of the original set, with 2"n" members.
p3442
aVThe negative powers of 2 are commonly used, and the first two have special names: "half", and "quarter".
p3443
aVIn the base 2 (binary) number system, integer powers of 2 are written as 1 followed or preceded by a number of zeroes determined by the sign and magnitude of the exponent. For example, two to the power of three is written as 1000 in binary.
p3444
aVPowers of one.
p3445
aVThe integer powers of one are all one: .
p3446
aVPowers of zero.
p3447
aVIf the exponent is positive, the power of zero is zero: , where .
p3448
aVIf the exponent is negative, the power of zero (0"n", where "n" < 0) is undefined, because division by zero is implied.
p3449
aVIf the exponent is zero, some authors define , whereas others leave it undefined, as discussed below.
p3450
aVPowers of minus one.
p3451
aVIf "n" is an even integer, then (\u22121)"n" = 1.
p3452
aVIf "n" is an odd integer, then (\u22121)"n" = \u22121.
p3453
aVBecause of this, powers of \u22121 are useful for expressing alternating sequences. For a similar discussion of powers of the complex number "i", see the section on Powers of complex numbers.
p3454
aVLarge exponents.
p3455
aVThe limit of a sequence of powers of a number greater than one diverges, in other words they grow without bound:
p3456
aV"b""n" \u2192 \u221e as "n" \u2192 \u221e when "b" > 1
p3457
aVThis can be read as ""b" to the power of "n" tends to +\u221e as "n" tends to infinity when "b" is greater than one".
p3458
aVPowers of a number with absolute value less than one tend to zero:
p3459
aV"b""n" \u2192 0 as "n" \u2192 \u221e when |"b"| < 1
p3460
aVAny power of one is always one:
p3461
aV"b""n" = 1 for all "n" if "b" = 1
p3462
aVIf the number "b" varies tending to 1 as the exponent tends to infinity then the limit is not necessarily one of those above. A particularly important case is
p3463
aV(1 + 1/"n")"n" \u2192 "e" as "n" \u2192 \u221e
p3464
aVSee the section below, The exponential function.
p3465
aVOther limits, in particular of those tending to indeterminate forms, are described in limits of powers below.
p3466
aVRational exponents.
p3467
aVAn '" "n"-th root"' of a number "b" is a number "x" such that "x""n" = "b".
p3468
aVIf "b" is a positive real number and "n" is a positive integer, then there is exactly one positive real solution to "xn" = "b". This solution is called the '"principal "n"-th root"' of "b". It is denoted "n"\u221a"b", where \u221a\u2002 is the radical symbol; alternatively, the principal root may be written "b"1/"n". For example: 41/2 = 2, 81/3 = 2.
p3469
aVThe fact that formula_10 solves formula_11 follows from noting that
p3470
aVformula_12
p3471
aVIf "n" is even, then "xn" = "b" has two real solutions if "b" is positive, which are the positive and negative "n"th roots (the positive one being denoted formula_13). If "b" is negative, the equation has no solution in real numbers for even "n".
p3472
aVIf "n" is odd, then "xn" = "b" has one real solution. The solution is positive if "b" is positive and negative if "b" is negative.
p3473
aVThe principal root of a positive real number "b" with a rational exponent "u"/"v" in lowest terms satisfies
p3474
aVformula_14
p3475
aVwhere "u" is an integer and "v" is a positive integer.
p3476
aVRational powers "u"/"v", where "u"/"v" is in lowest terms, are positive if "u" is even (and hence "v" is odd) (because then "b""u" is positive), and negative for negative "b" if "u" and "v" are odd (because then "b""u" is negative). There are two roots, one of each sign, if "b" is positive and "v" is even (as exemplified by the case in which "u"=1 and "v"=2, whereby a positive "b" has two square roots); in this case the principal root is defined to be the positive one.
p3477
aVThus we have (\u221227)1/3 = \u22123 and (\u221227)2/3 = 9. The number 4 has two 3/2"th" roots, namely 8 and \u22128; however, by convention 43/2 denotes the principal root which is 8. Since there is no real number "x" such that "x"2 = \u22121, the definition of "b""u"/"v" when "b" is negative and "v" is even must use the imaginary unit "i", as described more fully in the section § Powers of complex numbers.
p3478
aVCare needs to be taken when applying the power identities with negative "n"th roots. For instance,
p3479
aVReal exponents.
p3480
aVThe identities and properties shown above for integer exponents are true for positive real numbers with non-integer exponents as well. However the identity
p3481
aVformula_15
p3482
aVcannot be extended consistently to cases where "b" is a negative real number (see Real exponents with negative bases). The failure of this identity is the basis for the problems with complex number powers detailed under failure of power and logarithm identities.
p3483
aVThe extension of exponentiation to real powers of positive real numbers can be done either by extending the rational powers to reals by continuity, or more usually as given in the section Powers via logarithms below.
p3484
aVLimits of rational exponents.
p3485
aVSince any irrational number can be expressed as the limit of a sequence of rational numbers, exponentiation of a positive real number "b" with an arbitrary real exponent "x" can be defined by continuity with the rule
p3486
aVformula_16
p3487
aVwhere the limit as "r" gets close to "x" is taken only over rational values of "r". This limit only exists for positive "b". The (\u03b5, \u03b4)-definition of limit is used, this involves showing that for any desired accuracy of the result formula_17 one can choose a sufficiently small interval around so all the rational powers in the interval are within the desired accuracy.
p3488
aVFor example, if formula_18, the nonterminating decimal representation formula_19 can be used (based on strict monotonicity of the rational power) to obtain the intervals bounded by rational powers
p3489
aVformula_20, formula_21, formula_22, \u2026
p3490
aVThe bounded intervals converge to a unique real number, denoted by formula_23. This technique can be used to obtain any irrational power of . The function formula_24 is thus defined for any real number .
p3491
aVThe exponential function.
p3492
aVThe important mathematical constant E (mathematical constant), sometimes called Euler's number, is approximately equal to 2.718 and is the base of the natural logarithm. Although exponentiation of "e" could, in principle, be treated the same as exponentiation of any other real number, such exponentials turn out to have particularly elegant and useful properties. Among other things, these properties allow exponentials of "e" to be generalized in a natural way to other types of exponents, such as complex numbers or even matrices, while coinciding with the familiar meaning of exponentiation with rational exponents.
p3493
aVAs a consequence, the notation "e""x" usually denotes a generalized exponentiation definition called the exponential function, exp("x"), which can be defined in many equivalent ways, for example by:
p3494
aVformula_25
p3495
aVAmong other properties, exp satisfies the exponential identity:
p3496
aVformula_26
p3497
aVThe exponential function is defined for all integer, fractional, real, and complex values of . In fact, the matrix exponential is well-defined for square matrices (in which case the exponential identity only holds when and commute), and is useful for solving systems of linear differential equations.
p3498
aVSince exp(1) is equal to and exp("x") satisfies the exponential identity, it immediately follows that exp("x") coincides with the repeated-multiplication definition of "e""x" for integer "x", and it also follows that rational powers denote (positive) roots as usual, so exp("x") coincides with the "e""x" definitions in the previous section for all real "x" by continuity.
p3499
aVPowers via logarithms.
p3500
aVThe natural logarithm ln("x") is the inverse of the exponential function "e""x". It is defined for "b" > 0, and satisfies
p3501
aVformula_27
p3502
aVIf "b""x" is to preserve the logarithm and exponent rules, then one must have
p3503
aVformula_28
p3504
aVfor each real number "x".
p3505
aVThis can be used as an alternative definition of the real number power "b""x" and agrees with the definition given above using rational exponents and continuity. The definition of exponentiation using logarithms is more common in the context of complex numbers, as discussed below.
p3506
aVReal exponents with negative bases.
p3507
aVPowers of a positive real number are always positive real numbers. The solution of x2 = 4, however, can be either 2 or \u22122. The principal value of 41/2 is 2, but \u22122 is also a valid square root. If the definition of exponentiation of real numbers is extended to allow negative results then the result is no longer well behaved.
p3508
aVNeither the logarithm method nor the rational exponent method can be used to define "b""r" as a real number for a negative real number "b" and an arbitrary real number "r". Indeed, "e""r" is positive for every real number "r", so ln("b") is not defined as a real number for "b" \u2264 0.
p3509
aVThe rational exponent method cannot be used for negative values of "b" because it relies on continuity. The function "f"("r") = "b""r" has a unique continuous extension from the rational numbers to the real numbers for each "b" > 0. But when "b" < 0, the function "f" is not even continuous on the set of rational numbers "r" for which it is defined.
p3510
aVFor example, consider "b" = \u22121. The "n"th root of \u22121 is \u22121 for every odd natural number "n". So if "n" is an odd positive integer, (\u22121)("m"/"n") = \u22121 if "m" is odd, and (\u22121)("m"/"n") = 1 if "m" is even. Thus the set of rational numbers "q" for which (\u22121)"q" = 1 is dense in the rational numbers, as is the set of "q" for which (\u22121)"q" = \u22121. This means that the function (\u22121)"q" is not continuous at any rational number "q" where it is defined.
p3511
aVOn the other hand, arbitrary complex powers of negative numbers "b" can be defined by choosing a "complex" logarithm of "b".
p3512
aVIrrational exponents.
p3513
aVIf is a positive algebraic number, and is a rational number, it has been shown above that is algebraic. This remains true even if one accepts any algebraic number for , with the only difference that may take several values (see below), all algebraic. Gelfond\u2013Schneider theorem provides some information on the nature of when is irrational (that is not rational). It states:
p3514
aVComplex exponents with positive real bases.
p3515
aVImaginary exponents with base "e".
p3516
aVThe geometric interpretation of the operations on complex numbers and the definition of the exponential function is the clue to understanding "e""ix" for real "x". In particular, for two complex numbers "z1", "z2" with polar coordinates ("r1", "\u03b81"), ("r2", "\u03b82"), their product "z1z2" is equal to ("r1r2", "\u03b81" + "\u03b82"). Consider the right triangle in the complex plane which has as vertices. For large values of "n", the triangle is almost a circular sector with a radius of 1 and a small central angle equal to "x"/"n" radians. 1 + "ix"/"n" may then be approximated by the number with polar coordinates . So, in the limit as "n" approaches infinity, approaches (1, "x"/"n")"n" = (1"n", "nx"/"n") = (1, "x"), the point on the unit circle whose angle from the positive real axis is "x" radians. The cartesian coordinates of this point are (cos "x", sin "x"). So ; this is Euler's formula, connecting algebra to trigonometry by means of complex numbers.
p3517
aVThe solutions to the equation "e""z" = 1 are the integer multiples of 2\u03c0"i":
p3518
aVformula_29
p3519
aVMore generally, if e"v" = "w", then every solution to "e""z" = "w" can be obtained by adding an integer multiple of 2\u03c0"i" to "v":
p3520
aVformula_30
p3521
aVThus the complex exponential function is a periodic function with period 2\u03c0"i".
p3522
aVMore simply: "e""i\u03c0" = \u22121; "e""x" + "iy" = "e""x"(cos "y" + "i" sin "y").
p3523
aVTrigonometric functions.
p3524
aVIt follows from Euler's formula stated above that the trigonometric functions cosine and sine are
p3525
aVformula_31
p3526
aVHistorically, cosine and sine were defined geometrically before the invention of complex numbers. The above formula reduces the complicated formulas for trigonometric functions of a sum into the simple exponentiation formula
p3527
aVformula_32
p3528
aVUsing exponentiation with complex exponents may reduce problems in trigonometry to algebra.
p3529
aVComplex exponents with base e.
p3530
aVThe power can be computed as "e""x" · "e""iy". The real factor "e""x" is the absolute value of "z" and the complex factor "e""iy" identifies the direction of "z".
p3531
aVComplex exponents with positive real bases.
p3532
aVIf "b" is a positive real number, and "z" is any complex number, the power "b""z" is defined as "e""z"·ln("b"), where "x" = ln("b") is the unique real solution to the equation "e""x" = "b". So the same method working for real exponents also works for complex exponents.
p3533
aVFor example:
p3534
aV2"i" = "e" "i"·ln(2) = cos(ln(2)) + "i"·sin(ln(2)) \u2248 0.76924 + 0.63896"i"
p3535
aV"e""i" \u2248 0.54030 + 0.84147"i"
p3536
aV10"i" \u2248 \u22120.66820 + 0.74398"i"
p3537
aV("e"2\u03c0)"i" \u2248 535.49"i" \u2248 1
p3538
aVThe identity formula_33 is not generally valid for complex powers. A simple counterexample is given by:
p3539
aVformula_34
p3540
aVThe identity is, however, valid when formula_35 is a real number, and also when formula_36 is an integer.
p3541
aVPowers of complex numbers.
p3542
aVInteger powers of nonzero complex numbers are defined by repeated multiplication or division as above. If "i" is the imaginary unit and "n" is an integer, then "i""n" equals 1, "i", \u22121, or \u2212"i", according to whether the integer "n" is congruent to 0, 1, 2, or 3 modulo 4. Because of this, the powers of "i" are useful for expressing sequences of period 4.
p3543
aVComplex powers of positive reals are defined via "e""x" as in section Complex exponents with positive real bases above. These are continuous functions.
p3544
aVTrying to extend these functions to the general case of noninteger powers of complex numbers that are not positive reals leads to difficulties. Either we define discontinuous functions or multivalued functions. Neither of these options is entirely satisfactory.
p3545
aVThe rational power of a complex number must be the solution to an algebraic equation. Therefore it always has a finite number of possible values. For example, "w" = "z"1/2 must be a solution to the equation "w"2 = "z". But if "w" is a solution, then so is \u2212"w", because (\u22121)2 = 1. A unique but somewhat arbitrary solution called the principal value can be chosen using a general rule which also applies for nonrational powers.
p3546
aVComplex powers and logarithms are more naturally handled as single valued functions on a Riemann surface. Single valued versions are defined by choosing a sheet. The value has a discontinuity along a branch cut. Choosing one out of many solutions as the principal value leaves us with functions that are not continuous, and the usual rules for manipulating powers can lead us astray.
p3547
aVAny nonrational power of a complex number has an infinite number of possible values because of the multi-valued nature of the complex logarithm. The principal value is a single value chosen from these by a rule which, amongst its other properties, ensures powers of complex numbers with a positive real part and zero imaginary part give the same value as for the corresponding real numbers.
p3548
aVExponentiating a real number to a complex power is formally a different operation from that for the corresponding complex number. However in the common case of a positive real number the principal value is the same.
p3549
aVThe powers of negative real numbers are not always defined and are discontinuous even where defined. In fact, they are only defined when the exponent is a rational number with the denominator being an odd integer. When dealing with complex numbers the complex number operation is normally used instead.
p3550
aVComplex exponents with complex bases.
p3551
aVFor complex numbers "w" and "z" with "w" \u2260 0, the notation "w""z" is ambiguous in the same sense that log "w" is.
p3552
aVTo obtain a value of "w""z", first choose a logarithm of "w"; call it log "w". Such a choice may be the principal value Log "w" (the default, if no other specification is given), or perhaps a value given by some other branch of log "w" fixed in advance. Then, using the complex exponential function one defines
p3553
aVformula_37
p3554
aVbecause this agrees with the earlier definition in the case where "w" is a positive real number and the (real) principal value of log "w" is used.
p3555
aVIf "z" is an integer, then the value of "w""z" is independent of the choice of log "w", and it agrees with the earlier definition of exponentiation with an integer exponent.
p3556
aVIf "z" is a rational number "m"/"n" in lowest terms with "z" > 0, then the infinitely many choices of log "w" yield only "n" different values for "w""z"; these values are the "n" complex solutions "s" to the equation "s""n" = "w""m".
p3557
aVIf "z" is an irrational number, then the infinitely many choices of log "w" lead to infinitely many distinct values for "w""z".
p3558
aVThe computation of complex powers is facilitated by converting the base "w" to polar form, as described in detail below.
p3559
aVA similar construction is employed in quaternions.
p3560
aVComplex roots of unity.
p3561
aVA complex number "w" such that "w""n" = 1 for a positive integer "n" is an '" "n"th root of unity"'. Geometrically, the "n"th roots of unity lie on the unit circle of the complex plane at the vertices of a regular "n"-gon with one vertex on the real number 1.
p3562
aVIf "w""n" = 1 but "w""k" \u2260 1 for all natural numbers "k" such that 0 < "k" < "n", then "w" is called a '"primitive "n"th root of unity."' The negative unit \u22121 is the only primitive square root of unity. The imaginary unit "i" is one of the two primitive 4-th roots of unity; the other one is \u2212"i".
p3563
aVThe number "e" is the primitive "n"th root of unity with the smallest positive complex argument. (It is sometimes called the '"principal "n"th root of unity"', although this terminology is not universal and should not be confused with the principal value of "n"\u221a1, which is 1.)
p3564
aVThe other "n"th roots of unity are given by
p3565
aVformula_38
p3566
aVfor 2 \u2264 "k" \u2264 "n".
p3567
aVRoots of arbitrary complex numbers.
p3568
aVAlthough there are infinitely many possible values for a general complex logarithm, there are only a finite number of values for the power "wq" in the important special case where "q" = 1/"n" and "n" is a positive integer. These are the ""'n"th roots"' of "w"; they are solutions of the equation "zn" = "w". As with real roots, a second root is also called a square root and a third root is also called a cube root.
p3569
aVIt is conventional in mathematics to define "w"1/"n" as the principal value of the root. If "w" is a positive real number, it is also conventional to select a positive real number as the principal value of the root "w"1/"n". For general complex numbers, the "n"th root with the smallest argument is often selected as the principal value of the "n"th root operation, as with principal values of roots of unity.
p3570
aVThe set of "n"th roots of a complex number "w" is obtained by multiplying the principal value "w"1/"n" by each of the "n"th roots of unity. For example, the fourth roots of 16 are 2, \u22122, 2"i", and \u22122"i", because the principal value of the fourth root of 16 is 2 and the fourth roots of unity are 1, \u22121, "i", and \u2212"i".
p3571
aVComputing complex powers.
p3572
aVIt is often easier to compute complex powers by writing the number to be exponentiated in polar form. Every complex number "z" can be written in the polar form
p3573
aVformula_39
p3574
aVwhere "r" is a nonnegative real number and \u03b8 is the (real) argument of "z". The polar form has a simple geometric interpretation: if a complex number "u" + "iv" is thought of as representing a point ("u", "v") in the complex plane using Cartesian coordinates, then ("r", \u03b8) is the same point in polar coordinates. That is, "r" is the "radius" "r"2 = "u"2 + "v"2 and \u03b8 is the "angle" \u03b8 = atan2("v", "u"). The polar angle \u03b8 is ambiguous since any integer multiple of 2\u03c0 could be added to \u03b8 without changing the location of the point. Each choice of \u03b8 gives in general a different possible value of the power. A branch cut can be used to choose a specific value. The principal value (the most common branch cut), corresponds to \u03b8 chosen in the interval (\u2212\u03c0, \u03c0]. For complex numbers with a positive real part and zero imaginary part using the principal value gives the same result as using the corresponding real number.
p3575
aVIn order to compute the complex power "w""z", write "w" in polar form:
p3576
aVformula_40
p3577
aVThen
p3578
aVformula_41
p3579
aVand thus
p3580
aVformula_42
p3581
aVIf "z" is decomposed as "c" + "di", then the formula for "w""z" can be written more explicitly as
p3582
aVformula_43
p3583
aVThis final formula allows complex powers to be computed easily from decompositions of the base into polar form and the exponent into Cartesian form. It is shown here both in polar form and in Cartesian form (via Euler's identity).
p3584
aVThe following examples use the principal value, the branch cut which causes \u03b8 to be in the interval (\u2212\u03c0, \u03c0]. To compute "i""i", write "i" in polar and Cartesian forms:
p3585
aVformula_44
p3586
aVThen the formula above, with "r" = 1, \u03b8 = , "c" = 0, and "d" = 1, yields:
p3587
aVformula_45
p3588
aVSimilarly, to find (\u22122)3 + 4"i", compute the polar form of \u22122,
p3589
aVformula_46
p3590
aVand use the formula above to compute
p3591
aVformula_47
p3592
aVThe value of a complex power depends on the branch used. For example, if the polar form "i" = 1"e" is used to compute "i" "i", the power is found to be "e"\u2212; the principal value of "i" "i", computed above, is "e"\u2212. The set of all possible values for "i" "i" is given by:
p3593
aVformula_8
p3594
aVSo there is an infinity of values which are possible candidates for the value of "i""i", one for each integer "k". All of them have a zero imaginary part so one can say "i""i" has an infinity of valid real values.
p3595
aVFailure of power and logarithm identities.
p3596
aVSome identities for powers and logarithms for positive real numbers will fail for complex numbers, no matter how complex powers and complex logarithms are defined "as single-valued functions". For example:
p3597
aVZero to the power of zero.
p3598
aVDiscrete exponents.
p3599
aVThere are many widely used formulas having terms involving natural-number exponents that require 00 to be evaluated to 1.
p3600
aVFor example:
p3601
aVHowever, not all sources define 00 to be 1, particularly in the context of continuously varying exponents.
p3602
aVContinuous exponents.
p3603
aVWhen the form 00 arises as a limit of formula_66, it must be handled as an indeterminate form.
p3604
aV:formula_67.
p3605
aVSo 00 is an indeterminate form. This behavior shows that the two-variable function "x""y", though continuous on the set {("x","y"): "x" > 0}, cannot be extended to a continuous function on any set containing (0,0), no matter how 00 is defined. However, under certain conditions, such as when "f" and "g" are both analytic functions and "f" is positive on the open interval (0,"b") for some positive "b", the limit approaching from the right is always 1.
p3606
aVHistory of differing points of view.
p3607
aVThe debate over the definition of formula_68 has been going on at least since the early 19th century. At that time, most mathematicians agreed that formula_69, until in 1821 Cauchy listed formula_68 along with expressions like formula_71 in a table of indeterminate forms. In the 1830s Libri published an unconvincing argument for formula_69, and Möbius sided with him, erroneously claiming that formula_73 whenever formula_74. A commentator who signed his name simply as "S" provided the counterexample of formula_75, and this quieted the debate for some time. More historical details can be found in Knuth (1992).
p3608
aVMore recent authors interpret the situation above in different ways:
p3609
aVTreatment on computers.
p3610
aVIEEE floating point standard.
p3611
aVThe IEEE 754-2008 floating point standard is used in the design of most floating point libraries. It recommends a number of functions for computing a power:
p3612
aVProgramming languages.
p3613
aVMost programming language with a power function are implemented using the IEEE pow function and therefore evaluate 00 as 1. The later C and C++ standards describe this as the normative behaviour. The Java standard mandates this behavior. The .NET Framework method codice_1 also treats 00 as 1.
p3614
aVLimits of powers.
p3615
aVThe section zero to the power of zero gives a number of examples of limits which are of the indeterminate form 00. The limits in these examples exist, but have different values, showing that the two-variable function "x""y" has no limit at the point (0,0). One may ask at what points this function does have a limit.
p3616
aVMore precisely, consider the function "f"("x","y") = "x""y" defined on "D" = {("x","y") \u2208 R2 : "x" > 0}. Then "D" can be viewed as a subset of 2 (that is, the set of all pairs ("x","y") with "x","y" belonging to the extended real number line  = [\u2212\u221e, +\u221e], endowed with the product topology), which will contain the points at which the function "f" has a limit.
p3617
aVIn fact, "f" has a limit at all accumulation points of "D", except for (0,0), (+\u221e,0), (1,+\u221e) and (1,\u2212\u221e). Accordingly, this allows one to define the powers "x""y" by continuity whenever 0 \u2264 "x" \u2264 +\u221e, \u2212\u221e \u2264 y \u2264 +\u221e, except for 00, (+\u221e)0, 1+\u221e and 1\u2212\u221e, which remain indeterminate forms.
p3618
aVUnder this definition by continuity, we obtain:
p3619
aVThese powers are obtained by taking limits of "x""y" for "positive" values of "x". This method does not permit a definition of "x""y" when "x" < 0, since pairs ("x","y") with "x" < 0 are not accumulation points of "D".
p3620
aVOn the other hand, when "n" is an integer, the power "x""n" is already meaningful for all values of "x", including negative ones. This may make the definition 0"n" = +\u221e obtained above for negative "n" problematic when "n" is odd, since in this case "x""n" \u2192 +\u221e as "x" tends to 0 through positive values, but not negative ones.
p3621
aVEfficient computation with integer exponents.
p3622
aVThe simplest method of computing "b""n" requires multiplication operations, but it can be computed more efficiently than that, as illustrated by the following example. To compute 2100, note that . Compute the following in order:
p3623
aVThis series of steps only requires 8 multiplication operations instead of 99 (since the last product above takes 2 multiplications).
p3624
aVIn general, the number of multiplication operations required to compute
p3625
aV"b""n" can be reduced to \u0398(log "n") by using exponentiation by squaring or (more generally) addition-chain exponentiation. Finding the "minimal" sequence of multiplications (the minimal-length addition chain for the exponent) for "b""n" is a difficult problem for which no efficient algorithms are currently known (see Subset sum problem), but many reasonably efficient heuristic algorithms are available.
p3626
aVExponential notation for function names.
p3627
aVPlacing an integer superscript after the name or symbol of a function, as if the function were being raised to a power, commonly refers to repeated function composition rather than repeated multiplication. Thus "f" 3("x") may mean "f"("f"("f"("x"))); in particular, "f" \u22121("x") usually denotes the inverse function of "f". Iterated functions are of interest in the study of fractals and dynamical systems. Babbage was the first to study the problem of finding a functional square root "f" 1/2("x").
p3628
aVHowever, for historical reasons, a special syntax applies to the trigonometric functions: a positive exponent applied to the function's abbreviation means that the result is raised to that power, while an exponent of \u22121 denotes the inverse function. That is, sin2"x" is just a shorthand way to write (sin "x")2 without using parentheses, whereas sin\u22121"x" refers to the inverse function of the sine, also called arcsin "x". There is no need for a shorthand for the reciprocals of trigonometric functions since each has its own name and abbreviation; for example, 1/(sin "x") = (sin "x")\u22121 = csc "x". A similar convention applies to logarithms, where log2"x" usually means (log "x")2, not log log "x".
p3629
aVGeneralizations.
p3630
aVIn linear algebra.
p3631
aVIn linear algebra "A"0 is defined as "I" for every square matrix "A", and "A""n" is the product formula_84 ("n" factors). Moreover, if "A" is an invertible matrix, then "A"\u2212"n" is defined as ("A"\u22121)"n".
p3632
aVIn abstract algebra.
p3633
aVExponentiation for integer exponents can be defined for quite general structures in abstract algebra.
p3634
aVLet "X" be a set with a power-associative binary operation which is written multiplicatively. Then "x""n" is defined for any element "x" of "X" and any nonzero natural number "n" as the product of "n" copies of "x", which is recursively defined by
p3635
aVformula_44
p3636
aVOne has the following properties
p3637
aVformula_8
p3638
aVIf the operation has a two-sided identity element 1, then "x"0 is defined to be equal to 1 for any "x".
p3639
aVformula_44
p3640
aVIf the operation also has two-sided inverses and multiplication is associative, then the magma is a group. The inverse of "x" can be denoted by "x"\u22121 and follows all the usual rules for exponents.
p3641
aVformula_88
p3642
aVIf the multiplication operation is commutative (as for instance in abelian groups), then the following holds:
p3643
aV formula_89
p3644
aVIf the binary operation is written additively, as it often is for abelian groups, then "exponentiation is repeated multiplication" can be reinterpreted as "multiplication is repeated addition". Thus, each of the laws of exponentiation above has an analogue among laws of multiplication.
p3645
aVWhen one has several operations around, any of which might be repeated using exponentiation, it is common to indicate which operation is being repeated by placing its symbol in the superscript. Thus, "x"\u2217"n" is "x" \u2217 ··· \u2217 "x", while "x"#"n" is "x" # ··· # "x", whatever the operations \u2217 and # might be.
p3646
aVSuperscript notation is also used, especially in group theory, to indicate conjugation. That is, "g""h" = "h"\u22121"gh", where "g" and "h" are elements of some group. Although conjugation obeys some of the same laws as exponentiation, it is not an example of repeated multiplication in any sense. A quandle is an algebraic structure in which these laws of conjugation play a central role.
p3647
aVOver sets.
p3648
aVIf "n" is a natural number and "A" is an arbitrary set, the expression "A""n" is often used to denote the set of ordered "n"-tuples of elements of "A". This is equivalent to letting "A""n" denote the set of functions from the set {0, 1, 2, \u2026, "n"\u22121} to the set "A"; the "n"-tuple ("a"0, "a"1, "a"2, \u2026, a"n"\u22121) represents the function that sends "i" to "a""i".
p3649
aVFor an infinite cardinal number \u03ba and a set "A", the notation "A"\u03ba is also used to denote the set of all functions from a set of size \u03ba to "A". This is sometimes written \u03ba"A" to distinguish it from cardinal exponentiation, defined below.
p3650
aVThis generalized exponential can also be defined for operations on sets or for sets with extra structure. For example, in linear algebra, it makes sense to index direct sums of vector spaces over arbitrary index sets. That is, we can speak of
p3651
aV formula_90
p3652
aVwhere each "V""i" is a vector space.
p3653
aVThen if "V""i" = "V" for each "i", the resulting direct sum can be written in exponential notation as "V"\u2295N, or simply "V"N with the understanding that the direct sum is the default. We can again replace the set N with a cardinal number "n" to get "V""n", although without choosing a specific standard set with cardinality "n", this is defined only up to isomorphism. Taking "V" to be the field R of real numbers (thought of as a vector space over itself) and "n" to be some natural number, we get the vector space that is most commonly studied in linear algebra, the Euclidean space R"n".
p3654
aVIf the base of the exponentiation operation is a set, the exponentiation operation is the Cartesian product unless otherwise stated. Since multiple Cartesian products produce an "n"-tuple, which can be represented by a function on a set of appropriate cardinality, "S""N" becomes simply the set of all functions from "N" to "S" in this case:
p3655
aV formula_91
p3656
aVThis fits in with the exponentiation of cardinal numbers, in the sense that |"S""N"| = |"S"||"N"|, where |"X"| is the cardinality of "X". When "2" is defined as {0, 1}, we have |2"X"| = 2|"X"|, where 2"X", usually denoted by P("X"), is the power set of "X"; each subset "Y" of "X" corresponds uniquely to a function on "X" taking the value 1 for "x" \u2208 "Y" and 0 for "x" \u2209 "Y".
p3657
aVIn category theory.
p3658
aVIn a Cartesian closed category, the exponential operation can be used to raise an arbitrary object to the power of another object. This generalizes the Cartesian product in the category of sets. If 0 is an initial object in a Cartesian closed category, then the exponential object 00 is isomorphic to any terminal object 1.
p3659
aVOf cardinal and ordinal numbers.
p3660
aVIn set theory, there are exponential operations for cardinal and ordinal numbers.
p3661
aVIf \u03ba and \u03bb are cardinal numbers, the expression \u03ba\u03bb represents the cardinality of the set of functions from any set of cardinality \u03bb to any set of cardinality \u03ba. If \u03ba and \u03bb are finite, then this agrees with the ordinary arithmetic exponential operation. For example, the set of 3-tuples of elements from a 2-element set has cardinality 8 = 23. In cardinal arithmetic, \u03ba0 is always 1 (even if \u03ba is an infinite cardinal or zero).
p3662
aVExponentiation of cardinal numbers is distinct from exponentiation of ordinal numbers, which is defined by a limit process involving transfinite induction.
p3663
aVRepeated exponentiation.
p3664
aVJust as exponentiation of natural numbers is motivated by repeated multiplication, it is possible to define an operation based on repeated exponentiation; this operation is sometimes called hyper-4 or tetration. Iterating tetration leads to another operation, and so on, a concept named hyperoperation. This sequence of operations is expressed by the Ackermann function and Knuth's up-arrow notation. Just as exponentiation grows faster than multiplication, which is faster growing than addition, tetration is faster growing than exponentiation. Evaluated at (3,3), the functions addition, multiplication, exponentiation, and tetration yield 6, 9, 27, and 7,625,597,484,987 (327=333=33) respectively.
p3665
aVIn programming languages.
p3666
aVThe superscript notation "x""y" is convenient in handwriting but inconvenient for typewriters and computer terminals that align the baselines of all characters on each line. Many programming languages have alternate ways of expressing exponentiation that do not use superscripts:
p3667
aVMany programming languages lack syntactic support for exponentiation, but provide library functions.
p3668
aVIn Bash, C, C++, C#, Java, JavaScript, Perl, PHP, Python and Ruby, the symbol ^ represents bitwise XOR. In Pascal, it represents indirection. In OCaml and Standard ML, it represents string concatenation.
p3669
aVHistory of the notation.
p3670
aVThe term "power" was used by the Greek mathematician Euclid for the square of a line. Archimedes discovered and proved the law of exponents, 10a 10b = 10a+b, necessary to manipulate powers of 10. In the 9th century, the Persian mathematician Muhammad ibn M\u016bs\u0101 al-Khw\u0101rizm\u012b used the terms "mal" for a square and "kab" for a cube, which later Islamic mathematicians represented in mathematical notation as "m" and "k", respectively, by the 15th century, as seen in the work of Ab\u016b al-Hasan ibn Al\u012b al-Qalas\u0101d\u012b.
p3671
aVIn the late 16th century, Jost Bürgi used Roman Numerals for exponents.
p3672
aVEarly in the 17th century, the first form of our modern exponential notation was introduced by Rene Descartes in his text titled "La Géométrie"; there, the notation is introduced in Book I.
p3673
aVNicolas Chuquet used a form of exponential notation in the 15th century, which was later used by Henricus Grammateus and Michael Stifel in the 16th century. Samuel Jeake introduced the term "indices" in 1696. In the 16th century Robert Recorde used the terms square, cube, zenzizenzic (fourth power), sursolid (fifth), zenzicube (sixth), second sursolid (seventh), and zenzizenzizenzic (eighth). "Biquadrate" has been used to refer to the fourth power as well.
p3674
aVSome mathematicians (e.g., Isaac Newton) used exponents only for powers greater than two, preferring to represent squares as repeated multiplication. Thus they would write polynomials, for example, as "ax" + "bxx" + "cx"3 + "d".
p3675
aVAnother historical synonym, involution, is now rare and should not be confused with its more common meaning.
p3676
asS'Coordinate system'
p3677
(lp3678
V<!--
p3679
aVIn geometry, a coordinate system is a system which uses one or more numbers, or coordinates, to uniquely determine the position of a point or other geometric element on a manifold such as Euclidean space. The order of the coordinates is significant and they are sometimes identified by their position in an ordered tuple and sometimes by a letter, as in "the "x"-coordinate". The coordinates are taken to be real numbers in elementary mathematics, but may be complex numbers or elements of a more abstract system such as a commutative ring. The use of a coordinate system allows problems in geometry to be translated into problems about numbers and "vice versa"; this is the basis of analytic geometry.
p3680
aVCommon coordinate systems.
p3681
aVNumber line.
p3682
aVThe simplest example of a coordinate system is the identification of points on a line with real numbers using the "number line". In this system, an arbitrary point "O" (the "origin") is chosen on a given line. The coordinate of a point "P" is defined as the signed distance from "O" to "P", where the signed distance is the distance taken as positive or negative depending on which side of the line "P" lies. Each point is given a unique coordinate and each real number is the coordinate of a unique point.
p3683
aVCartesian coordinate system.
p3684
aVThe prototypical example of a coordinate system is the Cartesian coordinate system. In the plane, two perpendicular lines are chosen and the coordinates of a point are taken to be the signed distances to the lines. 
p3685
aVIn three dimensions, three perpendicular planes are chosen and the three coordinates of a point are the signed distances to each of the planes. This can be generalized to create "n" coordinates for any point in "n"-dimensional Euclidean space.
p3686
aVDepending on the direction and order of the coordinate axis the system may be a right-hand or a left-hand system.
p3687
aVPolar coordinate system.
p3688
aVAnother common coordinate system for the plane is the "polar coordinate system". A point is chosen as the "pole" and a ray from this point is taken as the "polar axis". For a given angle \u03b8, there is a single line through the pole whose angle with the polar axis is \u03b8 (measured counterclockwise from the axis to the line). Then there is a unique point on this line whose signed distance from the origin is "r" for given number "r". For a given pair of coordinates ("r", \u03b8) there is a single point, but any point is represented by many pairs of coordinates. For example ("r", \u03b8), ("r", \u03b8+2\u03c0) and (\u2212"r", \u03b8+\u03c0) are all polar coordinates for the same point. The pole is represented by (0, \u03b8) for any value of \u03b8. 
p3689
aVCylindrical and spherical coordinate systems.
p3690
aVThere are two common methods for extending the polar coordinate system to three dimensions. In the cylindrical coordinate system, a "z"-coordinate with the same meaning as in Cartesian coordinates is added to the "r" and \u03b8 polar coordinates. Spherical coordinates take this a step further by converting the pair of cylindrical coordinates ("r", "z") to polar coordinates (\u03c1, \u03c6) giving a triple ("\u03c1", "\u03b8", \u03c6).
p3691
aVCylindrical coordinates system have the following coordinates, \u03c1,\u03c6,z
p3692
aVHomogeneous coordinate system.
p3693
aVA point in the plane may be represented in "homogeneous coordinates" by a triple ("x", "y", "z") where "x"/"z" and "y"/"z" are the Cartesian coordinates of the point. This introduces an "extra" coordinate since only two are needed to specify a point on the plane, but this system is useful in that it represents any point on the projective plane without the use of infinity. In general, a homogeneous coordinate system is one where only the ratios of the coordinates are significant and not the actual values.
p3694
aVOther commonly used systems.
p3695
aVSome other common coordinate systems are the following:
p3696
aVorthogonal coordinates
p3697
aVThere are ways of describing curves without coordinates, using intrinsic equations that use invariant quantities such as curvature and arc length. These include:
p3698
aVCoordinates of geometric objects.
p3699
aVCoordinates systems are often used to specify the position of a point, but they may also be used to specify the position of more complex figures such as lines, planes, circles or spheres. For example Plücker coordinates are used to determine the position of a line in space. When there is a need, the type of figure being described is used to distinguish the type of coordinate system, for example the term "line coordinates" is used for any coordinate system that specifies the position of a line.
p3700
aVIt may occur that systems of coordinates for two different sets of geometric figures are equivalent in terms of their analysis. An example of this is the systems of homogeneous coordinates for points and lines in the projective plane. The two systems in a case like this are said to be "dualistic". Dualistic systems have the property that results from one system can be carried over to the other since these results are only different interpretations of the same analytical result; this is known as the "principle of duality".
p3701
aVTransformations.
p3702
aVBecause there are often many different possible coordinate systems for describing geometrical figures, it is important to understand how they are related. Such relations are described by "coordinate transformations" which give formulas for the coordinates in one system in terms of the coordinates in another system. For example, in the plane, if Cartesian coordinates ("x", "y") and polar coordinates ("r", "\u03b8") have the same origin, and the polar axis is the positive "x" axis, then the coordinate transformation from polar to Cartesian coordinates is given by "x" = "r" cos"\u03b8" and "y" = "r" sin"\u03b8".
p3703
aVWith every bijection from the space to itself two coordinate transformations can be associated:
p3704
aVFor example, in 1D, if the mapping is a translation of 3 to the right, the first moves the origin from 0 to 3, so that the coordinate of each point becomes 3 less, while the second moves the origin from 0 to \u22123, so that the coordinate of each point becomes 3 more.
p3705
aVCoordinate curves and surfaces.
p3706
aVIn two dimensions if all but one coordinate in a point coordinate system is held constant and the remaining coordinate is allowed to vary, then the resulting curve is called a coordinate curve (some authors use the phrase "coordinate line"). This procedure does not always make sense, for example there are no coordinate curves in a homogeneous coordinate system. In the Cartesian coordinate system the coordinate curves are, in fact, straight lines. Specifically, they are the lines parallel to one of the coordinate axes. For other coordinate systems the coordinates curves may be general curves. For example the coordinate curves in polar coordinates obtained by holding "r" constant are the circles with center at the origin. Coordinates systems for Euclidean space other than the Cartesian coordinate system are called curvilinear coordinate systems.
p3707
aVIn three-dimensional space, if one coordinate is held constant and the remaining coordinates are allowed to vary, then the resulting surface is called a coordinate surface. For example the coordinate surfaces obtained by holding \u03c1 constant in the spherical coordinate system are the spheres with center at the origin. In three-dimensional space the intersection of two coordinate surfaces is a coordinate curve. Coordinate hypersurfaces are defined similarly in higher dimensions.
p3708
aVCoordinate maps.
p3709
aVThe concept of a "coordinate map", or "chart" is central to the theory of manifolds. A coordinate map is essentially a coordinate system for a subset of a given space with the property that each point has exactly one set of coordinates. More precisely, a coordinate map is a homeomorphism from an open subset of a space "X" to an open subset of R"n". It is often not possible to provide one consistent coordinate system for an entire space. In this case, a collection of coordinate maps are put together to form an atlas covering the space. A space equipped with such an atlas is called a "manifold" and additional structure can be defined on a manifold if the structure is consistent where the coordinate maps overlap. For example a differentiable manifold is a manifold where the change of coordinates from one coordinate map to another is always a differentiable function.
p3710
aVOrientation-based coordinates.
p3711
aVIn geometry and kinematics, coordinate systems are used not only to describe the (linear) position of points, but also to describe the angular position of axes, planes, and rigid bodies. In the latter case, the orientation of a second (typically referred to as "local") coordinate system, fixed to the node, is defined based on the first (typically referred to as "global" or "world" coordinate system). For instance, the orientation of a rigid body can be represented by an orientation matrix, which includes, in its three columns, the Cartesian coordinates of three points. These points are used to define the orientation of the axes of the local system; they are the tips of three unit vectors aligned with those axes.
p3712
asS'Random'
p3713
(lp3714
sS'Linear equation'
p3715
(lp3716
VA linear equation is an algebraic equation in which each term is either a constant or the product of a constant and (the first power of) a single variable.
p3717
aVLinear equations can have one or more variables. Linear equations occur abundantly in most subareas of mathematics and especially in applied mathematics. While they arise quite naturally when modeling many phenomena, they are particularly useful since many non-linear equations may be reduced to linear equations by assuming that quantities of interest vary to only a small extent from some "background" state. Linear equations do not include exponents.
p3718
aVThis article considers the case of a single equation for which one searches the real solutions. All its content applies for complex solutions and, more generally for linear equations with coefficients and solutions in any field.
p3719
aVOne variable.
p3720
aVA linear equation in one unknown "x" may always be rewritten
p3721
aVformula_1
p3722
aVIf "a" \u2260 0, there is a unique solution 
p3723
aVformula_2
p3724
aVIf "a" = 0, then either the equation does not have any solution, if "b" \u2260 0 (it is inconsistent), or every number is a solution, if "b" is also zero.
p3725
aVTwo variables.
p3726
aVA common form of a linear equation in the two variables "x" and "y" is
p3727
aVformula_3
p3728
aVwhere "m" and "b" designate constants (parameters). The origin of the name "linear" comes from the fact that the set of solutions of such an equation forms a straight line in the plane. In this particular equation, the constant "m" determines the slope or gradient of that line, and the constant term "b" determines the point at which the line crosses the "y"-axis, otherwise known as the y-intercept.
p3729
aVSince terms of linear equations cannot contain products of distinct or equal variables, nor any power (other than 1) or other function of a variable, equations involving terms such as "xy", "x"2, "y"1/3, and sin("x") are "nonlinear".
p3730
aVForms for two-dimensional linear equations.
p3731
aVLinear equations can be rewritten using the laws of elementary algebra into several different forms. These equations are often referred to as the "equations of the straight line." In what follows, "x", "y", "t", and "\u03b8" are variables; other letters represent constants (fixed numbers).
p3732
aVGeneral (or standard) form.
p3733
aVIn the general (or standard) form the linear equation is written as:
p3734
aV formula_4
p3735
aVwhere "A" and "B" are not both equal to zero. The equation is usually written so that "A" \u2265 0, by convention. The graph of the equation is a straight line, and every straight line can be represented by an equation in the above form. If "A" is nonzero, then the "x"-intercept, that is, the "x"-coordinate of the point where the graph crosses the "x"-axis (where, "y" is zero), is "C"/"A". If "B" is nonzero, then the "y"-intercept, that is the "y"-coordinate of the point where the graph crosses the "y"-axis (where x is zero), is "C"/"B", and the slope of the line is \u2212"A"/"B". The general form is sometimes written as:
p3736
aV formula_5
p3737
aVwhere "a" and "b" are not both equal to zero. The two versions can be converted from one to the other by moving the constant term to the other side of the equal sign.
p3738
aVformula_6
p3739
aVSlope\u2013intercept form.
p3740
aVwhere "m" is the slope of the line and "b" is the "y" intercept, which is the "y" coordinate of the location where the line crosses the "y" axis. This can be seen by letting "x" = 0, which immediately gives "y" = "b". It may be helpful to think about this in terms of "y" = "b" + "mx"; where the line passes through the point (0, "b") and extends to the left and right at a slope of "m". Vertical lines, having undefined slope, cannot be represented by this form.
p3741
aVformula_7
p3742
aVPoint\u2013slope form.
p3743
aVwhere "m" is the slope of the line and ("x"1,"y"1) is any point on the line.
p3744
aVThe point-slope form expresses the fact that the difference in the "y" coordinate between two points on a line (that is, "y" \u2212 "y"1) is proportional to the difference in the "x" coordinate (that is, "x" \u2212 "x"1). The proportionality constant is "m" (the slope of the line).
p3745
aVformula_8
p3746
aVTwo-point form.
p3747
aVwhere ("x"1, "y"1) and ("x"2, "y"2) are two points on the line with "x"2 \u2260 "x"1. This is equivalent to the point-slope form above, where the slope is explicitly given as ("y"2 \u2212 "y"1)/("x"2 \u2212 "x"1).
p3748
aVMultiplying both sides of this equation by ("x"2 \u2212 "x"1) yields a form of the line generally referred to as the symmetric form:
p3749
aVformula_9
p3750
aVExpanding the products and regrouping the terms leads to the general form:
p3751
aVformula_10
p3752
aVUsing a determinant, one gets a determinant form, easy to remember:
p3753
aVformula_11
p3754
aV formula_12
p3755
aVIntercept form.
p3756
aVwhere "a" and "b" must be nonzero. The graph of the equation has "x"-intercept "a" and "y"-intercept "b". The intercept form is in standard form with "A"/"C" = 1/"a" and "B"/"C" = 1/"b". Lines that pass through the origin or which are horizontal or vertical violate the nonzero condition on "a" or "b" and cannot be represented in this form.
p3757
aVMatrix form.
p3758
aVUsing the order of the standard form
p3759
aV formula_13
p3760
aVone can rewrite the equation in matrix form:
p3761
aVformula_14
p3762
aVFurther, this representation extends to systems of linear equations.
p3763
aV formula_15
p3764
aV formula_16
p3765
aVbecomes:
p3766
aVformula_17
p3767
aVSince this extends easily to higher dimensions, it is a common representation in linear algebra, and in computer programming. There are named methods for solving system of linear equations, like Gauss-Jordan which can be expressed as matrix elementary row operations.
p3768
aVformula_18
p3769
aVParametric form.
p3770
aVand
p3771
aVformula_19
p3772
aVTwo simultaneous equations in terms of a variable parameter "t", with slope , "x"-intercept and "y"-intercept .
p3773
aVThis can also be related to the two-point form, where , "U" = "h", , and "W" = "k":
p3774
aVformula_20
p3775
aVand
p3776
aVformula_21
p3777
aVIn this case "t" varies from 0 at point ("h","k") to 1 at point ("p","q"), with values of "t" between 0 and 1 providing interpolation and other values of "t" providing extrapolation.
p3778
aV2D vector determinant form.
p3779
aVThe equation of a line can also be written as the determinant of two vectors. If formula_22 and formula_23 are unique points on the line, then formula_24 will also be a point on the line if the following is true:
p3780
aV formula_25
p3781
aVOne way to understand this formula is to use the fact that the determinant of two vectors on the plane will give the area of the parallelogram they form. Therefore, if the determinant equals zero then the parallelogram has no area, and that will happen when two vectors are on the same line.
p3782
aVTo expand on this we can say that formula_26, formula_27 and formula_28. Thus formula_29 and formula_30, then the above equation becomes:
p3783
aVformula_31
p3784
aVThus, 
p3785
aVformula_32
p3786
aVErgo,
p3787
aVformula_33
p3788
aVThen dividing both side by formula_34 would result in the \u201cTwo-point form\u201d shown above, but leaving it here allows the equation to still be valid when formula_35.
p3789
aV formula_36
p3790
aVSpecial cases.
p3791
aVThis is a special case of the standard form where "A" = 0 and "B" = 1, or of the slope-intercept form where the slope "m" = 0. The graph is a horizontal line with "y"-intercept equal to "b". There is no "x"-intercept, unless "b" = 0, in which case the graph of the line is the "x"-axis, and so every real number is an "x"-intercept.
p3792
aV formula_37
p3793
aVThis is a special case of the standard form where "A" = 1 and "B" = 0. The graph is a vertical line with "x"-intercept equal to "a". The slope is undefined. There is no "y"-intercept, unless "a" = 0, in which case the graph of the line is the "y"-axis, and so every real number is a "y"-intercept. This is the only type of line which is not the graph of a function (it obviously fails the vertical line test).
p3794
aVConnection with linear functions.
p3795
aVA linear equation, written in the form "y" = "f"("x") whose graph crosses the origin ("x","y") = (0,0), that is, whose "y"-intercept is 0, has the following properties:
p3796
aVformula_38
p3797
aVand
p3798
aVformula_39
p3799
aVwhere "a" is any scalar. A function which satisfies these properties is called a "linear function" (or "linear operator", or more generally a "linear map"). However, linear equations that have non-zero "y"-intercepts, when written in this manner, produce functions which will have neither property above and hence are not linear functions in this sense. They are known as affine functions.
p3800
aVExamples.
p3801
aVAn everyday example of the use of different forms of linear equations is computation of tax with tax brackets. This is commonly done using either point\u2013slope form or slope\u2013intercept form; see Progressive tax#Computation for details.
p3802
aVMore than two variables.
p3803
aVA linear equation can involve more than two variables. Every linear equation in "n" unknowns may be rewritten 
p3804
aVformula_40
p3805
aVwhere, "a"1, "a"2, ..., "a""n" represent numbers, called the "coefficients", "x"1, "x"2, ..., "x""n" are the unknowns, and "b" is called the "constant term". When dealing with three or fewer variables, it is common to use "x", "y" and "z" instead of "x"1, "x"2 and "x"3.
p3806
aVIf all the coefficients are zero, then either "b" \u2260 0 and the equation does not have any solution, or "b" = 0 and every set of values for the unknowns is a solution.
p3807
aVIf at least one coefficient is nonzero, a permutation of the subscripts allows to suppose "a"1 \u2260 0, and rewrite the equation
p3808
aVformula_41
p3809
aVIn other words, if "a""i" \u2260 0, one may choose arbitrary values for all the unknowns except "x""i", and express "x""i" in term of these values.
p3810
aVIf "n" = 3 the set of the solutions is a plane in a three-dimensional space. More generally, the set of the solutions is an ("n" \u2013 1)-dimensional hyperplane in a "n"-dimensional Euclidean space (or affine space if the coefficients are complex numbers or belong to any field).
p3811
asS'Unit circle'
p3812
(lp3813
VIn mathematics, a unit circle is a circle with a radius of one. Frequently, especially in trigonometry, the unit circle is the circle of radius one centered at the origin (0, 0) in the Cartesian coordinate system in the Euclidean plane. The unit circle is often denoted "S"1; the generalization to higher dimensions is the unit sphere.
p3814
aVIf ("x", "y") is a point on the unit circle's circumference, then |"x"| and |"y"| are the lengths of the legs of a right triangle whose hypotenuse has length 1. Thus, by the Pythagorean theorem, "x" and "y" satisfy the equation
p3815
aVformula_1
p3816
aVSince "x"² = (\u2212"x")² for all "x", and since the reflection of any point on the unit circle about the "x"- or "y"-axis is also on the unit circle, the above equation holds for all points ("x", "y") on the unit circle, not only those in the first quadrant.
p3817
aVThe interior of the unit circle is called the open unit disk, while the interior of the unit circle combined with the unit circle itself is called the closed unit disk.
p3818
aVOne may also use other notions of "distance" to define other "unit circles", such as the Riemannian circle; see the article on mathematical norms for additional examples.
p3819
aVIn the complex plane.
p3820
aVThe unit circle can be considered as the unit complex numbers, i.e., the set of complex numbers "z" of the form 
p3821
aVformula_2
p3822
aVfor all "t". This relation is Euler's formula.
p3823
aVIn quantum mechanics, this is referred to as phase factor.
p3824
aVTrigonometric functions on the unit circle.
p3825
aVThe trigonometric functions cosine and sine of angle t (t for \u03b8, theta) may be defined on the unit circle as follows: If ("x", "y") is a point on the unit circle, and if the ray from the origin (0, 0) to ("x", "y") makes an angle "t" from the positive "x"-axis, (where counterclockwise turning is positive), then
p3826
aVformula_3
p3827
aVformula_4
p3828
aVThe equation "x"2 + "y"2 = 1 gives the relation
p3829
aVformula_5
p3830
aVThe unit circle also demonstrates that sine and cosine are periodic functions, with the identities
p3831
aVformula_6
p3832
aVformula_7
p3833
aVfor any integer "k".
p3834
aVTriangles constructed on the unit circle can also be used to illustrate the periodicity of the trigonometric functions. First, construct a radius OA from the origin to a point P("x"1,"y"1) on the unit circle such that an angle "t" with 0 < "t" < \u03c0/2 is formed with the positive arm of the "x"-axis. Now consider a point Q("x"1,0) and line segments PQ formula_8 OQ. The result is a right triangle \u0394OPQ with \u2220QOP = "t". Because PQ has length "y"1, OQ length "x"1, and OA length 1, sin("t") = "y"1 and cos("t") = "x"1. Having established these equivalences, take another radius OR from the origin to a point R(\u2212"x"1,"y"1) on the circle such that the same angle "t" is formed with the negative arm of the "x"-axis. Now consider a point S("\u2212x1",0) and line segments RS formula_8 OS. The result is a right triangle \u0394ORS with \u2220SOR = "t". It can hence be seen that, because \u2220ROQ = \u03c0\u2212"t", R is at (cos(\u03c0\u2212"t"),sin(\u03c0\u2212"t")) in the same way that P is at (cos("t"),sin("t")). The conclusion is that, since (\u2212"x"1,"y"1) is the same as (cos(\u03c0\u2212"t"),sin(\u03c0\u2212"t")) and ("x"1,"y"1) is the same as (cos("t"),sin("t")), it is true that sin("t") = sin(\u03c0\u2212"t") and \u2212cos("t") = cos(\u03c0\u2212"t"). It may be inferred in a similar manner that tan(\u03c0\u2212"t") = \u2212tan("t"), since tan("t") = "y"1/"x"1 and tan(\u03c0\u2212"t") = "y"1/(\u2212"x"1). A simple demonstration of the above can be seen in the equality sin(\u03c0/4) = sin(3\u03c0/4) = 1/sqrt(2).
p3835
aVWhen working with right triangles, sine, cosine, and other trigonometric functions only make sense for angle measures more than zero and less than \u03c0/2. However, when defined with the unit circle, these functions produce meaningful values for any real-valued angle measure \u2013 even those greater than 2\u03c0. In fact, all six standard trigonometric functions \u2013 sine, cosine, tangent, cotangent, secant, and cosecant, as well as archaic functions like versine and exsecant \u2013 can be defined geometrically in terms of a unit circle, as shown at right.
p3836
aVUsing the unit circle, the values of any trigonometric function for many angles other than those labeled can be calculated without the use of a calculator by using the Sum and Difference Formulas.
p3837
aVCircle group.
p3838
aVComplex numbers can be identified with points in the Euclidean plane, namely the number "a" + "bi" is identified with the point ("a", "b"). Under this identification, the unit circle is a group under multiplication, called the circle group. On the plane multiplication by formula_10 gives a counterclockwise rotation by \u03b8. This group has important applications in mathematics and science.
p3839
aVComplex dynamics.
p3840
aVJulia set of discrete nonlinear dynamical system with evolution function:
p3841
aVformula_11
p3842
aVis a unit circle. It is a simplest case so it is widely used in study of dynamical systems.
p3843
asS'Real analysis'
p3844
(lp3845
VReal analysis (traditionally, the theory of functions of a real variable) is a branch of mathematical analysis dealing with the real numbers and real-valued functions of a real variable. In particular, it deals with the analytic properties of real functions and sequences, including convergence and limits of sequences of real numbers, the calculus of the real numbers, and continuity, smoothness and related properties of real-valued functions.
p3846
aVScope.
p3847
aVConstruction of the real numbers.
p3848
aVThere are several ways of defining the real number system as an ordered field. The "synthetic" approach gives a list of axioms for the real numbers as a "complete ordered field". Under the usual axioms of set theory, one can show that these axioms are categorical, in the sense that there is a model for the axioms, and any two such models are isomorphic. Any one of these models must be explicitly constructed, and most of these models are built using the basic properties of the rational number system as an ordered field. These constructions are described in more detail in the main article.
p3849
aVOrder properties of the real numbers.
p3850
aVThe real numbers have several important lattice-theoretic properties that are absent in the complex numbers. Most importantly, the real numbers form an ordered field, in which addition and multiplication preserve positivity. Moreover, the ordering of the real numbers is total, and the real numbers have the least upper bound property. These order-theoretic properties lead to a number of important results in real analysis, such as the monotone convergence theorem, the intermediate value theorem and the mean value theorem.
p3851
aVHowever, while the results in real analysis are stated for real numbers, many of these results can be generalized to other mathematical objects. In particular, many ideas in functional analysis and operator theory generalize properties of the real numbers \u2013 such generalizations include the theories of Riesz spaces and positive operators. Also, mathematicians consider real and imaginary parts of complex sequences, or by pointwise evaluation of operator sequences.
p3852
aVSequences.
p3853
aVA sequence is usually defined as a function whose domain is a countable totally ordered set, although in many disciplines the domain is restricted, such as to the natural numbers. In real analysis a sequence is a function from a subset of the natural numbers to the real numbers. In other words, a sequence is a map "f"("n") : N \u2192 R. We might identify "an" = "f"("n") for all "n" or just write "an" : N \u2192 R.
p3854
aVLimits.
p3855
aVA limit is the value that a function or sequence "approaches" as the input or index approaches some value. Limits are essential to calculus (and mathematical analysis in general) and are used to define continuity, derivatives, and integrals.
p3856
aVContinuity.
p3857
aVA function from the set of real numbers to the real numbers can be represented by a graph in the Cartesian plane; such a function is continuous if, roughly speaking, the graph is a single unbroken curve with no "holes" or "jumps".
p3858
aVThere are several ways to make this intuition mathematically rigorous. These definitions are equivalent to one another, so the most convenient definition can be used to determine whether a given function is continuous or not. In the definitions below, 
p3859
aVformula_1
p3860
aVis a function defined on a subset "I" of the set R of real numbers. This subset "I" is referred to as the domain of "f". Some possible choices include "I"=R, the whole set of real numbers, an open interval
p3861
aVformula_2
p3862
aVor a closed interval
p3863
aVformula_3
p3864
aVHere, "a" and "b" are real numbers.
p3865
aVUniform continuity.
p3866
aVIf "X" and "Y" are subsets of the real numbers, a function "f" : "X" \u2192 "Y" is called uniformly continuous if for all "\u03b5" > 0 there exists a "\u03b4" > 0 such that for all "x", "y" \u2208 "X", |"x" \u2212 "y"| < "\u03b4" implies |"f"("x") \u2212 "f"("y")| < "\u03b5.
p3867
aVThe difference between being uniformly continuous, and being simply continuous at every point, is that in uniform continuity the value of "\u03b4" depends only on "\u03b5" and not on the point in the domain.
p3868
aVAbsolute continuity.
p3869
aVLet formula_4 be an interval in the real line R. A function formula_5 is absolutely continuous on formula_4 if for every positive number formula_7, there is a positive number formula_8 such that whenever a finite sequence of pairwise disjoint sub-intervals formula_9 of formula_4 satisfies
p3870
aVformula_11
p3871
aVthen
p3872
aVformula_12
p3873
aVThe collection of all absolutely continuous functions on "I" is denoted AC("I").
p3874
aVThe following conditions on a real-valued function "f" on a compact interval ["a","b"] are equivalent:
p3875
aV(1) "f" is absolutely continuous;
p3876
aV(2) "f" has a derivative "f" \u2032 almost everywhere, the derivative is Lebesgue integrable, and
p3877
aV: formula_13
p3878
aVfor all "x" on ["a","b"];
p3879
aV(3) there exists a Lebesgue integrable function "g" on ["a","b"] such that
p3880
aV: formula_14
p3881
aVfor all "x" on ["a","b"].
p3882
aVIf these equivalent conditions are satisfied then necessarily "g" = "f" \u2032 almost everywhere.
p3883
aVEquivalence between (1) and (3) is known as the fundamental theorem of Lebesgue integral calculus, due to Lebesgue.
p3884
aVSeries.
p3885
aVGiven an infinite sequence of numbers { "a""n" }, a series is informally the result of adding all those terms together: "a"1 + "a"2 + "a"3 + · · ·. These can be written more compactly using the summation symbol \u2211. An example is the famous series from Zeno's dichotomy and its mathematical representation:
p3886
aVformula_15
p3887
aVThe terms of the series are often produced according to a certain rule, such as by a formula, or by an algorithm.
p3888
aVTaylor series.
p3889
aVThe Taylor series of a real or complex-valued function "\u0192"("x") that is infinitely differentiable at a real or complex number "a" is the power series
p3890
aVformula_16
p3891
aVwhich can be written in the more compact sigma notation as
p3892
aVformula_17
p3893
aVwhere "n"! denotes the factorial of "n" and "\u0192" ("n")("a") denotes the "n"th derivative of "\u0192" evaluated at the point "a". The derivative of order zero "\u0192" is defined to be "\u0192" itself and and 0! are both defined to be 1. In the case that , the series is also called a Maclaurin series.
p3894
aVFourier Series.
p3895
aVA Fourier series decomposes periodic functions or periodic signals into the sum of a (possibly infinite) set of simple oscillating functions, namely sines and cosines (or complex exponentials). The study of Fourier series is a branch of Fourier analysis.
p3896
aVDifferentiation.
p3897
aVFormally, the derivative of the function "f" at "a" is the limit
p3898
aVformula_18
p3899
aVIf the derivative exists everywhere, the function is differentiable. One can take higher derivatives as well, by iterating this process.
p3900
aVOne can classify functions by their differentiability class. The class "C"0 consists of all continuous functions. The class "C"1 consists of all differentiable functions whose derivative is continuous; such functions are called continuously differentiable. Thus, a "C"1 function is exactly a function whose derivative exists and is of class "C"0. In general, the classes "Ck" can be defined recursively by declaring "C"0 to be the set of all continuous functions and declaring "Ck" for any positive integer "k" to be the set of all differentiable functions whose derivative is in "C""k"\u22121. In particular, "Ck" is contained in "C""k"\u22121 for every "k", and there are examples to show that this containment is strict. "C"\u221e is the intersection of the sets "Ck" as "k" varies over the non-negative integers. "C"\u03c9 is strictly contained in "C"\u221e.
p3901
aVIntegration.
p3902
aVRiemann integration.
p3903
aVThe Riemann integral is defined in terms of Riemann sums of functions with respect to "tagged partitions" of an interval. Let ["a","b"] be a closed interval of the real line; then a "tagged partition" of ["a","b"] is a finite sequence
p3904
aVformula_19
p3905
aVThis partitions the interval ["a","b"] into "n" sub-intervals indexed by "i", each of which is "tagged" with a distinguished point . A "Riemann sum" of a function "f" with respect to such a tagged partition is defined as
p3906
aVformula_20
p3907
aVthus each term of the sum is the area of a rectangle with height equal to the function value at the distinguished point of the given sub-interval, and width the same as the sub-interval width. Let be the width of sub-interval "i"; then the "mesh" of such a tagged partition is the width of the largest sub-interval formed by the partition, . The "Riemann integral" of a function "f" over the interval ["a","b"] is equal to "S" if:
p3908
aVFor all there exists such that, for any tagged partition ["a","b"] with mesh less than \u03b4, we have
p3909
aV:formula_21
p3910
aVWhen the chosen tags give the maximum (respectively, minimum) value of each interval, the Riemann sum becomes an upper (respectively, lower) Darboux sum, suggesting the close connection between the Riemann integral and the Darboux integral.
p3911
aVLebesgue integration.
p3912
aVLebesgue integration is a mathematical construction that extends the integral to a larger class of functions; it also extends the domains on which these functions can be defined.
p3913
aVDistributions.
p3914
aVDistributions (or generalized functions) are objects that generalize functions. Distributions make it possible to differentiate functions whose derivatives do not exist in the classical sense. In particular, any locally integrable function has a distributional derivative. 
p3915
aVRelation to complex analysis.
p3916
aVReal analysis is an area of analysis that studies concepts such as sequences and their limits, continuity, differentiation, integration and sequences of functions. By definition, real analysis focuses on the real numbers, often including positive and negative infinity to form the extended real line. Real analysis is closely related to complex analysis, which studies broadly the same properties of complex numbers. In complex analysis, it is natural to define differentiation via holomorphic functions, which have a number of useful properties, such as repeated differentiability, expressability as power series, and satisfying the Cauchy integral formula.
p3917
aVIn real analysis, it is usually more natural to consider differentiable, smooth, or harmonic functions, which are more widely applicable, but may lack some more powerful properties of holomorphic functions. However, results such as the fundamental theorem of algebra are simpler when expressed in terms of complex numbers.
p3918
aVTechniques from the theory of analytic functions of a complex variable are often used in real analysis \u2013 such as evaluation of real integrals by residue calculus.
p3919
aVImportant results.
p3920
aVImportant results include the Bolzano\u2013Weierstrass and Heine\u2013Borel theorems, the intermediate value theorem and mean value theorem, the fundamental theorem of calculus, and the monotone convergence theorem.
p3921
aVVarious ideas from real analysis can be generalized from real space to general metric spaces, as well as to measure spaces, Banach spaces, and Hilbert spaces.
p3922
asS'Pi Day'
p3923
(lp3924
VPi Day is an annual celebration of the mathematical constant (pi). Pi Day is observed on March 14 (3/14 in the "month/day" date format) since 3, 1, and 4 are the first three significant digits of . In 2009, the United States House of Representatives supported the designation of Pi Day.
p3925
aVPi Approximation Day is observed on July 22 (22/7 in the "day/month" date format), since the fraction is a common approximation of , which is accurate to two decimal places and dates from Archimedes.
p3926
aVHistory.
p3927
aVThe earliest known official or large-scale celebration of Pi Day was organized by Larry Shaw in 1988 at the San Francisco Exploratorium, where Shaw worked as a physicist, with staff and public marching around one of its circular spaces, then consuming fruit pies. The Exploratorium continues to hold Pi Day celebrations.
p3928
aVOn March 12, 2009, the U.S. House of Representatives passed a non-binding resolution (), recognizing March 14, 2009 as National Pi Day.
p3929
aVFor Pi Day 2010, Google presented a Google Doodle celebrating the holiday, with the word Google laid over images of circles and pi symbols.
p3930
aVThe entire month of March 2014 (3/14) was observed by some as "Pi Month".
p3931
aVIn the year 2015, Pi Day had special significance on 3/14/15 ("mm/dd/yy" date format) at 9:26:53 a.m. and also at p.m., with the date and time representing the first 10 digits of . That same second also contained a precise instant corresponding to "all" of the digits of .
p3932
aVObservance.
p3933
aVPi Day has been observed in many ways, including eating pie, throwing pies and discussing the significance of the number , due to a pun based on the words "pi" and "pie" being homophones in English (), as well as pies tending to be round, and thus related to . Some schools hold competitions as to which student can recall pi to the highest number of decimal places.
p3934
aVMassachusetts Institute of Technology has often mailed its application decision letters to prospective students for delivery on Pi Day. Starting in 2012, MIT has announced it will post those decisions (privately) online on Pi Day at exactly 6:28 pm, which they have called "Tau Time", to honor the rival numbers pi and tau equally. In 2015, the regular decisions were put online at 9:26 AM, following that year's "pi moment".
p3935
aVThe town of Princeton, New Jersey, hosts numerous events in a combined celebration of Pi Day and Albert Einstein's birthday, which is also March 14. Einstein lived in Princeton for more than twenty years while working at the Institute for Advanced Study. In addition to pie eating and recitation contests, there is an annual Einstein look-alike contest.
p3936
asS'Currying'
p3937
(lp3938
VIn mathematics and computer science, currying is the technique of translating the evaluation of a function that takes multiple arguments (or a tuple of arguments) into evaluating a sequence of functions, each with a single argument (partial application). It was introduced by Moses Schönfinkel
p3939
aVand later developed by Haskell Curry.
p3940
aVUncurrying is the dual transformation to currying, and can be seen as a form of defunctionalization. It takes a function "f"(x) which returns another function "g"(y) as a result, and yields a new function which takes a number of additional parameters and applies them to the function returned by function "f". The process can be iterated if necessary.
p3941
aVMotivation.
p3942
aVCurrying is similar to the process of calculating a function of multiple variables for some given values on paper.
p3943
aVFor example, given the function formula_1:
p3944
aVTo evaluate formula_2, first replace formula_3 with formula_4
p3945
aVSince the result is a function of formula_5, this new function formula_6 can be defined as formula_7
p3946
aVNext, replace the formula_5 argument with formula_9, producing formula_10
p3947
aVOn paper, using classical notation, this is usually done all in one step. However, each argument can be replaced sequentially as well. Each replacement results in a function taking exactly one argument. This produces a chain of functions as in lambda calculus, and multi-argument functions are usually represented in curried form.
p3948
aVSome programming languages almost always use curried functions to achieve multiple arguments; notable examples are ML and Haskell, where in both cases all functions have exactly one argument.
p3949
aVIf we let "f" be a function
p3950
aVformula_11
p3951
aVthen the function "h" where
p3952
aVformula_12
p3953
aVis a curried version of formula_13. Here, formula_14 is a function that maps an argument "y" to result "z". In particular,
p3954
aVformula_15
p3955
aVis the curried equivalent of the example above. Note, however, that currying, while similar, is not the same operation as partial function application.
p3956
aVDefinition.
p3957
aVGiven a function formula_16 of type formula_17, currying it makes a function formula_18. That is, formula_19 takes an argument of type formula_20 and returns a function of type formula_21. Uncurrying is the reverse transformation, and is most easily understood in terms of its right adjoint, apply.
p3958
aVThe \u2192 operator is often considered right-associative, so the curried function type formula_22 is often written as formula_23. Conversely, function application is considered to be left-associative, so that formula_24 is equivalent to formula_25.
p3959
aVCurried functions may be used in any language that supports closures; however, uncurried functions are generally preferred for efficiency reasons, since the overhead of partial application and closure creation can then be avoided for most function calls.
p3960
aVMathematical view.
p3961
aVIn theoretical computer science, currying provides a way to study functions with multiple arguments in very simple theoretical models such as the lambda calculus in which functions only take a single argument.
p3962
aVIn a set-theoretic paradigm, currying is the natural correspondence between the set formula_26 of functions from formula_27 to formula_28, and the set formula_29 of functions from formula_30 to the set of functions from formula_31 to formula_32. In category theory, currying can be found in the universal property of an exponential object, which gives rise to the following adjunction in cartesian closed categories: There is a natural isomorphism between the morphisms from a binary product formula_17 and the morphisms to an exponential object formula_34. In other words, currying is the statement that product and Hom are adjoint functors; that is, there is a natural transformation: 
p3963
aVformula_35
p3964
aVThis is the key property of being a Cartesian closed category, and more generally, a closed monoidal category. The latter, though more rarely discussed, is interesting, as it is the suitable setting for quantum computation,
p3965
aVUnder the Curry\u2013Howard correspondence, the existence of currying and uncurrying is equivalent to the logical theorem formula_36, as tuples (product type) corresponds to conjunction in logic, and function type corresponds to implication.
p3966
aVCurry is a continuous function in the Scott topology.
p3967
aVNaming.
p3968
aVThe name "currying", coined by Christopher Strachey in 1967, is a reference to logician Haskell Curry. The alternative name "Schönfinkelisation" has been proposed as a reference to Moses Schönfinkel.
p3969
aVContrast with partial function application.
p3970
aVCurrying and partial function application are often conflated. One of the significant differences between the two is that a call to a partially applied function returns the result right away, not another function down the currying chain; this distinction can be illustrated clearly for functions whose arity is greater than two.
p3971
aVGiven a function of type formula_37, currying produces formula_38. That is, while an evaluation of the first function might be represented as formula_39, evaluation of the curried function would be represented as formula_40, applying each argument in turn to a single-argument function returned by the previous invocation. Note that after calling formula_41, we are left with a function that takes a single argument and returns another function, not a function that takes two arguments.
p3972
aVIn contrast, partial function application refers to the process of fixing a number of arguments to a function, producing another function of smaller arity. Given the definition of formula_16 above, we might fix (or 'bind') the first argument, producing a function of type formula_43. Evaluation of this function might be represented as formula_44. Note that the result of partial function application in this case is a function that takes two arguments.
p3973
aVIntuitively, partial function application says "if you fix the first arguments of the function, you get a function of the remaining arguments". For example, if function "div" stands for the division operation "x"/"y", then "div" with the parameter "x" fixed at 1 (i.e., "div" 1) is another function: the same as the function "inv" that returns the multiplicative inverse of its argument, defined by "inv"("y") = 1/"y".
p3974
aVThe practical motivation for partial application is that very often the functions obtained by supplying some but not all of the arguments to a function are useful; for example, many languages have a function or operator similar to codice_1. Partial application makes it easy to define these functions, for example by creating a function that represents the addition operator with 1 bound as its first argument.
p3975
asS'Function composition'
p3976
(lp3977
VIn mathematics, function composition is the pointwise application of one function to the result of another to produce a third function. For instance, the functions and can be "composed" to yield a function which maps in to in . Intuitively, if is a function of , and is a function of , then is a function of . The resulting "composite" function is denoted , defined by for all in .
p3978
aVThe notation is read as " circle ", or " round ", or " composed with ", " after ", " following ", or " of ". Intuitively, composing two functions is a chaining process in which the output of the first function becomes the input of the second function.
p3979
aVThe composition of functions is just a particularization of the composition of relations, so all properties of the latter operation also transfer to the composition of functions. The composition of function has some additional properties however.
p3980
aV, and 
p3981
aVProperties.
p3982
aVThe composition of functions is always associative\u2014a property inherited from the composition of relations. That is, if , , and are three functions with suitably chosen domains and codomains, then , where the parentheses serve to indicate that composition is to be performed first for the parenthesized functions. Since there is no distinction between the choices of placement of parentheses, they may be left off without causing any ambiguity.
p3983
aVIn a strict sense, the composition can be built only if 's codomain equals 's domain; in a wider sense it is sufficient that the former is a subset of the latter.
p3984
aVMoreover, it is often convenient to tacitly restrict 's domain such that produces only values in 's domain; for example, the composition of the functions defined by and defined by can be defined on the interval .
p3985
aVThe functions and are said to commute with each other if . In general, composition of functions will not be commutative. Commutativity is a special property, attained only by particular functions, and often in special circumstances. For example, only when . The picture shows another example.
p3986
aVThe composition of one-to-one functions is always one-to-one. Similarly, the composition of two onto functions is always onto. It follows that composition of two bijections is also a bijection. The inverse function of a composition (assumed invertible) has the property that .
p3987
aVDerivatives of compositions involving differentiable functions can be found using the chain rule. Higher derivatives of such functions are given by Faà di Bruno's formula.
p3988
aVComposition monoids.
p3989
aVSuppose one has two (or more) functions having the same domain and codomain; these are often called "transformation"s. Then one can form chains of transformations composed together, such as . Such chains have the algebraic structure of a monoid, called a transformation monoid or (much more seldom) "composition monoid". In general, transformation monoids can have remarkably complicated structure. One particular notable example is the de Rham curve. The set of "all" functions is called the full transformation semigroup or "symmetric semigroup" on . (One can actually define two semigroups depending how one defines the semigroup operation as the left or right composition of functions.)
p3990
aVIf the transformation are bijective (and thus invertible), then the set of all possible combinations of these functions forms a transformation group; and one says that the group is generated by these functions. A fundamental result in group theory, Cayley's theorem, essentially says that any group is in fact just a group of permutations (up to isomorphism).
p3991
aVThe set of all bijective functions (called permutations) forms a group with respect to the composition operator. This is the symmetric group, also sometimes called the "composition group".
p3992
aVIn the symmetric semigroup (of all transformations) one also finds a weaker, non-unique notion of inverse (called a pseudoinverse) because the symmetric semigroup is a regular semigroup.
p3993
aVFunctional powers.
p3994
aVIf , then may compose with itself; this is sometimes denoted as . That is:
p3995
aVMore generally, for any natural number , the th functional power can be defined inductively by . Repeated composition of such a function with itself is called iterated function.
p3996
aVNote: If takes its values in a ring (in particular for real or complex-valued ), there is a risk of confusion, as could also stand for the -fold product of , e.g. . For trigonometric functions, usually the latter is meant, at least for positive exponents. For example, in trigonometry, this superscript notation represents standard exponentiation when used with trigonometric functions:
p3997
aVHowever, for negative exponents (especially \u22121), it nevertheless usually refers to the inverse function, e.g., .
p3998
aVIn some cases, when, for a given function , the equation has a unique solution , that function can be defined as the functional square root of , then written as .
p3999
aVMore generally, when has a unique solution for some natural number , then can be defined as .
p4000
aVUnder additional restrictions, this idea can be generalized so that the iteration count becomes a continuous parameter; in this case, such a system is called a flow, specified through solutions of Schröder's equation. Iterated functions and flows occur naturally in the study of fractals and dynamical systems.
p4001
aVAlternative notations.
p4002
aVMany mathematicians, particularly in group theory, omit the composition symbol, writing for .
p4003
aVIn the mid-20th century, some mathematicians decided that writing "" to mean "first apply , then apply " was too confusing and decided to change notations. They write for and for . This can be more natural and seem simpler than writing functions on the left in some areas \u2013 in linear algebra, for instance, when is a row vector and and denote matrices and the composition is by matrix multiplication. This alternative notation is called postfix notation. The order is important because matrix multiplication is non-commutative. Successive transformations applying and composing to the right agrees with the left-to-right reading sequence.
p4004
aVMathematicians who use postfix notation may write , meaning first apply and then apply , in keeping with the order the symbols occur in postfix notation, thus making the notation ambiguous. Computer scientists may write "" for this, thereby disambiguating the order of composition. To distinguish the left composition operator from a text semicolon, in the Z notation the \u2a3e character is used for left relation composition. Since all functions are binary relations, it is correct to use the semicolon for function composition as well (see the article on composition of relations for further details on this notation).
p4005
aVComposition operator.
p4006
aVGiven a function , the composition operator is defined as that operator which maps functions to functions as
p4007
aV:formula_1
p4008
aVComposition operators are studied in the field of operator theory.
p4009
aVIn programming languages.
p4010
aVFunction composition appears in one form or another in numerous programming languages.
p4011
aVMultivariate functions.
p4012
aVPartial composition is possible for multivariate functions. The function resulting when some argument of the function is replaced by the function is called a composition of and in some computer engineering contexts, and is denoted 
p4013
aVformula_2
p4014
aVWhen is a simple constant , composition degenerates into a (partial) valuation, whose result is also known as restriction or "co-factor".
p4015
aVformula_3
p4016
aVIn general, the composition of multivariate functions may involve several other functions as arguments, as in the definition of primitive recursive function. Given , a -ary function, and -ary functions , the composition of with , is the -ary function
p4017
aVformula_4.
p4018
aVThis is sometimes called the generalized composite of "f" with . The partial composition in only one argument mentioned previously can be instantiated from this more general scheme by setting all argument functions except one to be suitably chosen projection functions. Note also that can be seen as a single vector/tuple-valued function in this generalized scheme, in which case this is precisely the standard definition of function composition.
p4019
aVA set of finitary operations on some base set "X" is called a clone if it contains all projections and is closed under generalized composition. Note that a clone generally contains operations of various arities. The notion of commutation also finds an interesting generalization in the multivariate case; a function "f" of arity "n" is said to commute with a function "g" of arity "m" if "f" is a homomorphism preserving "g", and vice versa i.e.:
p4020
aVformula_5.
p4021
aVA unary operation always commutes with itself, but this is not necessarily the case for a binary (or higher arity) operation. A binary (or higher arity) operation that commutes with itself is called medial or entropic.
p4022
aVGeneralizations.
p4023
aVComposition can be generalized to arbitrary binary relations.
p4024
aVIf and are two binary relations, then their composition is the relation defined as .
p4025
aVConsidering a function as a special case of a binary relation (namely functional relations), function composition satisfies the definition for relation composition.
p4026
aVThe composition is defined in the same way for partial functions and Cayley's theorem has its analogue called Wagner-Preston theorem.
p4027
aVThe category of sets with functions as morphisms is the prototypical category. The axioms of a category are in fact inspired from the properties (and also the definition) of function composition. The structures given by composition are axiomatized and generalized in category theory with the concept of morphism as the category-theoretical replacement of functions. The order inversion in the formula applies for groups in general and for the inverse relation; each of these is a dagger category.
p4028
asS'Geometric topology'
p4029
(lp4030
VIn mathematics, geometric topology is the study of manifolds and maps between them, particularly embeddings of one manifold into another.
p4031
aVHistory.
p4032
aVGeometric topology as an area distinct from algebraic topology may be said to have originated in the 1935 classification of lens spaces by Reidemeister torsion, which required distinguishing spaces that are homotopy equivalent but not homeomorphic. This was the origin of "simple" homotopy theory.
p4033
aVDifferences between low-dimensional and high-dimensional topology.
p4034
aVManifolds differ radically in behavior in high and low dimension.
p4035
aVHigh-dimensional topology means manifolds of dimension 5 and above, or in relative terms, embeddings in codimension 3 and above, while low-dimensional topology, concerning questions of dimensions up to 4, or embeddings in codimension up to 2.
p4036
aVDimension 4 is special, in that in some respects (topologically), dimension 4 is high-dimensional, while in other respects (differentiably), dimension 4 is low-dimensional; this overlap yields phenomena exceptional to dimension 4, such as exotic differentiable structures on R4. Thus the topological classification of 4-manifolds is in principle easy, and the key questions are: does a topological manifold admit a differentiable structure, and if so, how many? Notably, the smooth case of dimension 4 is the last open case of the generalized Poincaré conjecture; see Gluck twists.
p4037
aVThe distinction is because surgery theory works in dimension 5 and above (in fact, it works topologically in dimension 4, though this is very involved to prove), and thus the behavior of manifolds in dimension 5 and above is controlled algebraically by surgery theory. In dimension 4 and below (topologically, in dimension 3 and below), surgery theory does not work, and other phenomena occur.
p4038
aVIndeed, one approach to discussing low-dimensional manifolds is to ask "what would surgery theory predict to be true, were it to work?" \u2013 and then understand low-dimensional phenomena as deviations from this.
p4039
aVThe precise reason for the difference at dimension 5 is because the Whitney embedding theorem, the key technical trick which underlies surgery theory, requires 2+1 dimensions. Roughly, the Whitney trick allows one to "unknot" knotted spheres \u2013 more precisely, remove self-intersections of immersions;
p4040
aVit does this via a homotopy of a disk \u2013 the disk has 2 dimensions, and the homotopy adds 1 more \u2013 and thus in codimension greater than 2, this can be done without intersecting itself; hence embeddings in codimension greater than 2 can be understood by surgery. In surgery theory, the key step is in the middle dimension, and thus when the middle dimension has codimension more than 2 (loosely, 2½ is enough, hence total dimension 5 is enough), the Whitney trick works. The key consequence of this is Smale's "h"-cobordism theorem, which works in dimension 5 and above, and forms the basis for surgery theory.
p4041
aVA modification of the Whitney trick can work in 4 dimensions, and is called Casson handles \u2013 because there are not enough dimensions, a Whitney disk introduces new kinks, which can be resolved by another Whitney disk, leading to a sequence ("tower") of disks. The limit of this tower yields a topological but not differentiable map, hence surgery works topologically but not differentiably in dimension 4.
p4042
aVImportant tools in geometric topology.
p4043
aVFundamental group.
p4044
aVIn all dimensions, the fundamental group of a manifold is a very important invariant, and determines much of the structure; in dimensions 1, 2 and 3, the possible fundamental groups are restricted, while in every dimension 4 and above every finitely presented group is the fundamental group of a manifold (note that it is sufficient to show this for 4- and 5-dimensional manifolds, and then to take products with spheres to get higher ones).
p4045
aVOrientability.
p4046
aVA manifold is orientable if it has a consistent choice of orientation, and a connected orientable manifold has exactly two different possible orientations. In this setting, various equivalent formulations of orientability can be given, depending on the desired application and level of generality. Formulations applicable to general topological manifolds often employ methods of homology theory, whereas for differentiable manifolds more structure is present, allowing a formulation in terms of differential forms. An important generalization of the notion of orientability of a space is that of orientability of a family of spaces parameterized by some other space (a fiber bundle) for which an orientation must be selected in each of the spaces which varies continuously with respect to changes in the parameter values.
p4047
aVHandle decompositions.
p4048
aVA handle decomposition of an "m"-manifold "M" is a union
p4049
aVformula_1
p4050
aVwhere each formula_2 is obtained from formula_3
p4051
aVby the attaching of formula_4-handles. A handle decomposition is to a manifold what a CW-decomposition is to a topological space\u2014in many regards the purpose of a handle decomposition is to have a language analogous to CW-complexes, but adapted to the world of smooth manifolds. Thus an "i"-handle is the smooth analogue of an "i"-cell. Handle decompositions of manifolds arise naturally via Morse theory. The modification of handle structures is closely linked to Cerf theory.
p4052
aVLocal flatness.
p4053
aVLocal flatness is a property of a submanifold in a topological manifold of larger dimension. In the category of topological manifolds, locally flat submanifolds play a role similar to that of embedded submanifolds in the category of smooth manifolds.
p4054
aVSuppose a "d" dimensional manifold "N" is embedded into an "n" dimensional manifold "M" (where "d" < "n"). If formula_5 we say "N" is locally flat at "x" if there is a neighborhood formula_6 of "x" such that the topological pair formula_7 is homeomorphic to the pair formula_8, with a standard inclusion of formula_9 as a subspace of formula_10. That is, there exists a homeomorphism formula_11 such that the image of formula_12 coincides with formula_9.
p4055
aVSchönflies theorems.
p4056
aVThe generalized Schoenflies theorem states that, if an ("n" \u2212 1)-dimensional sphere "S" is embedded into the "n"-dimensional sphere "Sn" in a locally flat way (that is, the embedding extends to that of a thickened sphere), then the pair ("Sn", "S") is homeomorphic to the pair ("Sn", "S""n"\u22121), where "S""n"\u22121 is the equator of the "n"-sphere. Brown and Mazur received the Veblen Prize for their independent proofs of this theorem.
p4057
aVBranches of geometric topology.
p4058
aVLow-dimensional topology.
p4059
aVLow-dimensional topology includes:
p4060
aVeach have their own theory, where there are some connections.
p4061
aVLow-dimensional topology is strongly geometric, as reflected in the uniformization theorem in 2 dimensions \u2013 every surface admits a constant curvature metric; geometrically, it has one of 3 possible geometries: positive curvature/spherical, zero curvature/flat, negative curvature/hyperbolic \u2013 and the geometrization conjecture (now theorem) in 3 dimensions \u2013 every 3-manifold can be cut into pieces, each of which has one of 8 possible geometries.
p4062
aV2-dimensional topology can be studied as complex geometry in one variable (Riemann surfaces are complex curves) \u2013 by the uniformization theorem every conformal class of metrics is equivalent to a unique complex one, and 4-dimensional topology can be studied from the point of view of complex geometry in two variables (complex surfaces), though not every 4-manifold admits a complex structure.
p4063
aVKnot theory.
p4064
aVKnot theory is the study of mathematical knots. While inspired by knots which appear in daily life in shoelaces and rope, a mathematician's knot differs in that the ends are joined together so that it cannot be undone. In mathematical language, a knot is an embedding of a circle in 3-dimensional Euclidean space, R3 (since we're using topology, a circle isn't bound to the classical geometric concept, but to all of its homeomorphisms). Two mathematical knots are equivalent if one can be transformed into the other via a deformation of R3 upon itself (known as an ambient isotopy); these transformations correspond to manipulations of a knotted string that do not involve cutting the string or passing the string through itself.
p4065
aVTo gain further insight, mathematicians have generalized the knot concept in several ways. Knots can be considered in other three-dimensional spaces and objects other than circles can be used; see "knot (mathematics)". Higher-dimensional knots are "n"-dimensional spheres in "m"-dimensional Euclidean space.
p4066
aVHigh-dimensional geometric topology.
p4067
aVIn high-dimensional topology, characteristic classes are a basic invariant, and surgery theory is a key theory.
p4068
aVA characteristic class is a way of associating to each principal bundle on a topological space "X" a cohomology class of "X". The cohomology class measures the extent to which the bundle is "twisted" \u2014 particularly, whether it possesses sections or not. In other words, characteristic classes are global invariants which measure the deviation of a local product structure from a global product structure. They are one of the unifying geometric concepts in algebraic topology, differential geometry and algebraic geometry.
p4069
aVSurgery theory is a collection of techniques used to produce one manifold from another in a 'controlled' way, introduced by . Surgery refers to cutting out parts of the manifold and replacing it with a part of another manifold, matching up along the cut or boundary. This is closely related to, but not identical with, handlebody decompositions. It is a major tool in the study and classification of manifolds of dimension greater than 3.
p4070
aVMore technically, the idea is to start with a well-understood manifold "M" and perform surgery on it to produce a manifold "M "\u2032 having some desired property, in such a way that the effects on the homology, homotopy groups, or other interesting invariants of the manifold are known.
p4071
aVThe classification of exotic spheres by led to the emergence of surgery theory as a major tool in high-dimensional topology.
p4072
asS'Strahler number'
p4073
(lp4074
VIn mathematics, the Strahler number or Horton\u2013Strahler number of a mathematical tree is a numerical measure of its branching complexity.
p4075
aVThese numbers were first developed in hydrology by and ; in this application, they are referred to as the Strahler stream order and are used to define stream size based on a hierarchy of tributaries. They also arise in the analysis of L-systems and of hierarchical biological structures such as (biological) trees and animal respiratory and circulatory systems, in register allocation for compilation of high level programming languages and in the analysis of social networks. Alternative stream ordering systems have been developed by Shreve and Hodgkinson et al.
p4076
aVDefinition.
p4077
aVAll trees in this context are directed graphs, oriented from the root towards the leaves; in other words, they are arborescences. The degree of a node in a tree is just its number of children. One may assign a Strahler number to all nodes of a tree, in bottom-up order, as follows:
p4078
aVThe Strahler number of a tree is the number of its root node.
p4079
aVAlgorithmically, these numbers may be assigned by performing a depth-first search and assigning each node's number in postorder.
p4080
aVThe same numbers may also be generated via a pruning process in which the tree is simplified in a sequence of stages, where in each stage one removes all leaf nodes and all of the paths of degree-one nodes leading to leaves: the Strahler number of a node is the stage at which it would be removed by this process, and the Strahler number of a tree is the number of stages required to remove all of its nodes. Another equivalent definition of the Strahler number of a tree is that it is the height of the largest complete binary tree that can be homeomorphically embedded into the given tree; the Strahler number of a node in a tree is similarly the height of the largest complete binary tree that can be embedded below that node.
p4081
aVAny node with Strahler number "i" must have at least two descendants with Strahler number "i" \u2212 1, at least four descendants with Strahler number "i" \u2212 2, etc., and at least 2"i" \u2212 1 leaf descendants. Therefore, in a tree with "n" nodes, the largest possible Strahler number is log2 "n". However, unless the tree forms a complete binary tree its Strahler number will be less than this bound. In an "n"-node binary tree, chosen uniformly at random among all possible binary trees, the expected index of the root is with high probability very close to log4 "n".
p4082
aVApplications.
p4083
aVRiver networks.
p4084
aVIn the application of the Strahler stream order to hydrology, each segment of a stream or river within a river network is treated as a node in a tree, with the next segment downstream as its parent. When two first-order streams come together, they form a second-order stream. When two second-order streams come together, they form a third-order stream. Streams of lower order joining a higher order stream do not change the order of the higher stream. Thus, if a first-order stream joins a second-order stream, it remains a second-order stream. It is not until a second-order stream combines with another second-order stream that it becomes a third-order stream. As with mathematical trees, a segment with index "i" must be fed by at least 2"i" \u2212 1 different tributaries of index 1. Shreve noted that Horton\u2019s and Strahler\u2019s Laws should be expected from any topologically random distribution. A later review of the relationships confirmed this argument, establishing that, from the properties the laws describe, no conclusion can be drawn to explain the structure or origin of the stream network.
p4085
aVTo qualify as a stream a hydrological feature must be either recurring or perennial. Recurring (or "intermittent") streams have water in the channel for at least part of the year. The index of a stream or river may range from 1 (a stream with no tributaries) to 12 (the most powerful river, the Amazon, at its mouth). The Ohio River is of order eight and the Mississippi River is of order 10. Estimates are that 80% of the streams on the planet are first to third order headwater streams.
p4086
aVIf the bifurcation ratio of a river network is low, there is a higher chance of flooding, as the water will be concentrated in one channel rather than spread out, as a higher bifurcation ratio would indicate. The bifurcation ratio can also show which parts of a drainage basin is more likely to flood, comparatively, by looking at the separate ratios. Most British rivers have a bifurcation ratio of between 3 and 5.
p4087
aVOther hierarchical systems.
p4088
aVThe Strahler numbering may be applied in the statistical analysis of any hierarchical system, not just to rivers.
p4089
aVRegister allocation.
p4090
aVWhen translating a high-level programming language to assembly language the minimum number of registers required to evaluate an expression tree is exactly its Strahler number. In this context, the Strahler number may also be called the register number.
p4091
aVFor expression trees that require more registers than are available, the Sethi\u2013Ullman algorithm may be used to translate an expression tree into a sequence of machine instructions that uses the registers as efficiently as possible, minimizing the number of times intermediate values are spilled from registers to main memory and the total number of instructions in the resulting compiled code.
p4092
aVRelated parameters.
p4093
aVBifurcation ratio.
p4094
aVAssociated with the Strahler numbers of a tree are "bifurcation ratios", numbers describing how close to balanced a tree is. For each order "i" in a hierarchy, the "i"th bifurcation ratio is
p4095
aVformula_1
p4096
aVwhere "ni" denotes the number of nodes with order "i".
p4097
aVThe bifurcation ratio of an overall hierarchy may be taken by averaging the bifurcation ratios at different orders. In a complete binary tree, the bifurcation ratio will be 2, while other trees will have smaller bifurcation ratios.
p4098
aVPathwidth.
p4099
aVThe pathwidth of an arbitrary undirected graph "G" may be defined as the smallest number "w" such that there exists an interval graph "H" containing "G" as a subgraph, with the largest clique in "H" having "w" + 1 vertices. For trees (viewed as undirected graphs by forgetting their orientation and root) the pathwidth differs from the Strahler number, but is closely related to it: in a tree with pathwidth "w" and Strahler number "s", these two numbers are related by the inequalities
p4100
aV"w" \u2264 s \u2264 2"w" + 2.
p4101
aVThe ability to handle graphs with cycles and not just trees gives pathwidth extra versatility compared to the Strahler number.
p4102
aVHowever, unlike the Strahler number, the pathwidth is defined only for the whole graph, and not separately for each node in the graph.
p4103
asS'Decision theory'
p4104
(lp4105
VDecision theory or theory of choice in economics, psychology, philosophy, mathematics, computer science, and statistics is concerned with identifying the values, uncertainties and other issues relevant in a given decision, its rationality, and the resulting optimal decision. It is closely related to the field of game theory; decision theory is concerned with the choices of individual agents whereas game theory is concerned with interactions of agents whose decisions affect each other.
p4106
aVNormative and descriptive decision theory.
p4107
aVNormative or prescriptive decision theory is concerned with identifying the best decision to take (in practice, there are situations in which "best" is not necessarily the maximal, optimum may also include values in addition to maximum, but within a specific or approximate range), assuming an ideal decision maker who is fully informed, able to compute with perfect accuracy, and fully rational. The practical application of this prescriptive approach (how people "ought to" make decisions) is called decision analysis, and aimed at finding tools, methodologies and software to help people make better decisions. The most systematic and comprehensive software tools developed in this way are called decision support systems.
p4108
aVIn contrast, positive or descriptive decision theory is concerned with describing observed behaviors under the assumption that the decision-making agents are behaving under some consistent rules. These rules may, for instance, have a procedural framework (e.g. Amos Tversky's elimination by aspects model) or an axiomatic framework, reconciling the Von Neumann-Morgenstern axioms with behavioural violations of the expected utility hypothesis, or they may explicitly give a functional form for time-inconsistent utility functions (e.g. Laibson's quasi-hyperbolic discounting). 
p4109
aVThe new prescriptions or predictions about behaviour that positive decision theory produces allow for further tests of the kind of decision-making that occurs in practice. There is a thriving dialogue with experimental economics, which uses laboratory and field experiments to evaluate and inform theory. In recent decades, there has also been increasing interest in what is sometimes called 'behavioral decision theory' and this has contributed to a re-evaluation of what rational decision-making requires.
p4110
aVWhat kinds of decisions need a theory?
p4111
aVChoice under uncertainty.
p4112
aVThis area represents the heart of decision theory. The procedure now referred to as expected value was known from the 17th century. Blaise Pascal invoked it in his famous wager (see below), which is contained in his "Pensées", published in 1670. The idea of expected value is that, when faced with a number of actions, each of which could give rise to more than one possible outcome with different probabilities, the rational procedure is to identify all possible outcomes, determine their values (positive or negative) and the probabilities that will result from each course of action, and multiply the two to give an expected value. The action to be chosen should be the one that gives rise to the highest total expected value. In 1738, Daniel Bernoulli published an influential paper entitled "Exposition of a New Theory on the Measurement of Risk", in which he uses the St. Petersburg paradox to show that expected value theory must be normatively wrong. He also gives an example in which a Dutch merchant is trying to decide whether to insure a cargo being sent from Amsterdam to St Petersburg in winter, when it is known that there is a 5% chance that the ship and cargo will be lost. In his solution, he defines a utility function and computes expected utility rather than expected financial value (see for a review).
p4113
aVIn the 20th century, interest was reignited by Abraham Wald's 1939 paper pointing out that the two central procedures of sampling\u2013distribution\u2013based statistical-theory, namely hypothesis testing and parameter estimation, are special cases of the general decision problem. Wald's paper renewed and synthesized many concepts of statistical theory, including loss functions, risk functions, admissible decision rules, antecedent distributions, Bayesian procedures, and minimax procedures. The phrase "decision theory" itself was used in 1950 by E. L. Lehmann.
p4114
aVThe revival of subjective probability theory, from the work of Frank Ramsey, Bruno de Finetti, Leonard Savage and others, extended the scope of expected utility theory to situations where subjective probabilities can be used. At this time, von Neumann's theory of expected utility proved that expected utility maximization followed from basic postulates about rational behavior.
p4115
aVThe work of Maurice Allais and Daniel Ellsberg showed that human behavior has systematic and sometimes important departures from expected-utility maximization. The prospect theory of Daniel Kahneman and Amos Tversky renewed the empirical study of economic behavior with less emphasis on rationality presuppositions. Kahneman and Tversky found three regularities \u2014 in actual human decision-making, "losses loom larger than gains"; persons focus more on "changes" in their utility\u2013states than they focus on absolute utilities; and the estimation of subjective probabilities is severely biased by anchoring.
p4116
aVCastagnoli and LiCalzi (1996), Bordley and LiCalzi (2000) recently showed that maximizing expected utility is mathematically equivalent to maximizing the probability that the uncertain consequences of a decision are preferable to an uncertain benchmark (e.g., the probability that a mutual fund strategy outperforms the S&P 500 or that a firm outperforms the uncertain future performance of a major competitor.). This reinterpretation relates to psychological work suggesting that individuals have fuzzy aspiration levels (Lopes & Oden), which may vary from choice context to choice context. Hence it shifts the focus from utility to the individual's uncertain reference point.
p4117
aVPascal's Wager is a classic example of a choice under uncertainty.
p4118
aVIntertemporal choice.
p4119
aVIntertemporal choice is concerned with the kind of choice where different actions lead to outcomes that are realised at different points in time. If someone received a windfall of several thousand dollars, they could spend it on an expensive holiday, giving them immediate pleasure, or they could invest it in a pension scheme, giving them an income at some time in the future. What is the optimal thing to do? The answer depends partly on factors such as the expected rates of interest and inflation, the person's life expectancy, and their confidence in the pensions industry. However even with all those factors taken into account, human behavior again deviates greatly from the predictions of prescriptive decision theory, leading to alternative models in which, for example, objective interest rates are replaced by subjective discount rates.
p4120
aVInteraction of decision makers.
p4121
aVSome decisions are difficult because of the need to take into account how other people in the situation will respond to the decision that is taken. The analysis of such social decisions is more often treated under the label of game theory, rather than decision theory, though it involves the same mathematical methods. From the standpoint of game theory most of the problems treated in decision theory are one-player games (or the one player is viewed as playing against an impersonal background situation). In the emerging socio-cognitive engineering, the research is especially focused on the different types of distributed decision-making in human organizations, in normal and abnormal/emergency/crisis situations.
p4122
aVOther-regarding preferences.
p4123
aVAlso called social preferences. In decisions which affect others, people will sometimes give up some direct personal benefit or take on a cost in order to achieve a fair or equal outcome. Bolton and Ockenfels (2000) and Fehr and Schmidt (1999) explore decision-makers who are concerned with fairness of distributions and have disutility from others' being much better off or much worse off. A closely related area of research is concerned with reciprocal fairness; the decision-makers desire to reward kind actions or intentions and punish unkind ones. 
p4124
aVComplex decisions.
p4125
aVOther areas of decision theory are concerned with decisions that are difficult simply because of their complexity, or the complexity of the organization that has to make them. Individuals making decisions may be limited in resources or are boundedly rational. In such cases the issue is not the deviation between real and optimal behaviour, but the difficulty of determining the optimal behaviour in the first place. The Club of Rome, for example, developed a model of economic growth and resource usage that helps politicians make real-life decisions in complex situations. Decisions are also affected by whether options are framed together or separately. This is known as the distinction bias.
p4126
aVHeuristics.
p4127
aVOne method of decision-making is heuristic. The heuristic approach makes decisions based on routine thinking. While this is quicker than step-by-step processing, heuristic decision-making opens the risk of inaccuracy. Mistakes that otherwise would have been avoided in step-by-step processing can be made. One common and incorrect thought process that results from heuristic thinking is the gambler's fallacy. The gambler's fallacy makes the mistake of believing that a random event is affected by previous random events. For example, there is a fifty percent chance of a coin landing on heads. Gambler's fallacy suggests that if the coin lands on tails, the next time it flips, it will land on heads, as if it's \u201cthe coin's turn\u201d to land on heads. This is simply not true. Such a fallacy is easily disproved in a step-by-step process of thinking. 
p4128
aVIn another example, when choosing between options involving extremes, decision-makers may have a heuristic that moderate alternatives are preferable to extreme ones. The Compromise Effect operates under a mindset driven by the belief that the most moderate option, amid extremes, carries the most benefits from each extreme.
p4129
aVAlternatives to decision theory.
p4130
aVA highly controversial issue is whether one can replace the use of probability in decision theory by other alternatives.
p4131
aVProbability theory.
p4132
aVThe Advocates of probability theory point to:
p4133
aVAlternatives to probability theory.
p4134
aVThe proponents of fuzzy logic, possibility theory, quantum cognition, Dempster\u2013Shafer theory, and info-gap decision theory maintain that probability is only one of many alternatives and point to many examples where non-standard alternatives have been implemented with apparent success; notably, probabilistic decision theory is sensitive to assumptions about the probabilities of various events, while non-probabilistic rules such as minimax are robust, in that they do not make such assumptions.
p4135
aVGeneral criticism.
p4136
aVA general criticism of decision theory based on a fixed universe of possibilities is that it considers the "known unknowns", not the "unknown unknowns": it focuses on expected variations, not on unforeseen events, which some argue (as in black swan theory) have outsized impact and must be considered \u2013 significant events may be "outside model". This line of argument, called the ludic fallacy, is that there are inevitable imperfections in modeling the real world by particular models, and that unquestioning reliance on models blinds one to their limits.
p4137
aV de Finetti, Bruno. "Foresight: its Logical Laws, Its Subjective Sources," (translation of the 1937 article in French) in H. E. Kyburg and H. E. Smokler (eds), "Studies in Subjective Probability," New York: Wiley, 1964.
p4138
asS"Spearman's rank correlation coefficient"
p4139
(lp4140
V In statistics, Spearman's rank correlation coefficient or Spearman's rho, named after Charles Spearman and often denoted by the Greek letter formula_1 (rho) or as formula_2, is a nonparametric measure of statistical dependence between two variables. It assesses how well the relationship between two variables can be described using a monotonic function. If there are no repeated data values, a perfect Spearman correlation of +1 or \u22121 occurs when each of the variables is a perfect monotone function of the other.
p4141
aVSpearman's coefficient, like any correlation calculation, is appropriate for both continuous and discrete variables, including ordinal variables. Spearman's formula_1 and Kendall's formula_4 can be formulated as special cases of a more a general correlation coefficient.
p4142
aVDefinition and calculation.
p4143
aVThe Spearman correlation coefficient is defined as the Pearson correlation coefficient between the ranked variables. For a sample of size "n", the "n" raw scores formula_5 are converted to ranks formula_6, and \u03c1 is computed from:
p4144
aVformula_7
p4145
aVwhere formula_8, is the difference between ranks. See the example below.
p4146
aVIdentical values (rank ties or value duplicates) are assigned a rank equal to the average of their positions in the ascending order of the values. In the table below, notice how the rank of values that are the same is the mean of what their ranks would otherwise be:
p4147
aVIn applications where duplicate values (ties) are known to be absent, a simpler procedure can be used to calculate \u03c1. 
p4148
aVNote that this method should not be used in cases where the data set is truncated; that is, when the Spearman correlation coefficient is desired for the top X records (whether by pre-change rank or post-change rank, or both), the user should use the Pearson correlation coefficient formula given above.
p4149
aVThe standard error of the coefficient ("\u03c3") was determined by Pearson in 1907 and Gosset in 1920. It is
p4150
aV formula_9
p4151
aVRelated quantities.
p4152
aVThere are several other numerical measures that quantify the extent of statistical dependence between pairs of observations. The most common of these is the Pearson product-moment correlation coefficient, which is a similar correlation method to Spearman's rank, that measures the \u201clinear\u201d relationships between the raw numbers rather than between their ranks.
p4153
aVAn alternative name for the Spearman rank correlation is the \u201cgrade correlation\u201d; in this, the \u201crank\u201d of an observation is replaced by the \u201cgrade\u201d. In continuous distributions, the grade of an observation is, by convention, always one half less than the rank, and hence the grade and rank correlations are the same in this case. More generally, the \u201cgrade\u201d of an observation is proportional to an estimate of the fraction of a population less than a given value, with the half-observation adjustment at observed values. Thus this corresponds to one possible treatment of tied ranks. While unusual, the term \u201cgrade correlation\u201d is still in use.
p4154
aVInterpretation.
p4155
aVThe sign of the Spearman correlation indicates the direction of association between "X" (the independent variable) and "Y" (the dependent variable). If "Y" tends to increase when "X" increases, the Spearman correlation coefficient is positive. If "Y" tends to decrease when "X" increases, the Spearman correlation coefficient is negative. A Spearman correlation of zero indicates that there is no tendency for "Y" to either increase or decrease when "X" increases. The Spearman correlation increases in magnitude as "X" and "Y" become closer to being perfect monotone functions of each other. When "X" and "Y" are perfectly monotonically related, the Spearman correlation coefficient becomes 1. A perfect monotone increasing relationship implies that for any two pairs of data values "X""i", "Y""i" and "X""j", "Y""j", that "X""i" \u2212 "X""j" and "Y""i" \u2212 "Y""j" always have the same sign. A perfect monotone decreasing relationship implies that these differences always have opposite signs.
p4156
aVThe Spearman correlation coefficient is often described as being "nonparametric". This can have two meanings. First, the fact that a perfect Spearman correlation results when "X" and "Y" are related by any monotonic function can be contrasted with the Pearson correlation, which only gives a perfect value when "X" and "Y" are related by a linear function. The other sense in which the Spearman correlation is nonparametric in that its exact sampling distribution can be obtained without requiring knowledge ("i.e.", knowing the parameters) of the joint probability distribution of "X" and "Y".
p4157
aVExample.
p4158
aVIn this example, the raw data in the table below is used to calculate the correlation between the IQ of a person with the number of hours spent in front of TV per week.
p4159
aVFirstly, evaluate formula_10. To do so use the following steps, reflected in the table below.
p4160
aVWith formula_10 found, add them to find formula_21. The value of "n" is 10. These values can now be substituted back into the equation :formula_22 to give
p4161
aVformula_23
p4162
aVwhich evaluates to "\u03c1" = -29/165 = \u22120.175757575...
p4163
aVwith a P-value = 0.627188 (using the t distribution)
p4164
aVThis low value shows that the correlation between IQ and hours spent watching TV is very low, although the negative value suggests that the longer the time spent watching television the lower the IQ. In the case of ties in the original values, this formula should not be used; instead, the Pearson correlation coefficient should be calculated on the ranks (where ties are given ranks, as described above).
p4165
aVDetermining significance.
p4166
aVOne approach to test whether an observed value of \u03c1 is significantly different from zero ("r" will always maintain \u22121 \u2264 "r" \u2264 1) is to calculate the probability that it would be greater than or equal to the observed "r", given the null hypothesis, by using a permutation test. An advantage of this approach is that it automatically takes into account the number of tied data values there are in the sample, and the way they are treated in computing the rank correlation.
p4167
aVAnother approach parallels the use of the Fisher transformation in the case of the Pearson product-moment correlation coefficient. That is, confidence intervals and hypothesis tests relating to the population value \u03c1 can be carried out using the Fisher transformation:
p4168
aV formula_24
p4169
aVIf "F"("r") is the Fisher transformation of "r", the sample Spearman rank correlation coefficient, and "n" is the sample size, then
p4170
aVformula_25
p4171
aVis a z-score for "r" which approximately follows a standard normal distribution under the null hypothesis of statistical independence (\u03c1 = 0).
p4172
aVOne can also test for significance using
p4173
aVformula_26
p4174
aVwhich is distributed approximately as Student's t distribution with "n" \u2212 2 degrees of freedom under the null hypothesis. A justification for this result relies on a permutation argument.
p4175
aVpvrank is a very recent R package that computes rank correlations and their p-values with various options for tied ranks. It is possible to compute exact Spearman coefficient test p-values for "n" \u2264 26.
p4176
aVA generalization of the Spearman coefficient is useful in the situation where there are three or more conditions, a number of subjects are all observed in each of them, and it is predicted that the observations will have a particular order. For example, a number of subjects might each be given three trials at the same task, and it is predicted that performance will improve from trial to trial. A test of the significance of the trend between conditions in this situation was developed by E. B. Page and is usually referred to as Page's trend test for ordered alternatives.
p4177
aVCorrespondence analysis based on Spearman's rho.
p4178
aVClassic correspondence analysis is a statistical method that gives a score to every value of two nominal variables. In this way the Pearson correlation coefficient between them is maximized.
p4179
aVThere exists an equivalent of this method, called grade correspondence analysis, which maximizes Spearman's rho or Kendall's tau.
p4180
asS'Structured program theorem'
p4181
(lp4182
VThe structured program theorem, also called Böhm-Jacopini theorem, is a result in programming language theory. It states that a class of control flow graphs (historically called charts in this context) can compute any computable function if it combines subprograms in only three specific ways (control structures). These are
p4183
aVThe structured chart subject to these constraints may however use additional variables in the form bits (stored in an extra integer variable in the original proof) in order to keep track of information that the original program represents by the program location. The construction was based on Böhm's programming language P\u2032\u2032.
p4184
aVOrigin and variants.
p4185
aVThe theorem is typically credited to a 1966 paper by Corrado Böhm and Giuseppe Jacopini. David Harel wrote in 1980 that the Böhm\u2013Jacopini paper enjoyed "universal popularity", particularly with proponents of structured programming. Harel also noted that "due to its rather technical style 1966 Böhm\u2013Jacopini paper is apparently more often cited than read in detail" and, after reviewing a large number of papers published up to 1980, Harel argued that the contents of the Böhm\u2013Jacopini proof was usually misrepresented as a folk theorem that essentially contains a simpler result, a result which itself can be traced to the inception on modern computing theory in the papers of von Neumann and Kleene.
p4186
aVHarel also writes that the more generic name was proposed by H.D. Mills as "The Structure Theorem" in the early 1970s.
p4187
aVSingle-while-loop, folk version of the theorem.
p4188
aVThis version of the theorem replaces all the original program's control flow with a single global codice_1 loop that simulates a program counter going over all possible labels (flowchart boxes) in the original non-structured program. Harel traced the origin of this folk theorem to two papers marking the beginning of computing. One is the 1946 description of the von Neumann architecture, which explains how a program counter operates in terms of a while loop. Harel notes that the single loop used by the folk version of the structured programming theorem basically just provides operational semantics for the execution of a flowchart on a von Neumann computer. Another, even older source that Harel traced the folk version of the theorem is Stephen Kleene's normal form theorem from 1936.
p4189
aVDonald Knuth criticized this form of the proof, which results in pseudocode like the one below, by pointing out that the structure of the original program is completely lost in this transformation. Similarly, Bruce Ian Mills wrote about this approach that "The spirit of block structure is a style, not a language. By simulating a Von Neumann machine, we can produce the behavior of any spaghetti code within the confines of a block-structured language. This does not prevent it from being spaghetti."
p4190
aVBöhm and Jacopini's proof.
p4191
aVThe proof in Böhm and Jacopini's paper proceeds by induction on the structure of the flow chart. Because it employed pattern matching in graphs, the proof of Böhm and Jacopini's was not really practical as a program transformation algorithm, and thus opened the door for additional research in this direction.
p4192
aVImplications and refinements.
p4193
aVThe Böhm-Jacopini proof did not settle the question of whether to adopt structured programming for software development, partly because the construction was more likely to obscure a program than to improve it. On the contrary, it signalled the beginning of the debate. Edsger Dijkstra's famous letter, "Go To Statement Considered Harmful," followed in 1968.
p4194
aVSome academics took a purist approach to the Böhm-Jacopini result and argued that even instructions like codice_2 and codice_3 from the middle of loops are bad practice as they are not needed in the Böhm-Jacopini proof, and thus they advocated that all loops should have a single exit point. This purist approach is embodied in the Pascal programming language (designed in 1968\u20131969), which up to the mid-1990s was the preferred tool for teaching introductory programming classes in academia.
p4195
aVEdward Yourdon notes that in the 1970s there was even philosophical opposition to transforming unstructured programs into structured ones by automated means, based on the argument that one needed to think in structured programming fashion from the get go. The pragmatic counterpoint was that such transformations benefited a large body of existing programs. Among the first proposals for an automated transformation was a 1971 paper by Edward Ashcroft and Zohar Manna.
p4196
aVThe direct application of the Böhm-Jacopini theorem may result in additional local variables being introduced in the structured chart, and may also result in some code duplication. The latter issue is called the loop and a half problem in this context. Pascal is affected by both of these problems and according to empirical studies cited by Eric S. Roberts, student programmers had difficulty formulating correct solutions in Pascal for several simple problems, including writing a function for searching an element in an array. A 1980 study by Henry Shapiro cited by Roberts found that using only the Pascal-provided control structures, the correct solution was given by only 20% of the subjects, while no subject wrote incorrect code for this problem if allowed to write a return from the middle of a loop.
p4197
aVIn 1973, S. Rao Kosaraju proved that it's possible to avoid adding additional variables in structured programming, as long as arbitrary-depth, multi-level breaks from loops are allowed. Furthermore, Kosaraju proved that a strict hierarchy of programs exists, nowadays called the "Kosaraju hierarchy", in that for every integer "n", there exists a program containing a multi-level break of depth "n" that cannot be rewritten as program with multi-level breaks of depth less than "n" (without introducing additional variables). Kosaraju cites the multi-level break construct to the BLISS programming language. The multi-level breaks, in the form a codice_4 keyword were actually introduced in the BLISS-11 version of that language; the original BLISS only had single-level breaks. The BLISS family of languages didn't provide an unrestricted goto. The Java programming language would later follow this approach as well.
p4198
aVA simpler result from Kosaraju's paper is that a program is reducible to a structured program (without adding variables) if and only if it does not contain a loop with two distinct exits. Reducibility was defined by Kosaraju, loosely speaking, as computing the same function and using the same "primitive actions" and predicates as the original program, but possibly using different control flow structures. (This is a narrower notion of reducibility than what Böhm-Jacopini used.) Inspired by this result, in section VI of his highly-cited paper that introduced the notion of cyclomatic complexity, Thomas J. McCabe described an analogue of Kuratowski's theorem for the control flow graphs (CFG) of non-structured programs, which is to say, the minimal subgraphs that make the CFG of a program non-structured. These subgraphs have a very good description in natural language. They are:
p4199
aVMcCabe actually found that these four graphs are not independent when appearing as subgraphs, meaning that a necessary and sufficient condition for a program to be non-structured is for its CFG to have as subgraph one of any subset of three of these four graphs. He also found that if a non-structured program contains one of these four sub-graphs, it must contain another distinct one from the set of four. This latter result helps explain how the control flow of non-structured program becomes entangled in what is popularly called "spaghetti code". McCabe also devised a numerical measure that, given an arbitrary program, quantifies how far off it is from the ideal of being a structured program; McCabe called his measure essential complexity.
p4200
aVMcCabe's characterization of the forbidden graphs for structured programming can be considered incomplete, at least if the Dijkstra's D structures are considered the building blocks.
p4201
aVUp to 1990 there were quite a few proposed methods for eliminating gotos from existing program, while preserving most of their structure. The various approaches to this problem also proposed several notions of equivalence, which are stricter than simply Turing equivalence, in order to avoid output like the folk theorem discussed above. The strictness of the chosen notion of equivalence dictates the minimal set of control flow structures needed. The 1988 JACM paper by Lyle Ramshaw surveys the field up to that point, as well proposing its own method. Ramshaw's algorithm was used for example in some Java decompilers because the Java virtual machine code has branch instructions with targets expressed as offsets, but the high-level Java language only has multi-level codice_2 and codice_6 statements. Ammarguellat (1992) proposed a transformation method that goes back to enforcing single-exit.
p4202
aVApplication to Cobol.
p4203
aVIn the 1980s IBM researcher Harlan Mills oversaw the development of the COBOL Structuring Facility, which applied a structuring algorithm to COBOL code. Mills's transformation involved the following steps for each procedure.
p4204
aVNote that this construction can be improved by converting some cases of the selection statement into subprocedures.
p4205
aVFurther reading.
p4206
aVMaterial not yet covered above:
p4207
asS'Limit (mathematics)'
p4208
(lp4209
VIn mathematics, a limit is the value that a function or sequence "approaches" as the input or index approaches some value. Limits are essential to calculus (and mathematical analysis in general) and are used to define continuity, derivatives, and integrals.
p4210
aVThe concept of a limit of a sequence is further generalized to the concept of a limit of a topological net, and is closely related to limit and direct limit in category theory.
p4211
aVIn formulas, a limit is usually written as
p4212
aVformula_1
p4213
aVand is read as "the limit of "f" of "n" as "n" approaches "c" equals "L"". Here "lim" indicates "limit", and the fact that function "f"("n") approaches the limit "L" as "n" approaches "c" is represented by the right arrow (\u2192), as in
p4214
aVformula_2
p4215
aVLimit of a function.
p4216
aVSuppose is a real-valued function and is a real number. The expression
p4217
aVformula_3
p4218
aVmeans that can be made to be as close to as desired by making sufficiently close to . In that case, the above equation can be read as "the limit of of , as approaches , is ". 
p4219
aVAugustin-Louis Cauchy in 1821, followed by Karl Weierstrass, formalized the definition of the limit of a function as the above definition, which became known as the (\u03b5, \u03b4)-definition of limit in the 19th century. The definition uses (the lowercase Greek letter "epsilon") to represent any small positive number, so that " becomes arbitrarily close to " means that eventually lies in the interval , which can also be written using the absolute value sign as . The phrase "as approaches " then indicates that we refer to values of whose distance from is less than some positive number (the lower case Greek letter "delta")\u2014that is, values of within either or , which can be expressed with . The first inequality means that the distance between and is greater than and that , while the second indicates that is within distance of .
p4220
aVNote that the above definition of a limit is true even if . Indeed, the function need not even be defined at .
p4221
aVFor example, if
p4222
aVformula_4
p4223
aVthen is not defined (see division by zero), yet as moves arbitrarily close to 1, correspondingly approaches 2:
p4224
aVThus, can be made arbitrarily close to the limit of 2 just by making sufficiently close to .
p4225
aVIn other words, formula_5 
p4226
aVThis can also be calculated algebraically, as formula_6 for all real numbers . 
p4227
aVNow since is continuous in at 1, we can now plug in 1 for , thus formula_7.
p4228
aVIn addition to limits at finite values, functions can also have limits at infinity. For example, consider 
p4229
aVformula_8
p4230
aVAs becomes extremely large, the value of approaches 2, and the value of can be made as close to 2 as one could wish just by picking sufficiently large. In this case, the limit of as approaches infinity is 2. In mathematical notation,
p4231
aVformula_9
p4232
aVLimit of a sequence.
p4233
aVConsider the following sequence: 1.79, 1.799, 1.7999... It can be observed that the numbers are "approaching" 1.8, the limit of the sequence.
p4234
aVFormally, suppose is a sequence of real numbers. It can be stated that the real number is the "limit" of this sequence, namely:
p4235
aVformula_10
p4236
aVwhich is read as
p4237
aV"The limit of "an" as "n" approaches infinity equals "L""
p4238
aVto mean
p4239
aVFor every real number , there exists a natural number such that for all , we have .
p4240
aVIntuitively, this means that eventually all elements of the sequence get arbitrarily close to the limit, since the absolute value is the distance between and . Not every sequence has a limit; if it does, it is called "convergent", and if it does not, it is "divergent". One can show that a convergent sequence has only one limit.
p4241
aVThe limit of a sequence and the limit of a function are closely related. On one hand, the limit as goes to infinity of a sequence is simply the limit at infinity of a function defined on the natural numbers . On the other hand, a limit of a function as goes to infinity, if it exists, is the same as the limit of any arbitrary sequence that approaches , and where is never equal to . Note that one such sequence would be .
p4242
aVLimit as "standard part".
p4243
aVIn non-standard analysis (which involves a hyperreal enlargement of the number system), the limit of a sequence formula_11 can be expressed as the standard part of the value formula_12 of the natural extension of the sequence at an infinite hypernatural index "n=H". Thus, 
p4244
aVformula_13.
p4245
aVHere the standard part function "st" rounds off each finite hyperreal number to the nearest real number (the difference between them is infinitesimal). This formalizes the natural intuition that for "very large" values of the index, the terms in the sequence are "very close" to the limit value of the sequence. Conversely, the standard part of a hyperreal formula_14 represented in the ultrapower construction by a Cauchy sequence formula_11, is simply the limit of that sequence:
p4246
aVformula_16.
p4247
aVIn this sense, taking the limit and taking the standard part are equivalent procedures.
p4248
aVConvergence and fixed point.
p4249
aVA formal definition of convergence can be stated as follows.
p4250
aVSuppose formula_17 as formula_18 goes from formula_19 to formula_20 is a sequence that converges to formula_21, with formula_22 for all formula_18. If positive constants formula_24 and formula_25 exist with
p4251
aV:::::formula_26
p4252
aVthen formula_17 as formula_18 goes from formula_19 to formula_20 converges to formula_21 of order formula_25, with asymptotic error constant formula_24
p4253
aVGiven a function formula_34 with a fixed point formula_21, there is a nice checklist for checking the convergence of the sequence formula_36.
p4254
aV1) First check that p is indeed a fixed point:
p4255
aV:formula_37
p4256
aV2) Check for linear convergence. Start by finding formula_38. If...
p4257
aV3) If it is found that there is something better than linear the expression should be checked for quadratic convergence. Start by finding formula_39 If...
p4258
aVTopological net.
p4259
aVAll of the above notions of limit can be unified and generalized to arbitrary topological spaces by introducing topological nets and defining their limits.
p4260
aVAn alternative is the concept of limit for filters on topological spaces.
p4261
asS'Alphabet (computer science)'
p4262
(lp4263
VIn computer science and mathematical logic, a non-empty set is called alphabet when its intended use in string operations shall be indicated. Its members are then commonly called "symbols" or "letters", e.g. characters or digits. For example a common alphabet is {0,1}, the binary alphabet. A finite string is a finite sequence of letters from an alphabet; for instance a binary string is a string drawn from the alphabet {0,1}. An infinite sequence of letters may be constructed from elements of an alphabet as well.
p4264
aVGiven an alphabet formula_1, we write formula_2 to denote the set of all finite strings over the alphabet formula_1. Here, the formula_4 denotes the Kleene star operator, so formula_2 is also called the Kleene closure of formula_1. We write formula_7 (or occasionally, formula_8 or formula_9) to denote the set of all infinite sequences over the alphabet formula_1.
p4265
aVFor example, using the binary alphabet {0,1}, the strings \u03b5, 0, 1, 00, 01, 10, 11, 000, etc. are all in the Kleene closure of the alphabet (where \u03b5 represents the empty string).
p4266
aVAlphabets are important in the use of formal languages, automata and semiautomata. In most cases, for defining instances of automata, such as deterministic finite automata (DFAs), it is required to specify an alphabet from which the input strings for the automaton are built.
p4267
aVIf "L" is a formal language, i.e. a (possibly infinite) set of finite-length strings, the '"alphabet of "L""' is the set of all symbols that may occur in any string in "L".
p4268
aVFor example, if "L" is the set of all variable identifiers in the programming language C, "L"\u2019s alphabet is the set { a, b, c, ..., x, y, z, A, B, C, ..., X, Y, Z, 0, 1, 2, ..., 7, 8, 9, _ }.
p4269
asS'Entscheidungsproblem'
p4270
(lp4271
VIn mathematics and computer science, the (, German for 'decision problem') is a challenge posed by David Hilbert in 1928. The asks for an algorithm that takes as input a statement of a first-order logic (possibly with a finite number of axioms beyond the usual axioms of first-order logic) and answers "Yes" or "No" according to whether the statement is "universally valid", i.e., valid in every structure satisfying the axioms. By the completeness theorem of first-order logic, a statement is universally valid if and only if it can be deduced from the axioms, so the can also be viewed as asking for an algorithm to decide whether a given statement is provable from the axioms using the rules of logic.
p4272
aVIn 1936, Alonzo Church and Alan Turing published independent papers showing that a general solution to the Entscheidungsproblem is impossible, assuming that the intuitive notion of "effectively calculable" is captured by the functions computable by a Turing machine (or equivalently, by those expressible in the lambda calculus). This assumption is now known as the Church\u2013Turing thesis.
p4273
aVHistory of the problem.
p4274
aVThe origin of the goes back to Gottfried Leibniz, who in the seventeenth century, after having constructed a successful mechanical calculating machine, dreamt of building a machine that could manipulate symbols in order to determine the truth values of mathematical statements. He realized that the first step would have to be a clean formal language, and much of his subsequent work was directed towards that goal. In 1928, David Hilbert and Wilhelm Ackermann posed the question in the form outlined above.
p4275
aVIn continuation of his "program," Hilbert posed three questions at an international conference in 1928, the third of which became known as "Hilbert's ." As late as 1930, he believed that there would be no such thing as an unsolvable problem.
p4276
aVNegative answer.
p4277
aVBefore the question could be answered, the notion of "algorithm" had to be formally defined. This was done by Alonzo Church in 1936 with the concept of "effective calculability" based on his \u03bb calculus and by Alan Turing in the same year with his concept of Turing machines. Turing immediately recognized that these are equivalent models of computation. 
p4278
aVThe negative answer to the "" was then given by Alonzo Church in 1935\u201336 and independently shortly thereafter by Alan Turing in 1936. Church proved that there is no computable function which decides for two given \u03bb-calculus expressions whether they are equivalent or not. He relied heavily on earlier work by Stephen Kleene. Turing reduced the halting problem for Turing machines to the . The work of both authors was heavily influenced by Kurt Gödel's earlier work on his incompleteness theorem, especially by the method of assigning numbers (a Gödel numbering) to logical formulas in order to reduce logic to arithmetic.
p4279
aVThe is related to Hilbert's tenth problem, which asks for an algorithm to decide whether Diophantine equations have a solution. The non-existence of such an algorithm, established by Yuri Matiyasevich in 1970, also implies a negative answer to the Entscheidungsproblem.
p4280
aVSome first-order theories are algorithmically decidable; examples of this include Presburger arithmetic, real closed fields and static type systems of many programming languages. The general first-order theory of the natural numbers expressed in Peano's axioms cannot be decided with such an algorithm, however.
p4281
aVPractical decision procedures.
p4282
aVHaving practical decision procedures for classes of logical formulas is of considerable interest for program verification and circuit verification. Pure Boolean logical formulas are usually decided using SAT-solving techniques based on the DPLL algorithm. Conjunctive formulas over linear real or rational arithmetic can be decided using the simplex algorithm, formulas in linear integer arithmetic (Presburger arithmetic) can be decided using Cooper's algorithm or William Pugh's Omega test. Formulas with negations, conjunctions and disjunctions combine the difficulties of satisfiability testing with that of decision of conjunctions; they are generally decided nowadays using SMT-solving technique, which combine SAT-solving with decision procedures for conjunctions and propagation techniques. Real polynomial arithmetic, also known as the theory of real closed fields, is decidable, for instance using the cylindrical algebraic decomposition; unfortunately the complexity of that algorithm is excessive for most practical uses.
p4283
asS'Algorithmic information theory'
p4284
(lp4285
VAlgorithmic information theory is a subfield of information theory and computer science that concerns itself with the relationship between computation and information. According to Gregory Chaitin, it is "the result of putting Shannon's information theory and Turing's computability theory into a cocktail shaker and shaking vigorously."
p4286
aVOverview.
p4287
aVAlgorithmic information theory principally studies complexity measures on strings (or other data structures). Because most mathematical objects can be described in terms of strings, or as the limit of a sequence of strings, it can be used to study a wide variety of mathematical objects, including integers.
p4288
aVInformally, from the point of view of algorithmic information theory, the information content of a string is equivalent to the length of the most-compressed possible self-contained representation of that string. A self-contained representation is essentially a program \u2013 in some fixed but otherwise irrelevant universal programming language \u2013 that, when run, outputs the original string.
p4289
aVFrom this point of view, a 3000 page encyclopedia actually contains less information than 3000 pages of completely random letters, despite the fact that the encyclopedia is much more useful. This is because to reconstruct the entire sequence of random letters, one must know, more or less, what every single letter is. On the other hand, if every vowel were removed from the encyclopedia, someone with reasonable knowledge of the English language could reconstruct it, just as one could likely reconstruct the sentence "Ths sntnc hs lw nfrmtn cntnt" from the context and consonants present.
p4290
aVUnlike classical information theory, algorithmic information theory gives formal, rigorous definitions of a random string and a random infinite sequence that do not depend on physical or philosophical intuitions about nondeterminism or likelihood. (The set of random strings depends on the choice of the universal Turing machine used to define Kolmogorov complexity, but any choice
p4291
aVgives identical asymptotic results because the Kolmogorov complexity of a string is invariant up to an additive constant depending only on the choice of universal Turing machine. For this reason the set of random infinite sequences is independent of the choice of universal machine.)
p4292
aVSome of the results of algorithmic information theory, such as Chaitin's incompleteness theorem, appear to challenge common mathematical and philosophical intuitions. Most notable among these is the construction of Chaitin's constant \u03a9, a real number which expresses the probability that a self-delimiting universal Turing machine will halt when its input is supplied by flips of a fair coin (sometimes thought of as the probability that a random computer program will eventually halt). Although \u03a9 is easily defined, in any consistent axiomatizable theory one can only compute finitely many digits of \u03a9, so it is in some sense "unknowable", providing an absolute limit on knowledge that is reminiscent of Gödel's Incompleteness Theorem. Although the digits of \u03a9 cannot be determined, many properties of \u03a9 are known; for example, it is an algorithmically random sequence and thus its binary digits are evenly distributed (in fact it is normal).
p4293
aVHistory.
p4294
aVAlgorithmic information theory was founded by Ray Solomonoff, who published the basic ideas on which the field is based as part of his invention of algorithmic probability - a way to overcome serious problems associated with the application of Bayes' rules in statistics. He first described his results at a Conference at Caltech in 1960, and in a report, February 1960, "A Preliminary Report on a General Theory of Inductive Inference." Algorithmic information theory was later developed independently by Andrey Kolmogorov, in 1965 and Gregory Chaitin, around 1966.
p4295
aVThere are several variants of Kolmogorov complexity or algorithmic information; the most widely used one is based on self-delimiting programs and is mainly due to Leonid Levin (1974). Per Martin-Löf also contributed significantly to the information theory of infinite sequences. An axiomatic approach to algorithmic information theory based on Blum axioms (Blum 1967) was introduced by Mark Burgin in a paper presented for publication by Andrey Kolmogorov (Burgin 1982). The axiomatic approach encompasses other approaches in the algorithmic information theory. It is possible to treat different measures of algorithmic information as particular cases of axiomatically defined measures of algorithmic information. Instead of proving similar theorems, such as the basic invariance theorem, for each particular measure, it is possible to easily deduce all such results from one corresponding theorem proved in the axiomatic setting. This is a general advantage of the axiomatic approach in mathematics. The axiomatic approach to algorithmic information theory was further developed in the book (Burgin 2005) and applied to software metrics (Burgin and Debnath, 2003; Debnath and Burgin, 2003).
p4296
aVPrecise definitions.
p4297
aVA binary string is said to be random if the Kolmogorov complexity of the string is at least the length of the string. A simple counting argument shows that some strings of any given length are random, and almost all strings are very close to being random. Since Kolmogorov complexity depends on a fixed choice of universal Turing machine (informally, a fixed "description language" in which the "descriptions" are given), the collection of random strings does depend on the choice of fixed universal machine. Nevertheless, the collection of random strings, as a whole, has similar properties regardless of the fixed machine, so one can (and often does) talk about the properties of random strings as a group without having to first specify a universal machine.
p4298
aVAn infinite binary sequence is said to be random if, for some constant "c", for all "n", the Kolmogorov complexity of the initial segment of length "n" of the sequence is at least "n" \u2212 "c". It can be shown that almost every sequence (from the point of view of the standard measure \u2014 "fair coin" or Lebesgue measure \u2014 on the space of infinite binary sequences) is random. Also, since it can be shown that the Kolmogorov complexity relative to two different universal machines differs by at most a constant, the collection of random infinite sequences does not depend on the choice of universal machine (in contrast to finite strings). This definition of randomness is usually called "Martin-Löf" randomness, after Per Martin-Löf, to distinguish it from other similar notions of randomness. It is also sometimes called "1-randomness" to distinguish it from other stronger notions of randomness (2-randomness, 3-randomness, etc.).
p4299
aVSpecific sequence.
p4300
aVAlgorithmic information theory (AIT) is the information theory of individual objects, using computer science, and concerns itself with the relationship between computation, information, and randomness.
p4301
aVThe information content or complexity of an object can be measured by the length of its shortest description. For instance the string
p4302
aVcodice_1
p4303
aVhas the short description "32 repetitions of '01'", while
p4304
aVcodice_2
p4305
aVpresumably has no simple description other than writing down the string itself.
p4306
aVMore formally, the Algorithmic Complexity (AC) of a string x is defined as the length of the shortest program that computes or outputs x, where the program is run on some fixed reference universal computer.
p4307
aVA closely related notion is the probability that a universal computer outputs some string x when fed with a program chosen at random. This Algorithmic "Solomonoff" Probability (AP) is key in addressing the old philosophical problem of induction in a formal way.
p4308
aVThe major drawback of AC and AP are their incomputability. Time-bounded "Levin" complexity penalizes a slow program by adding the logarithm of its running time to its length. This leads to computable variants of AC and AP, and Universal "Levin" Search (US) solves all inversion problems in optimal time (apart from some unrealistically large multiplicative constant).
p4309
aVAC and AP also allow a formal and rigorous definition of randomness of individual strings to not depend on physical or philosophical intuitions about non-determinism or likelihood. Roughly, a string is Algorithmic "Martin-Loef" Random (AR) if it is incompressible in the sense that its algorithmic complexity is equal to its length.
p4310
aVAC, AP, and AR are the core sub-disciplines of AIT, but AIT spawns into many other areas. It serves as the foundation of the Minimum Description Length (MDL) principle, can simplify proofs in computational complexity theory, has been used to define a universal similarity metric between objects, solves the Maxwell daemon problem, and many others.
p4311
asS'Order theory'
p4312
(lp4313
VOrder theory is a branch of mathematics which investigates our intuitive notion of order using binary relations. It provides a formal framework for describing statements such as "this is less than that" or "this precedes that". This article introduces the field and provides basic definitions. A list of order-theoretic terms can be found in the order theory glossary.
p4314
aVBackground and motivation.
p4315
aVOrders are everywhere in mathematics and related fields like computer science. The first order often discussed in primary school is the standard order on the natural numbers e.g. "2 is less than 3", "10 is greater than 5", or "Does Tom have fewer cookies than Sally?". This intuitive concept can be extended to orders on other sets of numbers, such as the integers and the reals. The idea of being greater than or less than another number is one of the basic intuitions of number systems (compare with numeral systems) in general (although one usually is also interested in the actual difference of two numbers, which is not given by the order). Another familiar example of an ordering is the lexicographic order of words in a dictionary.
p4316
aVThe above types of orders have a special property: each element can be "compared" to any other element, i.e. it is greater, smaller, or equal. However, this is not always a desired requirement. For example, consider the subset ordering of sets. If a set "A" contains all the elements of a set "B", then "B" is said to be smaller than or equal to "A". Yet there are some sets that cannot be related in this fashion. Whenever both contain some elements that are not in the other, the two sets are not related by subset-inclusion. Hence, subset-inclusion is only a "partial order", as opposed to the "total orders" given before.
p4317
aVOrder theory captures the intuition of orders that arises from such examples in a general setting. This is achieved by specifying properties that a relation \u2264 must have to be a mathematical order. This more abstract approach makes much sense, because one can derive numerous theorems in the general setting, without focusing on the details of any particular order. These insights can then be readily transferred to many less abstract applications.
p4318
aVDriven by the wide practical usage of orders, numerous special kinds of ordered sets have been defined, some of which have grown into mathematical fields of their own. In addition, order theory does not restrict itself to the various classes of ordering relations, but also considers appropriate functions between them. A simple example of an order theoretic property for functions comes from analysis where monotone functions are frequently found.
p4319
aVBasic definitions.
p4320
aVThis section introduces ordered sets by building upon the concepts of set theory, arithmetic, and binary relations.
p4321
aVPartially ordered sets.
p4322
aVOrders are special binary relations. Suppose that "P" is a set and that \u2264 is a relation on "P". Then \u2264 is a partial order if it is reflexive, antisymmetric, and transitive, i.e., for all "a", "b" and "c" in "P", we have that:
p4323
aV"a" \u2264 "a" (reflexivity)
p4324
aV if "a" \u2264 "b" and "b" \u2264 "a" then "a" = "b" (antisymmetry)
p4325
aV if "a" \u2264 "b" and "b" \u2264 "c" then "a" \u2264 "c" (transitivity).
p4326
aVA set with a partial order on it is called a partially ordered set, poset, or just an ordered set if the intended meaning is clear. By checking these properties, one immediately sees that the well-known orders on natural numbers, integers, rational numbers and reals are all orders in the above sense. However, they have the additional property of being total, i.e., for all "a" and "b" in "P", we have that:
p4327
aV"a" \u2264 "b" or "b" \u2264 "a" (totality).
p4328
aVThese orders can also be called linear orders or chains. While many classical orders are linear, the subset order on sets provides an example where this is not the case. Another example is given by the divisibility relation "|". For two natural numbers "n" and "m", we write "n"|"m" if "n" divides "m" without remainder. One easily sees that this yields a partial order.
p4329
aVThe identity relation = on any set is also a partial order in which every two distinct elements are incomparable. It is also the only relation that is both a partial order and an equivalence relation. Many advanced properties of posets are interesting mainly for non-linear orders.
p4330
aVVisualizing a poset.
p4331
aVHasse diagrams can visually represent the elements and relations of a partial ordering. These are graph drawings where the vertices are the elements of the poset and the ordering relation is indicated by both the edges and the relative positioning of the vertices. Orders are drawn bottom-up: if an element "x" is smaller than (precedes) "y" then there exists a path from "x" to "y" that is directed upwards. It is often necessary for the edges connecting elements to cross each other, but elements must never be located within an edge. An instructive exercise is to draw the Hasse diagram for the set of natural numbers that are smaller than or equal to 13, ordered by | (the "divides" relation).
p4332
aVEven some infinite sets can be diagrammed by superimposing an ellipsis (...) on a finite sub-order. This works well for the natural numbers, but it fails for the reals, where there is no immediate successor above 0; however, quite often one can obtain an intuition related to diagrams of a similar kind.
p4333
aVSpecial elements within an order.
p4334
aVIn a partially ordered set there may be some elements that play a special role. The most basic example is given by the least element of a poset. For example, 1 is the least element of the positive integers and the empty set is the least set under the subset order. Formally, an element "m" is a least element if:
p4335
aV "m" \u2264 "a", for all elements "a" of the order.
p4336
aVThe notation 0 is frequently found for the least element, even when no numbers are concerned. However, in orders on sets of numbers, this notation might be inappropriate or ambiguous, since the number 0 is not always least. An example is given by the above divisibility order |, where 1 is the least element since it divides all other numbers. In contrast, 0 is the number that is divided by all other numbers. Hence it is the greatest element of the order. Other frequent terms for the least and greatest elements is bottom and top or zero and unit.
p4337
aVLeast and greatest elements may fail to exist, as the example of the real numbers shows. But if they exist, they are always unique. In contrast, consider the divisibility relation | on the set {2,3,4,5,6}. Although this set has neither top nor bottom, the elements 2, 3, and 5 have no elements below them, while 4, 5, and 6 have none above. Such elements are called minimal and maximal, respectively. Formally, an element "m" is minimal if:
p4338
aV "a" \u2264 "m" implies "a" = "m", for all elements "a" of the order.
p4339
aVExchanging \u2264 with \u2265 yields the definition of maximality. As the example shows, there can be many maximal elements and some elements may be both maximal and minimal (e.g. 5 above). However, if there is a least element, then it is the only minimal element of the order. Again, in infinite posets maximal elements do not always exist - the set of all "finite" subsets of a given infinite set, ordered by subset inclusion, provides one of many counterexamples. An important tool to ensure the existence of maximal elements under certain conditions is Zorn's Lemma.
p4340
aVSubsets of partially ordered sets inherit the order. We already applied this by considering the subset {2,3,4,5,6} of the natural numbers with the induced divisibility ordering. Now there are also elements of a poset that are special with respect to some subset of the order. This leads to the definition of upper bounds'". Given a subset "S" of some poset "P", an upper bound of "S" is an element "b" of "P" that is above all elements of "S". Formally, this means that
p4341
aV "s" \u2264 "b", for all "s" in "S".
p4342
aVLower bounds again are defined by inverting the order. For example, -5 is a lower bound of the natural numbers as a subset of the integers. Given a set of sets, an upper bound for these sets under the subset ordering is given by their union. In fact, this upper bound is quite special: it is the smallest set that contains all of the sets. Hence, we have found the least upper bound of a set of sets. This concept is also called supremum or join, and for a set "S" one writes sup("S") or v"S" for its least upper bound. Conversely, the greatest lower bound is known as infimum or meet and denoted inf("S") or ^"S". These concepts play an important role in many applications of order theory. For two elements "x" and "y", one also writes "x" v "y" and "x" ^ "y" for sup({"x","y"}) and inf({"x","y"}), respectively. 
p4343
aVFor another example, consider again the relation | on natural numbers. The least upper bound of two numbers is the smallest number that is divided by both of them, i.e. the least common multiple of the numbers. Greatest lower bounds in turn are given by the greatest common divisor.
p4344
aVDuality.
p4345
aVIn the previous definitions, we often noted that a concept can be defined by just inverting the ordering in a former definition. This is the case for "least" and "greatest", for "minimal" and "maximal", for "upper bound" and "lower bound", and so on. This is a general situation in order theory: A given order can be inverted by just exchanging its direction, pictorially flipping the Hasse diagram top-down. This yields the so-called dual, inverse, or opposite order.
p4346
aVEvery order theoretic definition has its dual: it is the notion one obtains by applying the definition to the inverse order. Since all concepts are symmetric, this operation preserves the theorems of partial orders. For a given mathematical result, one can just invert the order and replace all definitions by their duals and one obtains another valid theorem. This is important and useful, since one obtains two theorems for the price of one. Some more details and examples can be found in the article on duality in order theory.
p4347
aVConstructing new orders.
p4348
aVThere are many ways to construct orders out of given orders. The dual order is one example. Another important construction is the cartesian product of two partially ordered sets, taken together with the product order on pairs of elements. The ordering is defined by ("a", "x") \u2264 ("b", "y") if (and only if) "a" \u2264 "b" and "x" \u2264 "y". (Notice carefully that there are three distinct meanings for the relation symbol \u2264 in this definition.) The disjoint union of two posets is another typical example of order construction, where the order is just the (disjoint) union of the original orders.
p4349
aVEvery partial order \u2264 gives rise to a so-called strict order <, by defining "a" < "b" if "a" \u2264 "b" and not "b" \u2264 "a". This transformation can be inverted by setting "a" \u2264 "b" if "a" < "b" or "a" = "b". The two concepts are equivalent although in some circumstances one can be more convenient to work with than the other.
p4350
aVFunctions between orders.
p4351
aVIt is reasonable to consider functions between partially ordered sets having certain additional properties that are related to the ordering relations of the two sets. The most fundamental condition that occurs in this context is monotonicity. A function "f" from a poset "P" to a poset "Q" is monotone, or order-preserving, if "a" \u2264 "b" in "P" implies "f"("a") \u2264 "f"("b") in "Q" (Noting that, strictly, the two relations here are different since they apply to different sets.). The converse of this implication leads to functions that are order-reflecting, i.e. functions "f" as above for which "f"("a") \u2264 "f"("b") implies "a" \u2264 "b". On the other hand, a function may also be order-reversing or antitone, if "a" \u2264 "b" implies "f"("b") \u2264 "f"("a").
p4352
aVAn order-embedding is a function "f" between orders that is both order-preserving and order-reflecting. Examples for these definitions are found easily. For instance, the function that maps a natural number to its successor is clearly monotone with respect to the natural order. Any function from a discrete order, i.e. from a set ordered by the identity order "=", is also monotone. Mapping each natural number to the corresponding real number gives an example for an order embedding. The set complement on a powerset is an example of an antitone function.
p4353
aVAn important question is when two orders are "essentially equal", i.e. when they are the same up to renaming of elements. Order isomorphisms are functions that define such a renaming. An order-isomorphism is a monotone bijective function that has a monotone inverse. This is equivalent to being a surjective order-embedding. Hence, the image "f"("P") of an order-embedding is always isomorphic to "P", which justifies the term "embedding".
p4354
aVA more elaborate type of functions is given by so-called Galois connections. Monotone Galois connections can be viewed as a generalization of order-isomorphisms, since they constitute of a pair of two functions in converse directions, which are "not quite" inverse to each other, but that still have close relationships.
p4355
aVAnother special type of self-maps on a poset are closure operators, which are not only monotonic, but also idempotent, i.e. "f"("x") = "f"("f"("x")), and extensive (or "inflationary"), i.e. "x" \u2264 "f"("x"). These have many applications in all kinds of "closures" that appear in mathematics.
p4356
aVBesides being compatible with the mere order relations, functions between posets may also behave well with respect to special elements and constructions. For example, when talking about posets with least element, it may seem reasonable to consider only monotonic functions that preserve this element, i.e. which map least elements to least elements. If binary infima ^ exist, then a reasonable property might be to require that "f"("x"^"y") = "f"("x")^"f"("y"), for all "x" and "y". All of these properties, and indeed many more, may be compiled under the label of limit-preserving functions.
p4357
aVFinally, one can invert the view, switching from "functions of orders" to "orders of functions". Indeed, the functions between two posets "P" and "Q" can be ordered via the pointwise order. For two functions "f" and "g", we have "f" \u2264 "g" if "f"("x") \u2264 "g"("x") for all elements "x" of "P". This occurs for example in domain theory, where function spaces play an important role.
p4358
aVSpecial types of orders.
p4359
aVMany of the structures that are studied in order theory employ order relations with further properties. In fact, even some relations that are not partial orders are of special interest. Mainly the concept of a preorder has to be mentioned. A preorder is a relation that is reflexive and transitive, but not necessarily antisymmetric. Each preorder induces an equivalence relation between elements, where "a" is equivalent to "b", if "a" \u2264 "b" and "b" \u2264 "a". Preorders can be turned into orders by identifying all elements that are equivalent with respect to this relation.
p4360
aVSeveral types of orders can be defined from numerical data on the items of the order: a total order results from attaching distinct real numbers to each item and using the numerical comparisons to order the items; instead, if distinct items are allowed to have equal numerical scores, one obtains a strict weak ordering. Requiring two scores to be separated by a fixed threshold before they may be compared leads to the concept of a semiorder, while allowing the threshold to vary on a per-item basis produces an interval order.
p4361
aVAn additional simple but useful property leads to so-called well-orders, for which all non-empty subsets have a minimal element. Generalizing well-orders from linear to partial orders, a set is well partially ordered if all its non-empty subsets have a finite number of minimal elements.
p4362
aVMany other types of orders arise when the existence of infima and suprema of certain sets is guaranteed. Focusing on this aspect, usually referred to as completeness of orders, one obtains:
p4363
aVHowever, one can go even further: if all finite non-empty infima exist, then \u2227 can be viewed as a total binary operation in the sense of universal algebra. Hence, in a lattice, two operations \u2227 and \u2228 are available, and one can define new properties by giving identities, such as
p4364
aV "x" \u2227 ("y" \u2228 "z")  =  ("x" \u2227 "y") \u2228 ("x" \u2227 "z"), for all "x", "y", and "z".
p4365
aVThis condition is called distributivity and gives rise to distributive lattices. There are some other important distributivity laws which are discussed in the article on distributivity in order theory. Some additional order structures that are often specified via algebraic operations and defining identities are
p4366
aVwhich both introduce a new operation ~ called negation. Both structures play a role in mathematical logic and especially Boolean algebras have major applications in computer science.
p4367
aVFinally, various structures in mathematics combine orders with even more algebraic operations, as in the case of quantales, that allow for the definition of an addition operation.
p4368
aVMany other important properties of posets exist. For example, a poset is locally finite if every closed interval ["a", "b"] in it is finite. Locally finite posets give rise to incidence algebras which in turn can be used to define the Euler characteristic of finite bounded posets.
p4369
aVSubsets of ordered sets.
p4370
aVIn an ordered set, one can define many types of special subsets based on the given order. A simple example are upper sets; i.e. sets that contain all elements that are above them in the order. Formally, the upper closure of a set "S" in a poset "P" is given by the set {"x" in "P" | there is some "y" in "S" with "y" \u2264 "x"}. A set that is equal to its upper closure is called an upper set. Lower sets are defined dually.
p4371
aVMore complicated lower subsets are ideals, which have the additional property that each two of their elements have an upper bound within the ideal. Their duals are given by filters. A related concept is that of a directed subset, which like an ideal contains upper bounds of finite subsets, but does not have to be a lower set. Furthermore it is often generalized to preordered sets.
p4372
aVA subset which is - as a sub-poset - linearly ordered, is called a chain. The opposite notion, the antichain, is a subset that contains no two comparable elements; i.e. that is a discrete order.
p4373
aVRelated mathematical areas.
p4374
aVAlthough most mathematical areas "use" orders in one or the other way, there are also a few theories that have relationships which go far beyond mere application. Together with their major points of contact with order theory, some of these are to be presented below.
p4375
aVUniversal algebra.
p4376
aVAs already mentioned, the methods and formalisms of universal algebra are an important tool for many order theoretic considerations. Beside formalizing orders in terms of algebraic structures that satisfy certain identities, one can also establish other connections to algebra. An example is given by the correspondence between Boolean algebras and Boolean rings. Other issues are concerned with the existence of free constructions, such as "free lattices" based on a given set of generators. Furthermore, closure operators are important in the study of universal algebra.
p4377
aVTopology.
p4378
aVIn topology orders play a very prominent role. In fact, the set of open sets provides a classical example of a complete lattice, more precisely a complete Heyting algebra (or "frame" or "locale"). Filters and nets are notions closely related to order theory and the closure operator of sets can be used to define topology. Beyond these relations, topology can be looked at solely in terms of the open set lattices, which leads to the study of pointless topology. Furthermore, a natural preorder of elements of the underlying set of a topology is given by the so-called specialization order, that is actually a partial order if the topology is T0.
p4379
aVConversely, in order theory, one often makes use of topological results. There are various ways to define subsets of an order which can be considered as open sets of a topology. Especially, it is interesting to consider topologies on a poset ("X", \u2264) that in turn induce \u2264 as their specialization order. The "finest" such topology is the Alexandrov topology, given by taking all upper sets as opens. Conversely, the "coarsest" topology that induces the specialization order is the upper topology, having the complements of principal ideals (i.e. sets of the form {"y" in "X" | "y" \u2264 "x"} for some "x") as a subbase. Additionally, a topology with specialization order \u2264 may be order consistent, meaning that their open sets are "inaccessible by directed suprema" (with respect to \u2264). The finest order consistent topology is the Scott topology, which is coarser than the Alexandrov topology. A third important topology in this spirit is the Lawson topology. There are close connections between these topologies and the concepts of order theory. For example, a function preserves directed suprema iff it is continuous with respect to the Scott topology (for this reason this order theoretic property is also called Scott-continuity).
p4380
aVCategory theory.
p4381
aVThe visualization of orders with Hasse diagrams has a straightforward generalization: instead of displaying lesser elements "below" greater ones, the direction of the order can also be depicted by giving directions to the edges of a graph. In this way, each order is seen to be equivalent to a directed acyclic graph, where the nodes are the elements of the poset and there is a directed path from "a" to "b" if and only if "a" \u2264 "b". Dropping the requirement of being acyclic, one can also obtain all preorders.
p4382
aVWhen equipped with all transitive edges, these graphs in turn are just special categories, where elements are objects and each set of morphisms between two elements is at most singleton. Functions between orders become functors between categories. Interestingly, many ideas of order theory are just concepts of category theory in small. For example, an infimum is just a categorical product. More generally, one can capture infima and suprema under the abstract notion of a categorical limit (or "colimit", respectively). Another place where categorical ideas occur is the concept of a (monotone) Galois connection, which is just the same as a pair of adjoint functors.
p4383
aVBut category theory also has its impact on order theory on a larger scale. Classes of posets with appropriate functions as discussed above form interesting categories. Often one can also state constructions of orders, like the product order, in terms of categories. Further insights result when categories of orders are found categorically equivalent to other categories, for example of topological spaces. This line of research leads to various "representation theorems", often collected under the label of Stone duality.
p4384
aVHistory.
p4385
aVAs explained before, orders are ubiquitous in mathematics. However, earliest explicit mentionings of partial orders are probably to be found not before the 19th century. In this context the works of George Boole are of great importance. Moreover, works of Charles Sanders Peirce, Richard Dedekind, and Ernst Schröder also consider concepts of order theory. Certainly, there are others to be named in this context and surely there exists more detailed material on the history of order theory. 
p4386
aVThe term "poset" as an abbreviation for partially ordered set was coined by Garrett Birkhoff in the second edition of his influential book "Lattice Theory".
p4387
asS'Besov space'
p4388
(lp4389
VIn mathematics, the Besov space (named after Oleg Vladimirovich Besov) formula_1 is a complete quasinormed space which is a Banach space when . It, as well as the similarly defined Triebel\u2013Lizorkin space, serve to generalize more elementary function spaces and are effective at measuring (in a sense) smoothness properties of functions.
p4390
aVDefinition.
p4391
aVLet 
p4392
aVformula_2 
p4393
aVand define the modulus of continuity by
p4394
aVformula_3
p4395
aVLet be a non-negative integer and define: with . The Besov space formula_1 contains all functions such that
p4396
aVformula_5
p4397
aVNorm.
p4398
aVThe Besov space formula_1 is equipped with the norm
p4399
aVformula_7
p4400
aVThe Besov spaces formula_8 coincide with the more classical Sobolev spaces formula_9.
p4401
aVIf formula_10 then formula_11.
p4402
asS'Dynamical systems theory'
p4403
(lp4404
VDynamical systems theory is an area of mathematics used to describe the behavior of complex dynamical systems, usually by employing differential equations or difference equations. When differential equations are employed, the theory is called "continuous dynamical systems". When difference equations are employed, the theory is called "discrete dynamical systems". When the time variable runs over a set that is discrete over some intervals and continuous over other intervals or is any arbitrary time-set such as a cantor set\u2014one gets dynamic equations on time scales. Some situations may also be modeled by mixed operators, such as differential-difference equations.
p4405
aVThis theory deals with the long-term qualitative behavior of dynamical systems, and studies the solutions of the equations of motion of systems that are primarily mechanical in nature; although this includes both planetary orbits as well as the behaviour of electronic circuits and the solutions to partial differential equations that arise in biology. Much of modern research is focused on the study of chaotic systems.
p4406
aVThis field of study is also called just "Dynamical systems", "Mathematical Dynamical Systems Theory" and "Mathematical theory of dynamical systems".
p4407
aVOverview.
p4408
aVDynamical systems theory and chaos theory deal with the long-term qualitative behavior of dynamical systems. Here, the focus is not on finding precise solutions to the equations defining the dynamical system (which is often hopeless), but rather to answer questions like "Will the system settle down to a steady state in the long term, and if so, what are the possible steady states?", or "Does the long-term behavior of the system depend on its initial condition?"
p4409
aVAn important goal is to describe the fixed points, or steady states of a given dynamical system; these are values of the variable that don't change over time. Some of these fixed points are "attractive", meaning that if the system starts out in a nearby state, it converges towards the fixed point.
p4410
aVSimilarly, one is interested in "periodic points", states of the system that repeat after several timesteps. Periodic points can also be attractive. Sharkovskii's theorem is an interesting statement about the number of periodic points of a one-dimensional discrete dynamical system.
p4411
aVEven simple nonlinear dynamical systems often exhibit seemingly random behavior that has been called "chaos". The branch of dynamical systems that deals with the clean definition and investigation of chaos is called "chaos theory".
p4412
aVHistory.
p4413
aVThe concept of dynamical systems theory has its origins in Newtonian mechanics. There, as in other natural sciences and engineering disciplines, the evolution rule of dynamical systems is given implicitly by a relation that gives the state of the system only a short time into the future.
p4414
aVBefore the advent of fast computing machines, solving a dynamical system required sophisticated mathematical techniques and could only be accomplished for a small class of dynamical systems.
p4415
aVSome excellent presentations of mathematical dynamic system theory include , , , and .
p4416
aVConcepts.
p4417
aVDynamical systems.
p4418
aVThe dynamical system concept is a mathematical formalization for any fixed "rule" that describes the time dependence of a point's position in its ambient space. Examples include the mathematical models that describe the swinging of a clock pendulum, the flow of water in a pipe, and the number of fish each spring in a lake.
p4419
aVA dynamical system has a "state" determined by a collection of real numbers, or more generally by a set of points in an appropriate "state space". Small changes in the state of the system correspond to small changes in the numbers. The numbers are also the coordinates of a geometrical space\u2014a manifold. The "evolution rule" of the dynamical system is a fixed rule that describes what future states follow from the current state. The rule is deterministic: for a given time interval only one future state follows from the current state.
p4420
aVDynamicism.
p4421
aVDynamicism, also termed the "dynamic hypothesis" or the "dynamic hypothesis in cognitive science" or "dynamic cognition", is a new approach in cognitive science exemplified by the work of philosopher Tim van Gelder. It argues that differential equations are more suited to modelling cognition than more traditional computer models.
p4422
aVNonlinear system.
p4423
aVIn mathematics, a nonlinear system is a system that is not linear\u2014i.e., a system that does not satisfy the superposition principle. Less technically, a nonlinear system is any problem where the variable(s) to solve for cannot be written as a linear sum of independent components. A nonhomogeneous system, which is linear apart from the presence of a function of the independent variables, is nonlinear according to a strict definition, but such systems are usually studied alongside linear systems, because they can be transformed to a linear system as long as a particular solution is known.
p4424
aVArithmetic dynamics is a field that emerged in the 1990s that amalgamates two areas of mathematics, dynamical systems and number theory. Classically, discrete dynamics refers to the study of the iteration of self-maps of the complex plane or real line. Arithmetic dynamics is the study of the number-theoretic properties of integer, rational, -adic, and/or algebraic points under repeated application of a polynomial or rational function.
p4425
aVChaos theory describes the behavior of certain dynamical systems \u2013 that is, systems whose state evolves with time \u2013 that may exhibit dynamics that are highly sensitive to initial conditions (popularly referred to as the butterfly effect). As a result of this sensitivity, which manifests itself as an exponential growth of perturbations in the initial conditions, the behavior of chaotic systems appears random. This happens even though these systems are deterministic, meaning that their future dynamics are fully defined by their initial conditions, with no random elements involved. This behavior is known as deterministic chaos, or simply "chaos".
p4426
aVComplex systems is a scientific field, which studies the common properties of systems considered complex in nature, society and science. It is also called "complex systems theory", "complexity science", "study of complex systems" and/or "sciences of complexity". The key problems of such systems are difficulties with their formal modeling and simulation. From such perspective, in different research contexts complex systems are defined on the base of their different attributes.
p4427
aVThe study of complex systems is bringing new vitality to many areas of science where a more typical reductionist strategy has fallen short. "Complex systems" is therefore often used as a broad term encompassing a research approach to problems in many diverse disciplines including neurosciences, social sciences, meteorology, chemistry, physics, computer science, psychology, artificial life, evolutionary computation, economics, earthquake prediction, molecular biology and inquiries into the nature of living cells themselves.
p4428
aVControl theory is an interdisciplinary branch of engineering and mathematics, that deals with influencing the behavior of dynamical systems.
p4429
aVErgodic theory is a branch of mathematics that studies dynamical systems with an invariant measure and related problems. Its initial development was motivated by problems of statistical physics.
p4430
aVFunctional analysis is the branch of mathematics, and specifically of analysis, concerned with the study of vector spaces and operators acting upon them. It has its historical roots in the study of functional spaces, in particular transformations of functions, such as the Fourier transform, as well as in the study of differential and integral equations. This usage of the word "functional" goes back to the calculus of variations, implying a function whose argument is a function. Its use in general has been attributed to mathematician and physicist Vito Volterra and its founding is largely attributed to mathematician Stefan Banach.
p4431
aVThe concept of graph dynamical systems (GDS) can be used to capture a wide range of processes taking place on graphs or networks. A major theme in the mathematical and computational analysis of graph dynamical system is to relate their structural properties (e.g. the network connectivity) and the global dynamics that result.
p4432
aVProjected dynamical systems is a mathematical theory investigating the behaviour of dynamical systems where solutions are restricted to a constraint set. The discipline shares connections to and applications with both the static world of optimization and equilibrium problems and the dynamical world of ordinary differential equations. A projected dynamical system is given by the flow to the projected differential equation.
p4433
aVSymbolic dynamics is the practice of modelling a topological or smooth dynamical system by a discrete space consisting of infinite sequences of abstract symbols, each of which corresponds to a state of the system, with the dynamics (evolution) given by the shift operator.
p4434
aVSystem dynamics is an approach to understanding the behaviour of complex systems over time. It deals with internal feedback loops and time delays that affect the behaviour of the entire system. What makes using system dynamics different from other approaches to studying complex systems is the use of feedback loops and stocks and flows. These elements help describe how even seemingly simple systems display baffling nonlinearity.
p4435
aVTopological dynamics is a branch of the theory of dynamical systems in which qualitative, asymptotic properties of dynamical systems are studied from the viewpoint of general topology.
p4436
aVApplications.
p4437
aVIn biomechanics.
p4438
aVIn sports biomechanics, dynamical systems theory has emerged in the movement sciences as a viable framework for modeling athletic performance. From a dynamical systems perspective, the human movement system is a highly intricate network of co-dependent sub-systems (e.g. respiratory, circulatory, nervous, skeletomuscular, perceptual) that are composed of a large number of interacting components (e.g. blood cells, oxygen molecules, muscle tissue, metabolic enzymes, connective tissue and bone). In dynamical systems theory, movement patterns emerge through generic processes of self-organization found in physical and biological systems.
p4439
aVIn cognitive science.
p4440
aVDynamical system theory has been applied in the field of neuroscience and cognitive development, especially in the neo-Piagetian theories of cognitive development. It is the belief that cognitive development is best represented by physical theories rather than theories based on syntax and AI. It also believed that differential equations are the most appropriate tool for modeling human behavior. These equations are interpreted to represent an agent's cognitive trajectory through state space. In other words, dynamicists argue that psychology should be (or is) the description (via differential equations) of the cognitions and behaviors of an agent under certain environmental and internal pressures. The language of chaos theory is also frequently adopted.
p4441
aVIn it, the learner's mind reaches a state of disequilibrium where old patterns have broken down. This is the phase transition of cognitive development. Self-organization (the spontaneous creation of coherent forms) sets in as activity levels link to each other. Newly formed macroscopic and microscopic structures support each other, speeding up the process. These links form the structure of a new state of order in the mind through a process called "scalloping" (the repeated building up and collapsing of complex performance.) This new, novel state is progressive, discrete, idiosyncratic and unpredictable.
p4442
aVDynamic systems theory has recently been used to explain a long-unanswered problem in child development referred to as the A-not-B error.
p4443
aVIn human development.
p4444
aVDynamic systems theory is a psychological theory of human development. Unlike dynamical systems theory, which is a mathematical construct, dynamic systems theory is primarily non-mathematical and driven by qualitative theoretical propositions. This psychological theory does, however, apply metaphors derived from the mathematical concepts of dynamical systems theory to attempt to explain the existence of apparently complex phenomena in human psychological and motor development.
p4445
asS'4D'
p4446
(lp4447
V4D or 4-D may refer to:
p4448
asS'Binary operation'
p4449
(lp4450
VIn mathematics, a binary operation on a set is a calculation that combines two elements of the set (called operands) to produce another element of the set (more formally, an operation whose arity is two, and whose two domains and one codomain are (subsets of) the same set). Examples include the familiar elementary arithmetic operations of addition, subtraction, multiplication and division. Other examples are readily found in different areas of mathematics, such as vector addition, matrix multiplication and conjugation in groups.
p4451
aVTerminology.
p4452
aVMore precisely, a binary operation on a set "S" is a map which sends elements of the Cartesian product to "S":
p4453
aVformula_1
p4454
aVBecause the result of performing the operation on a pair of elements of "S" is again an element of "S", the operation is called a closed binary operation on "S" (or sometimes expressed as having the property of closure). If "f" is not a function, but is instead a partial function, it is called a partial binary operation. For instance, division of real numbers is a partial binary operation, because one can't divide by zero: "a"/0 is not defined for any real "a". Note however that both in algebra and model theory the binary operations considered are defined on all of .
p4455
aVSometimes, especially in computer science, the term is used for any binary function.
p4456
aVBinary operations are the keystone of algebraic structures studied in abstract algebra: they are essential in the definitions of groups, monoids, semigroups, rings, and more. Most generally, a "magma" is a set together with some binary operation defined on it.
p4457
aVProperties and examples.
p4458
aVTypical examples of binary operations are the addition (+) and multiplication (×) of numbers and matrices as well as composition of functions on a single set.
p4459
aVFor instance,
p4460
aVMany binary operations of interest in both algebra and formal logic are commutative, satisfying for all elements "a" and "b" in "S", or associative, satisfying for all "a", "b" and "c" in "S". Many also have identity elements and inverse elements.
p4461
aVThe first three examples above are commutative and all of the above examples are associative.
p4462
aVOn the set of real numbers R, subtraction, that is, , is a binary operation which is not commutative since, in general, . It is also not associative, since, in general, ; for instance, but .
p4463
aVOn the set of natural numbers N, the binary operation exponentiation, , is not commutative since, in general, and is also not associative since . For instance, with , and , , but . By changing the set N to the set of integers Z, this binary operation becomes a partial binary operation since it is now undefined when and "b" is any negative integer. For either set, this operation has a "right identity" (which is 1) since for all "a" in the set, which is not an "identity" (two sided identity) since in general.
p4464
aVDivision (/), a partial binary operation on the set of real or rational numbers, is not commutative or associative as well. Tetration (\u2191\u2191), as a binary operation on the natural numbers, is not commutative nor associative and has no identity element.
p4465
aVNotation.
p4466
aVBinary operations are often written using infix notation such as , , or (by juxtaposition with no symbol) "ab" rather than by functional notation of the form . Powers are usually also written without operator, but with the second argument as superscript.
p4467
aVBinary operations sometimes use prefix or (probably more often) postfix notation, both of which dispense with parentheses. They are also called, respectively, Polish notation and reverse Polish notation.
p4468
aVPair and tuple.
p4469
aVA binary operation, "ab", depends on the ordered pair ("a, b") and so ("ab")"c" (where the parentheses here mean first operate on the ordered pair ("a", "b") and then operate on the result of that using the ordered pair (("ab"), "c")) depends in general on the ordered pair (("a", "b"), "c"). Thus, for the general, non-associative case, binary operations can be represented with binary trees.
p4470
aVHowever:
p4471
aVBinary operations as ternary relations.
p4472
aVA binary operation "f" on a set "S" may be viewed as a "ternary" relation on "S", that is, the set of triples ("a", "b", "f(a,b)") in "S" × "S" × "S" for all "a" and "b" in "S".
p4473
aVExternal binary operations.
p4474
aVAn external binary operation is a binary function from "K" × "S" to "S". This differs from a binary operation in the strict sense in that "K" need not be "S"; its elements come from "outside".
p4475
aVAn example of an external binary operation is scalar multiplication in linear algebra. Here "K" is a field and "S" is a vector space over that field.
p4476
aVAn external binary operation may alternatively be viewed as an action; "K" is acting on "S".
p4477
aVNote that the dot product of two vectors is not a binary operation, external or otherwise, as it maps from "S"× "S" to "K", where "K" is a field and "S" is a vector space over "K".
p4478
asS'Dependent and independent variables'
p4479
(lp4480
VVariables used in an experiment or modelling can be divided into three types: "dependent variable", "independent variable", or other. The "dependent variable" represents the output or effect, or is tested to see if it is the effect. The "independent variables" represent the inputs or causes, or are tested to see if they are the cause. Other variables may also be observed for various reasons.
p4481
aVUse.
p4482
aVMathematics.
p4483
aVIn mathematics, a function is a rule for taking an input (usually a number) and providing an output (which is also usually a number). A symbol that stands for an arbitrary input is called a independent variable, while a symbol that stands for an arbitrary output is called a dependent variable. The most common symbol for the input is "x", and the most common symbol for the output is "y"; the function itself is commonly written formula_1.
p4484
aVIt is possible to have multiple independent variables and/or multiple dependent variables. For instance, in multivariable calculus, one often encounters functions of the form formula_2, where "z" is a dependent variable and "x" and "y" are independent variables. Functions with multiple outputs are often written as vector-valued functions.
p4485
aVIn advanced mathematics, a function between a set X and a set Y is a subset of the Cartesian product formula_3 such that every element of X appears in an ordered pair with exactly one element of Y. In this situation, a symbol representing an element of X may be called a dependent variable and a symbol representing an element of Y may be called an independent variable, such as when X is a manifold and the symbol "x" represents an arbitrary point in the manifold. However, many advanced textbooks do not distinguish between dependent and independent variables.
p4486
aVStatistics.
p4487
aVIn a statistics experiment, the dependent variable is the event studied and expected to change whenever the independent variable is altered.
p4488
aVData mining.
p4489
aVIn data mining tools (for multivariate statistics and machine learning), the depending variable is assigned a "role" as target variable (or in some tools as "label attribute"), while a dependent variable may be assigned a role as "regular variable". Known values for the target variable are provided for the training data set and test data set, but should be predicted for other data. The target variable is used in supervised learning algorithms but not in non-supervised learning.
p4490
aVModelling.
p4491
aVIn mathematical modelling, the dependent variable is studied to see if and how much it varies as the independent variables vary. In the simple stochastic linear model formula_4 the term formula_5 is the "i" th value of the dependent variable and formula_6 is "i" th value of the independent variable. The term formula_7 is known as the "error" and contains the variability of the dependent variable not explained by the independent variable.
p4492
aVWith multiple independent variables, the expression is: formula_8, where "n" is the number of independent variables.
p4493
aVSimulation.
p4494
aVIn simulation, the dependent variable is changed in response to changes in the independent variables.
p4495
aVStatistics synonyms.
p4496
aVIndependent variable.
p4497
aVAn independent variable is also known as a "predictor variable", "regressor", "controlled variable", "manipulated variable", "explanatory variable", "exposure variable" (see reliability theory), "risk factor" (see medical statistics), "feature" (in machine learning and pattern recognition) or an "input variable."
p4498
aV"Explanatory variable" is preferred by some authors over "independent variable" when the quantities treated as "independent variables" may not be statistically independent.
p4499
aVIndependent variable(s) may be of these kinds: continuous variable(s), binary/dichotomous variable(s), nominal categorical variable(s), ordinal categorical variable(s), among others.
p4500
aVDependent variable.
p4501
aVA dependent variable is also known as a "response variable", "regressand", "measured variable", "responding variable", "explained variable", "outcome variable", "experimental variable", and "output variable".
p4502
aVIf the independent variable is referred to as an "explanatory variable" (see above) then the term "response variable" is preferred by some authors for the dependent variable.
p4503
aVOther variables.
p4504
aVA variable may be thought to alter the dependent or independent variables, but may not actually be the focus of the experiment. So that variable will be kept constant or monitored to try to minimise its effect on the experiment. Such variables may be called a "controlled variable" or "control variable" or "extraneous variable".
p4505
aVExtraneous variables, if included in a regression as independent variables, may aid a researcher with accurate response parameter estimation, prediction, and goodness of fit, but are not of substantive interest to the hypothesis under examination. For example, in a study examining the effect of post-secondary education on lifetime earnings, some extraneous variables might be gender, ethnicity, social class, genetics, intelligence, age, and so forth. A variable is extraneous only when it can be assumed (or shown) to influence the dependent variable. If included in a regression, it can improve the fit of the model. If it is excluded from the regression and if it has a non-zero covariance with one or more of the independent variables of interest, its omission will bias the regression's result for the effect of that independent variable of interest. This effect is called confounding or omitted variable bias; in these situations, design changes and/or statistical control is necessary.
p4506
aVExtraneous variables are often classified into three types:
p4507
aVIn quasi-experiments, differentiating between dependent and other variables may be downplayed in favour of differentiating between those variables that can be altered by the researcher and those that cannot. Variables in quasi-experiments may be referred to as "extraneous variables", "subject variables", "experimental variables", "situational variables", "pseudo-independent variables", "ex post facto variables", "natural group variables" or "non-manipulated variables".
p4508
aVIn modelling, variability that is not covered by the explanatory variable is designated by formula_7 and is known as the "residual", "side effect", "error", "unexplained share", "residual variable", or "tolerance".
p4509
aV In a study whether taking vitamin C pills daily make people live longer, researchers will dictate the vitamin C intake of a group of people over time. One part of the group will be given vitamin C pills daily. The other part of the group will be given a placebo pill. Nobody in the group knows which part they are in. The researchers will check the life span of the people in both groups. Here, the dependent variable is the life span and the independent variable is a binary variable for the use or non-use of vitamin C.
p4510
aV In a study measuring the influence of different quantities of fertilizer on plant growth, the independent variable would be the amount of fertilizer used. The dependent variable would be the growth in height or mass of the plant. The controlled variables would be the type of plant, the type of fertilizer, the amount of sunlight the plant gets, the size of the pots, etc.
p4511
aV In a study of how different doses of a drug affect the severity of symptoms, a researcher could compare the frequency and intensity of symptoms when different doses are administered. Here the independent variable is the dose and the dependent variable is the frequency/intensity of symptoms.
p4512
aV In measuring the amount of color removed from beetroot samples at different temperatures, temperature is the independent variable and amount of pigment removed is the dependent variable.
p4513
aV In sociology, in measuring the effect of education on income or wealth, the dependent variable is level of income/wealth and the independent variable is the education level of the individual.
p4514
asS'Formula'
p4515
(lp4516
VIn science, a formula is a concise way of expressing information symbolically as in a mathematical or chemical formula. The informal use of the term formula in science refers to the general construct of a relationship between given quantities. The plural of "formula" can be spelled either as "formulas" or "formulae" (from the original Latin).
p4517
aVIn mathematics, a formula is an entity constructed using the symbols and formation rules of a given logical language. For example, determining the volume of a sphere requires a significant amount of integral calculus or its geometrical analogue, the method of exhaustion; but, having done this once in terms of some parameter (the radius for example), mathematicians have produced a formula to describe the volume: This particular formula is:
p4518
aVHaving obtained this result, and knowing the radius of any sphere in question, we can quickly and easily determine its volume. Note that the volume "V" and the radius "r" are expressed as single letters instead of words or phrases. This convention, while less important in a relatively simple formula, means that mathematicians can more quickly manipulate larger and more complex formulas. Mathematical formulas are often algebraic, closed form, and/or analytical.
p4519
aVIn modern chemistry, a chemical formula is a way of expressing information about the proportions of atoms that constitute a particular chemical compound, using a single line of chemical element symbols, numbers, and sometimes other symbols, such as parentheses, brackets, and plus (+) and minus (\u2212) signs. For example, H2O is the chemical formula for water, specifying that each molecule consists of two hydrogen (H) atoms and one oxygen (O) atom. Similarly, O denotes an ozone molecule consisting of three oxygen atoms and having a net negative charge.
p4520
aVIn a general context, formulas are applied to provide a mathematical solution for real world problems. Some may be general: , which is one expression of Newton's second law, is applicable to a wide range of physical situations. Other formulas may be specially created to solve a particular problem; for example, using the equation of a sine curve to model the movement of the tides in a bay. In all cases, however, formulas form the basis for calculations.
p4521
aVExpressions are distinct from formulas in that they cannot contain an equals sign (=). Whereas formulas are comparable to sentences, expressions are more like phrases.
p4522
aVChemical formulas.
p4523
aVA chemical formula identifies each constituent element by its chemical symbol and indicates the proportionate number of atoms of each element. In empirical formulas, these proportions begin with a key element and then assign numbers of atoms of the other elements in the compound, as ratios to the key element. For molecular compounds, these ratio numbers can all be expressed as whole numbers. For example, the empirical formula of ethanol may be written C2H6O because the molecules of ethanol all contain two carbon atoms, six hydrogen atoms, and one oxygen atom. Some types of ionic compounds, however, cannot be written with entirely whole-number empirical formulas. An example is boron carbide, whose formula of CBn is a variable non-whole number ratio with n ranging from over 4 to more than 6.5.
p4524
aVWhen the chemical compound of the formula consists of simple molecules, chemical formulas often employ ways to suggest the structure of the molecule. These types of formulas are variously known as molecular formulas and condensed formulas. A molecular formula enumerates the number of atoms to reflect those in the molecule, so that the molecular formula for glucose is C6H12O6 rather than the glucose empirical formula, which is CH2O. Except for very simple substances, molecular chemical formulas lack needed structural information, and are ambiguous.
p4525
aVIn computing.
p4526
aVIn computing, a formula typically describes a calculation, such as addition, to be performed on one or more variables. A formula is often implicitly provided in the form of a computer instruction such as.
p4527
aV "Degrees Celsius" = (5/9)*("Degrees Fahrenheit"  - 32)
p4528
aVIn computer spreadsheet software, a formula indicating how to compute the value of a cell, say "A3", is written such as
p4529
aV "=A1+A2"
p4530
aVwhere "A1" and "A2" refer to other cells (column A, row 1 or 2) within the spreadsheet. This is a shortcut for the "paper" form "A3 = A1+A2" where "A3" is, by convention, omitted because the result is always stored in the cell itself and stating its name would be redundant.
p4531
aVFormulas with prescribed units.
p4532
aVA physical quantity can be expressed as the product of a number and a physical unit. A formula expresses a relationship between physical quantities. A necessary condition for a formula to be valid is that all terms have the same dimension, meaning every term in the formula could be potentially converted to contain the identical unit (or product of identical units).
p4533
aVIn the example above, for the volume of a sphere, we may wish to compute with "r" = 2.0 cm, which yields
p4534
aVformula_1
p4535
aVThere is vast educational training about retaining units in computations, and converting units to a desirable form, such as in units conversion by factor-label.
p4536
aVThe vast majority of computations with measurements are done in computer programs with no facility for retaining a symbolic computation of the units. Only the numerical quantity is used in the computation. This requires that the universal formula be converted to a formula that is intended to be used only with prescribed units, meaning the numerical quantity is implicitly assumed to be multiplying a particular unit. The requirements about the prescribed units must be given to users of the input and the output of the formula.
p4537
aVFor example suppose the formula is to require that formula_2, where tbsp is the U.S. tablespoon (as seen in conversion of units) and VOL is the name for the number used by the computer. Similarly, the formula is to require
p4538
aVformula_3. The derivation of the formula proceeds as:
p4539
aV formula_4
p4540
aVGiven that formula_5,
p4541
aVthe formula with prescribed units is
p4542
aV formula_6
p4543
aVThe formula is not complete without words such as:
p4544
aV"VOL is volume in tbsp and RAD is radius in cm".
p4545
aVOther possible words are "VOL is the ratio of formula_7 to tbsp and RAD is the ratio of formula_8 to cm."
p4546
aVThe formula with prescribed units could also appear with simple symbols, 
p4547
aVperhaps even the identical symbols as in the original dimensional formula:
p4548
aV formula_9
p4549
aVand the accompanying words could be: "where V is volume (tbsp) and r is radius (cm)".
p4550
aVIf the physical formula is not dimensionally homogeneous, and therefore erroneous, 
p4551
aVthe falsehood becomes apparent in the impossibility 
p4552
aVto derive a formula with prescribed units. It would not be possible to
p4553
aVderive a formula consisting only of numbers and dimensionless ratios.
p4554
aVIn science.
p4555
aVFormulas used in science almost always require a choice of units. Formulas are used to express relationships between various quantities, such as temperature, mass, or charge in physics; supply, profit, or demand in economics; or a wide range of other quantities in other disciplines.
p4556
aVAn example of a formula used in science is Boltzmann's entropy formula. In statistical thermodynamics, it is a probability equation relating the entropy "S" of an ideal gas to the quantity "W", which is the number of microstates corresponding to a given macrostate:
p4557
aVformula_10           (1) S= k ln W
p4558
aVwhere "k" is Boltzmann's constant equal to 1.38062 x 10\u221223 joule/kelvin and "W" is the number of microstates consistent with the given macrostate.
p4559
asS'Percentage'
p4560
(lp4561
VIn mathematics, a percentage is a number or ratio expressed as a fraction of 100. It is often denoted using the percent sign, "%", or the abbreviation "pct."; sometimes the abbreviation "pc" is used in the case of quantities in economics. A percentage is a dimensionless number (pure number).
p4562
aVFor example, 45% (read as "forty-five percent") is equal to 45/100, or 0.45. A related system which expresses a number as a fraction of 1,000 uses the terms "per mil" and "millage". Percentages are used to express how large or small one quantity is relative to another quantity. The first quantity usually represents a part of, or a change in, the second quantity. For example, an increase of $0.15 on a price of $2.50 is an increase by a fraction of 0.15/2.50 = 0.06. Expressed as a percentage, this is therefore a 6% increase. While percentage values are often between 0 and 100 there is no restriction and one may, for example, refer to 111% or \u221235%.
p4563
aVHistory.
p4564
aVIn Ancient Rome, long before the existence of the decimal system, computations were often made in fractions which were multiples of 1/100. For example Augustus levied a tax of 1/100 on goods sold at auction known as "centesima rerum venalium". Computation with these fractions was similar to computing percentages. As denominations of money grew in the Middle Ages, computations with a denominator of 100 became more standard and from the late 15th century to the early 16th century it became common for arithmetic texts to include such computations. Many of these texts applied these methods to profit and loss, interest rates, and the Rule of Three. By the 17th century it was standard to quote interest rates in hundredths.
p4565
aVPercent sign.
p4566
aVThe term "per cent" is derived from the Latin "per centum", meaning "by the hundred". 
p4567
aVThe sign for "per cent" evolved by gradual contraction of the Italian term "per cento", meaning "for a hundred". The "per" was often abbreviated as "p." and eventually disappeared entirely. The "cento" was contracted to two circles separated by a horizontal line, from which the modern "%" symbol is derived.
p4568
aVCalculations.
p4569
aVThe percent value is computed by multiplying the numeric value of the ratio by 100. For example, to find 50 apples as a percentage of 1250 apples, first compute the ratio 50/1250 = 0.04, and then multiply by 100 to obtain 4%. The percent value can also be found by multiplying first, so in this example the 50 would be multiplied by 100 to give 5,000, and this result would be divided by 1250 to give 4%.
p4570
aVTo calculate a percentage of a percentage, convert both percentages to fractions of 100, or to decimals, and multiply them. For example, 50% of 40% is:
p4571
aVIt is not correct to divide by 100 and use the percent sign at the same time. (E.g. , not , which actually is . A term such as would also be incorrect, this would be read as (1) percent even if the intent was to say 100%.)
p4572
aVWhenever we talk about a percentage, it is important to specify what it is relative to, i.e. what is the total that corresponds to 100%. The following problem illustrates this point.
p4573
aVIn a certain college 60% of all students are female, and 10% of all students are computer science majors. If 5% of female students are computer science majors, what percentage of computer science majors are female?
p4574
aVWe are asked to compute the ratio of female computer science majors to all computer science majors. We know that 60% of all students are female, and among these 5% are computer science majors, so we conclude that (60/100) × (5/100) = 3/100 or 3% of all students are female computer science majors. Dividing this by the 10% of all students that are computer science majors, we arrive at the answer: 3%/10% = 30/100 or 30% of all computer science majors are female.
p4575
aVThis example is closely related to the concept of conditional probability.
p4576
aVPercentage increase and decrease.
p4577
aVSometimes due to inconsistent usage, it is not always clear from the context what a percentage is relative to. When speaking of a "10% rise" or a "10% fall" in a quantity, the usual interpretation is that this is relative to the "initial value" of that quantity. For example, if an item is initially priced at $200 and the price rises 10% (an increase of $20), the new price will be $220. Note that this final price is 110% of the initial price (100% + 10% = 110%).
p4578
aVSome other examples of percent changes:
p4579
aVIn general, a change of formula_1 percent in a quantity results in a final amount that is formula_2 percent of the original amount (equivalently, formula_3 times the original amount).
p4580
aVCompounding percentages.
p4581
aVIt is important to understand that percent changes, as they have been discussed here, "do not add" in the usual way, if applied sequentially. For example, if the 10% increase in price considered earlier (on the $200 item, raising its price to $220) is followed by a 10% decrease in the price (a decrease of $22), the final price will be $198, "not" the original price of $200. The reason for the apparent discrepancy is that the two percent changes (+10% and \u221210%) are measured relative to "different" quantities ($200 and $220, respectively), and thus do not "cancel out".
p4582
aVIn general, if an increase of formula_1 percent is followed by a decrease of formula_1 percent, and the initial amount was formula_6, the final amount is formula_7; thus the net change is an overall decrease by formula_1 percent "of" formula_1 percent (the square of the original percent change when expressed as a decimal number). Thus, in the above example, after an increase and decrease of formula_10 percent, the final amount, $198, was 10% of 10%, or 1%, less than the initial amount of $200.
p4583
aVThis can be expanded for a case where you do not have the same percent change. If the initial percent change is formula_1 and the second percent change is formula_12, and the initial amount was formula_6, then the final amount is formula_14. To change the above example, after an increase of formula_10 and decrease of formula_16 percent, the final amount, $209, is 4.5% more than the initial amount of $200.
p4584
aVIn the case of interest rates, it is a common practice to state the percent change differently. If an interest rate rises from 10% to 15%, for example, it is typical to say, "The interest rate increased by 5%" \u2014 rather than by 50%, which would be correct when measured as a percentage of the initial rate (i.e., from 0.10 to 0.15 is an increase of 50%). Such ambiguity can be avoided by using the term "percentage points" (pp). In the previous example, the interest rate "increased by 5 pp" from 10% to 15%. If the rate then drops by 5 percentage points, it will return to the initial rate of 10%, as expected.
p4585
aVWord and symbol.
p4586
aVIn British English, "percent" is sometimes written as two words ("per cent", although "percentage" and "percentile" are written as one word). In American English, "percent" is the most common variant (but cf. "per mille" written as two words).
p4587
aVIn the early part of the twentieth century, there was a dotted abbreviation form ""per cent."," as opposed to "per cent". The form "per cent." is still in use as a part of the highly formal language found in certain documents like commercial loan agreements (particularly those subject to, or inspired by, common law), as well as in the Hansard transcripts of British Parliamentary proceedings. The term has been attributed to Latin "per centum". The concept of considering values as parts of a hundred is originally Greek. The symbol for percent (%) evolved from a symbol abbreviating the Italian "per cento". In some other languages, the form "prosent" is used instead. Some languages use both a word derived from "percent" and an expression in that language meaning the same thing, e.g. Romanian "procent" and "la sut\u0103" (thus, "10 %" can be read or sometimes written "ten for hundred", similarly with the English "one out of ten"). Other abbreviations are rarer, but sometimes seen.
p4588
aVGrammar and style guides often differ as to how percentages are to be written. For instance, it is commonly suggested that the word percent (or per cent) be spelled out in all texts, as in "1 percent" and not "1%". Other guides prefer the word to be written out in humanistic texts, but the symbol to be used in scientific texts. Most guides agree that they always be written with a numeral, as in "5 percent" and not "five percent", the only exception being at the beginning of a sentence: "Ten percent of all writers love style guides." Decimals are also to be used instead of fractions, as in "3.5 percent of the gain" and not "3 ½ percent of the gain". It is also widely accepted to use the percent symbol (%) in tabular and graphic material.
p4589
aVIn line with common English practice, style guides\u2014such as "The Chicago Manual of Style"\u2014generally state that the number and percent sign are written without any space in between.
p4590
aVHowever, the International System of Units and the ISO 31-0 standard require a space.
p4591
aVOther uses.
p4592
aVThe word "percentage" is often a misnomer in the context of sports statistics, when the referenced number is expressed as a decimal proportion, not a percentage: "The Phoenix Suns' Shaquille O'Neal led the NBA with a .609 field goal percentage (FG%) during the 2008-09 season." (O'Neal made 60.9% of his shots, not 0.609%.) Likewise, the winning percentage of a team, the fraction of matches that the club has won, is also usually expressed as a decimal proportion; a team that has a .500 winning percentage has won 50% of their matches. The practice is probably related to the similar way that batting averages are quoted.
p4593
aVAs "percent" it is used to describe the steepness of the slope of a road or railway, formula for which is formula_17 which could also be expressed as the tangent of the angle of inclination times 100. The is the ratio of distances a vehicle would advance vertically and horizontally, respectively, when going up- or downhill, expressed in percent.
p4594
aVPercentage is also used to express composition of a mixture by mass percent and mole percent.
p4595
asS'Y-intercept'
p4596
(lp4597
VIn analytic geometry, using the common convention that the horizontal axis represents a variable "x" and the vertical axis represents a variable "y", a ""'y"-intercept"' is a point where the graph of a function or relation intersects with the "y"-axis of the coordinate system. As such, these points satisfy "x" = 0.
p4598
aVUsing equations.
p4599
aVIf the curve in question is given as "y" = "f"("x"), the "y"-coordinate of the "y"-intercept is found by calculating "f"(0). Functions which are undefined at "x" = 0 have no "y"-intercept.
p4600
aVMultiple y-intercepts.
p4601
aVSome 2-dimensional mathematical relationships such as circles, ellipses, and hyperbolas can have more than one "y"-intercept. Because functions associate "x" values to no more than one "y" value as part of their definition, they can have at most one "y"-intercept.
p4602
aVx-intercepts.
p4603
aVAnalogously, an "x"-intercept is a point where the graph of a function or relation intersects with the "x"-axis. As such, these points satisfy "y"=0. The zeros, or roots, of such a function or relation are the "x"-coordinates of these "x"-intercepts.
p4604
aVUnlike "y"-intercepts, functions of the form "y" = "f"("x") may contain multiple "x"-intercepts. The "x"-intercepts of functions, if any exist, are often more difficult to locate than the "y"-intercept, as finding the y intercept involves simply evaluating the function at "x"=0.
p4605
aVIn higher dimensions.
p4606
aVThe notion may be extended for 3-dimensional space and higher dimensions, as well as for other coordinate axes, possibly with other names. For example, one may speak of the "I"-intercept of the current-voltage characteristic of, say, a diode. (In electrical engineering, "I" is the symbol used for electric current.)
p4607
asS'Parameter'
p4608
(lp4609
VA parameter (from the Ancient Greek \u03c0\u03b1\u03c1\u03ac, "para", meaning "beside, subsidiary" and \u03bc\u03ad\u03c4\u03c1\u03bf\u03bd, "metron", meaning "measure"), in its common meaning, is a characteristic, feature, or measurable factor that can help in defining a particular system. A parameter is an important element to consider in evaluation or comprehension of an event, project, or situation. "Parameter" has more specific interpretations in mathematics, logic, linguistics, environmental science, and other disciplines.
p4610
aVMathematical functions.
p4611
aVMathematical functions have one or more arguments that are designated in the definition by variables. A function definition can also contain parameters, but unlike variables, parameters are not listed among the arguments that the function takes. When parameters are present, the definition actually defines a whole family of functions, one for every valid set of values of the parameters. For instance, one could define a general quadratic function by declaring
p4612
aVformula_1;
p4613
aVhere, the variable "x" designates the function's argument, but "a", "b", and "c" are parameters that determine which particular quadratic function is being considered. A parameter could be incorporated into the function name to indicate its dependence on the parameter. For instance, one may define the base "b" of a logarithm by
p4614
aVformula_2
p4615
aVwhere "b" is a parameter that indicates which logarithmic function is being used. It is not an argument of the function, and will, for instance, be a constant when considering the derivative formula_3.
p4616
aVIn some informal situations it is a matter of convention (or historical accident) whether some or all of the symbols in a function definition are called parameters. However, changing the status of symbols between parameter and variable changes the function as a mathematical object. For instance, the notation for the falling factorial power
p4617
aVformula_4,
p4618
aVdefines a polynomial function of "n" (when "k" is considered a parameter), but is not a polynomial function of "k" (when "n" is considered a parameter). Indeed, in the latter case, it is only defined for non-negative integer arguments. More formal presentations of such situations typically start out with a function of several variables (including all those that might sometimes be called "parameters") such as
p4619
aVformula_5
p4620
aVas the most fundamental object being considered, then defining functions with fewer variables from the main one by means of currying.
p4621
aVSometimes it is useful to consider all functions with certain parameters as "parametric family", i.e. as an indexed family of functions. Examples from probability theory are given further below.
p4622
aVMathematical models.
p4623
aVIn the context of a mathematical model, such as a probability distribution, the distinction between variables and parameters was described by Bard as follows:
p4624
aVWe refer to the relations which supposedly describe a certain physical situation, as a "model". Typically, a model consists of one or more equations. The quantities appearing in the equations we classify into "variables" and "parameters". The distinction between these is not always clear cut, and it frequently depends on the context in which the variables appear. Usually a model is designed to explain the relationships that exist among quantities which can be measured independently in an experiment; these are the variables of the model. To formulate these relationships, however, one frequently introduces "constants" which stand for inherent properties of nature (or of the materials and equipment used in a given experiment). These are the parameters.
p4625
aVAnalytic geometry.
p4626
aVIn analytic geometry, curves are often given as the image of some function. The argument of the function is invariably called "the parameter". A circle of radius 1 centered at the origin can be specified in more than one form: 
p4627
aVformula_6
p4628
aVformula_7
p4629
aVwhere "t" is the "parameter".
p4630
aVHence these equations, which might be called functions elsewhere are in analytic geometry characterized as parametric equations and the independent variables are considered as parameters.
p4631
aVMathematical analysis.
p4632
aVIn mathematical analysis, integrals dependent on a parameter are often considered. These are of the form
p4633
aVformula_8
p4634
aVIn this formula, "t" is the argument of the function "F", and on the right-hand side the "parameter" on which the integral depends. When evaluating the integral, "t" is held constant, and so it is considered to be a parameter. If we are interested in the value of "F" for different values of "t", we then consider "t" to be a variable. The quantity "x" is a "dummy variable" or "variable of integration" (confusingly, also sometimes called a "parameter of integration").
p4635
aVStatistics and econometrics.
p4636
aVIn statistics and econometrics, the probability framework above still holds, but attention shifts to estimating the parameters of a distribution based on observed data, or testing hypotheses about them. In classical estimation these parameters are considered "fixed but unknown", but in Bayesian estimation they are treated as random variables, and their uncertainty is described as a distribution.
p4637
aVIn estimation theory of statistics, "statistic" or estimator refers to samples, whereas "parameter" or estimand refers to populations, where the samples are taken from. A statistic is a numerical characteristic of a sample that can be used as an estimate of the corresponding parameter, the numerical characteristic of the population from which the sample was drawn. 
p4638
aVFor example, the sample mean (estimator), denoted formula_9, can be used as an estimate of the "mean" parameter (estimand), denoted "\u03bc", of the population from which the sample was drawn. Similarly, the sample variance (estimator), denoted "S"2, can be used to estimate the "variance" parametor (estimand), denoted "\u03c3"2, of the population from which the sample was drawn. (Note that the sample standard deviation ("S") is not an unbiased estimate of the population standard deviation ("\u03c3"): see Unbiased estimation of standard deviation.)
p4639
aVIt is possible to make statistical inferences without assuming a particular parametric family of probability distributions. In that case, one speaks of "non-parametric statistics" as opposed to the parametric statistics just described. For example, a test based on Spearman's rank correlation coefficient would be called non-parametric since the statistic is computed from the rank-order of the data disregarding their actual values (and thus regardless of the distribution they were sampled from), whereas those based on the Pearson product-moment correlation coefficient are parametric tests since it is computed directly from the data values and thus estimates the parameter known as the population correlation.
p4640
aVProbability theory.
p4641
aV probability theory, one may describe the distribution of a random variable as belonging to a "family" of probability distributions, distinguished from each other by the values of a finite number of "parameters". For example, one talks about "a Poisson distribution with mean value \u03bb". The function defining the distribution (the probability mass function) is:
p4642
aVformula_10
p4643
aVThis example nicely illustrates the distinction between constants, parameters, and variables. "e" is Euler's number, a fundamental mathematical constant. The parameter \u03bb is the mean number of observations of some phenomenon in question, a property characteristic of the system. "k" is a variable, in this case the number of occurrences of the phenomenon actually observed from a particular sample. If we want to know the probability of observing "k"1 occurrences, we plug it into the function to get formula_11. Without altering the system, we can take multiple samples, which will have a range of values of "k", but the system is always characterized by the same \u03bb.
p4644
aVFor instance, suppose we have a radioactive sample that emits, on average, five particles every ten minutes. We take measurements of how many particles the sample emits over ten-minute periods. The measurements exhibit different values of "k", and if the sample behaves according to Poisson statistics, then each value of "k" will come up in a proportion given by the probability mass function above. From measurement to measurement, however, \u03bb remains constant at 5. If we do not alter the system, then the parameter \u03bb is unchanged from measurement to measurement; if, on the other hand, we modulate the system by replacing the sample with a more radioactive one, then the parameter \u03bb would increase.
p4645
aVAnother common distribution is the normal distribution, which has as parameters the mean \u03bc and the variance \u03c3².
p4646
aVIn these above examples, the distributions of the random variables are completely specified by the type of distribution, i.e. Poisson or normal, and the parameter values, i.e. mean and variance. In such a case, we have a parameterized distribution.
p4647
aVIt is possible to use the sequence of moments (mean, mean square, ...) or cumulants (mean, variance, ...) as parameters for a probability distribution: see Statistical parameter.
p4648
aVComputing.
p4649
aVIn computing a parameter is defined as "a reference or value that is passed to a function, procedure, subroutine, command, or program". For example, a program may be passed the name of a file on which it should perform some function.
p4650
aVComputer programming.
p4651
aVIn computer programming two notions of parameter are commonly used, and referred to as parameters and arguments, or more formally (in computer science) as a formal parameter and an actual parameter. In casual usage these are sometimes not distinguished, and the terms "parameter" and "argument" are incorrectly used interchangeably.
p4652
aVIn the definition of a function such as 
p4653
aV"f"("x") = "x" + 2,
p4654
aV"x" is a "formal parameter" ("parameter"). When the function is evaluated, as in 
p4655
aV"f"(3) or "y" = "f"(3) + 5,
p4656
aV3 is the "actual parameter" ("argument"): the value that is substituted for the "formal parameter" used in the function definition.
p4657
aVThese concepts are discussed in a more precise way in functional programming and its foundational disciplines, lambda calculus and combinatory logic. Terminology varies between languages: some computer languages such as C define parameter and argument as given here, while Eiffel for instance uses an alternative convention.
p4658
aVEngineering.
p4659
aVIn engineering (especially involving data acquisition) the term "parameter" sometimes loosely refers to an individual measured item. This usage isn't consistent, as sometimes the term "channel" refers to an individual measured item, with "parameter" referring to the setup information about that channel.
p4660
aV"Speaking generally, properties are those physical quantities which directly describe the physical attributes of the system; parameters are those combinations of the properties which suffice to determine the response of the system. Properties can have all sorts of dimensions, depending upon the system being considered; parameters are dimensionless, or have the dimension of time or its reciprocal."
p4661
aVThe term can also be used in engineering contexts, however, as it is typically used in the physical sciences.
p4662
aVEnvironmental science.
p4663
aVIn environmental science and particularly in chemistry and microbiology, a parameter is used to describe a discrete chemical or microbiological entity which can be assigned a value which is commonly a concentration. The value may also be a logical entity (present or absent), a statistical result such as a 95%ile value or in some cases a subjective value
p4664
aVLinguistics.
p4665
aVWithin linguistics, the word "parameter" is almost exclusively used to denote a binary switch in a Universal Grammar within a Principles and Parameters framework.
p4666
aVLogic.
p4667
aVIn logic, the parameters passed to (or operated on by) an "open predicate" are called "parameters" by some authors (e.g., Prawitz, "Natural Deduction"; Paulson, "Designing a theorem prover"). Parameters locally defined within the predicate are called "variables". This extra distinction pays off when defining substitution (without this distinction special provision must be made to avoid variable capture). Others (maybe most) just call parameters passed to (or operated on by) an open predicate "variables", and when defining substitution have to distinguish between "free variables" and "bound variables".
p4668
aVMusic.
p4669
aVIn music theory, a parameter denotes an element which may be manipulated (composed), separately from the other elements. The term is used particularly for pitch, loudness, duration, and timbre, though theorists or composers have sometimes considered other musical aspects as parameters. The term is particularly used in serial music, where each parameter may follow some specified series. Paul Lansky and George Perle criticized the extension of the word "parameter" to this sense, since it is not closely related to its mathematical sense, but it remains common. The term is also common in music production, as the functions of audio processing units (such as the attack, release, ratio, threshold, and other variables on a compressor) are defined by parameters specific to the type of unit (compressor, equalizer, delay, etc).
p4670
asS'Monster group'
p4671
(lp4672
VIn the mathematical field of group theory, the monster group M or F1 (also known as the Fischer\u2013Griess monster, or the Friendly Giant) is the sporadic group of the highest order, namely:
p4673
aVIt is a "simple group", meaning it does not have any proper non-trivial normal subgroups (that is, the only non-trivial normal subgroup is M itself).
p4674
aVThe finite simple groups have been completely classified, this group consists of 18 countably infinite families, plus 26 sporadic groups that do not follow such a systematic pattern. The monster group is the largest of these sporadic groups and contains all but six of the other sporadic groups as subquotients. Robert Griess has called these six exceptions pariahs, and refers to the others as the "happy family".
p4675
aVExistence and uniqueness.
p4676
aVThe monster was predicted by Bernd Fischer (unpublished) and in about 1973 as a simple group containing a double cover of Fischer's Baby Monster group as a centralizer of an involution. Within a few months the order of M was found by Griess using the Thompson order formula, and Fischer, Conway, Norton and Thompson discovered other groups as subquotients, including many of the known sporadic groups, and two new ones: the Thompson group and the Harada\u2013Norton group. constructed M as the automorphism group of the Griess algebra, a 196884-dimensional commutative nonassociative algebra. and subsequently simplified this construction.
p4677
aVGriess's construction showed that the monster existed. showed that its uniqueness (as a simple group satisfying certain conditions coming from the classification of finite simple groups) would follow from the existence of a 196883-dimensional faithful representation. A proof of the existence of such a representation was announced by , though he has never published the details. gave the first complete published proof of the uniqueness of the monster (more precisely, they showed that a group with the same centralizers of involutions as the monster is isomorphic to the monster).
p4678
aVRepresentations.
p4679
aVThe minimal degree of a faithful complex representation is 196883, which is the product of the 3 largest prime divisors of the order of M.
p4680
aVThe character table of the monster, a 194-by-194 array, was calculated in 1979 by Fischer and Donald Livingstone using computer programs written by Michael Thorne. The smallest faithful linear representation over any field has dimension 196882 over the field with 2 elements, only 1 less than the dimension of the smallest faithful complex representation.
p4681
aVThe smallest faithful permutation representation of the monster is on 
p4682
aV24 · 37 · 53 · 74 · 11 · 132 · 29 · 41 · 59 · 71 (about 1020)
p4683
aVpoints.
p4684
aVThe monster can be realized as a Galois group over the rational numbers , and as a Hurwitz group .
p4685
aVThe monster is unusual among simple groups in that there is no known easy way to represent its elements. This is not due so much to its size as to the absence of "small" representations. For example, the simple groups "A"100 and SL20(2) are far larger, but easy to calculate with as they have "small" permutation or linear representations. The alternating groups have permutation representations that are "small" compared to the size of the group, and all finite simple groups of Lie type have linear representations that are "small" compared to the size of the group. All sporadic groups other than the monster also have linear representations small enough that they are easy to work with on a computer (the next hardest case after the monster is the baby monster, with a representation of dimension 4370).
p4686
aVA computer construction.
p4687
aVRobert A. Wilson has found explicitly (with the aid of a computer) two 196882 by 196882 matrices (with elements in the field of order 2) which together generate the monster group; this is one dimension lower than the 196883-dimensional representation in characteristic 0. Performing calculations with these matrices is possible but is too expensive in terms of time and storage space to be useful. Wilson with collaborators has found a method of performing calculations with the monster that is considerably faster.
p4688
aVLet "V" be a 196882 dimensional vector space over the field with 2 elements. A large subgroup "H" (preferably a maximal subgroup) of the monster is selected in which it is easy to perform calculations. The subgroup "H" chosen is 31+12.2.Suz.2, where Suz is the Suzuki group. Elements of the monster are stored as words in the elements of "H" and an extra generator "T". It is reasonably quick to calculate the action of one of these words on a vector in "V". Using this action, it is possible to perform calculations (such as the order of an element of the monster). Wilson has exhibited vectors "u" and "v" whose joint stabilizer is the trivial group. Thus (for example) one can calculate the order of an element "g" of the monster by finding the smallest "i" > 0 such that "g""i""u" = "u" and "g""i""v" = "v".
p4689
aVThis and similar constructions (in different characteristics) have been used to find some of its non-local maximal subgroups.
p4690
aVMoonshine.
p4691
aVThe monster group is one of two principal constituents in the Monstrous moonshine conjecture by Conway and Norton, which relates discrete and non-discrete mathematics and was finally proved by Richard Borcherds in 1992.
p4692
aVIn this setting, the monster group is visible as the automorphism group of the monster module, a vertex operator algebra, an infinite dimensional algebra containing the Griess algebra, and acts on the monster Lie algebra, a generalized Kac\u2013Moody algebra.
p4693
aVMcKay's E8 observation.
p4694
aVThere are also connections between the monster and the extended Dynkin diagrams formula_1 specifically between the nodes of the diagram and certain conjugacy classes in the monster, known as "McKay's E8 observation". This is then extended to a relation between the extended diagrams formula_2 and the groups 3."Fi"24', 2."B", and "M", where these are (3/2/1-fold central extensions) of the Fischer group, baby monster group, and monster. These are the sporadic groups associated with centralizers of elements of type 1A, 2A, and 3A in the monster, and the order of the extension corresponds to the symmetries of the diagram. See ADE classification: trinities for further connections (of McKay correspondence type), including (for the monster) with the rather small simple group PSL(2,11) and with the 120 tritangent planes of a canonic sextic curve of genus 4.
p4695
aVSubgroup structure.
p4696
aVThe monster has at least 44 conjugacy classes of maximal subgroups. Non-abelian simple groups of some 60 isomorphism types are found as subgroups or as quotients of subgroups. The largest alternating group represented is A12.
p4697
aVThe monster contains 20 of the 26 sporadic groups as subquotients. This diagram, based on one in the book "Symmetry and the monster" by Mark Ronan, shows how they fit together. The lines signify inclusion, as a subquotient, of the lower group by the upper one. The circled symbols denote groups not involved in larger sporadic groups. For the sake of clarity redundant inclusions are not shown.
p4698
aV44 of the classes of maximal subgroups of the monster are given by the following list, which is (as of 2013) believed to be complete except possibly for almost simple subgroups with non-abelian simple socles of the form L2(13), U3(4), U3(8) or Suz(8) , . However, tables of maximal subgroups have often been found to contain subtle errors, and in particular at least two of the subgroups on the list below were incorrectly omitted in some previous lists. 
p4699
aV2.B Centralizer of an involution; contains the normalizer (47:23) × 2 of a Sylow 47-subgroup. 
p4700
aV21+24.Co1 Centralizer of an involution. 
p4701
aV3.Fi24 Normalizer of a subgroup of order 3; contains the normalizer ((29:14) × 3).2 of a Sylow 29-subgroup. 
p4702
aV22.2E6(22):S3 Normalizer of a Klein 4-group. 
p4703
aV210+16.O10+(2)
p4704
aV22+11+22.(M24 × S3) Normalizer of a Klein 4-group; contains the normalizer (23:11) × S4 of a Sylow 23-subgroup. 
p4705
aV31+12.2Suz.2 Normalizer of a subgroup of order 3.
p4706
aV25+10+20.(S3 × L5(2))
p4707
aVS3 × Th Normalizer of a subgroup of order 3; contains the normalizer (31:15) × S3 of a Sylow 31-subgroup. 
p4708
aV23+6+12+18.(L3(2) × 3S6)
p4709
aV38.O8\u2212(3).23
p4710
aV(D10 × HN).2 Normalizer of a subgroup of order 5.
p4711
aV(32:2 × O8+(3)).S4
p4712
aV32+5+10.(M11 × 2S4)
p4713
aV33+2+6+6:(L3(3) × SD16)
p4714
aV51+6:2J2:4 Normalizer of a subgroup of order 5.
p4715
aV(7:3 × He):2 Normalizer of a subgroup of order 7.
p4716
aV(A5 × A12):2
p4717
aV53+3.(2 × L3(5))
p4718
aV(A5 × U3(8):31):2 Contains the normalizer ((19:9) × A5):2 of a Sylow 19-subgroup. 
p4719
aV52+2+4:(S3 × GL2(5))
p4720
aV(L3(2) × S4(4):2).2 Contains the normalizer ((17:8) × L3(2)).2 of a Sylow 17-subgroup. 
p4721
aV71+4:(3 × 2S7) Normalizer of a subgroup of order 7.
p4722
aV(52:4.22 × U3(5)).S3
p4723
aV(L2(11) × M12):2 Contains the normalizer (11:5 × M12):2 of a subgroup of order 11.
p4724
aV(A7 × (A5 × A5):22):2
p4725
aV54:(3 × 2L2(25)):22
p4726
aV72+1+2:GL2(7)
p4727
aVM11 × A6.22
p4728
aV(S5 × S5 × S5):S3
p4729
aV(L2(11) × L2(11)):4
p4730
aV132:2L2(13).4
p4731
aV(72:(3 × 2A4) × L2(7)):2
p4732
aV(13:6 × L3(3)).2 Normalizer of a subgroup of order 13.
p4733
aV131+2:(3 × 4S4) Normalizer of a subgroup of order 13; normalizer of a Sylow 13-subgroup. 
p4734
aVL2(71) Contains the normalizer 71:35 of a Sylow 71-subgroup. 
p4735
aVL2(59) Contains the normalizer 59:29 of a Sylow 59-subgroup. 
p4736
aV112:(5 × 2A5) Normalizer of a Sylow 11-subgroup. 
p4737
aVL2(41) found a maximal subgroup of this form; due to a subtle error, some previous lists and papers stated that no such maximal subgroup existed.
p4738
aVL2(29):2 
p4739
aV72:SL2(7) This was accidentally omitted on some previous lists of 7-local subgroups. 
p4740
aVL2(19):2 
p4741
aV41:40 Normalizer of a Sylow 41-subgroup. 
p4742
asS'3D'
p4743
(lp4744
V3D or 3-D may refer to:
p4745
asS'Identity (mathematics)'
p4746
(lp4747
VIn mathematics an identity is an equality relation "A" = "B", such that "A" and "B" contain some variables and "A" and "B" produce the same value as each other regardless of what values (usually numbers) are substituted for the variables. In other words, "A" = "B" is an identity if "A" and "B" define the same functions. This means that an "identity" is an "equality" between functions that are differently defined. For example ("a" + "b")2  =  "a"2 + 2"ab" + "b"2 and are identities. Identities are sometimes indicated by the triple bar symbol \u2261 instead of =, the equals sign.
p4748
aVCommon identities.
p4749
aVTrigonometric identities.
p4750
aVGeometrically, these are identities involving certain functions of one or more angles. They are distinct from triangle identities, which are identities involving both angles and side lengths of a triangle. Only the former are covered in this article.
p4751
aVThese identities are useful whenever expressions involving trigonometric functions need to be simplified. An important application is the integration of non-trigonometric functions: a common technique involves first using the substitution rule with a trigonometric function, and then simplifying the resulting integral with a trigonometric identity.
p4752
aVOne example is :formula_1
p4753
aVwhich is true for all complex values of formula_2 (since the complex numbers formula_3 are the domain of sin and cos), as opposed to
p4754
aVformula_4
p4755
aVwhich is true only for some values of formula_2, not all. For example, the latter equation is true when formula_6 false when formula_7. 
p4756
aVExponential identities.
p4757
aVThe following identities hold for all integer exponents, provided that the base is non-zero:
p4758
aVformula_8
p4759
aVExponentiation is not commutative. This contrasts with addition and multiplication, which are. For example, and , but , whereas .
p4760
aVExponentiation is not associative either. Addition and multiplication are. For example,
p4761
aVformula_9
p4762
aVLogarithmic identities.
p4763
aVSeveral important formulas, sometimes called "logarithmic identities" or "log laws", relate logarithms to one another.
p4764
aVProduct, quotient, power and root.
p4765
aVThe logarithm of a product is the sum of the logarithms of the numbers being multiplied; the logarithm of the ratio of two numbers is the difference of the logarithms. The logarithm of the power of a number is "p" times the logarithm of the number itself; the logarithm of a root is the logarithm of the number divided by "p". The following table lists these identities with examples. Each of the identities can be derived after substitution of the logarithm definitions x = blogb(x), and/or y = blogb(y), in the left hand sides.
p4766
aVChange of base.
p4767
aVThe logarithm log"b"("x") can be computed from the logarithms of "x" and "b" with respect to an arbitrary base "k" using the following formula:
p4768
aV formula_10
p4769
aVTypical scientific calculators calculate the logarithms to bases 10 and "e". Logarithms with respect to any base "b" can be determined using either of these two logarithms by the previous formula:
p4770
aVformula_11
p4771
aVGiven a number "x" and its logarithm log"b"("x") to an unknown base "b", the base is given by:
p4772
aV formula_12
p4773
aVHyperbolic function identities.
p4774
aVThe hyperbolic functions satisfy many identities, all of them similar in form to the trigonometric identities. In fact, Osborn's rule states that one can convert any trigonometric identity into a hyperbolic identity by expanding it completely in terms of integral powers of sines and cosines, changing sine to sinh and cosine to cosh, and switching the sign of every term which contains a product of 2, 6, 10, 14, ... sinhs.
p4775
aVThe Gudermannian function gives a direct relationship between the circular functions and the hyperbolic ones that does not involve complex numbers.
p4776
asS'Hyperplane arrangements'
p4777
(lp4778
sS'Nth root'
p4779
(lp4780
VIn mathematics, the ""'n"th root"' of a number "x", where "n" is a positive integer, is a number "r" which, when raised to the power "n" yields "x"
p4781
aVformula_1
p4782
aVwhere "n" is the "degree" of the root. A root of degree 2 is called a "square root" and a root of degree 3, a "cube root". Roots of higher degree are referred by using ordinal numbers, as in "fourth root", "twentieth root", etc.
p4783
aVFor example:
p4784
aVA real number or complex number has "n" roots of degree "n". While the roots of 0 are not distinct (all equaling 0), the "n" "n"th roots of any other real or complex number are all distinct. If "n" is even and "x" is real and positive, one of its "n"th roots is positive, one is negative, and the rest are complex but not real; if "n" is even and "x" is real and negative, none of the "n"th roots is real. If "n" is odd and "x" is real, one "n"th root is real and has the same sign as "x" , while the other roots are not real. Finally, if "x" is not real, then none of its "n"th roots is real.
p4785
aVRoots are usually written using the radical symbol or "radix" formula_2 or formula_3, with formula_4 or formula_5 denoting the square root, formula_6 denoting the fourth root, and so on. In the expression formula_7, "n" is called the index, formula_2 is the radical sign or "radix", and "x" is called the radicand. Since the radical symbol denotes a function, when a number is presented under the radical symbol it must return only one result, so a non-negative real root, called the '"principal "n"th root, is preferred rather than others; if the only real root is negative, as for the cube root of \u20138, again the real root is considered the principal root. An unresolved root, especially one using the radical symbol, is often referred to as a surd or a radical. Any expression containing a radical, whether it is a square root, a cube root, or a higher root, is called a radical expression, and if it contains no transcendental functions or transcendental numbers it is called an algebraic expression.
p4786
aVIn calculus, roots"' are treated as special cases of exponentiation, where the exponent is a fraction:
p4787
aVformula_9
p4788
aVRoots are particularly important in the theory of infinite series; the root test determines the radius of convergence of a power series. "Nth roots" can also be defined for complex numbers, and the complex roots of 1 (the roots of unity) play an important role in higher mathematics. Galois theory can be used to determine which algebraic numbers can be expressed using roots, and to prove the Abel-Ruffini theorem, which states that a general polynomial equation of degree five or higher cannot be solved using roots alone; this result is also known as "the insolubility of the quintic".
p4789
aVEtymology.
p4790
aVOrigin of the root symbol.
p4791
aVThe origin of the root symbol \u221a is largely speculative. Some sources imply that the symbol was first used by Arabic mathematicians. One of those mathematicians was Ab\u016b al-Hasan ibn Al\u012b al-Qalas\u0101d\u012b ("1421\u20131486"). Legend has it that it was taken from the Arabic letter ("\u01e7\u012bm," ), which is the first letter in the Arabic word ("jadhir", meaning "root"; ). However, many scholars, including Leonhard Euler, believe it originates from the letter "r", the first letter of the Latin word "radix" (meaning "root"), referring to the same mathematical operation. The symbol was first seen in print without the vinculum (the horizontal "bar" over the numbers inside the radical symbol) in the year 1525 in "Die Coss" by Christoff Rudolff, a German mathematician.
p4792
aVThe Unicode and HTML character codes for the radical symbols are:
p4793
aVEtymology of "surd".
p4794
aVThe term "surd" traces back to al-Khw\u0101rizm\u012b (c. 825), who referred to rational and irrational numbers as "audible" and "inaudible", respectively. This later led to the Arabic word "" ("asamm", meaning "deaf" or "dumb") for "irrational number" being translated into Latin as "surdus" (meaning "deaf" or "mute"). Gerard of Cremona (c. 1150), Fibonacci (1202), and then Robert Recorde (1551) all used the term to refer to "unresolved irrational roots".
p4795
aVDefinition and notation.
p4796
aVAn ""'n"th root"' of a number "x", where "n" is a positive integer, is any of the "n" real or complex numbers "r" whose "n"th power is "x":
p4797
aVformula_10
p4798
aVEvery positive real number "x" has a single positive "n"th root, called the principal "n"th root, which is written formula_7. For "n" equal to 2 this is called the principal square root and the "n" is omitted. The "n"th root can also be represented using exponentiation as "x"1/n.
p4799
aVFor even values of "n", positive numbers also have a negative "n"th root, while negative numbers do not have a real "n"th root. For odd values of "n", every negative number "x" has a real negative "n"th root. For example, \u22122 has a real 5th root, formula_12 but \u22122 does not have any real 6th roots.
p4800
aVEvery non-zero number "x", real or complex, has "n" different complex number "n"th roots including any positive or negative roots. They are all distinct except in the case of "x" = 0, all of whose "n"th roots equal 0.
p4801
aVThe "n"th roots of almost all numbers (all integers except the "n"th powers, and all rationals except the quotients of two "n"th powers) are irrational. For example,
p4802
aVformula_13
p4803
aVAll "n"th roots of integers, and in fact of all algebraic numbers, are algebraic.
p4804
aVSquare roots.
p4805
aVA square root of a number "x" is a number "r" which, when squared, becomes "x":
p4806
aVformula_14
p4807
aVEvery positive real number has two square roots, one positive and one negative. For example, the two square roots of 25 are 5 and \u22125. The positive square root is also known as the principal square root, and is denoted with a radical sign:
p4808
aVformula_15
p4809
aVSince the square of every real number is a positive real number, negative numbers do not have real square roots. However, every negative number has two imaginary square roots. For example, the square roots of \u221225 are 5"i" and \u22125"i", where "i" represents a square root of \u22121.
p4810
aVCube roots.
p4811
aV[function.svg|thumb|right|The graph formula_16.]]
p4812
aVA cube root of a number "x" is a number "r" whose cube is "x":
p4813
aVformula_17
p4814
aVEvery real number "x" has exactly one real cube root, written formula_7. For example,
p4815
aVformula_19
p4816
aVEvery real number has two additional complex cube roots.
p4817
aVIdentities and properties.
p4818
aVEvery positive real number has a positive "n"th root and the rules for operations with such surds are straightforward:
p4819
aVformula_20
p4820
aVformula_21
p4821
aVUsing the exponent form as in formula_22 normally makes it easier to cancel out powers and roots.
p4822
aVformula_23
p4823
aVProblems can occur when taking the "n"th roots of negative or complex numbers. For instance:
p4824
aVformula_24
p4825
aVwhereas
p4826
aVformula_25
p4827
aVwhen taking the principal value of the roots.
p4828
aVSimplified form of a radical expression.
p4829
aVA non-nested radical expression is said to be in simplified form if
p4830
aVFor example, to write the radical expression formula_26 in simplified form, we can proceed as follows. First, look for a perfect square under the square root sign and remove it: 
p4831
aVformula_27
p4832
aVNext, there is a fraction under the radical sign, which we change as follows:
p4833
aVformula_28
p4834
aVFinally, we remove the radical from the denominator as follows:
p4835
aVformula_29
p4836
aVWhen there is a denominator involving surds it is always possible to find a factor to multiply both numerator and denominator by to simplify the expression. For instance using the factorization of the sum of two cubes:
p4837
aVformula_30
p4838
aVSimplifying radical expressions involving nested radicals can be quite difficult. It is not immediately obvious for instance that:
p4839
aVformula_31
p4840
aVInfinite series.
p4841
aVThe radical or root may be represented by the infinite series:
p4842
aVformula_32
p4843
aVwith formula_33. This expression can be derived from the binomial series.
p4844
aVComputing principal roots.
p4845
aVThe "n"th root of an integer is not always an integer, and if it is not an integer then it is not a rational number. For instance, the fifth root of 34 is
p4846
aVformula_34
p4847
aVwhere the dots signify that the decimal expression does not end after any finite number of digits. Since in this example the digits after the decimal never enter a repeating pattern, the number is irrational.
p4848
aVn-th root algorithm.
p4849
aVThe "n"th root of a number "A" can be computed by the "n"th root algorithm, a special case of Newton's method. Start with an initial guess "x"0 and then iterate using the recurrence relation
p4850
aVformula_35
p4851
aVuntil the desired precision is reached.
p4852
aVDepending on the application, it may be enough to use only the first Newton approximant:
p4853
aVformula_36
p4854
aVFor example, to find the fifth root of 34, note that 25 = 32 and thus take "x" = 2, "n" = 5 and "y" = 2 in the above formula. This yields
p4855
aVformula_37
p4856
aVThe error in the approximation is only about 0.03%.
p4857
aVNewton's method can be modified to produce a generalized continued fraction for the "n"th root which can be modified in various ways as described in that article. For example:
p4858
aVformula_38
p4859
aVformula_39
p4860
aVIn the case of the fifth root of 34 above (after dividing out selected common factors):
p4861
aVformula_40
p4862
aVDigit-by-digit calculation of principal roots of decimal (base 10) numbers.
p4863
aVBuilding on the digit-by-digit calculation of a square root, it can be seen that the formula used there, formula_41, or formula_42, follows a pattern involving Pascal's triangle. For the "n"th root of a number formula_43 is defined as the value of element formula_44 in row formula_45 of Pascal's Triangle such that formula_46, we can rewrite the expression as formula_47. For convenience, call the result of this expression formula_48. Using this more general expression, any positive principal root can be computed, digit-by-digit, as follows.
p4864
aVWrite the original number in decimal form. The numbers are written similar to the long division algorithm, and, as in long division, the root will be written on the line above. Now separate the digits into groups of digits equating to the root being taken, starting from the decimal point and going both left and right. The decimal point of the root will be above the decimal point of the square. One digit of the root will appear above each group of digits of the original number.
p4865
aVBeginning with the left-most group of digits, do the following procedure for each group:
p4866
aVExamples.
p4867
aVFind the square root of 152.2756.
p4868
aVFind the cube root of 4192 to the nearest hundredth.
p4869
aVLogarithmic computation.
p4870
aVThe principal "n"th root of a positive number can be computed using logarithms. Starting from the equation that defines "r" as an "n"th root of "x", namely formula_57 with "x" positive and therefore its principal root "r" also positive, one takes logarithms of both sides (any base of the logarithm will do; base 10 is used here) to obtain
p4871
aVformula_58
p4872
aVThe root "r" is recovered from this by taking the antilog:
p4873
aVformula_59
p4874
aVFor the case in which "x" is negative and "n" is odd, there is one real root "r" which is also negative. This can be found by first multiplying both sides of the defining equation by \u20131 to obtain formula_60 then proceeding as before to find |"r" |, and using "r" = \u2013|"r" |.
p4875
aVGeometric constructibility.
p4876
aVThe ancient Greek mathematicians knew how to use compass and straightedge to construct a length equal to the square root of a given length. In 1837 Pierre Wantzel proved that an "n"th root of a given length cannot be constructed if "n" > 2.
p4877
aVComplex roots.
p4878
aVEvery complex number other than 0 has "n" different "n"th roots.
p4879
aVSquare roots.
p4880
aVThe two square roots of a complex number are always negatives of each other. For example, the square roots of are and , and the square roots of are
p4881
aVformula_61
p4882
aVIf we express a complex number in polar form, then the square root can be obtained by taking the square root of the radius and halving the angle:
p4883
aVformula_62
p4884
aVA "principal" root of a complex number may be chosen in various ways, for example
p4885
aVformula_63
p4886
aVwhich introduces a branch cut in the complex plane along the positive real axis with the condition , or along the negative real axis with .
p4887
aVUsing the first(last) branch cut the principal square root formula_64 maps formula_65 to the half plane with non-negative imaginary(real) part. The last branch cut is presupposed in mathematical software like Matlab or Scilab.
p4888
aVRoots of unity.
p4889
aVThe number 1 has "n" different "n"th roots in the complex plane, namely
p4890
aVformula_66
p4891
aVwhere
p4892
aVformula_67
p4893
aVThese roots are evenly spaced around the unit circle in the complex plane, at angles which are multiples of formula_68. For example, the square roots of unity are 1 and \u22121, and the fourth roots of unity are 1, formula_44, \u22121, and formula_70.
p4894
aV"n"th roots.
p4895
aVEvery complex number has "n" different "n"th roots in the complex plane. These are
p4896
aVformula_71
p4897
aVwhere "\u03b7" is a single "n"th root, and 1, "\u03c9", "\u03c9"2, ... "\u03c9""n"\u22121 are the "n"th roots of unity. For example, the four different fourth roots of 2 are
p4898
aVformula_72
p4899
aVIn polar form, a single "n"th root may be found by the formula
p4900
aVformula_73
p4901
aVHere "r" is the magnitude (the modulus, also called the absolute value) of the number whose root is to be taken; if the number can be written as "a+bi" then formula_74. Also, formula_75 is the angle formed as one pivots on the origin counterclockwise from the positive horizontal axis to a ray going from the origin to the number; it has the properties that formula_76 formula_77 and formula_78
p4902
aVThus finding "n"th roots in the complex plane can be segmented into two steps. First, the magnitude of all the "n"th roots is the "n"th root of the magnitude of the original number. Second, the angle between the positive horizontal axis and a ray from the origin to one of the "n"th roots is formula_79, where formula_75 is the angle defined in the same way for the number whose root is being taken. Furthermore, all "n" of the "n"th roots are at equally spaced angles from each other.
p4903
aVIf "n" is even, a complex number's "n"th roots, of which there are an even number, come in additive inverse pairs, so that if a number "r"1 is one of the "n"th roots then "r"2 = \u2013"r"1 is another. This is because raising the latter's coefficient \u20131 to the "n"th power for even "n" yields 1: that is, (\u2013"r"1)"n" = (\u20131)"n" × "r"1"n" = "r"1"n".
p4904
aVAs with square roots, the formula above does not define a continuous function over the entire complex plane, but instead has a branch cut at points where "\u03b8" / "n" is discontinuous.
p4905
aVSolving polynomials.
p4906
aVIt was once conjectured that all polynomial equations could be solved algebraically (that is, that all roots of a polynomial could be expressed in terms of a finite number of radicals and elementary operations). However, while this is true for third degree polynomials (cubics) and fourth degree polynomials (quartics), the Abel-Ruffini theorem (1824) shows that this is not true in general when the degree is 5 or greater. For example, the solutions of the equation
p4907
aVformula_81
p4908
aVcannot be expressed in terms of radicals. ("cf." quintic equation)
p4909
asS'Random walk'
p4910
(lp4911
VA random walk is a mathematical formalization of a path that consists of a succession of random steps. For example, the path traced by a molecule as it travels in a liquid or a gas, the search path of a foraging animal, the price of a fluctuating stock and the financial status of a gambler can all be "modeled" as random walks, although they may not be truly random in reality. The term "random walk" was first introduced by Karl Pearson in 1905. Random walks have been used in many fields: ecology, economics, psychology, computer science, physics, chemistry, and biology. Random walks explain the observed behaviors of many processes in these fields, and thus serve as a fundamental model for the recorded stochastic activity.
p4912
aVVarious different types of random walks are of interest. Often, random walks are assumed to be Markov chains or Markov processes, but other, more complicated walks are also of interest. Some random walks are on graphs, others on the line, in the plane, in higher dimensions, or even curved surfaces, while some random walks are on groups. Random walks also vary with regard to the time parameter. Often, the walk is in discrete time, and indexed by the natural numbers, as in formula_1. However, some walks take their steps at random times, and in that case the position formula_2 is defined for the continuum of times formula_3. Specific cases or limits of random walks include the Lévy flight. Random walks are related to the diffusion models and are a fundamental topic in discussions of Markov processes. Several properties of random walks, including dispersal distributions, first-passage times and encounter rates, have been extensively studied.
p4913
aVLattice random walk.
p4914
aVA popular random walk model is that of a random walk on a regular lattice, where at each step the location jumps to another site according to some probability distribution. In a simple random walk, the location can only jump to neighboring sites of the lattice, forming a lattice path. In simple symmetric random walk on a locally finite lattice, the probabilities of the location jumping to each one of its immediate neighbours are the same. The best studied example is of random walk on the "d"-dimensional integer lattice (sometimes called the hypercubic lattice) formula_4.
p4915
aVOne-dimensional random walk.
p4916
aVAn elementary example of a random walk is the random walk on the integer number line, formula_5, which starts at 0 and at each step moves +1 or \u22121 with equal probability.
p4917
aVThis walk can be illustrated as follows. A marker is placed at zero on the number line and a fair coin is flipped. If it lands on heads, the marker is moved one unit to the right. If it lands on tails, the marker is moved one unit to the left. After five flips, the marker could now be on 1, \u22121, 3, \u22123, 5, or \u22125. With five flips, three heads and two tails, in any order, will land on 1. There are 10 ways of landing on 1 (by flipping three heads and two tails), 10 ways of landing on \u22121 (by flipping three tails and two heads), 5 ways of landing on 3 (by flipping four heads and one tail), 5 ways of landing on \u22123 (by flipping four tails and one head), 1 way of landing on 5 (by flipping five heads), and 1 way of landing on \u22125 (by flipping five tails). See the figure below for an illustration of the possible outcomes of 5 flips.
p4918
aV[walk 2500.svg|right|thumb|280px|Random walk in two dimensions ([http://upload.wikimedia.org/wikipedia/commons/f/f3/Random_walk_2500_animated.svg animated version)]]
p4919
aV[walk 25000 not animated.svg|right|thumb|280px|Random walk in two dimensions with 25 thousand steps ([http://upload.wikimedia.org/wikipedia/commons/c/cb/Random_walk_25000.svg animated version)]]
p4920
aVTo define this walk formally, take independent random variables formula_6, where each variable is either 1 or \u22121, with a 50% probability for either value, and set formula_7 and formula_8 The series formula_9 is called the simple random walk on formula_5. This series (the sum of the sequence of \u22121s and 1s) gives the distance walked, if each part of the walk is of length one.
p4921
aVThe expectation formula_11 of formula_12 is zero. That is, the mean of all coin flips approaches zero as the number of flips increases. This follows by the finite additivity property of expectation:
p4922
aVformula_13
p4923
aVA similar calculation, using the independence of the random variables and the fact that formula_14, shows that:
p4924
aVformula_15
p4925
aVThis hints that formula_16, the expected translation distance after "n" steps, should be of the order of formula_17. In fact,
p4926
aVformula_18
p4927
aVThis result shows that diffusion is ineffective for mixing because of the way the square root behaves for large formula_19.
p4928
aVHow many times will a random walk cross a boundary line if permitted to continue walking forever? A simple random walk on formula_5 will cross every point an infinite number of times. This result has many names: the "level-crossing phenomenon", "recurrence" or the "gambler's ruin". The reason for the last name is as follows: a gambler with a finite amount of money will eventually lose when playing "a fair game" against a bank with an infinite amount of money. The gambler's money will perform a random walk, and it will reach zero at some point, and the game will be over.
p4929
aVIf "a" and "b" are positive integers, then the expected number of steps until a one-dimensional simple random walk starting at 0 first hits "b" or \u2212"a" is "ab". The probability that this walk will hit "b" before \u2212"a" is formula_21, which can be derived from the fact that simple random walk is a martingale.
p4930
aVSome of the results mentioned above can be derived from properties of Pascal's triangle. The number of different walks of "n" steps where each step is +1 or \u22121 is 2"n". For the simple random walk, each of these walks are equally likely. In order for "Sn" to be equal to a number "k" it is necessary and sufficient that the number of +1 in the walk exceeds those of \u22121 by "k". The number of walks which satisfy formula_22 is equally the number of ways of choosing ("n" + "k")/2 elements from an "n" element set, denoted formula_23. For this to be non-zero, it is necessary that "n" + "k" be an even number. Therefore, the probability that formula_22 is equal to formula_25. By representing entries of Pascal's triangle in terms of factorials and using Stirling's formula, one can obtain good estimates for these probabilities for large values of formula_26.
p4931
aVIf the space is confined to formula_5+ for brevity, the number of ways in which a random walk will land on any given number having five flips can be shown as {0,5,0,4,0,1}.
p4932
aVThis relation with Pascal's triangle is demonstrated for small values of "n". At zero turns, the only possibility will be to remain at zero. However, at one turn, there is one chance of landing on \u22121 or one chance of landing on 1. At two turns, a marker at 1 could move to 2 or back to zero. A marker at \u22121, could move to \u22122 or back to zero. Therefore, there is one chance of landing on \u22122, two chances of landing on zero, and one chance of landing on 2.
p4933
aVThe central limit theorem and the law of the iterated logarithm describe important aspects of the behavior of simple random walks on formula_5. In particular, the former entails that as "n" increases, the probabilities (proportional to the numbers in each row) approach a normal distribution.
p4934
aVAs a direct generalization, one can consider random walks on crystal lattices (infinite-fold abelian covering graphs over finite graphs). Actually it is possible to establish the central limit theorem and large deviation theorem in this setting
p4935
aVAs a Markov chain.
p4936
aVA one-dimensional random walk can also be looked at as a Markov chain whose state space is given by the integers formula_29 For some number "p" satisfying formula_30, the transition probabilities (the probability "Pi,j" of moving from state "i" to state "j") are given by
p4937
aVformula_31
p4938
aVHigher dimensions.
p4939
aVImagine now a drunkard walking randomly in an idealized city. The city is effectively infinite and arranged in a square grid, and at every intersection, the drunkard chooses one of the four possible routes (including the one he came from) with equal probability. Formally, this is a random walk on the set of all points in the plane with integer coordinates.
p4940
aVWill the drunkard ever get back to his home from the bar? This is the 2-dimensional equivalent of the level crossing problem discussed above. It turns out that he almost surely will in a 2-dimensional random walk, but for 3 dimensions or higher, the probability of returning to the origin decreases as the number of dimensions increases. In 3 dimensions, the probability decreases to roughly 34%.
p4941
aVThe trajectory of a random walk is the collection of sites it visited, considered as a set with disregard to "when" the walk arrived at the point. In one dimension, the trajectory is simply all points between the minimum height the walk achieved and the maximum (both are, on average, on the order of \u221a"n"). In higher dimensions the set has interesting geometric properties. In fact, one gets a discrete fractal, that is a set which exhibits stochastic self-similarity on large scales, but on small scales one can observe "jaggedness" resulting from the grid on which the walk is performed. The two books of Lawler referenced below are a good source on this topic.
p4942
aVRelation to Wiener process.
p4943
aVA Wiener process is a stochastic process with similar behaviour to Brownian motion, the physical phenomenon of a minute particle diffusing in a fluid. (Sometimes the Wiener process is called "Brownian motion", although this is strictly speaking a confusion of a model with the phenomenon being modeled.)
p4944
aVA Wiener process is the scaling limit of random walk in dimension 1. This means that if you take a random walk with very small steps you get an approximation to a Wiener process (and, less accurately, to Brownian motion). To be more precise, if the step size is \u03b5, one needs to take a walk of length "L"/\u03b52 to approximate a Wiener length of "L". As the step size tends to 0 (and the number of steps increases proportionally) random walk converges to a Wiener process in an appropriate sense. Formally, if "B" is the space of all paths of length "L" with the maximum topology, and if "M" is the space of measure over "B" with the norm topology, then the convergence is in the space "M". Similarly, a Wiener process in several dimensions is the scaling limit of random walk in the same number of dimensions.
p4945
aVA random walk is a discrete fractal (a function with integer dimensions; 1, 2, ...), but a Wiener process trajectory is a true fractal, and there is a connection between the two. For example, take a random walk until it hits a circle of radius "r" times the step length. The average number of steps it performs is "r"2. This fact is the "discrete version" of the fact that a Wiener process walk is a fractal of Hausdorff dimension 2.
p4946
aVIn two dimensions, the average number of points the same random walk has on the "boundary" of its trajectory is "r"4/3. This corresponds to the fact that the boundary of the trajectory of a Wiener process is a fractal of dimension 4/3, a fact predicted by Mandelbrot using simulations but proved only in 2000
p4947
aVby Lawler, Schramm and Werner.
p4948
aVA Wiener process enjoys many symmetries random walk does not. For example, a Wiener process walk is invariant to rotations, but random walk is not, since the underlying grid is not (random walk is invariant to rotations by 90 degrees, but Wiener processes are invariant to rotations by, for example, 17 degrees too). This means that in many cases, problems on random walk are easier to solve by translating them to a Wiener process, solving the problem there, and then translating back. On the other hand, some problems are easier to solve with random walks due to its discrete nature.
p4949
aVRandom walk and Wiener process can be "coupled", namely manifested on the same probability space in a dependent way that forces them to be quite close. The simplest such coupling is the Skorokhod embedding, but other, more precise couplings exist as well.
p4950
aVThe convergence of a random walk toward the Wiener process is controlled by the central limit theorem. For a particle in a known fixed position at "t" = 0, the theorem tells us that after a large number of independent steps in the random walk, the walker's position is distributed according to a normal distribution of total variance:
p4951
aVformula_32
p4952
aVwhere "t" is the time elapsed since the start of the random walk, formula_33 is the size of a step of the random walk, and formula_34 is the time elapsed between two successive steps.
p4953
aVThis corresponds to the Green function of the diffusion equation that controls the Wiener process, which demonstrates that, after a large number of steps, the random walk converges toward a Wiener process.
p4954
aVIn 3D, the variance corresponding to the Green's function of the diffusion equation is:
p4955
aVformula_35
p4956
aVBy equalizing this quantity with the variance associated to the position of the random walker, one obtains the equivalent diffusion coefficient to be considered for the asymptotic Wiener process toward which the random walk converges after a large number of steps:
p4957
aVformula_36 (valid only in 3D)
p4958
aVRemark: the two expressions of the variance above correspond to the distribution associated to the vector formula_37 that links the two ends of the random walk, in 3D. The variance associated to each component formula_38, formula_39 or formula_40 is only one third of this value (still in 3D).
p4959
aVGaussian random walk.
p4960
aVA random walk having a step size that varies according to a normal distribution is used as a model for real-world time series data such as financial markets. The Black\u2013Scholes formula for modeling option prices, for example, uses a Gaussian random walk as an underlying assumption.
p4961
aVHere, the step size is the inverse cumulative normal distribution formula_41 where 0 \u2264 "z" \u2264 1 is a uniformly distributed random number, and \u03bc and \u03c3 are the mean and standard deviations of the normal distribution, respectively.
p4962
aVIf \u03bc is nonzero, the random walk will vary about a linear trend. If vs is the starting value of the random walk, the expected value after "n" steps will be vs + "n"\u03bc.
p4963
aVFor the special case where \u03bc is equal to zero, after "n" steps, the translation distance's probability distribution is given by "N"(0, "n"\u03c32), where "N"() is the notation for the normal distribution, "n" is the number of steps, and \u03c3 is from the inverse cumulative normal distribution as given above.
p4964
aVProof: The Gaussian random walk can be thought of as the sum of a series of independent and identically distributed random variables, Xi from the inverse cumulative normal distribution with mean equal zero and \u03c3 of the original inverse cumulative normal distribution:
p4965
aV Z = formula_42,
p4966
aVbut we have the distribution for the sum of two independent normally distributed random variables, Z = X + Y, is given by 
p4967
aV "N"(\u03bcX + \u03bcY, \u03c32X + \u03c32Y) (see here). 
p4968
aVIn our case, \u03bcX = \u03bcY = 0 and \u03c32X = \u03c32Y = \u03c32 yield
p4969
aV "N"(0, 2\u03c32)
p4970
aVBy induction, for "n" steps we have 
p4971
aV Z ~ "N"(0, "n"\u03c32).
p4972
aVFor steps distributed according to any distribution with zero mean and a finite variance (not necessarily just a normal distribution), the root mean square translation distance after "n" steps is
p4973
aVformula_43
p4974
aVBut for the Gaussian random walk, this is just the standard deviation of the translation distance's distribution after "n" steps. Hence, if \u03bc is equal to zero, and since the root mean square(rms) translation distance is one standard deviation, there is 68.27% probability that the rms translation distance after "n" steps will fall between ± \u03c3formula_44. Likewise, there is 50% probability that the translation distance after "n" steps will fall between ± 0.6745\u03c3formula_44.
p4975
aVAnomalous diffusion.
p4976
aVIn disordered systems such as porous media and fractals formula_46 may not be proportional to formula_47 but to formula_48. The exponent formula_49 is called the anomalous diffusion exponent and can be larger or smaller than 2. Anomalous diffusion may also be expressed as \u03c3r2 ~ Dt\u03b1 where \u03b1 is the anomaly parameter.
p4977
aVNumber of Distinct Sites.
p4978
aVThe number of distinct sites visited by a single random
p4979
aVwalker formula_50 has been studied extensively for square and
p4980
aVcubic lattices and for fractals 
p4981
aV. This quantity is useful
p4982
aVfor the analysis of problems of trapping and kinetic reactions.
p4983
aVIt is also related to the vibrational density of states
p4984
aV, diffusion reactions processes 
p4985
aVand spread of populations in ecology.
p4986
aVThe generalization of this problem to the number of
p4987
aVdistinct sites visited by formula_19 random walkers, formula_52, has recently
p4988
aVbeen studied for d-dimensional Euclidean lattices. The number of distinct sites visited by N walkers
p4989
aVis not simply related to the number of distinct sites visited
p4990
aVby each walker.
p4991
aVApplications.
p4992
aVThe following are some applications of random walk:
p4993
aVIn all these cases, random walk is often substituted for Brownian motion.
p4994
aV*When this last approach is used in computer science it is known as Markov Chain Monte Carlo or MCMC for short. Often, sampling from some complicated state space also allows one to get a probabilistic estimate of the space's size. The estimate of the permanent of a large matrix of zeros and ones was the first major problem tackled using this approach.
p4995
aVVariants of random walks.
p4996
aVA number of types of stochastic processes have been considered that are similar to the pure random walks but where the simple structure is allowed to be more generalized. The "pure" structure can be characterized by the steps being defined by independent and identically distributed random variables.
p4997
aVRandom walk on graphs.
p4998
aVA random walk of length "k" on a possibly infinite graph "G" with a root "0" is a stochastic process with random variables formula_53 such that formula_54 and
p4999
aVformula_55 is a vertex chosen uniformly at random from the neighbors of formula_56.
p5000
aVThen the number formula_57 is the probability that a random walk of length "k" starting at "v" ends at "w".
p5001
aVIn particular, if "G" is a graph with root "0", formula_58 is the probability that a formula_59-step random walk returns to "0".
p5002
aVAssume now that our city is no longer a perfect square grid. When our drunkard reaches a certain junction he picks between the various available roads with equal probability. Thus, if the junction has seven exits the drunkard will go to each one with probability one seventh. This is a random walk on a graph. Will our drunkard reach his home? It turns out that under rather mild conditions, the answer is still yes. For example, if the lengths of all the blocks are between "a" and "b" (where "a" and "b" are any two finite positive numbers), then the drunkard will, almost surely, reach his home. Notice that we do not assume that the graph is planar, i.e. the city may contain tunnels and bridges. One way to prove this result is using the connection to electrical networks. Take a map of the city and place a one ohm resistor on every block. Now measure the "resistance between a point and infinity". In other words, choose some number "R" and take all the points in the electrical network with distance bigger than "R" from our point and wire them together. This is now a finite electrical network and we may measure the resistance from our point to the wired points. Take "R" to infinity. The limit is called the "resistance between a point and infinity". It turns out that the following is true (an elementary proof can be found in the book by Doyle and Snell):
p5003
aVTheorem: "a graph is transient if and only if the resistance between a point and infinity is finite. It is not important which point is chosen if the graph is connected."
p5004
aVIn other words, in a transient system, one only needs to overcome a finite resistance to get to infinity from any point. In a recurrent system, the resistance from any point to infinity is infinite.
p5005
aVThis characterization of recurrence and transience is very useful, and specifically it allows us to analyze the case of a city drawn in the plane with the distances bounded.
p5006
aVA random walk on a graph is a very special case of a Markov chain. Unlike a general Markov chain, random walk on a graph enjoys a property called "time symmetry" or "reversibility". Roughly speaking, this property, also called the principle of detailed balance, means that the probabilities to traverse a given path in one direction or in the other have a very simple connection between them (if the graph is regular, they are just equal). This property has important consequences.
p5007
aVStarting in the 1980s, much research has gone into connecting properties of the graph to random walks. In addition to the electrical network connection described above, there are important connections to isoperimetric inequalities, see more here, functional inequalities such as Sobolev and Poincaré inequalities and properties of solutions of Laplace's equation. A significant portion of this research was focused on Cayley graphs of finitely generated groups. For example, the proof of Dave Bayer and Persi Diaconis that 7 riffle shuffles are enough to mix a pack of cards (see more details under shuffle) is in effect a result about random walk on the group "Sn", and the proof uses the group structure in an essential way. In many cases these discrete results carry over to, or are derived from manifolds and Lie groups.
p5008
aVA good reference for random walk on graphs is the online book by Aldous and Fill. For groups see the book of Woess.
p5009
aVIf the transition kernel formula_60 is itself random (based on an environment formula_61) then the random walk is called a "random walk in random environment". When the law of the random walk includes the randomness of formula_61, the law is called the annealed law; on the other hand, if formula_61 is seen as fixed, the law is called a quenched law. See the book of Hughes or the lecture notes of Zeitouni.
p5010
aVWe can think about choosing every possible edge with the same probability as maximizing uncertainty (entropy) locally. We could also do it globally \u2013 in maximal entropy random walk (MERW) we want all paths to be equally probable, or in other words: for each two vertexes, each path of given length is equally probable. This random walk has much stronger localization properties.
p5011
aVSelf-interacting random walks.
p5012
aVThere are a number of interesting models of random paths in which each step depends on the past in a complicated manner. All are more complex for solving analytically than the usual random walk; still, the behavior of any model of a random walker is obtainable using computers. Examples include:
p5013
aVThe self-avoiding walk of length n on Z^d is the random n-step path which starts at the origin, makes transitions only between adjacent sites in Z^d, never revisits a site, and is chosen uniformly among all such paths. In two dimensions, due to self-trapping, a typical self-avoiding walk is very short, while in higher dimension it grows beyond all bounds. 
p5014
aVThis model has often been used in polymer physics (since the 1960s).
p5015
aVLong-range correlated walks.
p5016
aVLong-range correlated time series are found in many biological, climatological and economic systems.
p5017
asS'X-intercept'
p5018
(lp5019
sVGödel number
p5020
(lp5021
sS'Strict weak ordering'
p5022
(lp5023
sS'Proportionality'
p5024
(lp5025
VProportionality may refer to:
p5026
aVProportion redirects here. Proportion may refer to:
p5027
aVProportional redirects here. Proportional may refer to:
p5028
asS'Base (mathematics)'
p5029
(lp5030
sS'Universe of discourse'
p5031
(lp5032
sS"Hilbert's paradox of the Grand Hotel"
p5033
(lp5034
VHilbert's paradox of the Grand Hotel'" is a veridical paradox (a valid argument with a seemingly absurd conclusion, as opposed to a "falsidical paradox", which is a seemingly valid demonstration of an actual contradiction) about infinite sets meant to illustrate certain counterintuitive properties of infinite sets. The idea was introduced by David Hilbert in a lecture he gave in 1924 and was popularized through George Gamow's 1947 book "One Two Three ... Infinity".
p5035
aVThe paradox.
p5036
aVConsider a hypothetical hotel with a countably infinite number of rooms, all of which are occupied. One might be tempted to think that the hotel would not be able to accommodate any newly arriving guests, as would be the case with a finite number of rooms.
p5037
aVFinitely many new guests.
p5038
aVSuppose a new guest arrives and wishes to be accommodated in the hotel. Because the hotel has infinite rooms, we can move any guest occupying any room n to room n+1, then fit the newcomer into room 1. By repeating this procedure, it is possible to make room for any finite number of new guests.
p5039
aVInfinitely many new guests.
p5040
aVIt is also possible to accommodate a "countably infinite" number of new guests: just move the person occupying room 1 to room 2, the guest occupying room 2 to room 4, and, in general, the guest occupying room "n" to room 2"n", and all the odd-numbered rooms (which are countably infinite) will be free for the new guests.
p5041
aVInfinitely many coaches with infinitely many guests each.
p5042
aVIt is possible to accommodate countably infinitely many coachloads of countably infinite passengers each, by several different methods. Most methods depend on the seats in the coaches being already numbered (alternatively, the hotel manager must have the axiom of countable choice at his or her disposal). In general any pairing function can be used to solve this problem. For each of these methods, consider a passenger's seat number on a coach to be formula_1, and their coach number to be formula_2, and the numbers formula_1 and formula_2 are then fed into the two arguments of the pairing function.
p5043
aVPrime powers method.
p5044
aVEmpty the odd numbered rooms by sending the guest in room formula_5 to room formula_6, then put the first coach's load in rooms formula_7, the second coach's load in rooms formula_8; for coach number formula_2 we use the rooms formula_10 where formula_11 is the formula_2th odd prime number. This solution leaves certain rooms empty (which may or may not be useful to the hotel); specifically, all odd numbers that are not prime powers, such as 15 or 847, will no longer be occupied. (So, strictly speaking, this shows that the number of arrivals is "less than or equal to" the number of vacancies created. It is easier to show, by an independent means, that the number of arrivals is also "greater than or equal to" the number of vacancies, and thus that they are "equal", than to modify the algorithm to an exact fit.) (The algorithm works equally well if one interchanges formula_1 and formula_2, but whichever choice is made, it must be applied uniformly throughout.)
p5045
aVInterleaving method.
p5046
aVFor each passenger, compare the lengths of formula_1 and formula_2 as written in decimal. (Treat each hotel resident as being in coach #0.) If either number is shorter, add leading zeroes to it until both values have the same number of digits. Interleave the digits to produce a room number: its digits will be digit of coach number-digit of seat number-digit of coach number-digit of seat number-etc. The hotel (coach #0) guest in room number 1729 moves to room 01070209 (i.e., room 1,070,209.) The passenger on seat 1234 of coach 789 goes to room 01728394 (or just 1728394).
p5047
aVUnlike the prime powers solution, this one fills the hotel completely, and we can extrapolate a guest's original coach and seat by reversing the interleaving process. First add a leading zero if the room has an odd number of digits. Then de-interleave the number into two numbers: the seat number consists of the odd-numbered digits and the coach number is the even-numbered ones. Of course, the original encoding is arbitrary, and the roles of the two numbers can be reversed (seat-odd and coach-even), so long as it is applied consistently.
p5048
aVTriangular number method.
p5049
aVThose already in the hotel will be moved to room formula_17, or the formula_1th triangular number. Those in a coach will be in room formula_19, or the formula_20 triangular number, plus formula_21. In this way all the rooms will be filled by one, and only one, guest.
p5050
aVThis pairing function can be demonstrated visually by structuring the hotel as a one-room-deep, infinitely tall pyramid. The pyramid's topmost row is a single room: room 1; its second row is rooms 2 and 3; and so on. The column formed by the set of rightmost rooms will correspond to the triangular numbers. Once they are filled (by the hotel's redistributed occupants), the remaining empty rooms form the shape of a pyramid exactly identical to the original shape. Thus, the process can be repeated for each infinite set. Doing this one at a time for each coach would require an infinite number of steps, but by using the prior formulas, a guest can determine what his room "will be" once his coach has been reached in the process, and can simply go there immediately.
p5051
aVFurther layers of infinity.
p5052
aVSuppose the hotel is next to an ocean, and an infinite number of aircraft carriers arrive, each bearing an infinite number of coaches, each with an infinite number of passengers. This is a situation involving three "levels" of infinity, and it can be solved by extensions of any of the previous solutions.
p5053
aVThe prime power solution can be applied with further exponentiation of prime numbers, resulting in very large room numbers even given small inputs. For example, the passenger in the second seat of the third bus on the second aircraft carrier (address 2-3-2) would raise the 2nd odd prime (5) to 49, which is the result of the 3rd odd prime (7) being raised to the power of his seat number (2). This room number would have over thirty decimal digits.
p5054
aVThe interleaving method can be used with three interleaved "strands" instead of two. The passenger with the address 2-3-2 would go to room 232, while the one with the address 4935-198-82217 would go to room #008,402,912,391,587 (the leading zeroes can be removed).
p5055
aVAnticipating the possibility of any number of layers of infinite guests, the hotel may wish to assign rooms such that no guest will need to move, no matter how many guests arrive afterward. One solution is to convert each arrival's address into a binary number in which ones are used as separators at the start of each layer, while a number within a given layer (such as a guests' coach number) is represented with that many zeroes. Thus, a guest with the prior address 2-5-1-3-1 (five infinite layers) would go to room 10010000010100010 (decimal 295458).
p5056
aVAs an added step in this process, one zero can be removed from each section of the number; in this example, the guest's new room is 101000011001 (decimal 2585). This ensures that every room could be filled by a hypothetical guest. If no infinite sets of guests arrive, then only rooms that are a power of two will be occupied.
p5057
aVInfinite layers of nesting.
p5058
aVAlthough a room can be found for any finite number of nested infinities of people, the same is not always true for an infinite number of layers, even if a finite number of elements exists at each layer. For example, suppose some people arrive in a set of flying saucer spaceships which are nested in accordance to the following rules: the smallest ships, each 100 cubic meters in volume, contain ten people. After this, every ship (of any size) is grouped with nine other ships of the same size, inside a mothership exactly 100 times the volume of each of its ten daughter ships. All ships of the same size are isomorphic to one another; for example, each 1,000,000-cubic-meter ship contains exactly ten 10,000-cubic-meter ships, each of which contains exactly ten 100-cubic-meter ships, each containing ten people. This extends upward infinitely, so that there is no "largest ship".
p5059
aVA given passenger's address in this system would be infinite in length, corresponding to the decimal form of one of the real numbers ranging from 0 (address 0-0-0...) to 1 (address 9-9-9...). Exactly one guest would have the address corresponding to one-sixth (1-6-6-6...), for example, and another to the value of pi minus three (1-4-1-5...). The set of real numbers, and the set of guests in this example, is uncountably infinite. Because no one-to-one pairing can be made between countable and uncountable sets, room at the hotel cannot be made for all of these guests, although any countably infinite subset of them can still be accommodated -- for example, the set of guests whose addresses terminate in an infinitely repeating sequence, corresponding to a rational number.
p5060
aVIf this variant is modified in certain ways, then the set of people is countable again. For example, suppose there "were" a largest ship, directly containing a finite (or countably infinite) number of both ships and people, and each of these ships in turn contained both ships and people, and so forth. This time, any given person is a finite number of levels "down" from the top, and thus can be identified with a unique finite address. The set of people is countable again, even if the total number of layers is infinite, because we do not have to consider an "infinitieth layer" in either direction.
p5061
aVAnalysis.
p5062
aVThese cases constitute a paradox not in the sense that they entail a logical contradiction, but in the sense that they demonstrate a counter-intuitive result that is provably true: the statements "there is a guest to every room" and "no more guests can be accommodated" are not equivalent when there are infinitely many rooms. An analogous situation is presented in Cantor's diagonal proof.
p5063
aVInitially, this state of affairs might seem to be counter-intuitive. The properties of "infinite collections of things" are quite different from those of "finite collections of things". The paradox of Hilbert's Grand Hotel can be understood by using Cantor's theory of transfinite numbers. Thus, while in an ordinary (finite) hotel with more than one room, the number of odd-numbered rooms is obviously smaller than the total number of rooms. However, in Hilbert's aptly named Grand Hotel, the quantity of odd-numbered rooms is not smaller than total "number" of rooms. In mathematical terms, the cardinality of the subset containing the odd-numbered rooms is the same as the cardinality of the set of all rooms. Indeed, infinite sets are characterized as sets that have proper subsets of the same cardinality. For countable sets (sets with the same cardinality as the natural numbers) this cardinality is formula_22.
p5064
aVRephrased, for any countably infinite set, there exists a bijective function which maps the countably infinite set to the set of natural numbers, even if the countably infinite set contains the natural numbers. For example, the set of rational numbers\u2014those numbers which can be written as a quotient of integers\u2014contains the natural numbers as a subset, but is no bigger than the set of natural numbers since the rationals are countable: There is a bijection from the naturals to the rationals.
p5065
aVThe Grand Hotel Cigar Mystery.
p5066
aVAnother story regarding the Grand Hotel can be used to show that mathematical induction only works from an induction basis.
p5067
aVSuppose that the Grand Hotel does not allow smoking, and no cigars may be taken into the Hotel. Despite this, the guest in room 1 goes to the guest in room 2 to get a cigar. The guest in room 2 goes to room 3 to get two cigars\u2014one for himself and one for the guest in room 1. In general, the guest in room N goes to room (N+1) to get N cigars. They each return, smoke one cigar and give the rest to the guest from room (N-1). Thus despite the fact no cigars have been brought into the hotel, each guest can smoke a cigar inside the property.
p5068
aVThe fallacy of this story derives from the fact that there is no inductive point (base-case) from which the induction can derive. Although it is shown that if the guest from room N has N cigars then both he and all guests in lower-numbered rooms can smoke, it is never proved that any of the guests actually have cigars. Therefore it does not follow that any guest can smoke a cigar inside the Hotel. The fact that the story mentions that cigars are not allowed into the hotel is designed to highlight the fallacy. However, since there is an infinite number of rooms in the hotel and each guest (N) must go to guest (N+1) for his cigar, this process of going up one room never ends and no cigars are ever smoked.
p5069
asS'Group theory'
p5070
(lp5071
VIn mathematics and abstract algebra, group theory studies the algebraic structures known as groups. 
p5072
aVThe concept of a group is central to abstract algebra: other well-known algebraic structures, such as rings, fields, and vector spaces, can all be seen as groups endowed with additional operations and axioms. Groups recur throughout mathematics, and the methods of group theory have influenced many parts of algebra. Linear algebraic groups and Lie groups are two branches of group theory that have experienced advances and have become subject areas in their own right.
p5073
aVVarious physical systems, such as crystals and the hydrogen atom, can be modelled by symmetry groups. Thus group theory and the closely related representation theory have many important applications in physics, chemistry, and materials science. Group theory is also central to public key cryptography.
p5074
aVOne of the most important mathematical achievements of the 20th century was the collaborative effort, taking up more than 10,000 journal pages and mostly published between 1960 and 1980, that culminated in a complete classification of finite simple groups.
p5075
aVHistory.
p5076
aVGroup theory has three main historical sources: number theory, the theory of algebraic equations, and geometry. The number-theoretic strand was begun by Leonhard Euler, and developed by Gauss's work on modular arithmetic and additive and multiplicative groups related to quadratic fields. Early results about permutation groups were obtained by Lagrange, Ruffini, and Abel in their quest for general solutions of polynomial equations of high degree. Évariste Galois coined the term "group" and established a connection, now known as Galois theory, between the nascent theory of groups and field theory. In geometry, groups first became important in projective geometry and, later, non-Euclidean geometry. Felix Klein's Erlangen program proclaimed group theory to be the organizing principle of geometry.
p5077
aVGalois, in the 1830s, was the first to employ groups to determine the solvability of polynomial equations. Arthur Cayley and Augustin Louis Cauchy pushed these investigations further by creating the theory of permutation groups. The second historical source for groups stems from geometrical situations. In an attempt to come to grips with possible geometries (such as euclidean, hyperbolic or projective geometry) using group theory, Felix Klein initiated the Erlangen programme. Sophus Lie, in 1884, started using groups (now called Lie groups) attached to analytic problems. Thirdly, groups were, at first implicitly and later explicitly, used in algebraic number theory.
p5078
aVThe different scope of these early sources resulted in different notions of groups. The theory of groups was unified starting around 1880. Since then, the impact of group theory has been ever growing, giving rise to the birth of abstract algebra in the early 20th century, representation theory, and many more influential spin-off domains. The classification of finite simple groups is a vast body of work from the mid 20th century, classifying all the finite simple groups.
p5079
aVMain classes of groups.
p5080
aVThe range of groups being considered has gradually expanded from finite permutation groups and special examples of matrix groups to abstract groups that may be specified through a presentation by generators and relations.
p5081
aVPermutation groups.
p5082
aVThe first class of groups to undergo a systematic study was permutation groups. Given any set "X" and a collection "G" of bijections of "X" into itself (known as "permutations") that is closed under compositions and inverses, "G" is a group acting on "X". If "X" consists of "n" elements and "G" consists of "all" permutations, "G" is the symmetric group S"n"; in general, any permutation group "G" is a subgroup of the symmetric group of "X". An early construction due to Cayley exhibited any group as a permutation group, acting on itself () by means of the left regular representation.
p5083
aVIn many cases, the structure of a permutation group can be studied using the properties of its action on the corresponding set. For example, in this way one proves that for , the alternating group A"n" is simple, i.e. does not admit any proper normal subgroups. This fact plays a key role in the impossibility of solving a general algebraic equation of degree in radicals.
p5084
aVMatrix groups.
p5085
aVThe next important class of groups is given by "matrix groups", or linear groups. Here "G" is a set consisting of invertible matrices of given order "n" over a field "K" that is closed under the products and inverses. Such a group acts on the "n"-dimensional vector space "K""n" by linear transformations. This action makes matrix groups conceptually similar to permutation groups, and the geometry of the action may be usefully exploited to establish properties of the group "G".
p5086
aVTransformation groups.
p5087
aVPermutation groups and matrix groups are special cases of transformation groups: groups that act on a certain space "X" preserving its inherent structure. In the case of permutation groups, "X" is a set; for matrix groups, "X" is a vector space. The concept of a transformation group is closely related with the concept of a symmetry group: transformation groups frequently consist of "all" transformations that preserve a certain structure.
p5088
aVThe theory of transformation groups forms a bridge connecting group theory with differential geometry. A long line of research, originating with Lie and Klein, considers group actions on manifolds by homeomorphisms or diffeomorphisms. The groups themselves may be discrete or continuous.
p5089
aVAbstract groups.
p5090
aVMost groups considered in the first stage of the development of group theory were "concrete", having been realized through numbers, permutations, or matrices. It was not until the late nineteenth century that the idea of an abstract group as a set with operations satisfying a certain system of axioms began to take hold. A typical way of specifying an abstract group is through a presentation by "generators and relations",
p5091
aV formula_1
p5092
aVA significant source of abstract groups is given by the construction of a "factor group", or quotient group, "G"/"H", of a group "G" by a normal subgroup "H". Class groups of algebraic number fields were among the earliest examples of factor groups, of much interest in number theory. If a group "G" is a permutation group on a set "X", the factor group "G"/"H" is no longer acting on "X"; but the idea of an abstract group permits one not to worry about this discrepancy.
p5093
aVThe change of perspective from concrete to abstract groups makes it natural to consider properties of groups that are independent of a particular realization, or in modern language, invariant under isomorphism, as well as the classes of group with a given such property: finite groups, periodic groups, simple groups, solvable groups, and so on. Rather than exploring properties of an individual group, one seeks to establish results that apply to a whole class of groups. The new paradigm was of paramount importance for the development of mathematics: it foreshadowed the creation of abstract algebra in the works of Hilbert, Emil Artin, Emmy Noether, and mathematicians of their school.
p5094
aVTopological and algebraic groups.
p5095
aVAn important elaboration of the concept of a group occurs if "G" is endowed with additional structure, notably, of a topological space, differentiable manifold, or algebraic variety. If the group operations "m" (multiplication) and "i" (inversion),
p5096
aV formula_2
p5097
aVare compatible with this structure, i.e. are continuous, smooth or regular (in the sense of algebraic geometry) maps, then "G" becomes a topological group, a Lie group, or an algebraic group.
p5098
aVThe presence of extra structure relates these types of groups with other mathematical disciplines and means that more tools are available in their study. Topological groups form a natural domain for abstract harmonic analysis, whereas Lie groups (frequently realized as transformation groups) are the mainstays of differential geometry and unitary representation theory. Certain classification questions that cannot be solved in general can be approached and resolved for special subclasses of groups. Thus, compact connected Lie groups have been completely classified. There is a fruitful relation between infinite abstract groups and topological groups: whenever a group "\u0393" can be realized as a lattice in a topological group "G", the geometry and analysis pertaining to "G" yield important results about "\u0393". A comparatively recent trend in the theory of finite groups exploits their connections with compact topological groups (profinite groups): for example, a single "p"-adic analytic group "G" has a family of quotients which are finite "p"-groups of various orders, and properties of "G" translate into the properties of its finite quotients.
p5099
aVBranches of group theory.
p5100
aVFinite group theory.
p5101
aVDuring the twentieth century, mathematicians investigated some aspects of the theory of finite groups in great depth, especially the local theory of finite groups and the theory of solvable and nilpotent groups. As a consequence, the complete classification of finite simple groups was achieved, meaning that all those simple groups from which all finite groups can be built are now known.
p5102
aVDuring the second half of the twentieth century, mathematicians such as Chevalley and Steinberg also increased our understanding of finite analogs of classical groups, and other related groups. One such family of groups is the family of general linear groups over finite fields. 
p5103
aVFinite groups often occur when considering symmetry of mathematical or
p5104
aVphysical objects, when those objects admit just a finite number of structure-preserving transformations. The theory of Lie groups,
p5105
aVwhich may be viewed as dealing with "continuous symmetry", is strongly influenced by the associated Weyl groups. These are finite groups generated by reflections which act on a finite-dimensional Euclidean space. The properties of finite groups can thus play a role in subjects such as theoretical physics and chemistry.
p5106
aVRepresentation of groups.
p5107
aVSaying that a group "G" "acts" on a set "X" means that every element of "G" defines a bijective map on the set "X" in a way compatible with the group structure. When "X" has more structure, it is useful to restrict this notion further: a representation of "G" on a vector space "V" is a group homomorphism:
p5108
aV"\u03c1" : "G" \u2192 GL("V"),
p5109
aVwhere GL("V") consists of the invertible linear transformations of "V". In other words, to every group element "g" is assigned an automorphism "\u03c1"("g") such that for any "h" in "G".
p5110
aVThis definition can be understood in two directions, both of which give rise to whole new domains of mathematics. On the one hand, it may yield new information about the group "G": often, the group operation in "G" is abstractly given, but via "\u03c1", it corresponds to the multiplication of matrices, which is very explicit. On the other hand, given a well-understood group acting on a complicated object, this simplifies the study of the object in question. For example, if "G" is finite, it is known that "V" above decomposes into irreducible parts. These parts in turn are much more easily manageable than the whole "V" (via Schur's lemma).
p5111
aVGiven a group "G", representation theory then asks what representations of "G" exist. There are several settings, and the employed methods and obtained results are rather different in every case: representation theory of finite groups and representations of Lie groups are two main subdomains of the theory. The totality of representations is governed by the group's characters. For example, Fourier polynomials can be interpreted as the characters of U(1), the group of complex numbers of absolute value "1", acting on the "L"2-space of periodic functions.
p5112
aVLie theory.
p5113
aVA Lie group is a group that is also a differentiable manifold, with the property that the group operations are compatible with the smooth structure. Lie groups are named after Sophus Lie, who laid the foundations of the theory of continuous transformation groups. The term "groupes de Lie" first appeared in French in 1893 in the thesis of Lie\u2019s student Arthur Tresse, page 3.
p5114
aVLie groups represent the best-developed theory of continuous symmetry of mathematical objects and structures, which makes them indispensable tools for many parts of contemporary mathematics, as well as for modern theoretical physics. They provide a natural framework for analysing the continuous symmetries of differential equations (differential Galois theory), in much the same way as permutation groups are used in Galois theory for analysing the discrete symmetries of algebraic equations. An extension of Galois theory to the case of continuous symmetry groups was one of Lie's principal motivations.
p5115
aVCombinatorial and geometric group theory.
p5116
aVGroups can be described in different ways. Finite groups can be described by writing down the group table consisting of all possible multiplications . A more compact way of defining a group is by "generators and relations", also called the "presentation" of a group. Given any set "F" of generators {"g""i"}"i" \u2208 "I", the free group generated by "F" subjects onto the group "G". The kernel of this map is called subgroup of relations, generated by some subset "D". The presentation is usually denoted by . For example, the group can be generated by one element "a" (equal to +1 or \u22121) and no relations, because never equals 0 unless "n" is zero. A string consisting of generator symbols and their inverses is called a "word".
p5117
aVCombinatorial group theory studies groups from the perspective of generators and relations. It is particularly useful where finiteness assumptions are satisfied, for example finitely generated groups, or finitely presented groups (i.e. in addition the relations are finite). The area makes use of the connection of graphs via their fundamental groups. For example, one can show that every subgroup of a free group is free.
p5118
aVThere are several natural questions arising from giving a group by its presentation. The "word problem" asks whether two words are effectively the same group element. By relating the problem to Turing machines, one can show that there is in general no algorithm solving this task. Another, generally harder, algorithmically insoluble problem is the group isomorphism problem, which asks whether two groups given by different presentations are actually isomorphic. For example the additive group Z of integers can also be presented by
p5119
aVit may not be obvious that these groups are isomorphic.
p5120
aVGeometric group theory attacks these problems from a geometric viewpoint, either by viewing groups as geometric objects, or by finding suitable geometric objects a group acts on. The first idea is made precise by means of the Cayley graph, whose vertices correspond to group elements and edges correspond to right multiplication in the group. Given two elements, one constructs the word metric given by the length of the minimal path between the elements. A theorem of Milnor and Svarc then says that given a group "G" acting in a reasonable manner on a metric space "X", for example a compact manifold, then "G" is quasi-isometric (i.e. looks similar from the far) to the space "X".
p5121
aVConnection of groups and symmetry.
p5122
aVGiven a structured object "X" of any sort, a symmetry is a mapping of the object onto itself which preserves the structure. This occurs in many cases, for example
p5123
aV:formula_3
p5124
aVhas the two solutions formula_4, and formula_5. In this case, the group that exchanges the two roots is the Galois group belonging to the equation. Every polynomial equation in one variable has a Galois group, that is a certain permutation group on its roots.
p5125
aVThe axioms of a group formalize the essential aspects of symmetry. Symmetries form a group: they are closed because if you take a symmetry of an object, and then apply another symmetry, the result will still be a symmetry. The identity keeping the object fixed is always a symmetry of an object. Existence of inverses is guaranteed by undoing the symmetry and the associativity comes from the fact that symmetries are functions on a space, and composition of functions are associative.
p5126
aVFrucht's theorem says that every group is the symmetry group of some graph. So every abstract group is actually the symmetries of some explicit object.
p5127
aVThe saying of "preserving the structure" of an object can be made precise by working in a category. Maps preserving the structure are then the morphisms, and the symmetry group is the automorphism group of the object in question.
p5128
aVApplications of group theory.
p5129
aVApplications of group theory abound. Almost all structures in abstract algebra are special cases of groups. Rings, for example, can be viewed as abelian groups (corresponding to addition) together with a second operation (corresponding to multiplication). Therefore group theoretic arguments underlie large parts of the theory of those entities.
p5130
aVGalois theory.
p5131
aVGalois theory uses groups to describe the symmetries of the roots of a polynomial (or more precisely the automorphisms of the algebras generated by these roots). The fundamental theorem of Galois theory provides a link between algebraic field extensions and group theory. It gives an effective criterion for the solvability of polynomial equations in terms of the solvability of the corresponding Galois group. For example, "S"5, the symmetric group in 5 elements, is not solvable which implies that the general quintic equation cannot be solved by radicals in the way equations of lower degree can. The theory, being one of the historical roots of group theory, is still fruitfully applied to yield new results in areas such as class field theory.
p5132
aVAlgebraic topology.
p5133
aVAlgebraic topology is another domain which prominently associates groups to the objects the theory is interested in. There, groups are used to describe certain invariants of topological spaces. They are called "invariants" because they are defined in such a way that they do not change if the space is subjected to some deformation. For example, the fundamental group "counts" how many paths in the space are essentially different. The Poincaré conjecture, proved in 2002/2003 by Grigori Perelman is a prominent application of this idea. The influence is not unidirectional, though. For example, algebraic topology makes use of Eilenberg\u2013MacLane spaces which are spaces with prescribed homotopy groups. Similarly algebraic K-theory stakes in a crucial way on classifying spaces of groups. Finally, the name of the torsion subgroup of an infinite group shows the legacy of topology in group theory.
p5134
aVAlgebraic geometry and cryptography.
p5135
aVAlgebraic geometry and cryptography likewise uses group theory in many ways. Abelian varieties have been introduced above. The presence of the group operation yields additional information which makes these varieties particularly accessible. They also often serve as a test for new conjectures. The one-dimensional case, namely elliptic curves is studied in particular detail. They are both theoretically and practically intriguing. Very large groups of prime order constructed in Elliptic-Curve Cryptography serve for public key cryptography. Cryptographical methods of this kind benefit from the flexibility of the geometric objects, hence their group structures, together with the complicated structure of these groups, which make the discrete logarithm very hard to calculate. One of the earliest encryption protocols, Caesar's cipher, may also be interpreted as a (very easy) group operation. In another direction, toric varieties are algebraic varieties acted on by a torus. Toroidal embeddings have recently led to advances in algebraic geometry, in particular resolution of singularities.
p5136
aVAlgebraic number theory.
p5137
aVAlgebraic number theory is a special case of group theory, thereby following the rules of the latter. For example, Euler's product formula
p5138
aVformula_6
p5139
aVcaptures the fact that any integer decomposes in a unique way into primes. The failure of this statement for more general rings gives rise to class groups and regular primes, which feature in Kummer's treatment of Fermat's Last Theorem.
p5140
aVHarmonic analysis.
p5141
aVAnalysis on Lie groups and certain other groups is called harmonic analysis. Haar measures, that is, integrals invariant under the translation in a Lie group, are used for pattern recognition and other image processing techniques.
p5142
aVCombinatorics.
p5143
aVIn combinatorics, the notion of permutation group and the concept of group action are often used to simplify the counting of a set of objects; see in particular Burnside's lemma.
p5144
aVMusic.
p5145
aVThe presence of the 12-periodicity in the circle of fifths yields applications of elementary group theory in musical set theory.
p5146
aVPhysics.
p5147
aVIn physics, groups are important because they describe the symmetries which the laws of physics seem to obey. According to Noether's theorem, every continuous symmetry of a physical system corresponds to a conservation law of the system. Physicists are very interested in group representations, especially of Lie groups, since these representations often point the way to the "possible" physical theories. Examples of the use of groups in physics include the Standard Model, gauge theory, the Lorentz group, and the Poincaré group.
p5148
aVChemistry and materials science.
p5149
aVIn chemistry and materials science, groups are used to classify crystal structures, regular polyhedra, and the symmetries of molecules. The assigned point groups can then be used to determine physical properties (such as polarity and chirality), spectroscopic properties (particularly useful for Raman spectroscopy and infrared spectroscopy), and to construct molecular orbitals.
p5150
aVMolecular symmetry is responsible for many physical and spectroscopic properties of compounds and provides relevant information about how chemical reactions occur. In order to assign a point group for any given molecule, it is necessary to find the set of symmetry operations present on it. The symmetry operation is an action, such as a rotation around an axis or a reflection through a mirror plane. In other words, it is an operation that moves the molecule such that it is indistinguishable from the original configuration. In group theory, the rotation axes and mirror planes are called "symmetry elements". These elements can be a point, line or plane with respect to which the symmetry operation is carried out. The symmetry operations of a molecule determine the specific point group for this molecule.
p5151
aVIn chemistry, there are five important symmetry operations. The identity operation (E) consists of leaving the molecule as it is. This is equivalent to any number of full rotations around any axis. This is a symmetry of all molecules, whereas the symmetry group of a chiral molecule consists of only the identity operation. Rotation around an axis (C"n") consists of rotating the molecule around a specific axis by a specific angle. For example, if a water molecule rotates 180° around the axis that passes through the oxygen atom and between the hydrogen atoms, it is in the same configuration as it started. In this case, , since applying it twice produces the identity operation. Other symmetry operations are: reflection, inversion and improper rotation (rotation followed by reflection).
p5152
asS'Right-hand rule'
p5153
(lp5154
VIn mathematics and physics, the right-hand rule is a common mnemonic for understanding notation conventions for vectors in 3 dimensions. There are several right hand rules.
p5155
aVAmpere's right hand screw rules.
p5156
aVIntroduction.
p5157
aVAmpère's right hand screw rule (also called "right-hand grip rule", "coffee-mug rule", or the "corkscrew-rule"), is used either when a vector (such as the Euler vector) must be defined to represent the rotation of a body, a magnetic field or a fluid, or vice versa when it is necessary to decode the rotation vector, to understand how the corresponding rotation occurs. It reveals a connection between the current and the magnetic field lines in the magnetic field that the current created.
p5158
aVAndré-Marie Ampère, a French physicist and mathematician, who discovered this rule, inspired by Hans Christian Oersted, another physicist who did an experiment of a magnet needle swirled when an electric current went by, meaning electricity could create magnetic fields. After that, Ampere was encouraged to explain the phenomenon by using physical and mathematical ways. Then the easy-doing rule was discovered.
p5159
aVApplication.
p5160
aVThis version of the rule is used in two complementary applications of Ampère's circuital law:
p5161
aVThe rule is also used to determine the direction of the torque vector. If you grip the imaginary axis of rotation of the rotational force so that your fingers point in the direction of the force, then the extended thumb points in the direction of the torque vector.
p5162
aVThe right-hand rule is just a convention. When applying the rule to current in a straight wire, for example, the direction of the magnetic field (counterclockwise instead of clockwise when viewed from the tip of the thumb) is a result of this convention and not an underlying physical phenomenon. The thumb points direction of current and fingers point direction of magnetic lines of force.
p5163
aVRight hand rules for electrical wire "cutting" magnetic field lines.
p5164
aVIntroduction.
p5165
aVYou can see a scenario of an electrical wire "cutting" magnetic field lines. The word cutting means that the wire is moving perpendicularly or with an angle to the perpendicular plane of a magnetic field. As a result, it will appear currents inside the electric wire. The right-hand rule is used to identify the direction of the current.
p5166
aVJohn Ambrose Fleming, an English engineer and physicist, discovered the rule.
p5167
aVAs the picture illustrated, the steps of the right-hand rule is showed below:
p5168
aVRight-hand rule for cross products.
p5169
aVThe cross product of two vectors is often encountered in physics and engineering. For example, in statics and dynamics, torque is the cross product of lever length and force, and angular momentum is the cross product of linear momentum and distance from an origin. In electricity and magnetism, the force exerted on a moving charged particle when moving in a magnetic field B is given by:
p5170
aVformula_1
p5171
aVMagnetic force on a moving charged particle.
p5172
aVThe direction of the cross product may be found by application of the right hand rule as follows: Using your right hand,
p5173
aVFor example, for a positively charged particle moving to the North, in a region where the magnetic field points West, the resultant force will point up.
p5174
aVApplications.
p5175
aVThe first form of the rule is used to determine the direction of the cross product of two vectors. This leads to widespread use in physics, wherever the cross product occurs. A list of physical quantities whose directions are related by the right-hand rule is given below. (Some of these are related only indirectly to cross products, and use the second form.)
p5176
asS'Homotopy'
p5177
(lp5178
VIn topology, two continuous functions from one topological space to another are called homotopic (Greek \u1f41\u03bc\u03cc\u03c2 ("homós") = same, similar, and \u03c4\u03cc\u03c0\u03bf\u03c2 ("tópos") = place) if one can be "continuously deformed" into the other, such a deformation being called a homotopy between the two functions. A notable use of homotopy is the definition of homotopy groups and cohomotopy groups, important invariants in algebraic topology.
p5179
aVIn practice, there are technical difficulties in using homotopies with certain spaces. Algebraic topologists work with compactly generated spaces, CW complexes, or spectra.
p5180
aVFormal definition.
p5181
aVFormally, a homotopy between two continuous functions "f" and "g" from a 
p5182
aVtopological space "X" to a topological space "Y" is defined to be a continuous function from the product of the space "X" with the unit interval [0,1] to "Y" such that, if then and 
p5183
aVIf we think of the second parameter of "H" as time then "H" describes a "continuous deformation" of "f" into "g": at time 0 we have the function "f" and at time 1 we have the function "g". We can also think of the second parameter as a "slider control" that allows us to smoothly transition from "f" to "g" as the slider moves from 0 to 1, and vice versa.
p5184
aVAn alternative notation is to say that a homotopy between two continuous functions is a family of continuous functions for such that and and the map is continuous from to Y. The two versions coincide by setting It is not sufficient to require each map to be continuous.
p5185
aVThe animation that is looped above right provides an example of a homotopy between two embeddings, "f" and "g", of the torus into . "X" is the torus, "Y" is , "f" is some continuous function from the torus to "R"3 that takes the torus to the embedded surface-of-a-doughnut shape with which the animation starts; "g" is some continuous function that takes the torus to the embedded surface-of-a-coffee-mug shape. The animation shows the image of "h"t"(x)" as a function of the parameter t, where t varies with time from 0 to 1 over each cycle of the animation loop. It pauses, then shows the image as t varies back from 1 to 0, pauses, and repeats this cycle.
p5186
aVProperties.
p5187
aVContinuous functions "f" and "g" are said to be homotopic if and only if there is a homotopy "H" taking "f" to "g" as described above.
p5188
aVBeing homotopic is an equivalence relation on the set of all continuous functions from "X" to "Y". 
p5189
aVThis homotopy relation is compatible with function composition in the following sense: if are homotopic, and are homotopic, then their compositions and are also homotopic.
p5190
aVHomotopy equivalence.
p5191
aVGiven two spaces "X" and "Y", we say they are homotopy equivalent, or of the same homotopy type, if there exist continuous maps and such that is homotopic to the identity map id"X" and is homotopic to id"Y".
p5192
aVThe maps "f" and "g" are called homotopy equivalences in this case. Every homeomorphism is a homotopy equivalence, but the converse is not true: for example, a solid disk is not homeomorphic to a single point (since there is no bijection between them), although the disk and the point are homotopy equivalent (since you can deform the disk along radial lines continuously to a single point). Spaces that are homotopy equivalent to a point are called contractible.
p5193
aVIntuitively, two spaces "X" and "Y" are homotopy equivalent if they can be transformed into one another ("i.e.", made homeomorphic) by bending, shrinking and expanding operations.
p5194
aVFor example, a solid disk or solid ball is homotopy equivalent to a point, and is homotopy equivalent to the unit circle "S"1.
p5195
aVHowever, one has to be careful to not think of such transformations in terms of embeddings only \u2014 for example, the double torus and the double torus with the rings interlinked are homotopy equivalent (since they are homeomorphic), even though the said transformation cannot be embedded in three-dimensional Euclidean space without the rings "passing through" each other.
p5196
aVNull-homotopy.
p5197
aVA function "f" is said to be null-homotopic if it is homotopic to a constant function. (The homotopy from "f" to a constant function is then sometimes called a null-homotopy.) For example, a map "f" from the unit circle "S"1 to any space "X" is null-homotopic precisely when it can be extended to a map from the unit disk "D"2 to "X" that agrees with "f" on the boundary.
p5198
aVIt follows from these definitions that a space "X" is contractible if and only if the identity map from "X" to itself\u2014which is always a homotopy equivalence\u2014is null-homotopic.
p5199
aVInvariance.
p5200
aVHomotopy equivalence is important because in algebraic topology many concepts are homotopy invariant, that is, they respect the relation of homotopy equivalence. For example, if "X" and "Y" are homotopy equivalent spaces, then:
p5201
aVAn example of an algebraic invariant of topological spaces which is not homotopy-invariant is compactly supported homology (which is, roughly speaking, the homology of the compactification, and compactification is not homotopy-invariant).
p5202
aVRelative homotopy.
p5203
aVIn order to define the fundamental group, one needs the notion of homotopy relative to a subspace. These are homotopies which keep the elements of the subspace fixed. Formally: if "f" and "g" are continuous maps from "X" to "Y" and "K" is a subset of "X", then we say that "f" and "g" are homotopic relative to "K" if there exists a homotopy between "f" and "g" such that for all and Also, if "g" is a retract from "X" to "K" and "f" is the identity map, this is known as a strong deformation retract of "X" to "K".
p5204
aVWhen "K" is a point, the term pointed homotopy is used.
p5205
aVGroups.
p5206
aVSince the relation of two functions being homotopic relative to a subspace is an equivalence relation, we can look at the equivalence classes of maps between a fixed "X" and "Y". If we fix the unit interval crossed with itself "n" times, and we take a subspace to be its boundary \u2202([0,1"n") then the equivalence classes form a group, denoted \u03c0"n"("Y","y"0), where "y"0 is in the image of the subspace \u2202([0,1]"n").
p5207
aVWe can define the action of one equivalence class on another, and so we get a group. These groups are called the homotopy groups. In the case it is also called the fundamental group.
p5208
aVCategory.
p5209
aVThe idea of homotopy can be turned into a formal category of category theory. The homotopy category is the category whose objects are topological spaces, and whose morphisms are homotopy equivalence classes of continuous maps. Two topological spaces "X" and "Y" are isomorphic in this category if and only if they are homotopy-equivalent. Then a functor on the category of topological spaces is homotopy invariant if it can be expressed as a functor on the homotopy category.
p5210
aVFor example, homology groups are a "functorial" homotopy invariant: this means that if "f" and "g" from "X" to "Y" are homotopic, then the group homomorphisms induced by "f" and "g" on the level of homology groups are the same: H"n"("f") = H"n"("g") : H"n"("X") \u2192 H"n"("Y") for all "n". Likewise, if "X" and "Y" are in addition path connected, and the homotopy between "f" and "g" is pointed, then the group homomorphisms induced by "f" and "g" on the level of homotopy groups are also the same: \u03c0"n"("f") = \u03c0"n"("g") : \u03c0"n"("X") \u2192 \u03c0"n"("Y").
p5211
aVTimelike.
p5212
aVOn a Lorentzian manifold, certain curves are distinguished as timelike. A timelike homotopy between two timelike curves is a homotopy such that each intermediate curve is timelike. No closed timelike curve (CTC) on a Lorentzian manifold is timelike homotopic to a point (that is, null timelike homotopic); such a manifold is therefore said to be multiply connected by timelike curves. A manifold such as the 3-sphere can be simply connected (by any type of curve), and yet be timelike multiply connected.[http://dx.doi.org/10.1007/s10701-008-9254-9]
p5213
aVLifting property.
p5214
aVIf we have a homotopy and a cover and we are given a map such that ("h"0 is called a lift of "h"0), then we can lift all "H" to a map such that The homotopy lifting property is used to characterize fibrations.
p5215
aVExtension property.
p5216
aVAnother useful property involving homotopy is the homotopy extension property,
p5217
aVwhich characterizes the extension of a homotopy between two functions from a subset of some set to the set itself. It is useful when dealing with cofibrations.
p5218
aVIsotopy.
p5219
aVIn case the two given continuous functions "f" and "g" from the topological space "X" to the topological space "Y" are embeddings, one can ask whether they can be connected 'through embeddings'. This gives rise to the concept of isotopy, which is a homotopy, "H", in the notation used before, such that for each fixed "t", "H"("x","t") gives an embedding.
p5220
aVA related, but different, concept is that of ambient isotopy.
p5221
aVRequiring that two embeddings be isotopic is a stronger requirement than that they be homotopic. For example, the map from the interval [\u22121,1] into the real numbers defined by "f"("x") = \u2212"x" is "not" isotopic to the identity "g"("x") = "x". Any homotopy from "f" to the identity would have to exchange the endpoints, which would mean that they would have to 'pass through' each other. Moreover, "f" has changed the orientation of the interval and "g" has not, which is impossible under an isotopy. However, the maps are homotopic; one homotopy from "f" to the identity is "H": [\u22121,1] × [0,1] \u2192 [\u22121,1] given by "H"("x","y") = 2"yx"-"x".
p5222
aVTwo homeomorphisms (which are special cases of embeddings) of the unit ball which agree on the boundary can be shown to be isotopic using Alexander's trick. For this reason, the map of the unit disc in "R"2 defined by "f"("x","y") = (\u2212"x", \u2212"y") is isotopic to a 180-degree rotation around the origin, and so the identity map and "f" are isotopic because they can be connected by rotations.
p5223
aVThe unknot is not equivalent to the Trefoil knot since one cannot be deformed into the other through a continuous path of embeddings. Thus they are not ambient isotopic.
p5224
aVIn geometric topology\u2014for example in knot theory\u2014the idea of isotopy is used to construct equivalence relations. For example, when should two knots be considered the same? We take two knots, "K"1 and "K"2, in three-dimensional space. A knot is an embedding of a one-dimensional space, the "loop of string" (or the circle), into this space, and this embedding gives a homeomorphism between the circle and its image in the embedding space. The intuitive idea behind the notion of knot equivalence is that one can "deform" one embedding to another through a path of embeddings: a continuous function starting at t=0 giving the "K"1 embedding, ending at t=1 giving the "K"2 embedding, with all intermediate values corresponding to embeddings. This corresponds to the definition of isotopy. 
p5225
aVAn ambient isotopy, studied in this context, is an isotopy of the larger space, considered in light of its action on the embedded submanifold. Knots "K"1 and "K"2 are considered equivalent when there is an ambient isotopy which moves "K"1 to "K"2. This is the appropriate definition in the topological category.
p5226
aVSimilar language is used for the equivalent concept in contexts where one has a stronger notion of equivalence. For example a path between two smooth embeddings is a smooth isotopy.
p5227
aVApplications.
p5228
aVBased on the concept of the homotopy, computation methods for algebraic and differential equations have been developed. The methods for algebraic equations include the homotopy continuation method and the continuation method. The methods for differential equations include the homotopy analysis method.
p5229
asS'Wheel theory'
p5230
(lp5231
VWheels are a kind of algebra where division is always defined. In particular, division by zero is meaningful. The real numbers can be extended to a wheel, as can any commutative ring. 
p5232
aVAlso the Riemann sphere can be extended to a wheel by adjoining an element formula_1. The Riemann sphere is an extension of the complex plane by an element formula_2, where formula_3 for any complex formula_4. However, formula_1 is still undefined on the Riemann sphere, but defined in wheels.
p5233
aVThe algebra of wheels.
p5234
aVWheels discard the usual notion of division being a binary operator, replacing it with multiplication by a unary operator formula_6 similar (but not identical) to the reciprocal formula_7, such that formula_8 becomes shorthand for formula_9, and modifies the rules of algebra such that
p5235
aVPrecisely, a wheel is an algebraic structure with operations binary addition formula_15, multiplication formula_16, constants 0, 1 and unary formula_17, satisfying:
p5236
aVIf there is an element formula_26 with formula_27, then we may define negation by formula_28 and formula_29.
p5237
aVOther identities that may be derived are
p5238
aVHowever, if formula_33 and formula_34 we get the usual
p5239
aVThe subset formula_37 is always a commutative ring if negation can be defined as above, and every commutative ring is such a subset of a wheel. If formula_14 is an invertible element of the commutative ring, then formula_39. Thus, whenever formula_7 makes sense, it is equal to formula_6, but the latter is always defined, even when formula_42.
p5240
asS'Applied mathematics'
p5241
(lp5242
VApplied mathematics is a branch of mathematics that deals with mathematical methods that find use in science, engineering, business, computer science, and industry. Thus, "applied mathematics" is a mathematical science with specialized knowledge. The term "applied mathematics" also describes the professional specialty in which mathematicians work on practical problems by formulating and studying mathematical models. In the past, practical applications have motivated the development of mathematical theories, which then became the subject of study in pure mathematics where abstract concepts are studied for their own sake. The activity of applied mathematics is thus intimately connected with research in pure mathematics.
p5243
aVHistory.
p5244
aVHistorically, applied mathematics consisted principally of applied analysis, most notably differential equations; approximation theory (broadly construed, to include representations, asymptotic methods, variational methods, and numerical analysis); and applied probability. These areas of mathematics related directly to the development of Newtonian physics, and in fact, the distinction between mathematicians and physicists was not sharply drawn before the mid-19th century. This history left a pedagogical legacy in the United States: until the early 20th century, subjects such as classical mechanics were often taught in applied mathematics departments at American universities rather than in physics departments, and fluid mechanics may still be taught in applied mathematics departments. Engineering and computer science departments have traditionally made use of applied mathematics.
p5245
aVDivisions.
p5246
aVToday, the term "applied mathematics" is used in a broader sense. It includes the classical areas noted above as well as other areas that have become increasingly important in applications. Even fields such as number theory that are part of pure mathematics are now important in applications (such as cryptography), though they are not generally considered to be part of the field of applied mathematics "per se". Sometimes, the term "applicable mathematics" is used to distinguish between the traditional applied mathematics that developed alongside physics and the many areas of mathematics that are applicable to real-world problems today.
p5247
aVThere is no consensus as to what the various branches of applied mathematics are. Such categorizations are made difficult by the way mathematics and science change over time, and also by the way universities organize departments, courses, and degrees.
p5248
aVMany mathematicians distinguish between "applied mathematics," which is concerned with mathematical methods, and the "applications of mathematics" within science and engineering. A biologist using a population model and applying known mathematics would not be "doing" applied mathematics, but rather "using" it; however, mathematical biologists have posed problems that have stimulated the growth of pure mathematics. Mathematicians such as Poincaré and Arnold deny the existence of "applied mathematics" and claim that there are only "applications of mathematics." Similarly, non-mathematicians blend applied mathematics and applications of mathematics. The use and development of mathematics to solve industrial problems is also called "industrial mathematics".
p5249
aVThe success of modern numerical mathematical methods and software has led to the emergence of computational mathematics, computational science, and computational engineering, which use high-performance computing for the simulation of phenomena and the solution of problems in the sciences and engineering. These are often considered interdisciplinary.
p5250
aVUtility.
p5251
aVHistorically, mathematics was most important in the natural sciences and engineering. However, since World War II, fields outside of the physical sciences have spawned the creation of new areas of mathematics, such as game theory and social choice theory, which grew out of economic considerations, or neural networks, which arose out of the study of the brain in neuroscience.
p5252
aVThe advent of the computer has created new applications: studying and using the new computer technology itself (computer science) to study problems arising in other areas of science (computational science) as well as the mathematics of computation (for example, theoretical computer science, computer algebra, numerical analysis). Statistics is probably the most widespread mathematical science used in the social sciences, but other areas of mathematics, most notably economics, are proving increasingly useful in these disciplines.
p5253
aVStatus in academic departments.
p5254
aVAcademic institutions are not consistent in the way they group and label courses, programs, and degrees in applied mathematics. At some schools, there is a single mathematics department, whereas others have separate departments for Applied Mathematics and (Pure) Mathematics. It is very common for Statistics departments to be separate at schools with graduate programs, but many undergraduate-only institutions include statistics under the mathematics department.
p5255
aVMany applied mathematics programs (as opposed to departments) consist of primarily cross-listed courses and jointly appointed faculty in departments representing applications. Some Ph.D. programs in applied mathematics require little or no coursework outside of mathematics, while others require substantial coursework in a specific area of application. In some respects this difference reflects the distinction between "application of mathematics" and "applied mathematics".
p5256
aVSome universities in the UK host departments of "Applied Mathematics and Theoretical Physics", but it is now much less common to have separate departments of pure and applied mathematics. A notable exception to this is the Department of Applied Mathematics and Theoretical Physics at the University of Cambridge, housing the Lucasian Professor of Mathematics whose past holders include Isaac Newton, Charles Babbage, James Lighthill, Paul Dirac and Stephen Hawking.
p5257
aVSchools with separate applied mathematics departments range from Brown University, which has a large Division of Applied Mathematics that offers degrees through the doctorate, to Santa Clara University, which offers only the M.S. in applied mathematics. Research universities dividing their mathematics department into pure and applied sections include MIT.
p5258
aVAssociated mathematical sciences.
p5259
aVApplied mathematics is closely related to other mathematical sciences.
p5260
aVScientific computing.
p5261
aVScientific computing includes applied mathematics (especially numerical analysis), computing science (especially high-performance computing), and mathematical modelling in a scientific discipline.
p5262
aVComputer science.
p5263
aVComputer science relies on logic, algebra, and combinatorics.
p5264
aVOperations research and management science.
p5265
aVOperations research and management science are often taught in faculties of engineering, business, and public policy.
p5266
aVStatistics.
p5267
aVApplied mathematics has substantial overlap with the discipline of statistics. Statistical theorists study and improve statistical procedures with mathematics, and statistical research often raises mathematical questions. Statistical theory relies on probability and decision theory, and makes extensive use of scientific computing, analysis, and optimization; for the design of experiments, statisticians use algebra and combinatorial design. Applied mathematicians and statisticians often work in a department of mathematical sciences (particularly at colleges and small universities).
p5268
aVActuarial science.
p5269
aVActuarial science applies probability, statistics, and economic theory to assess risk in insurance, finance and other industries and professions.
p5270
aVMathematical economics.
p5271
aVMathematical economics is the application mathematical methods to represent theories and analyze problems in economics. The applied methods usually refer to nontrivial mathematical techniques or approaches. Mathematical economics is based on statistics, probability, mathematical programming (as well as other computational methods), operations research, game theory, and some methods from mathematical analysis. In this regard, it resembles (but is distinct from) financial mathematics, another part of applied mathematics.
p5272
aVAccording to the Mathematics Subject Classification (MSC), mathematical economics falls into the Applied mathematics/other classification of category 91:
p5273
aVGame theory, economics, social and behavioral sciences
p5274
aVwith MSC2010 classifications for 'Game theory' at codes 91Axx and for 'Mathematical economics' at codes 91Bxx.
p5275
aVOther disciplines.
p5276
aVThe line between applied mathematics and specific areas of application is often blurred. Many universities teach mathematical and statistical courses outside of the respective departments, in departments and areas including business, engineering, physics, chemistry, psychology, biology, computer science, scientific computation, and mathematical physics.
p5277
asS'Continuous function'
p5278
(lp5279
VIn mathematics, a continuous function is, roughly speaking, a function for which small changes in the input result in small changes in the output. Otherwise, a function is said to be a "discontinuous" function. A continuous function with a continuous inverse function is called a homeomorphism.
p5280
aVContinuity of functions is one of the core concepts of topology, which is treated in full generality below. The introductory portion of this article focuses on the special case where the inputs and outputs of functions are real numbers. In addition, this article discusses the definition for the more general case of functions between two metric spaces. In order theory, especially in domain theory, one considers a notion of continuity known as Scott continuity. Other forms of continuity do exist but they are not discussed in this article.
p5281
aVAs an example, consider the function "h"("t"), which describes the height of a growing flower at time "t". This function is continuous. By contrast, if "M"("t") denotes the amount of money in a bank account at time "t", then the function jumps whenever money is deposited or withdrawn, so the function "M"("t") is discontinuous.
p5282
aVHistory.
p5283
aVA form of this epsilon-delta definition of continuity was first given by Bernard Bolzano in 1817. Augustin-Louis Cauchy defined continuity of formula_1 as follows: an infinitely small increment formula_2 of the independent variable "x" always produces an infinitely small change formula_3 of the dependent variable "y" (see e.g., "Cours d'Analyse", p. 34). Cauchy defined infinitely small quantities in terms of variable quantities, and his definition of continuity closely parallels the infinitesimal definition used today (see microcontinuity). The formal definition and the distinction between pointwise continuity and uniform continuity were first given by Bolzano in the 1830s but the work wasn't published until the 1930s. Eduard Heine provided the first published definition of uniform continuity in 1872, but based these ideas on lectures given by Peter Gustav Lejeune Dirichlet in 1854.
p5284
aVReal-valued continuous functions.
p5285
aVDefinition.
p5286
aVA function from the set of real numbers to the real numbers can be represented by a graph in the Cartesian plane; such a function is continuous if, roughly speaking, the graph is a single unbroken curve with no "holes" or "jumps".
p5287
aVThere are several ways to make this definition mathematically rigorous. These definitions are equivalent to one another, so the most convenient definition can be used to determine whether a given function is continuous or not. In the definitions below, 
p5288
aVformula_4
p5289
aVis a function defined on a subset "I" of the set R of real numbers. This subset "I" is referred to as the domain of "f". Some possible choices include "I"=R, the whole set of real numbers, an open interval
p5290
aVformula_5
p5291
aVor a closed interval
p5292
aVformula_6
p5293
aVHere, "a" and "b" are real numbers.
p5294
aVDefinition in terms of limits of functions.
p5295
aVThe function "f" is "continuous at some point" "c" of its domain if the limit of "f"("x") as "x" approaches "c" through the domain of "f" exists and is equal to "f"("c"). In mathematical notation, this is written as
p5296
aVformula_7
p5297
aVIn detail this means three conditions: first, "f" has to be defined at "c". Second, the limit on the left hand side of that equation has to exist. Third, the value of this limit must equal "f"("c").
p5298
aVThe function "f" is said to be "continuous" if it is continuous at every point of its domain. 
p5299
aVIf the point "c" in the domain of "f" is not a limit point of the domain, then this condition is vacuously true, since "x" cannot approach "c" through values not equal to "c". Thus, for example, every function whose domain is the set of all integers is continuous.
p5300
aVDefinition in terms of limits of sequences.
p5301
aVOne can instead require that for any sequence formula_8 of points in the domain which converges to "c", the corresponding sequence formula_9 converges to "f"("c"). In mathematical notation, formula_10
p5302
aVWeierstrass definition (epsilon-delta) of continuous functions.
p5303
aVExplicitly including the definition of the limit of a function, we obtain a self-contained definition:
p5304
aVGiven a function "f" as above and an element "c" of the domain "I", "f" is said to be continuous at the point "c" if the following holds: For any number "\u03b5" > 0, however small, there exists some number "\u03b4" > 0 such that for all "x" in the domain of "f" with "c" \u2212 "\u03b4" < "x" < "c" + "\u03b4", the value of "f"("x") satisfies
p5305
aVformula_11
p5306
aVAlternatively written, continuity of "f" : "I" \u2192 "R" at "c" \u2208 "I" means that for every "\u03b5" > 0 there exists a "\u03b4" > 0 such that for all "x" \u2208 "I",:
p5307
aVformula_12
p5308
aVMore intuitively, we can say that if we want to get all the "f"("x") values to stay in some small neighborhood around "f"("c"), we simply need to choose a small enough neighborhood for the "x" values around "c", and we can do that no matter how small the "f"("x") neighborhood is; "f" is then continuous at "c".
p5309
aVIn modern terms, this is generalized by the definition of continuity of a function with respect to a basis for the topology, here the metric topology.
p5310
aVDefinition using oscillation.
p5311
aVContinuity can also be defined in terms of oscillation: a function "f" is continuous at a point "x"0 if and only if its oscillation at that point is zero; in symbols, formula_13 A benefit of this definition is that it "quantifies" discontinuity: the oscillation gives how "much" the function is discontinuous at a point.
p5312
aVThis definition is useful in descriptive set theory to study the set of discontinuities and continuous points \u2013 the continuous points are the intersection of the sets where the oscillation is less than "\u03b5" (hence a G\u03b4 set) \u2013 and gives a very quick proof of one direction of the Lebesgue integrability condition.
p5313
aVThe oscillation is equivalent to the "\u03b5"-"\u03b4" definition by a simple re-arrangement, and by using a limit (lim sup, lim inf) to define oscillation: if (at a given point) for a given "\u03b5"0 there is no "\u03b4" that satisfies the "\u03b5"-"\u03b4" definition, then the oscillation is at least "\u03b5"0, and conversely if for every "\u03b5" there is a desired "\u03b4," the oscillation is 0. The oscillation definition can be naturally generalized to maps from a topological space to a metric space.
p5314
aVDefinition using the hyperreals.
p5315
aVCauchy defined continuity of a function in the following intuitive terms: an infinitesimal change in the independent variable corresponds to an infinitesimal change of the dependent variable (see "Cours d'analyse", page 34). Non-standard analysis is a way of making this mathematically rigorous. The real line is augmented by the addition of infinite and infinitesimal numbers to form the hyperreal numbers. In nonstandard analysis, continuity can be defined as follows.
p5316
aVA real-valued function "f" is continuous at "x" if its natural extension to the hyperreals has the property that for all infinitesimal "dx", is infinitesimal
p5317
aV(see microcontinuity). In other words, an infinitesimal increment of the independent variable always produces to an infinitesimal change of the dependent variable, giving a modern expression to Augustin-Louis Cauchy's definition of continuity.
p5318
aVExamples.
p5319
aVAll polynomial functions, such as 
p5320
aV(pictured), are continuous. This is a consequence of the fact that, given two continuous functions
p5321
aVformula_14
p5322
aVdefined on the same domain "I", then the sum "f" + "g", and the product "fg" of the two functions are continuous (on the same domain "I"). Moreover, the function
p5323
aVformula_15
p5324
aVis continuous. (The points where "g"("x") is zero have to be discarded for "f"/"g" to be defined.) For example, the function (pictured)
p5325
aVformula_16
p5326
aVis defined for all real numbers and is continuous at every such point. The question of continuity at does not arise, since is not in the domain of "f". There is no continuous function "F": R \u2192 R that agrees with "f"("x") for all . The sinc function "g"("x") = (sin "x")/"x", defined for all "x"\u22600 is continuous at these points. However, this function "can" be extended to a continuous function on all real numbers, namely
p5327
aVformula_17
p5328
aVsince the limit of "g"("x"), when "x" approaches 0, is 1. Therefore, the point "x"=0 is called a removable singularity of "g".
p5329
aVGiven two continuous functions 
p5330
aVformula_18
p5331
aVthe composition 
p5332
aVformula_19
p5333
aVis continuous.
p5334
aVNon-examples.
p5335
aVAn example of a discontinuous function is the function "f" defined by "f"("x") = 1 if "x" > 0, "f"("x") = 0 if "x" \u2264 0. Pick for instance \u03b5 = . There is no \u03b4-neighborhood around "x" = 0 that will force all the "f"("x") values to be within \u03b5 of "f"(0). Intuitively we can think of this type of discontinuity as a sudden jump in function values. Similarly, the signum or sign function
p5336
aVformula_20
p5337
aVis discontinuous at "x" = 0 but continuous everywhere else. Yet another example: the function
p5338
aVformula_21
p5339
aVis continuous everywhere apart from "x" = 0.
p5340
aVThomae's function,
p5341
aVformula_22
p5342
aVis continuous at all irrational numbers and discontinuous at all rational numbers. In a similar vein, Dirichlet's function
p5343
aVformula_23
p5344
aVis nowhere continuous.
p5345
aVProperties.
p5346
aVIntermediate value theorem.
p5347
aVThe intermediate value theorem is an existence theorem, based on the real number property of completeness, and states:
p5348
aV If the real-valued function "f" is continuous on the closed interval ["a", "b"] and "k" is some number between "f"("a") and "f"("b"), then there is some number "c" in ["a", "b"] such that "f"("c") = "k".
p5349
aVFor example, if a child grows from 1 m to 1.5 m between the ages of two and six years, then, at some time between two and six years of age, the child's height must have been 1.25 m.
p5350
aVAs a consequence, if "f" is continuous on ["a", "b"] and "f"("a") and "f"("b") differ in sign, then, at some point "c" in ["a", "b"], "f"("c") must equal zero.
p5351
aVExtreme value theorem.
p5352
aVThe extreme value theorem states that if a function "f" is defined on a closed interval ["a","b"] (or any closed and bounded set) and is continuous there, then the function attains its maximum, i.e. there exists "c" \u2208 ["a","b"] with "f"("c") \u2265 "f"("x") for all "x" \u2208 ["a","b"]. The same is true of the minimum of "f". These statements are not, in general, true if the function is defined on an open interval ("a","b") (or any set that is not both closed and bounded), as, for example, the continuous function "f"("x") = 1/"x", defined on the open interval (0,1), does not attain a maximum, being unbounded above.
p5353
aVRelation to differentiability and integrability.
p5354
aVEvery differentiable function 
p5355
aVformula_24
p5356
aVis continuous, as can be shown. The converse does not hold: for example, the absolute value function
p5357
aVformula_25
p5358
aVis everywhere continuous. However, it is not differentiable at "x" = 0 (but is so everywhere else). Weierstrass's function is everywhere continuous but nowhere differentiable.
p5359
aVThe derivative "f\u2032"("x") of a differentiable function "f"("x") need not be continuous. If "f\u2032"("x") is continuous, "f"("x") is said to be continuously differentiable. The set of such functions is denoted "C"1(). More generally, the set of functions
p5360
aVformula_26
p5361
aV(from an open interval (or open subset of R) \u03a9 to the reals) such that "f" is "n" times differentiable and such that the "n"-th derivative of "f" is continuous is denoted "C""n"(\u03a9). See differentiability class. In the field of computer graphics, these three levels are sometimes called "G"0 (continuity of position), "G"1 (continuity of tangency), and "G"2 (continuity of curvature).
p5362
aVEvery continuous function 
p5363
aVformula_27
p5364
aVis integrable (for example in the sense of the Riemann integral). The converse does not hold, as the (integrable, but discontinuous) sign function shows.
p5365
aVPointwise and uniform limits.
p5366
aVGiven a sequence 
p5367
aVformula_28
p5368
aVof functions such that the limit 
p5369
aVformula_29
p5370
aVexists for all "x" in "I", the resulting function "f"("x") is referred to as the pointwise limit of the sequence of functions ("f""n")"n"\u2208N. The pointwise limit function need not be continuous, even if all functions "f""n" are continuous, as the animation at the right shows. However, "f" is continuous when the sequence converges uniformly, by the uniform convergence theorem. This theorem can be used to show that the exponential functions, logarithms, square root function, trigonometric functions are continuous.
p5371
aVDirectional and semi-continuity.
p5372
aVDiscontinuous functions may be discontinuous in a restricted way, giving rise to the concept of directional continuity (or right and left continuous functions) and semi-continuity. Roughly speaking, a function is "right-continuous" if no jump occurs when the limit point is approached from the right. More formally, "f" is said to be right-continuous at the point "c" if the following holds: For any number "\u03b5" > 0 however small, there exists some number "\u03b4" > 0 such that for all "x" in the domain with , the value of "f"("x") will satisfy
p5373
aVformula_30
p5374
aVThis is the same condition as for continuous functions, except that it is required to hold for "x" strictly larger than "c" only. Requiring it instead for all "x" with yields the notion of "left-continuous" functions. A function is continuous if and only if it is both right-continuous and left-continuous.
p5375
aVA function "f" is "lower semi-continuous" if, roughly, any jumps that might occur only go down, but not up. That is, for any "\u03b5" > 0, there exists some number "\u03b4" > 0 such that for all "x" in the domain with , the value of "f"("x") satisfies
p5376
aVformula_31
p5377
aVThe reverse condition is "upper semi-continuity".
p5378
aVContinuous functions between metric spaces.
p5379
aVThe concept of continuous real-valued functions can be generalized to functions between metric spaces. A metric space is a set "X" equipped with a function (called metric) "d""X", that can be thought of as a measurement of the distance of any two elements in "X". Formally, the metric is a function
p5380
aVformula_32
p5381
aVthat satisfies a number of requirements, notably the triangle inequality. Given two metric spaces ("X", d"X") and ("Y", d"Y") and a function
p5382
aVformula_33
p5383
aVthen "f" is continuous at the point "c" in "X" (with respect to the given metrics) if for any positive real number \u03b5, there exists a positive real number \u03b4 such that all "x" in "X" satisfying d"X"("x", "c") < \u03b4 will also satisfy d"Y"("f"("x"), "f"("c")) < \u03b5. As in the case of real functions above, this is equivalent to the condition that for every sequence ("x""n") in "X" with limit lim "x""n" = "c", we have lim "f"("x""n") = "f"("c"). The latter condition can be weakened as follows: "f" is continuous at the point "c" if and only if for every convergent sequence ("x""n") in "X" with limit "c", the sequence ("f"("x""n")) is a Cauchy sequence, and "c" is in the domain of "f".
p5384
aVThe set of points at which a function between metric spaces is continuous is a G\u03b4 set \u2013 this follows from the \u03b5-\u03b4 definition of continuity.
p5385
aVThis notion of continuity is applied, for example, in functional analysis. A key statement in this area says that a linear operator 
p5386
aVformula_34
p5387
aVbetween normed vector spaces "V" and "W" (which are vector spaces equipped with a compatible norm, denoted ||"x"||)
p5388
aVis continuous if and only if it is bounded, that is, there is a constant "K" such that 
p5389
aVformula_35
p5390
aVfor all "x" in "V".
p5391
aVUniform, Hölder and Lipschitz continuity.
p5392
aVThe concept of continuity for functions between metric spaces can be strengthened in various ways by limiting the way \u03b4 depends on \u03b5 and "c" in the definition above. Intuitively, a function "f" as above is uniformly continuous if the \u03b4 does 
p5393
aVnot depend on the point "c". More precisely, it is required that for every real number "\u03b5" > 0 there exists "\u03b4" > 0 such that for every "c", "b" \u2208 "X" with "d""X"("b", "c") < "\u03b4", we have that "d""Y"("f"("b"), "f"("c")) < "\u03b5". Thus, any uniformly continuous function is continuous. The converse does not hold in general, but holds when the domain space "X" is compact. Uniformly continuous maps can be defined in the more general situation of uniform spaces.
p5394
aVA function is Hölder continuous with exponent \u03b1 (a real number) if there is a constant "K" such that for all "b" and "c" in "X", the inequality
p5395
aVformula_36
p5396
aVholds. Any Hölder continuous function is uniformly continuous. The particular case is referred to as Lipschitz continuity. That is, a function is Lipschitz continuous if there is a constant "K" such that the inequality
p5397
aVformula_37
p5398
aVholds any "b", "c" in "X". The Lipschitz condition occurs, for example, in the Picard\u2013Lindelöf theorem concerning the solutions of ordinary differential equations.
p5399
aVContinuous functions between topological spaces.
p5400
aVAnother, more abstract, notion of continuity is continuity of functions between topological spaces in which there generally is no formal notion of distance, as there is in the case of metric spaces. A topological space is a set "X" together with a topology on "X", which is a set of subsets of "X" satisfying a few requirements with respect to their unions and intersections that generalize the properties of the open balls in metric spaces while still allowing to talk about the neighbourhoods of a given point. The elements of a topology are called open subsets of "X" (with respect to the topology).
p5401
aVA function 
p5402
aVformula_33
p5403
aVbetween two topological spaces "X" and "Y" is continuous if for every open set "V" \u2286 "Y", the inverse image
p5404
aVformula_39
p5405
aVis an open subset of "X". That is, "f" is a function between the sets "X" and "Y" (not on the elements of the topology "TX"), but the continuity of "f" depends on the topologies used on "X" and "Y".
p5406
aVThis is equivalent to the condition that the preimages of the closed sets (which are the complements of the open subsets) in "Y" are closed in "X".
p5407
aVAn extreme example: if a set "X" is given the discrete topology (in which every subset is open), all functions 
p5408
aVformula_40
p5409
aVto any topological space "T" are continuous. On the other hand, if "X" is equipped with the indiscrete topology (in which the only open subsets are the empty set and "X") and the space "T" set is at least T0, then the only continuous functions are the constant functions. Conversely, any function whose range is indiscrete is continuous.
p5410
aVAlternative definitions.
p5411
aVSeveral equivalent definitions for a topological structure exist and thus there are several equivalent ways to define a continuous function.
p5412
aVNeighborhood definition.
p5413
aVNeighborhoods continuity for functions between topological spaces at a point to be defined:
p5414
aVA function is continuous at a point iff for any neighborhood of its image the preimage is again a neighborhood of that point: formula_41
p5415
aVAccording to the property that neighborhood systems being upper sets this can be restated as follows:
p5416
aVformula_42
p5417
aVformula_43
p5418
aVThe second one being a restatement involving the image rather than the preimage.
p5419
aVLiterally, this means no matter how small the neighborhood is chosen one can always find a neighborhood mapped into it.
p5420
aVBesides, there's a simplification involving only open neighborhoods. In fact, they're equivalent:
p5421
aVformula_44
p5422
aVformula_45
p5423
aVThe second one again being a restatement using images rather than preimages.
p5424
aVIf "X" and "Y" are metric spaces, it is equivalent to consider the neighborhood system of open balls centered at "x" and "f"("x") instead of all neighborhoods. This gives back the above \u03b4-\u03b5 definition of continuity in the context of metric spaces. However, in general topological spaces, there is no notion of nearness or distance.
p5425
aVNote, however, that if the target space is Hausdorff, it is still true that "f" is continuous at "a" if and only if the limit of "f" as "x" approaches "a" is "f"("a"). At an isolated point, every function is continuous.
p5426
aVSequences and nets.
p5427
aVIn several contexts, the topology of a space is conveniently specified in terms of limit points. In many instances, this is accomplished by specifying when a point is the limit of a sequence, but for some spaces that are too large in some sense, one specifies also when a point is the limit of more general sets of points indexed by a directed set, known as nets. A function is (Heine-)continuous only if it takes limits of sequences to limits of sequences. In the former case, preservation of limits is also sufficient; in the latter, a function may preserve all limits of sequences yet still fail to be continuous, and preservation of nets is a necessary and sufficient condition.
p5428
aVIn detail, a function "f": "X" \u2192 "Y" is sequentially continuous if whenever a sequence ("x""n") in "X" converges to a limit "x", the sequence ("f"("x""n")) converges to "f"("x"). Thus sequentially continuous functions "preserve sequential limits". Every continuous function is sequentially continuous. If "X" is a first-countable space and countable choice holds, then the converse also holds: any function preserving sequential limits is continuous. In particular, if "X" is a metric space, sequential continuity and continuity are equivalent. For non first-countable spaces, sequential continuity might be strictly weaker than continuity. (The spaces for which the two properties are equivalent are called sequential spaces.) This motivates the consideration of nets instead of sequences in general topological spaces. Continuous functions preserve limits of nets, and in fact this property characterizes continuous functions.
p5429
aVClosure operator definition.
p5430
aVInstead of specifying the open subsets of a topological space, the topology can also be determined by a closure operator (denoted cl) which assigns to any subset "A" \u2286 "X" its closure, or an interior operator (denoted int), which assigns to any subset "A" of "X" its interior. In these terms, a function 
p5431
aVformula_46
p5432
aVbetween topological spaces is continuous in the sense above if and only if for all subsets "A" of "X"
p5433
aVformula_47
p5434
aVThat is to say, given any element "x" of "X" that is in the closure of any subset "A", "f"("x") belongs to the closure of "f"("A"). This is equivalent to the requirement that for all subsets "A"' of "X"'
p5435
aVformula_48
p5436
aVMoreover, 
p5437
aVformula_49
p5438
aVis continuous if and only if 
p5439
aVformula_50
p5440
aVfor any subset "A"' of "Y".
p5441
aVProperties.
p5442
aVIf "f": "X" \u2192 "Y" and "g": "Y" \u2192 "Z" are continuous, then so is the composition "g" \u2218 "f": "X" \u2192 "Z". If "f": "X" \u2192 "Y" is continuous and
p5443
aVThe possible topologies on a fixed set "X" are partially ordered: a topology \u03c41 is said to be coarser than another topology \u03c42 (notation: \u03c41 \u2286 \u03c42) if every open subset with respect to \u03c41 is also open with respect to \u03c42. Then, the identity map 
p5444
aVidX: ("X", \u03c42) \u2192 ("X", \u03c41)
p5445
aVis continuous if and only if \u03c41 \u2286 \u03c42 (see also comparison of topologies). More generally, a continuous function
p5446
aVformula_51
p5447
aVstays continuous if the topology \u03c4"Y" is replaced by a coarser topology and/or \u03c4"X" is replaced by a finer topology.
p5448
aVHomeomorphisms.
p5449
aVSymmetric to the concept of a continuous map is an open map, for which "images" of open sets are open. In fact, if an open map "f" has an inverse function, that inverse is continuous, and if a continuous map "g" has an inverse, that inverse is open. Given a bijective function "f" between two topological spaces, the inverse function "f"\u22121 need not be continuous. A bijective continuous function with continuous inverse function is called a "homeomorphism".
p5450
aVIf a continuous bijection has as its domain a compact space and its codomain is Hausdorff, then it is a homeomorphism.
p5451
aVDefining topologies via continuous functions.
p5452
aVGiven a function
p5453
aVformula_52
p5454
aVwhere "X" is a topological space and "S" is a set (without a specified topology), the final topology on "S" is defined by letting the open sets of "S" be those subsets "A" of "S" for which "f"\u22121("A") is open in "X". If "S" has an existing topology, "f" is continuous with respect to this topology if and only if the existing topology is coarser than the final topology on "S". Thus the final topology can be characterized as the finest topology on "S" that makes "f" continuous. If "f" is surjective, this topology is canonically identified with the quotient topology under the equivalence relation defined by "f".
p5455
aVDually, for a function "f" from a set "S" to a topological space, the initial topology on "S" has as open subsets "A" of "S" those subsets for which "f"("A") is open in "X". If "S" has an existing topology, "f" is continuous with respect to this topology if and only if the existing topology is finer than the initial topology on "S". Thus the initial topology can be characterized as the coarsest topology on "S" that makes "f" continuous. If "f" is injective, this topology is canonically identified with the subspace topology of "S", viewed as a subset of "X".
p5456
aVMore generally, given a set "S", specifying the set of continuous functions 
p5457
aVformula_53
p5458
aVinto all topological spaces "X" defines a topology. Dually, a similar idea can be applied to maps
p5459
aVformula_54
p5460
aVThis is an instance of a universal property.
p5461
aVRelated notions.
p5462
aVVarious other mathematical domains use the concept of continuity in different, but related meanings. For example, in order theory, an order-preserving function "f": "X" \u2192 "Y" between two complete lattices "X" and "Y" (particular types of partially ordered sets) is continuous if for each subset "A" of "X", we have sup("f"("A")) = "f"(sup("A")). Here sup is the supremum with respect to the orderings in "X" and "Y", respectively. Applying this to the complete lattice consisting of the open subsets of a topological space, this gives back the notion of continuity for maps between topological spaces.
p5463
aVIn category theory, a functor
p5464
aVformula_55
p5465
aVbetween two categories is called "continuous", if it commutes with small limits. That is to say,
p5466
aVformula_56
p5467
aVfor any small (i.e., indexed by a set "I", as opposed to a class) diagram of objects in formula_57.
p5468
aVA "continuity space" is a generalization of metric spaces and posets, which uses the concept of quantales, and that can be used to unify the notions of metric spaces and domains.
p5469
asS'Halting problem'
p5470
(lp5471
VIn computability theory, the halting problem is the problem of determining, from a description of an arbitrary computer program and an input, whether the program will finish running or continue to run forever.
p5472
aVAlan Turing proved in 1936 that a general algorithm to solve the halting problem for "all" possible program-input pairs cannot exist. A key part of the proof was a mathematical definition of a computer and program, which became known as a Turing machine; the halting problem is "undecidable" over Turing machines. It is one of the first examples of a decision problem.
p5473
aVJack Copeland (2004) attributes the term "halting problem" to Martin Davis.
p5474
aVBackground.
p5475
aVThe halting problem is a decision problem about properties of computer programs on a fixed Turing-complete model of computation, i.e. all programs that can be written in some given programming language that is general enough to be equivalent to a Turing machine. The problem is to determine, given a program and an input to the program, whether the program will eventually halt when run with that input. In this abstract framework, there are no resource limitations on the amount of memory or time required for the program's execution; it can take arbitrarily long, and use arbitrarily much storage space, before halting. The question is simply whether the given program will ever halt on a particular input.
p5476
aVFor example, in pseudocode, the program:
p5477
aVwhile (true) continue
p5478
aVdoes not halt; rather, it goes on forever in an infinite loop. On the other hand, the program
p5479
aVprint "Hello, world!"
p5480
aVdoes halt.
p5481
aVWhile deciding whether these programs halt is simple, more complex programs prove problematic.
p5482
aVOne approach to the problem might be to run the program for some number of steps and check if it halts. But if the program does not halt, it is unknown whether the program will eventually halt or run forever.
p5483
aVTuring proved no algorithm can exist which will always correctly decide whether, for a given arbitrary program and its input, the program halts when run with that input; the essence of Turing's proof is that any such algorithm can be made to contradict itself, and therefore cannot be correct.
p5484
aVImportance and consequences.
p5485
aVThe halting problem is historically important because it was one of the first problems to be proved undecidable. (Turing's proof went to press in May 1936, whereas Alonzo Church's proof of the undecidability of a problem in the lambda calculus had already been published in April 1936.) Subsequently, many other undecidable problems have been described; the typical method of proving a problem to be undecidable is with the technique of "reduction". To do this, it is sufficient to show that if a solution to the new problem were found, it could be used to decide an undecidable problem by transforming instances of the undecidable problem into instances of the new problem. Since we already know that "no" method can decide the old problem, no method can decide the new problem either. Often the new problem is reduced to solving the halting problem. (Note: the same technique is used to demonstrate that a problem is NP complete, only in this case, rather than demonstrating that there is no solution, it demonstrates there is no "polynomial time" solution, assuming P \u2260 NP).
p5486
aVFor example, one such consequence of the halting problem's undecidability is that there cannot be a general algorithm that decides whether a given statement about natural numbers is true or not. The reason for this is that the proposition stating that a certain program will halt given a certain input can be converted into an equivalent statement about natural numbers. If we had an algorithm that could solve every statement about natural numbers, it could certainly solve this one; but that would determine whether the original program halts, which is impossible, since the halting problem is undecidable.
p5487
aVRice's theorem generalizes the theorem that the halting problem is unsolvable. It states that for "any" non-trivial property, there is no general decision procedure that, for all programs, decides whether the partial function implemented by the input program has that property. (A partial function is a function which may not always produce a result, and so is used to model programs, which can either produce results or fail to halt.) For example, the property "halt for the input 0" is undecidable. Here, "non-trivial" means that the set of partial functions that satisfy the property is neither the empty set nor the set of all partial functions. For example, "halts or fails to halt on input 0" is clearly true of all partial functions, so it is a trivial property, and can be decided by an algorithm that simply reports "true." Also, note that this theorem holds only for properties of the partial function implemented by the program; Rice's Theorem does not apply to properties of the program itself. For example, "halt on input 0 within 100 steps" is not a property of the partial function that is implemented by the program\u2014it is a property of the program implementing the partial function and is very much decidable.
p5488
aVGregory Chaitin has defined a halting probability, represented by the symbol \u03a9, a type of real number that informally is said to represent the probability that a randomly produced program halts. These numbers have the same Turing degree as the halting problem. It is a normal and transcendental number which can be defined but cannot be completely computed. This means one can prove that there is no algorithm which produces the digits of \u03a9, although its first few digits can be calculated in simple cases.
p5489
aVWhile Turing's proof shows that there can be no general method or algorithm to determine whether algorithms halt, individual instances of that problem may very well be susceptible to attack. Given a specific algorithm, one can often show that it must halt for any input, and in fact computer scientists often do just that as part of a correctness proof. But each proof has to be developed specifically for the algorithm at hand; there is no "mechanical, general way" to determine whether algorithms on a Turing machine halt. However, there are some heuristics that can be used in an automated fashion to attempt to construct a proof, which succeed frequently on typical programs. This field of research is known as automated termination analysis.
p5490
aVSince the negative answer to the halting problem shows that there are problems that cannot be solved by a Turing machine, the Church\u2013Turing thesis limits what can be accomplished by any machine that implements effective methods. However, not all machines conceivable to human imagination are subject to the Church\u2013Turing thesis (e.g. oracle machines). It is an open question whether there can be actual deterministic physical processes that, in the long run, elude simulation by a Turing machine, and in particular whether any such hypothetical process could usefully be harnessed in the form of a calculating machine (a hypercomputer) that could solve the halting problem for a Turing machine amongst other things. It is also an open question whether any such unknown physical processes are involved in the working of the human brain, and whether humans can solve the halting problem (Copeland 2004, p. 15).
p5491
aVRepresentation as a set.
p5492
aVThe conventional representation of decision problems is the set of objects possessing the property in question. The halting set
p5493
aV "K" := { ("i", "x") | program "i" halts when run on input "x"}
p5494
aVrepresents the halting problem.
p5495
aVThis set is recursively enumerable, which means there is a computable function that lists all of the pairs ("i", "x") it contains. However, the complement of this set is not recursively enumerable.
p5496
aVThere are many equivalent formulations of the halting problem; any set whose Turing degree equals that of the halting problem is such a formulation. Examples of such sets include:
p5497
aVSketch of proof.
p5498
aVThe proof shows there is no total computable function that decides whether an arbitrary program "i" halts on arbitrary input "x"; that is, the following function "h" is not computable (Penrose 1990, p. 57\u201363):
p5499
aVformula_1
p5500
aVHere "program i" refers to the "i" th program in an enumeration of all the programs of a fixed Turing-complete model of computation.
p5501
aVPossible values for a total computable function "f" arranged in a 2D array. The orange cells are the diagonal. The values of "f"("i","i") and "g"("i") are shown at the bottom; "U" indicates that the function "g" is undefined for a particular input value.
p5502
aVThe proof proceeds by directly establishing that every total computable function with two arguments differs from the required function "h". To this end, given any total computable binary function "f", the following partial function "g" is also computable by some program "e":
p5503
aVformula_2
p5504
aVThe verification that "g" is computable relies on the following constructs (or their equivalents):
p5505
aVThe following pseudocode illustrates a straightforward way to compute "g":
p5506
aVBecause "g" is partial computable, there must be a program "e" that computes "g", by the assumption that the model of computation is Turing-complete. This program is one of all the programs on which the halting function "h" is defined. The next step of the proof shows that "h"("e","e") will not have the same value as "f"("e","e").
p5507
aVIt follows from the definition of "g" that exactly one of the following two cases must hold:
p5508
aVIn either case, "f" cannot be the same function as "h". Because "f" was an "arbitrary" total computable function with two arguments, all such functions must differ from "h".
p5509
aVThis proof is analogous to Cantor's diagonal argument. One may visualize a two-dimensional array with one column and one row for each natural number, as indicated in the table above. The value of "f"("i","j") is placed at column "i", row "j". Because "f" is assumed to be a total computable function, any element of the array can be calculated using "f". The construction of the function "g" can be visualized using the main diagonal of this array. If the array has a 0 at position ("i","i"), then "g"("i") is 0. Otherwise, "g"("i") is undefined. The contradiction comes from the fact that there is some column "e" of the array corresponding to "g" itself. Now assume "f" was the halting function "h", if "g"("e") is defined ( "g"("e") = 0 in this case ), "g"("e") halts so "f"("e,e") = 1. But "g"("e") = 0 only when "f"("e,e") = 0, contradicting "f"("e,e") = 1. Similarly, if "g"("e") is not defined, then halting function "f"("e,e") = 0, which leads to "g"("e") = 0 under "g"'s construction. This contradicts the assumption that "g"("e") not being defined. In both cases contradiction arises. Therefore any arbitrary computable function "f" cannot be the halting function "h".
p5510
aVProof as a corollary of the uncomputability of Kolmogorov complexity.
p5511
aVThe undecidability of the halting problem also follows from the fact that Kolmogorov complexity is not computable. If the halting problem were decidable, it would be possible to construct a program that generated programs of increasing length, running those that halt and comparing their final outputs with a string parameter until one matched (which must happen eventually, as any string can be generated by a program that contains it as data and just lists it); the length of the matching generated program would then be the Kolmogorov complexity of the parameter, as the terminating generated program must be the shortest (or shortest equal) such program.
p5512
aVCommon pitfalls.
p5513
aVThe difficulty in the halting problem lies in the requirement that the decision procedure must work for all programs and inputs. A particular program either halts on a given input or does not halt. Consider one algorithm that always answers "halts" and another that always answers "doesn't halt". For any specific program and input, one of these two algorithms answers correctly, even though nobody may know which one.
p5514
aVThere are programs (interpreters) that simulate the execution of whatever source code they are given. Such programs can demonstrate that a program does halt if this is the case: the interpreter itself will eventually halt its simulation, which shows that the original program halted. However, an interpreter will not halt if its input program does not halt, so this approach cannot solve the halting problem as stated. It does not successfully answer "doesn't halt" for programs that do not halt.
p5515
aVThe halting problem is theoretically decidable for linear bounded automata (LBAs) or deterministic machines with finite memory. A machine with finite memory has a finite number of states, and thus any deterministic program on it must eventually either halt or repeat a previous state:
p5516
aV..."any finite-state machine, if left completely to itself, will fall eventually into a perfectly periodic repetitive pattern". The duration of this repeating pattern cannot exceed the number of internal states of the machine... (italics in original, Minsky 1967, p. 24)
p5517
aVMinsky warns us, however, that machines such as computers with e.g., a million small parts, each with two states, will have at least 21,000,000 possible states:
p5518
aVThis is a 1 followed by about three hundred thousand zeroes ... Even if such a machine were to operate at the frequencies of cosmic rays, the aeons of galactic evolution would be as nothing compared to the time of a journey through such a cycle (Minsky 1967 p. 25):
p5519
aVMinsky exhorts the reader to be suspicious\u2014although a machine may be finite, and finite automata "have a number of theoretical limitations":
p5520
aV...the magnitudes involved should lead one to suspect that theorems and arguments based chiefly on the mere finiteness the state diagram may not carry a great deal of significance. (Minsky p. 25)
p5521
aVIt can also be decided automatically whether a nondeterministic machine with finite memory halts on none of, some of, or all of the possible sequences of nondeterministic decisions, by enumerating states after each possible decision.
p5522
aVFormalization.
p5523
aVIn his original proof Turing formalized the concept of "algorithm" by introducing Turing machines. However, the result is in no way specific to them; it applies equally to any other model of computation that is equivalent in its computational power to Turing machines, such as Markov algorithms, Lambda calculus, Post systems, register machines, or tag systems.
p5524
aVWhat is important is that the formalization allows a straightforward mapping of algorithms to some data type that the algorithm can operate upon. For example, if the formalism lets algorithms define functions over strings (such as Turing machines) then there should be a mapping of these algorithms to strings, and if the formalism lets algorithms define functions over natural numbers (such as computable functions) then there should be a mapping of algorithms to natural numbers. The mapping to strings is usually the most straightforward, but strings over an alphabet with "n" characters can also be mapped to numbers by interpreting them as numbers in an "n"-ary numeral system.
p5525
aVRelationship with Gödel's incompleteness theorems.
p5526
aVThe concepts raised by Gödel's incompleteness theorems are very similar to those raised by the halting problem, and the proofs are quite similar. In fact, a weaker form of the First Incompleteness Theorem is an easy consequence of the undecidability of the halting problem. This weaker form differs from the standard statement of the incompleteness theorem by asserting that a complete, consistent and sound axiomatization of all statements about natural numbers is unachievable. The "sound" part is the weakening: it means that we require the axiomatic system in question to prove only "true" statements about natural numbers (it's very important to observe that the statement of the standard form of Gödel's First Incompleteness Theorem is completely unconcerned with the question of truth, and only concerns formal provability).
p5527
aVThe weaker form of the theorem can be proven from the undecidability of the halting problem as follows. Assume that we have a consistent and complete axiomatization of all true first-order logic statements about natural numbers. Then we can build an algorithm that enumerates all these statements. This means that there is an algorithm "N"("n") that, given a natural number "n", computes a true first-order logic statement about natural numbers such that, for all the true statements, there is at least one "n" such that "N"("n") yields that statement. Now suppose we want to decide whether the algorithm with representation "a" halts on input "i". By using Kleene's T predicate, we can express the statement ""a" halts on input "i"" as a statement "H"("a", "i") in the language of arithmetic. Since the axiomatization is complete it follows that either there is an "n" such that "N"("n") = "H"("a", "i") or there is an "n'" such that "N"("n'") = ¬ "H"("a", "i"). So if we iterate over all "n" until we either find "H"("a", "i") or its negation, we will always halt. This means that this gives us an algorithm to decide the halting problem. Since we know that there cannot be such an algorithm, it follows that the assumption that there is a consistent and complete axiomatization of all true first-order logic statements about natural numbers must be false.
p5528
aVRecognizing partial solutions.
p5529
aVThere are many programs that either return a correct answer to the halting problem or do not return an answer at all. If it were possible to decide whether any given program gives only correct answers, one might hope to collect a large number of such programs and run them in parallel and determine whether any programs halt. Curiously, deciding whether a program is a partial halting solver (PHS) is as hard as the halting problem itself.
p5530
aVSuppose it's possible to decide whether any given program is a partial halting solver.
p5531
aVThen there exists a partial halting solver recognizer, PHSR, guaranteed to terminate with an answer.
p5532
aVConstruct a program H:
p5533
aVBy construction, program H is also guaranteed to terminate with an answer.
p5534
aVIf PHSR recognizes the constructed program X as a partial halting solver, that means that P, the only input for which X produces a result, halts.
p5535
aVIf PHSR fails to recognize X, then it must be because P does not halt.
p5536
aVTherefore H can decide whether an arbitrary program P halts; it solves the halting problem.
p5537
aVSince this is impossible, then the program PHSR could not have existed as supposed.
p5538
aVTherefore, it's not possible to decide whether any given program is a partial halting solver.
p5539
aVAvoiding the halting problem.
p5540
aVIn many practical situations, programmers try to avoid infinite loops\u2014they want every subroutine to finish (halt).
p5541
aVIn particular, in hard real-time computing,
p5542
aVprogrammers attempt to write subroutines that are not only guaranteed to finish (halt),
p5543
aVbut are guaranteed to finish before the given deadline.
p5544
aVSometimes these programmers use some general-purpose (Turing-complete) programming language,
p5545
aVbut attempt to write in a restricted style\u2014such as MISRA C\u2014that makes it easy to prove that the resulting subroutines finish before the given deadline.
p5546
aVOther times these programmers apply the rule of least power\u2014they deliberately use a computer language that is not quite fully Turing-complete, often a language that guarantees that all subroutines are guaranteed to finish, such as Coq.
p5547
asS'Aleph null'
p5548
(lp5549
sS'Epigraph (mathematics)'
p5550
(lp5551
VIn mathematics, the epigraph or supergraph of a function "f" : Rn\u2192R is the set of points lying on or above its graph:
p5552
aV formula_1
p5553
aVThe strict epigraph is the epigraph with the graph itself removed:
p5554
aV formula_2
p5555
aVThe same definitions are valid for a function that takes values in R \u222a \u221e. In this case, the epigraph is empty if and only if "f" is identically equal to infinity.
p5556
aVThe domain (rather than the co-domain) of the function is not particularly important for this definition; it can be any linear space or even an arbitrary set instead of formula_3.
p5557
aVSimilarly, the set of points on or below the function is its hypograph.
p5558
aVProperties.
p5559
aVA function is convex if and only if its epigraph is a convex set. The epigraph of a real affine function "g" : Rn\u2192R is a halfspace in Rn+1.
p5560
aVA function is lower semicontinuous if and only if its epigraph is closed.
p5561
asS'Immersion (mathematics)'
p5562
(lp5563
V"For a closed immersion in algebraic geometry, see closed immersion."
p5564
aVIn mathematics, an immersion is a differentiable function between differentiable manifolds whose derivative is everywhere injective. Explicitly, "f" : "M" \u2192 "N" is an immersion if
p5565
aVformula_1
p5566
aVis an injective function at every point "p" of "M" (where the notation "TpX" represents the tangent space of "X" at the point "p"). Equivalently, "f" is an immersion if its derivative has constant rank equal to the dimension of "M":
p5567
aVformula_2
p5568
aVThe function "f" itself need not be injective, only its derivative.
p5569
aVA related concept is that of an embedding. A smooth embedding is an injective immersion "f" : "M" \u2192 "N" which is also a topological embedding, so that "M" is diffeomorphic to its image in "N". An immersion is precisely a local embedding \u2013 i.e. for any point "x" \u2208 "M" there is a neighbourhood, "U" \u2282 "M", of "x" such that "f" : "U" \u2192 "N" is an embedding, and conversely a local embedding is an immersion. For infinite dimensional manifolds, this is sometimes taken to be the definition of an immersion.
p5570
aVIf "M" is compact, an injective immersion is an embedding, but if "M" is not compact then injective immersions need not be embeddings; compare to continuous bijections versus homeomorphisms.
p5571
aVRegular homotopy.
p5572
aVA regular homotopy between two immersions "f" and "g" from a manifold "M" to a manifold "N" is defined to be a differentiable function "H" : "M" × \u2192 "N" such for all "t" in [0, 1 the function "Ht" : "M" \u2192 "N" defined by "Ht"("x") = "H"("x", "t") for all "x" \u2208 "M" is an immersion, with "H"0 = "f", "H"1 = "g". A regular homotopy is thus a homotopy through immersions.
p5573
aVClassification.
p5574
aVHassler Whitney initiated the systematic study of immersions and regular homotopies in the 1940s, proving that for 2"m" < "n"+1 every map "f" : "Mm" \u2192 "Nn" of an "m"-dimensional manifold to an "n"-dimensional manifold is homotopic to an immersion, and in fact to an embedding for 2"m" < "n"; these are the Whitney immersion theorem and Whitney embedding theorem.
p5575
aVStephen Smale expressed the regular homotopy classes of immersions "f" : "Mm" \u2192 R"n" as the homotopy groups of a certain Stiefel manifold. The sphere eversion was a particularly striking consequence. 
p5576
aVMorris Hirsch generalized Smale's expression to a homotopy theory description of the regular homotopy classes of immersions of any "m"-dimensional manifold "Mm" in any "n"-dimensional manifold "Nn".
p5577
aVThe Hirsch-Smale classification of immersions was generalized by Mikhail Gromov.
p5578
aVExistence.
p5579
aVThe primary obstruction to the existence of an immersion "i" : "Mm" \u2192 R"n" is the stable normal bundle of "M," as detected by its characteristic classes, notably its Stiefel\u2013Whitney classes. That is, since R"n" is parallelizable, the pullback of its tangent bundle to "M" is trivial; since this pullback is the direct sum of the (intrinsically defined) tangent bundle on "M," "TM," which has dimension "m," and of the normal bundle \u03bd of the immersion "i," which has dimension "n"\u2212"m", for there to be a codimension "k" immersion of "M," there must be a vector bundle of dimension "k," \u03be"k", standing in for the normal bundle \u03bd, such that "TM" \u2295 \u03be"k" is trivial. Conversely, given such a bundle, an immersion of "M" with this normal bundle is equivalent to a codimension 0 immersion of the total space of this bundle, which is an open manifold.
p5580
aVThe stable normal bundle is the class of normal bundles plus trivial bundles, and thus if the stable normal bundle has cohomological dimension "k," it cannot come from an (unstable) normal bundle of dimension less than "k". Thus, the cohomology dimension of the stable normal bundle, as detected by its highest non-vanishing characteristic class, is an obstruction to immersions.
p5581
aVSince characteristic classes multiply under direct sum of vector bundles, this obstruction can be stated intrinsically in terms of the space "M" and its tangent bundle and cohomology algebra. This obstruction was stated (in terms of the tangent bundle, not stable normal bundle) by Whitney.
p5582
aVFor example, the Möbius strip has non-trivial tangent bundle, so it cannot immerse in codimension 0 (in R2), though it embeds in codimension 1 (in R3).
p5583
aVIn 1960, William S. Massey showed that these characteristic classes (the Stiefel\u2013Whitney classes of the stable normal bundle) vanish above degree "n"\u2212\u03b1("n"), where \u03b1("n") is the number of \u201c1\u201d digits when "n" is written in binary; this bound is sharp, as realized by real projective space. This gave evidence to the "Immersion Conjecture," namely that every "n"-manifold could be immersed in codimension "n"\u2212\u03b1("n"), i.e., in R2"n"\u2212\u03b1("n"). This conjecture was proven in 1985 by Ralph Cohen .
p5584
aVCodimension 0.
p5585
aVCodimension 0 immersions are equivalently "relative" dimension 0 "submersions," and are better thought of as submersions. A codimension 0 immersion of a closed manifold is precisely a covering map, i.e., a fiber bundle with 0-dimensional (discrete) fiber. By Ehresmann's theorem and Phillips' theorem on submersions, a proper submersion of manifolds is a fiber bundle, hence codimension/relative dimension 0 immersions/submersions behave like submersions.
p5586
aVFurther, codimenson 0 immersions do not behave like other immersions, which are largely determined by the stable normal bundle: in codimension 0 one has issues of fundamental class and cover spaces. For instance, there is no codimension 0 immersion S1 \u2192 R1, despite the circle being parallelizable, which can be proven because the line has no fundamental class, so one does not get the required map on top cohomology. Alternatively, this is by invariance of domain. Similarly, although S3 and the 3-torus T3 are both parallelizable, there is no immersion T3 \u2192 S3 \u2013 any such cover would have to be ramified at some points, since the sphere is simply connected.
p5587
aVAnother way of understanding this is that a codimension "k" immersion of a manifold corresponds to a codimension 0 immersion of a "k"-dimensional vector bundle, which is an "open" manifold if the codimension is greater than 0, but to a closed manifold in codimension 0 (if the original manifold is closed).
p5588
aVMultiple points.
p5589
aVA ""'k"-tuple point"' (double, triple, etc.) of an immersion "f" : "M" \u2192 "N" is an unordered set {"x"1, ..., "xk"} of distinct points "xi" \u2208 "M" with the same image "f"("xi") \u2208 "N". If "M" is an "m"-dimensional manifold and "N" is an "n"-dimensional manifold then for an immersion "f" : "M" \u2192 "N" in general position the set of "k"-tuple points is an "n"\u2212"k"("n"\u2212"m")-dimensional manifold. Every embedding is an immersion without multiple points (where "k" > 1). Note, however, that the converse is false: there are injective immersions that are not embeddings.
p5590
aVThe nature of the multiple points classifies immersions; for example, immersions of a circle in the plane are classified up to regular homotopy by the number of double points.
p5591
aVAt a key point in surgery theory it is necessary to decide if an immersion "f" : S"m" \u2192 "N2m" of an "m"-sphere in a 2"m"-dimensional manifold is regular homotopic to an embedding, in which case it can be killed by surgery. Wall associated to "f" an invariant \u03bc("f") in a quotient of the fundamental group ring Z[\u03c01("N")] which counts the double points of "f" in the universal cover of "N". For "m" > 2, "f" is regular homotopic to an embedding if and only if \u03bc("f") = 0 by the Whitney trick.
p5592
aVOne can study embeddings as "immersions without multiple points", since immersions are easier to classify. Thus, one can start from immersions and try to eliminate multiple points, seeing if one can do this without introducing other singularities \u2013 studying "multiple disjunctions". This was first done by André Haefliger, and this approach is fruitful in codimension 3 or more \u2013 from the point of view of surgery theory, this is "high (co)dimension", unlike codimension 2 which is the knotting dimension, as in knot theory. It is studied categorically via the "calculus of functors" by Thomas Goodwillie, John Klein, and Michael S. Weiss.
p5593
aVExamples and properties.
p5594
aVImmersed plane curves.
p5595
aVImmersed plane curves have a well-defined turning number, which can be defined as the total curvature divided by 2"\u03c0". This is invariant under regular homotopy, by the Whitney\u2013Graustein theorem \u2013 topologically, it is the degree of the Gauss map, or equivalently the winding number of the unit tangent (which does not vanish) about the origin. Further, this is a complete set of invariants \u2013 any two plane curves with the same turning number are regular homotopic.
p5596
aVEvery immersed plane curve lifts to an embedded space curve via separating the intersection points, which is not true in higher dimensions. With added data (which strand is on top), immersed plane curves yield knot diagrams, which are of central interest in knot theory. While immersed plane curves, up to regular homotopy, are determined by their turning number, knots have a very rich and complex structure.
p5597
aVImmersed surfaces in 3-space.
p5598
aVThe study of immersed surfaces in 3-space is closely connected with the study of knotted (embedded) surfaces in 4-space, by analogy with the theory of knot diagrams (immersed plane curves (2-space) as projections of knotted curves in 3-space): given a knotted surface in 4-space, one can project it to an immersed surface in 3-space, and conversely, given an immersed surface in 3-space, one may ask if it lifts to 4-space \u2013 is it the projection of a knotted surface in 4-space? This allows one to relate questions about these objects.
p5599
aVA basic result, in contrast to the case of plane curves, is that not every immersed surface lifts to a knotted surface. In some cases the obstruction is 2-torsion, such as in "Koschorke's example," which is an immersed surface (formed from 3 Möbius bands, with a triple point) that does not lift to a knotted surface, but it has a double cover that does lift. A detailed analysis is given in , while a more recent survey is given in .
p5600
aVGeneralizations.
p5601
aVA far-reaching generalization of immersion theory is the homotopy principle:
p5602
aVone may consider the immersion condition (the rank of the derivative is always "k") as a partial differential relation (PDR), as it can be stated in terms of the partial derivatives of the function. Then Smale\u2013Hirsch immersion theory is the result that this reduces to homotopy theory, and the homotopy principle gives general conditions and reasons for PDRs to reduce to homotopy theory.
p5603
asS'Permutation'
p5604
(lp5605
VIn mathematics, the notion of permutation relates to the act of rearranging, or permuting, all the members of a set into some sequence or order (unlike combinations, which are selections of some members of the set where order is disregarded). For example, written as tuples, there are six permutations of the set {1,2,3}, namely: (1,2,3), (1,3,2), (2,1,3), (2,3,1), (3,1,2), and (3,2,1). As another example, an anagram of a word, all of whose letters are different, is a permutation of its letters. The study of permutations of finite sets is a topic in the field of combinatorics.
p5606
aVPermutations occur, in more or less prominent ways, in almost every area of mathematics. They often arise when different orderings on certain finite sets are considered, possibly only because one wants to ignore such orderings and needs to know how many configurations are thus identified. For similar reasons permutations arise in the study of sorting algorithms in computer science.
p5607
aVThe number of permutations of "n" distinct objects is "n" factorial usually written as , which means the product of all positive integers less than or equal to "n".
p5608
aVIn algebra and particularly in group theory, a permutation of a set "S" is defined as a bijection from "S" to itself. That is, it is a function from "S" to "S" for which every element occurs exactly once as an image value. This is related to the rearrangement of the elements of "S" in which each element "s" is replaced by the corresponding "f"("s"). The collection of such permutations form a group called the symmetric group of "S". The key to this group's structure is the fact that the composition of two permutations (performing two given rearrangements in succession) results in another rearrangement. Permutations may "act" on structured objects by rearranging their components, or by certain replacements (substitutions) of symbols.
p5609
aVIn elementary combinatorics, the "k"-permutations, or partial permutations, are the ordered arrangements of "k" distinct elements selected from a set. When "k" is equal to the size of the set, these are the permutations of the set.
p5610
aVHistory.
p5611
aVThe rule to determine the number of permutations of "n" objects was known in Indian culture at least as early as around 1150: the Lilavati by the Indian mathematician Bhaskara II contains a passage that translates to
p5612
aVThe product of multiplication of the arithmetical series beginning and increasing by unity and continued to the number of places, will be the variations of number with specific figures.
p5613
aVFabian Stedman in 1677 described factorials when explaining the number of permutations of bells in change ringing. Starting from two bells: "first, "two" must be admitted to be varied in two ways" which he illustrates by showing 1 2 and 2 1. He then explains that with three bells there are "three times two figures to be produced out of three" which again is illustrated. His explanation involves "cast away 3, and 1.2 will remain; cast away 2, and 1.3 will remain; cast away 1, and 2.3 will remain". He then moves on to four bells and repeats the casting away argument showing that there will be four different sets of three. Effectively this is an recursive process. He continues with five bells using the "casting away" method and tabulates the resulting 120 combinations. At this point he gives up and remarks:
p5614
aVNow the nature of these methods is such, that the changes on one number comprehends the changes on all lesser numbers, ... insomuch that a compleat Peal of changes on one number seemeth to be formed by uniting of the compleat Peals on all lesser numbers into one entire body;
p5615
aVStedman widens the consideration of permutations; he goes on to consider the number of permutations of the letters of the alphabet and horses from a stable of 20.
p5616
aVA first case in which seemingly unrelated mathematical questions were studied with the help of permutations occurred around 1770, when Joseph Louis Lagrange, in the study of polynomial equations, observed that properties of the permutations of the roots of an equation are related to the possibilities to solve it. This line of work ultimately resulted, through the work of Évariste Galois, in Galois theory, which gives a complete description of what is possible and impossible with respect to solving polynomial equations (in one unknown) by radicals. In modern mathematics there are many similar situations in which understanding a problem requires studying certain permutations related to it.
p5617
aVDefinition and one-line notation.
p5618
aVThere are two equivalent common ways of regarding permutations, sometimes called the "active" and "passive" forms, or in older terminology "substitutions" and "permutations". Which form is preferable depends on the type of questions being asked in a given discipline.
p5619
aVThe "active" way to regard permutations of a set "S" (finite or infinite) is to define them as the bijections from "S" to itself. Thus, the permutations are thought of as functions which can be composed with each other, forming groups of permutations. From this viewpoint, the elements of "S" have no internal structure and are just labels for the objects being moved: one may refer to permutations of any set of "n" elements as "permutations on "n" letters".
p5620
aVIn Cauchy's "two-line notation", one lists the elements of "S" in the first row, and for each one its image below it in the second row. For instance, a particular permutation of the set "S" = {1,2,3,4,5} can be written as:
p5621
aV formula_1
p5622
aVthis means that "\u03c3" satisfies "\u03c3"(1)=2, "\u03c3"(2)=5, "\u03c3"(3)=4, "\u03c3"(4)=3, and "\u03c3"(5)=1. The elements of "S" may appear in any order in the first row. This permutation could also be written as:
p5623
aV formula_2
p5624
aVThe "passive" way to regard a permutation of the set "S" is an "ordered arrangement" (or listing, or linearly ordered arrangement, or sequence without repetition) of the elements of "S". This is related to the active form as follows. If there is a "natural" order for the elements of "S", say formula_3, then one uses this for the first row of the two-line notation:
p5625
aV formula_4
p5626
aVUnder this assumption, one may omit the first row and write the permutation in "one-line notation" as formula_5, that is, an ordered arrangement of S. Care must be taken to distinguish one-line notation from the cycle notation described later. In mathematics literature, a common usage is to omit parentheses for one-line notation, while using them for cycle notation. The one-line notation is also called the "word representation" of a permutation. The example above would then be 2 5 4 3 1 since the natural order 1 2 3 4 5 would be assumed for the first row. (It is typical to use commas to separate these entries only if some have two or more digits.) This form is more compact, and is common in elementary combinatorics and computer science. It is especially useful in applications where the elements of "S" or the permutations are to be compared as larger or smaller.
p5627
aVThere are "n"! permutations of a finite set "S" having "n" elements.
p5628
aVOther uses of the term "permutation".
p5629
aVThe concept of a permutation as an ordered arrangement admits several generalizations that are not permutations but have been called permutations in the literature.
p5630
aV"k"-permutations of "n".
p5631
aVA weaker meaning of the term "permutation", sometimes used in elementary combinatorics texts, designates those ordered arrangements in which no element occurs more than once, but without the requirement of using all the elements from a given set. These are not permutations except in special cases, but are natural generalizations of the ordered arrangement concept. Indeed, this use often involves considering arrangements of a fixed length "k" of elements taken from a given set of size "n", in other words, these ""'k"-permutations of "n""' are the different ordered arrangements of a "k"-element subset of an "n"-set (sometimes called variations in the older literature.) These objects are also known as partial permutations or as sequences without repetition, terms that avoid confusion with the other, more common, meaning of "permutation". The number of such formula_6-permutations of formula_7 is denoted variously by such symbols as formula_8, formula_9, formula_10, formula_11, or formula_12, and its value is given by the product
p5632
aV formula_13,
p5633
aVwhich is 0 when , and otherwise is equal to
p5634
aV formula_14
p5635
aVThe product is well defined without the assumption that formula_7 is a non-negative integer and is of importance outside combinatorics as well; it is known as the Pochhammer symbol formula_16 or as the formula_6-th falling factorial power formula_18 of formula_7.
p5636
aVThis usage of the term "permutation" is closely related to the term "combination". A "k"-element combination of an "n"-set "S" is a "k" element subset of "S", the elements of which are not ordered. By taking all the "k" element subsets of "S" and ordering each of them in all possible ways we obtain all the "k"-permutations of "S". The number of "k"-combinations of an "n"-set, "C"("n","k"), is therefore related to the number of "k"-permutations of "n" by:
p5637
aV formula_20
p5638
aVThese numbers are also known as binomial coefficients and denoted formula_21.
p5639
aVPermutations with repetition.
p5640
aVOrdered arrangements of the elements of a set "S" of length "n" where repetition is allowed are called "n"-tuples, but have sometimes been referred to as permutations with repetition although they are not permutations in general. They are also called words over the alphabet "S" in some contexts. If the set "S" has "k" elements, the number of "n"-tuples over "S" is:
p5641
aVformula_22
p5642
aVThere is no restriction on how often an element can appear in an "n"-tuple, but if restrictions are placed on how often an element can appear, this formula is no longer valid.
p5643
aVPermutations of multisets.
p5644
aVIf "M" is a finite multiset, then a multiset permutation is an ordered arrangement of elements of "M" in which each element appears exactly as often as is its multiplicity in "M". An anagram of a word having some repeated letters is an example of a multiset permutation. If the multiplicities of the elements of "M" (taken in some order) are formula_23, formula_24, ..., formula_25 and their sum (i.e., the size of "M") is "n", then the number of multiset permutations of "M" is given by the multinomial coefficient,
p5645
aVformula_26
p5646
aVFor example, the number of distinct anagrams of the word MISSISSIPPI is:
p5647
aVformula_27.
p5648
aVA k-permutation of a multiset "M" is a sequence of length "k" of elements of "M" in which each element appears "at most" its multiplicity in "M" times (an element's "repetition number").
p5649
aVCircular permutations.
p5650
aVPermutations, when considered as arrangements, are sometimes referred to as "linearly ordered" arrangements. In these arrangements there is a first element, a second element, and so on. If, however, the objects are arranged in a circular manner this distinguished ordering no longer exists, that is, there is no "first element" in the arrangement, any element can be considered as the start of the arrangement. The arrangements of objects in a circular manner are called circular permutations. These can be formally defined as equivalence classes of ordinary permutations of the objects, for the equivalence relation generated by moving the final element of the linear arrangement to its front.
p5651
aVTwo circular permutations are equivalent if one can be rotated into the other (that is, cycled without changing the relative positions of the elements). The following two circular permutations on four letters are considered to be the same.
p5652
aVThe circular arrangements are to be read counterclockwise, so the following two are not equivalent since no rotation can bring one to the other.
p5653
aVThe number of circular permutations of a set "S" with "n" elements is ("n" - 1)!.
p5654
aVPermutations in group theory.
p5655
aVThe set of all permutations of any given set "S" forms a group, with the composition of maps as the product operation and the identity function as the neutral element of the group. This is the symmetric group of "S", denoted by Sym("S"). Up to isomorphism, this symmetric group only depends on the cardinality of the set (called the "degree" of the group), so the nature of elements of "S" is irrelevant for the structure of the group. Symmetric groups have been studied mostly in the case of finite sets, so, confined to this case, one can assume without loss of generality that "S" = {1,2...,"n"} for some natural number "n". This is then the symmetric group of degree "n", usually written as .
p5656
aVAny subgroup of a symmetric group is called a permutation group. By Cayley's theorem any group is isomorphic to some permutation group, and every finite group to a subgroup of some finite symmetric group.
p5657
aVCycle notation.
p5658
aVThis alternative notation describes the effect of repeatedly applying the permutation, thought of as a function from a set onto itself. It expresses the permutation as a product of cycles corresponding to the orbits of the permutation; since distinct orbits are disjoint, this is referred to as "decomposition into disjoint cycles". 
p5659
aVStarting from some element "x" of "S", one writes the sequence ("x" "\u03c3"("x") "\u03c3"("\u03c3"("x")) ...) of successive images under "\u03c3", until the image returns to "x", at which point one closes the parenthesis rather than repeat "x". The set of values written down forms the orbit (under "\u03c3") of "x", and the parenthesized expression gives the corresponding cycle of "\u03c3". One then continues by choosing a new element "y" of "S" outside the previous orbit and writing down the cycle starting at "y"; and so on until all elements of "S" are written in cycles. Since for every new cycle the starting point can be chosen in different ways, there are in general many different cycle notations for the same permutation; for the example above one has:
p5660
aVformula_28
p5661
aVA cycle ("x") of length 1 occurs when \u03c3("x") = "x", and is commonly omitted from the cycle notation, provided the set "S" is clear: for any element "x" \u2208 "S" not appearing in a cycle, one implicitly assumes \u03c3("x") = "x". The identity permutation, which consists only of 1-cycles, can be denoted by a single 1-cycle (x), by the number 1, or by "id". 
p5662
aVA cycle ("x"1 "x"2 ... "x""k") of length "k" is called a "k"-cycle. Written by itself, it denotes a permutation in its own right, which maps "x""i" to "x""i"+1 for , and "x""k" to "x"1, while implicitly mapping all other elements of "S" to themselves (omitted 1-cycles). Therefore the individual cycles in the cycle notation can be interpreted as factors in a composition product. Since the orbits are disjoint, the corresponding cycles commute under composition, and so can be written in any order. The cycle decomposition is essentially unique: apart from the reordering the cycles in the product, there are no other ways to write "\u03c3" as a product of cycles. Each individual cycle can be written in different ways, as in the example above where (5 1 2) and (1 2 5) and (2 5 1) all denote the same cycle, though note that (5 2 1) denotes a different cycle.
p5663
aVAn element in a 1-cycle ("x"), corresponding to \u03c3("x") = "x", is called a fixed point of the permutation \u03c3. A permutation with no fixed points is called a derangement. Cycles of length two are called transpositions; such permutations merely exchange the place of two elements, implicitly leaving the others fixed. Since the orbits of a permutation partition the set "S", for a finite set of size "n", the lengths of the cycles of a permutation \u03c3 form a partition of "n" called the cycle type of \u03c3. There is a "1" in the cycle type for every fixed point of \u03c3, a "2" for every transposition, and so on. The cycle type of \u03b2 = (1 2 5)(3 4)(6 8)(7), is (3,2,2,1) which is sometimes written in a more compact form as (11,22,31).
p5664
aVThe number of "n"-permutations with "k" disjoint cycles is the signless Stirling number of the first kind, denoted by formula_29.
p5665
aVAbstract groups vs. permutations vs. group actions.
p5666
aVPermutation groups have more structure than abstract groups, and different realizations of a group as a permutation group need not be equivalent as permutations. For instance is naturally a permutation group, in which any transposition has cycle type (2,1); but the proof of Cayley's theorem realizes as a subgroup of (namely the permutations of the 6 elements of itself), in which permutation group transpositions have cycle type (2,2,2). Finding the minimal-order symmetric group containing a subgroup isomorphic to a given group (sometimes called minimal faithful degree representation) is a rather difficult problem. So in spite of Cayley's theorem, the study of permutation groups differs from the study of abstract groups, being a branch of representation theory.
p5667
aVMuch of the power of permutations can be regained in an abstract setting by considering group actions instead. A group action actually permutes the elements of a set according to the recipe provided by the abstract group. For example, acts faithfully and transitively (by permuting) a set with exactly three elements.
p5668
aVProduct and inverse.
p5669
aVThe product of two permutations is defined as their composition as functions, in other words "\u03c3·\u03c0" is the function that maps any element "x" of the set to "\u03c3"("\u03c0"("x")). Note that the rightmost permutation is applied to the argument first,
p5670
aVbecause of the way function application is written. Some authors prefer the leftmost factor acting first,
p5671
aVbut to that end permutations must be written to the "right" of their argument, for instance as an exponent, where "\u03c3" acting on "x" is written "x""\u03c3"; then the product is defined by "x""\u03c3·\u03c0" = ("x""\u03c3")"\u03c0". However this gives a "different" rule for multiplying permutations; this article uses the definition where the rightmost permutation is applied first.
p5672
aVSince the composition of two bijections always gives another bijection, the product of two permutations is again a permutation. In two-line notation, the product of two permutations is obtained by rearranging the columns of the second (leftmost) permutation so that its first row is identical with the second row of the first (rightmost) permutation. The product can then be written as the first row of the first permutation over the second row of the modified second permutation. For example, given the permutations,
p5673
aVformula_30
p5674
aVthe product "QP" is:
p5675
aVformula_31
p5676
aVIn cyclic notation this same product would be given by:
p5677
aVformula_32
p5678
aVSince function composition is associative, so is the product operation on permutations: ("\u03c3·\u03c0")·"\u03c1" = "\u03c3"·("\u03c0·\u03c1"). Therefore, products of more than two permutations are usually written without adding parentheses to express grouping; they are also usually written without a dot or other sign to indicate multiplication.
p5679
aVThe identity permutation, which maps every element of the set to itself, is the neutral element for this product. In two-line notation, the identity is
p5680
aVformula_33
p5681
aVSince bijections have inverses, so do permutations, and the inverse "\u03c3"\u22121 of "\u03c3" is again a permutation. Explicitly, whenever "\u03c3"("x")="y" one also has "\u03c3"\u22121("y")="x". In two-line notation the inverse can be obtained by interchanging the two lines (and sorting the columns if one wishes the first line to be in a given order). For instance
p5682
aVformula_34
p5683
aVHaving an associative product, a neutral element, and inverses for all its elements, makes the set of all permutations of "S" into a group, called the symmetric group of "S".
p5684
aVProperties.
p5685
aVEvery permutation of a finite set can be expressed as the product of transpositions.
p5686
aVMoreover, although many such expressions for a given permutation may exist, there can never be among them both expressions with an even number and expressions with an odd number of transpositions. All permutations are then classified as even or odd, according to the parity of the transpositions in any such expression.
p5687
aVMultiplying permutations written in cycle notation follows no easily described pattern, and the cycles of the product can be entirely different from those of the permutations being composed. However the cycle structure is preserved in the special case of conjugating a permutation "\u03c3" by another permutation "\u03c0", which means forming the product "\u03c0·\u03c3·\u03c0"\u22121. Here the cycle notation of the result can be obtained by taking the cycle notation for "\u03c3" and applying "\u03c0" to all the entries in it.
p5688
aVMatrix representation.
p5689
aVOne can represent a permutation of {1, 2, ..., "n"} as an "n"×"n" matrix. There are two natural ways to do so, but only one for which multiplications of matrices corresponds to multiplication of permutations in the same order: this is the one that associates to "\u03c3" the matrix "M" whose entry "M""i","j" is 1 if "i" = "\u03c3"("j"), and 0 otherwise. The resulting matrix has exactly one entry 1 in each column and in each row, and is called a "permutation matrix". <br>
p5690
aVHere (file) is a list of these matrices for permutations of 4 elements. The Cayley table on the right shows these matrices for permutations of 3 elements.
p5691
aVPermutation of components of a sequence.
p5692
aVAs with any group, one can consider actions of a symmetric group on a set, and there are many ways in which such an action can be defined. For the symmetric group of {1, 2, ..., "n"} there is one particularly natural action, namely the action by permutation on the set "X""n" of sequences of "n" symbols taken from some set "X". As with the matrix representation, there are two natural ways in which the result of permuting a sequence ("x"1,"x"2...,"x""n") by "\u03c3" can be defined, but only one is compatible with the multiplication of permutations (so as to give a left action of the symmetric group on "X""n"); with the multiplication rule used in this article this is the one given by
p5693
aVformula_35
p5694
aVThis means that each component "x""i" ends up at position "\u03c3"("i") in the sequence permuted by "\u03c3".
p5695
aVPermutations of totally ordered sets.
p5696
aVIn some applications, the elements of the set being permuted will be compared with each other. This requires that the set "S" has a total order so that any two elements can be compared. The set {1, 2, ..., "n"} is totally ordered by the usual "\u2264" relation and so it is the most frequently used set in these applications, but in general, any totally ordered set will do. In these applications, the ordered arrangement view of a permutation is needed to talk about the "positions" in a permutation.
p5697
aVHere are a number of properties that are directly related to the total ordering of "S".
p5698
aVAscents, descents, runs and excedances.
p5699
aVAn "ascent" of a permutation "\u03c3" of "n" is any position "i" < "n" where the following value is bigger than the current one. That is, if "\u03c3" = "\u03c3"1"\u03c3"2..."\u03c3""n", then "i" is an ascent if "\u03c3""i" < "\u03c3""i"+1.
p5700
aVFor example, the permutation 3452167 has ascents (at positions) 1,2,5,6.
p5701
aVSimilarly, a "descent" is a position "i" < "n" with "\u03c3""i" > "\u03c3""i"+1, so every "i" with formula_36 either is an ascent or is a descent of "\u03c3".
p5702
aVAn "ascending run" of a permutation is a nonempty increasing contiguous subsequence of the permutation that cannot be extended at either end; it corresponds to a maximal sequence of successive ascents (the latter may be empty: between two successive descents there is still an ascending run of length 1). By contrast an "increasing subsequence" of a permutation is not necessarily contiguous: it is an increasing sequence of elements obtained from the permutation by omitting the values at some positions.
p5703
aVFor example, the permutation 2453167 has the ascending runs 245, 3, and 167, while it has an increasing subsequence 2367.
p5704
aVIf a permutation has "k" \u2212 1 descents, then it must be the union of "k" ascending runs.
p5705
aVThe number of permutations of "n" with "k" ascents is (by definition) the Eulerian number formula_37; this is also the number of permutations of "n" with "k" descents. Some authors however define the Eulerian number formula_37 as the number of permutations with "k" ascending runs, which corresponds to "k"-1 descents.
p5706
aVAn excedance of a permutation "\u03c3"1"\u03c3"2..."\u03c3""n" in an index "j" such that "\u03c3""j" > "j". If the inequality is not strict, i.e. "\u03c3""j" \u2265 "j", then "j" is called a "weak excedance". The number of "n"-permutations with "k" excedances coincides with the number of "n"-permutations with "k" descents.
p5707
aVCanonical cycle notation (aka standard form).
p5708
aVIn some combinatorial contexts it useful to fix a certain order or the elements in the cycles and of the (disjoint) cycles themselves. Miklós Bóna calls the following ordering choices the "canonical cycle notation":
p5709
aVFor example, (312)(54)(8)(976) is a permutation in canonical cycle notation. Note that the canonical cycle notation does not omit one-cycles.
p5710
aVRichard P. Stanley calls the same choice of representation the "standard representation" of a permutation. and Martin Aigner uses the term "standard form" for the same notion. Sergey Kitaev also uses the "standard form" terminology, but reverses both choices, i.e. each cycle lists its least element first and the cycles are sorted in decreasing order of their least/first elements. In the remainder of this article, we use the first of these dual forms as the standard/canonical one.
p5711
aVFoata's transition lemma (or the fundamental bijection).
p5712
aVA natural question arises as to the relationship of the one-line and the canonical cycle notation. For example, considering the permutation (2)(31), which is in canonical cycle notation, if we erase its cycle parentheses, we obtain a different permutation in one-line notation, namely 231. (The permutation (2)(31) is actually 321 in one-line notation.) Foata's transition lemma establishes the nature of this correspondence as a bijection on the set of "n"-permutations (to itself). Richard P. Stanley calls this correspondence the "fundamental bijection".
p5713
aVLet formula_39 be the parentheses-erasing transformation. The inverse of formula_40 is a bit less intuitive. Starting with the one-line notation formula_41, the first cycle in canonical cycle notation must start with formula_42. As long as the subsequent elements are smaller than formula_42, we are in the same cycle. The second cycle starts at the smallest index formula_44 such that formula_45. In other words, formula_46 is larger than everything else to its left, so it is called a "left-to-right maximum". Every cycle in the canonical cycle notation starts with a left-to-right maximum.
p5714
aVFor example, in the one-line notation 312548976, 5 is the first element larger than 3, so the first cycle must be (312). Then 8 is the next element larger than 5, so the second cycle is (54). Since 9 is larger than 8, (8) is a cycle by itself. Finally, 9 is larger than all the remaining elements to its right, so the last cycle is (976).
p5715
aVAs a first corollary, the number of n-permutations with exactly "k" left-to-right maxima is also equal to the signless Stirling number of the first kind, formula_29. Furthermore, Foata's mapping takes an "n"-permutation with "k"-weak excedances to an "n"-permutations with "k" \u2212 1 ascents. For example, (2)(31) = 321 has two weak excedances (at index 1 and 2), whereas "f"(321)=231 has one ascent (at index 1, i.e. from 2 to 3).
p5716
aVInversions.
p5717
aVAn "inversion" of a permutation "\u03c3" is a pair ("i","j") of positions where the entries of a permutation are in the opposite order: formula_48 and formula_49. So a descent is just an inversion at two adjacent positions. For example, the permutation "\u03c3" = 23154 has three inversions: (1,3), (2,3), (4,5), for the pairs of entries (2,1), (3,1), (5,4).
p5718
aVSometimes an inversion is defined as the pair of values ("\u03c3""i","\u03c3""j") itself whose order is reversed; this makes no difference for the "number" of inversions, and this pair (reversed) is also an inversion in the above sense for the inverse permutation "\u03c3"\u22121. The number of inversions is an important measure for the degree to which the entries of a permutation are out of order; it is the same for "\u03c3" and for "\u03c3"\u22121. To bring a permutation with "k" inversions into order (i.e., transform it into the identity permutation), by successively applying (right-multiplication by) adjacent transpositions, is always possible and requires a sequence of "k" such operations. Moreover any reasonable choice for the adjacent transpositions will work: it suffices to choose at each step a transposition of "i" and where "i" is a descent of the permutation as modified so far (so that the transposition will remove this particular descent, although it might create other descents). This is so because applying such a transposition reduces the number of inversions by 1; also note that as long as this number is not zero, the permutation is not the identity, so it has at least one descent. Bubble sort and insertion sort can be interpreted as particular instances of this procedure to put a sequence into order. Incidentally this procedure proves that any permutation "\u03c3" can be written as a product of adjacent transpositions; for this one may simply reverse any sequence of such transpositions that transforms "\u03c3" into the identity. In fact, by enumerating all sequences of adjacent transpositions that would transform "\u03c3" into the identity, one obtains (after reversal) a "complete" list of all expressions of minimal length writing "\u03c3" as a product of adjacent transpositions.
p5719
aVThe number of permutations of "n" with "k" inversions is expressed by a Mahonian number, it is the coefficient of "X""k" in the expansion of the product
p5720
aVformula_50
p5721
aVwhich is also known (with "q" substituted for "X") as the q-factorial ["n"]"q"! . The expansion of the product appears in Necklace (combinatorics).
p5722
aVPermutations in computing.
p5723
aVNumbering permutations.
p5724
aVOne way to represent permutations of "n" is by an integer "N" with 0 \u2264 "N" < "n"!, provided convenient methods are given to convert between the number and the representation of a permutation as an ordered arrangement (sequence). This gives the most compact representation of arbitrary permutations, and in computing is particularly attractive when "n" is small enough that "N" can be held in a machine word; for 32-bit words this means "n" \u2264 12, and for 64-bit words this means "n" \u2264 20. The conversion can be done via the intermediate form of a sequence of numbers "d""n", "d""n"\u22121, ..., "d"2, "d"1, where "d""i" is a non-negative integer less than "i" (one may omit "d"1, as it is always 0, but its presence makes the subsequent conversion to a permutation easier to describe). The first step then is to simply express "N" in the factorial number system, which is just a particular mixed radix representation, where for numbers up to "n"! the bases for successive digits are "n", , ..., 2, 1. The second step interprets this sequence as a Lehmer code or (almost equivalently) as an inversion table.
p5725
aVIn the Lehmer code for a permutation "\u03c3", the number "d""n" represents the choice made for the first term "\u03c3"1, the number "d""n"\u22121 represents the choice made for the second term
p5726
aV"\u03c3"2 among the remaining elements of the set, and so forth. More precisely, each "d""n"+1\u2212"i" gives the number of "remaining" elements strictly less than the term "\u03c3""i". Since those remaining elements are bound to turn up as some later term "\u03c3""j", the digit "d""n"+1\u2212"i" counts the "inversions" ("i","j") involving "i" as smaller index (the number of values "j" for which "i" < "j" and "\u03c3""i" > "\u03c3""j"). The inversion table for "\u03c3" is quite similar, but here "d""n"+1\u2212"k" counts the number of inversions ("i","j") where "k" = "\u03c3""j" occurs as the smaller of the two values appearing in inverted order. Both encodings can be visualized by an "n" by "n" Rothe diagram (named after Heinrich August Rothe) in which dots at ("i","\u03c3""i") mark the entries of the permutation, and a cross at ("i","\u03c3""j") marks the inversion ("i","j"); by the definition of inversions a cross appears in any square that comes both before the dot ("j","\u03c3""j") in its column, and before the dot ("i","\u03c3""i") in its row. The Lehmer code lists the numbers of crosses in successive rows, while the inversion table lists the numbers of crosses in successive columns; it is just the Lehmer code for the inverse permutation, and vice versa.
p5727
aVTo effectively convert a Lehmer code "d""n", "d""n"\u22121, ..., "d"2, "d"1 into a permutation of an ordered set "S", one can start with a list of the elements of "S" in increasing order, and for "i" increasing from 1 to "n" set "\u03c3""i" to the element in the list that is preceded by "d""n"+1\u2212"i" other ones, and remove that element from the list. To convert an inversion table "d""n", "d""n"\u22121, ..., "d"2, "d"1 into the corresponding permutation, one can traverse the numbers from "d"1 to "d""n" while inserting the elements of "S" from largest to smallest into an initially empty sequence; at the step using the number "d" from the inversion table, the element from "S" inserted into the sequence at the point where it is preceded by "d" elements already present. Alternatively one could process the numbers from the inversion table and the elements of "S" both in the opposite order, starting with a row of "n" empty slots, and at each step place the element from "S" into the empty slot that is preceded by "d" other empty slots.
p5728
aVConverting successive natural numbers to the factorial number system produces those sequences in lexicographic order (as is the case with any mixed radix number system), and further converting them to permutations preserves the lexicographic ordering, provided the Lehmer code interpretation is used (using inversion tables, one gets a different ordering, where one starts by comparing permutations by the "place" of their entries 1 rather than by the value of their first entries). The sum of the numbers in the factorial number system representation gives the number of inversions of the permutation, and the parity of that sum gives the signature of the permutation. Moreover the positions of the zeroes in the inversion table give the values of left-to-right maxima of the permutation (in the example 6, 8, 9) while the positions of the zeroes in the Lehmer code are the positions of the right-to-left minima (in the example positions the 4, 8, 9 of the values 1, 2, 5); this allows computing the distribution of such extrema among all permutations. A permutation with Lehmer code "d""n", "d""n"\u22121, ..., "d"2, "d"1 has an ascent if and only if .
p5729
aVAlgorithms to generate permutations.
p5730
aVIn computing it may be required to generate permutations of a given sequence of values. The methods best adapted to do this depend on whether one wants some randomly chosen permutations, or all permutations, and in the latter case if a specific ordering is required. Another question is whether possible equality among entries in the given sequence is to be taken into account; if so, one should only generate distinct multiset permutations of the sequence.
p5731
aVAn obvious way to generate permutations of "n" is to generate values for the Lehmer code (possibly using the factorial number system representation of integers up to "n"!), and convert those into the corresponding permutations. However, the latter step, while straightforward, is hard to implement efficiently, because it requires "n" operations each of selection from a sequence and deletion from it, at an arbitrary position; of the obvious representations of the sequence as an array or a linked list, both require (for different reasons) about "n"2/4 operations to perform the conversion. With "n" likely to be rather small (especially if generation of all permutations is needed) that is not too much of a problem, but it turns out that both for random and for systematic generation there are simple alternatives that do considerably better. For this reason it does not seem useful, although certainly possible, to employ a special data structure that would allow performing the conversion from Lehmer code to permutation in "O"("n" log "n") time.
p5732
aVRandom generation of permutations.
p5733
aVFor generating random permutations of a given sequence of "n" values, it makes no difference whether one applies a randomly selected permutation of "n" to the sequence, or chooses a random element from the set of distinct (multiset) permutations of the sequence. This is because, even though in case of repeated values there can be many distinct permutations of "n" that result in the same permuted sequence, the number of such permutations is the same for each possible result. Unlike for systematic generation, which becomes unfeasible for large "n" due to the growth of the number "n"!, there is no reason to assume that "n" will be small for random generation.
p5734
aVThe basic idea to generate a random permutation is to generate at random one of the "n"! sequences of integers "d"1,"d"2...,"d""n" satisfying (since "d"1 is always zero it may be omitted) and to convert it to a permutation through a bijective correspondence. For the latter correspondence one could interpret the (reverse) sequence as a Lehmer code, and this gives a generation method first published in 1938 by Ronald A. Fisher and Frank Yates.
p5735
aVWhile at the time computer implementation was not an issue, this method suffers from the difficulty sketched above to convert from Lehmer code to permutation efficiently. This can be remedied by using a different bijective correspondence: after using "d""i" to select an element among "i" remaining elements of the sequence (for decreasing values of "i"), rather than removing the element and compacting the sequence by shifting down further elements one place, one swaps the element with the final remaining element. Thus the elements remaining for selection form a consecutive range at each point in time, even though they may not occur in the same order as they did in the original sequence. The mapping from sequence of integers to permutations is somewhat complicated, but it can be seen to produce each permutation in exactly one way, by an immediate induction. When the selected element happens to be the final remaining element, the swap operation can be omitted. This does not occur sufficiently often to warrant testing for the condition, but the final element must be included among the candidates of the selection, to guarantee that all permutations can be generated.
p5736
aVThe resulting algorithm for generating a random permutation of "a""a"[1, ..., "a"["n" \u2212 1] can be described as follows in pseudocode:
p5737
aVfor "i" from "n" downto 2
p5738
aVdo   "di" \u2190 random element of { 0, ..., "i" \u2212 1 }
p5739
aV: swap "a"["di"] and "a"["i" \u2212 1]
p5740
aVThis can be combined with the initialization of the array "a"["i"] = "i" as follows:
p5741
aVfor "i" from 0 to "n"\u22121
p5742
aVdo   "d""i"+1 \u2190 random element of { 0, ..., "i" }
p5743
aV: "a"["i"] \u2190 "a"["d""i"+1]
p5744
aV: "a"["d""i"+1] \u2190 "i"
p5745
aVIf "d""i"+1 = "i", the first assignment will copy an uninitialized value, but the second will overwrite it with the correct value "i".
p5746
aVGeneration in lexicographic order.
p5747
aVThere are many ways to systematically generate all permutations of a given sequence.
p5748
aVOne classical algorithm, which is both simple and flexible, is based on finding the next permutation in lexicographic ordering, if it exists. It can handle repeated values, for which case it generates the distinct multiset permutations each once. Even for ordinary permutations it is significantly more efficient than generating values for the Lehmer code in lexicographic order (possibly using the factorial number system) and converting those to permutations. To use it, one starts by sorting the sequence in (weakly) increasing order (which gives its lexicographically minimal permutation), and then repeats advancing to the next permutation as long as one is found. The method goes back to Narayana Pandita in 14th century India, and has been frequently rediscovered ever since.
p5749
aVThe following algorithm generates the next permutation lexicographically after a given permutation. It changes the given permutation in-place.
p5750
aVFor example, given the sequence 2, 3, 4 which starts in a weakly increasing order, and given that the index is zero-based, the steps are as follows: 
p5751
aVFollowing this algorithm, the next lexicographic permutation will be and the 24th permutation will be [4,3,2,1 at which point "a"["k"] < "a"["k" + 1] does not exist, indicating that this is the last permutation.
p5752
aVGeneration with minimal changes.
p5753
aVAn alternative to the above algorithm, the Steinhaus\u2013Johnson\u2013Trotter algorithm, generates an ordering on all the permutations of a given sequence with the property that any two consecutive permutations in its output differ by swapping two adjacent values. This ordering on the permutations was known to 17th-century English bell ringers, among whom it was known as "plain changes". One advantage of this method is that the small amount of change from one permutation to the next allows the method to be implemented in constant time per permutation. The same can also easily generate the subset of even permutations, again in constant time per permutation, by skipping every other output permutation.
p5754
aVAn alternative to Steinhaus\u2013Johnson\u2013Trotter is Heap's algorithm, said by Robert Sedgewick in 1977 to be the fastest algorithm of generating permutations in applications.
p5755
aVMeandric permutations.
p5756
aVMeandric systems give rise to "meandric permutations", a special subset of "alternate permutations". An alternate permutation of the set {1,2...,2"n"} is a cyclic permutation (with no fixed points) such that the digits in the cyclic notation form alternate between odd and even integers. Meandric permutations are useful in the analysis of RNA secondary structure. Not all alternate permutations are meandric. A modification of Heap's algorithm has been used to generate all alternate permutations of order "n" (that is, of length 2"n") without generating all (2"n")! permutations. Generation of these alternate permutations is needed before they are analyzed to determine if they are meandric or not.
p5757
aVThe algorithm is recursive. The following table exhibits a step in the procedure. In the previous step, all alternate permutations of length 5 have been generated. Three copies of each of these have a "6" added to the right end, and then a different transposition involving this last entry and a previous entry in an even position is applied (including the identity, i.e., no transposition).
p5758
aVSoftware implementations.
p5759
aVCalculator functions.
p5760
aVMany scientific calculators and computing software have a built-in function for calculating the number of "k"-permutations of "n".
p5761
aVSpreadsheet functions.
p5762
aVMost spreadsheet software also provides a built-in function for calculating the number of "k"-permutations of "n", called PERMUT in many popular spreadsheets.
p5763
aVApplications.
p5764
aVPermutations are used in the interleaver component of the error detection and correction algorithms, such as turbo codes,
p5765
aVfor example 3GPP Long Term Evolution mobile telecommunication standard uses these ideas (see 3GPP technical specification 36.212 ).
p5766
aVSuch applications raise the question of fast generation of permutations satisfying certain desirable properties. One of the methods is based on the permutation polynomials. Also as a base for optimal hashing in Unique Permutation Hashing.
p5767
asS'Automaton'
p5768
(lp5769
VAn automaton (plural: automata or automatons) is a self-operating machine.
p5770
aVEtymology.
p5771
aVThe word "automaton" is the latinization of the Greek , "automaton", (neuter) "acting of one's own will". This word was first used by Homer to describe automatic door opening, or automatic movement of wheeled tripods. It is more often used to describe non-electronic moving machines, especially those that have been made to resemble human or animal actions, such as the "jacks" on old public striking clocks, or the cuckoo and any other animated figures on a cuckoo clock.
p5772
aVAncient automata.
p5773
aVThere are many examples of automata in Greek Mythology: Hephaestus created automata for his workshop; Talos was an artificial man of bronze; Daedalus used quicksilver to install voice in his moving statues; King Alkinous of the Phaiakians employed gold and silver watchdogs; the Caucasian artificial eagle tortured Prometheus.
p5774
aVThe automata in the Hellenistic world were intended as tools, toys, religious idols, or prototypes for demonstrating basic scientific principles. Numerous water powered automata were built by Ktesibios, a Greek inventor and the first head of the Great Library of Alexandria, for example he ""used water to sound a whistle and make a model owl move. He had invented the world's first "cuckoo" clock"". This tradition continued in Alexandria with inventors such as the Greek mathematician Hero of Alexandria (sometimes known as Heron), whose writings on hydraulics, pneumatics, and mechanics described siphons, a fire engine, a water organ, the aeolipile, and a programmable cart.
p5775
aVComplex mechanical devices are known to have existed in Hellenistic Greece, though the only surviving example is the Antikythera mechanism, the earliest known analog computer. It is thought to have come originally from Rhodes, where there was apparently a tradition of mechanical engineering; the island was renowned for its automata; to quote Pindar's seventh Olympic Ode:
p5776
aVThe animated figures stand
p5777
aVAdorning every public street
p5778
aVAnd seem to breathe in stone, or
p5779
aVmove their marble feet.
p5780
aVHowever, the information gleaned from recent scans of the fragments indicate that it may have come from the colonies of Corinth in Sicily and implies a connection with Archimedes.
p5781
aVAccording to Jewish legend, Solomon used his wisdom to design a throne with mechanical animals which hailed him as king when he ascended it; upon sitting down an eagle would place a crown upon his head, and a dove would bring him a Torah scroll. It's also said that when King Solomon stepped upon the throne, a mechanism was set in motion. As soon as he stepped upon the first step, a golden ox and a golden lion each stretched out one foot to support him and help him rise to the next step. On each side, the animals helped the King up until he was comfortably seated upon the throne.
p5782
aVIn ancient China, a curious account of automata is found in the Lie Zi text, written in the 3rd century BC. Within it there is a description of a much earlier encounter between King Mu of Zhou (1023-957 BC) and a mechanical engineer known as Yan Shi, an 'artificer'. The latter proudly presented the king with a life-size, human-shaped figure of his mechanical handiwork (Wade-Giles spelling):
p5783
aVThe king stared at the figure in astonishment. It walked with rapid strides, moving its head up and down, so that anyone would have taken it for a live human being. The artificer touched its chin, and it began singing, perfectly in tune. He touched its hand, and it began posturing, keeping perfect time...As the performance was drawing to an end, the robot winked its eye and made advances to the ladies in attendance, whereupon the king became incensed and would have had Yen Shih Shi executed on the spot had not the latter, in mortal fear, instantly taken the robot to pieces to let him see what it really was. And, indeed, it turned out to be only a construction of leather, wood, glue and lacquer, variously coloured white, black, red and blue. Examining it closely, the king found all the internal organs complete\u2014liver, gall, heart, lungs, spleen, kidneys, stomach and intestines; and over these again, muscles, bones and limbs with their joints, skin, teeth and hair, all of them artificial...The king tried the effect of taking away the heart, and found that the mouth could no longer speak; he took away the liver and the eyes could no longer see; he took away the kidneys and the legs lost their power of locomotion. The king was delighted.
p5784
aVOther notable examples of automata include Archytas's dove, mentioned by Aulus Gellius. Similar Chinese accounts of flying automata are written of the 5th century BC Mohist philosopher Mozi and his contemporary Lu Ban, who made artificial wooden birds ("ma yuan") that could successfully fly according to the "Han Fei Zi" and other texts.
p5785
aVMedieval automata.
p5786
aVThe manufacturing tradition of automata continued in the Greek world well into the Middle Ages. On his visit to Constantinople in 949 ambassador Liutprand of Cremona described automata in the emperor Theophilos' palace, including "lions, made either of bronze or wood covered with gold, which struck the ground with their tails and roared with open mouth and quivering tongue," "a tree of gilded bronze, its branches filled with birds, likewise made of bronze gilded over, and these emitted cries appropriate to their species" and "the emperor\u2019s throne" itself, which "was made in such a cunning manner that at one moment it was down on the ground, while at another it rose higher and was to be seen up in the air." Similar automata in the throne room (singing birds, roaring and moving lions) were described by Luitprand's contemporary Constantine Porphyrogenitus, who later became emperor, in his book \u03a0\u03b5\u03c1\u1f76 \u03c4\u1fc6\u03c2 \u0392\u03b1\u03c3\u03b9\u03bb\u03b5\u03af\u03bf\u03c5 \u03a4\u03ac\u03be\u03b5\u03c9\u03c2.
p5787
aVIn the mid-8th century, the first wind powered automata were built: "statues that turned with the wind over the domes of the four gates and the palace complex of the Round City of Baghdad". The "public spectacle of wind-powered statues had its private counterpart in the 'Abbasid palaces where automata of various types were predominantly displayed." Also in the 8th century, the Muslim alchemist, J\u0101bir ibn Hayy\u0101n (Geber), included recipes for constructing artificial snakes, scorpions, and humans which would be subject to their creator's control in his coded "Book of Stones". In 827, Caliph Al-Ma'mun had a silver and golden tree in his palace in Baghdad, which had the features of an automatic machine. There were metal birds that sang automatically on the swinging branches of this tree built by Muslim inventors and engineers at the time. The Abbasid Caliph Al-Muqtadir also had a golden tree in his palace in Baghdad in 915, with birds on it flapping their wings and singing. In the 9th century, the Ban\u016b M\u016bs\u0101 brothers invented a programmable automatic flute player and which they described in their "Book of Ingenious Devices".
p5788
aVAl-Jazari described complex programmable humanoid automata amongst other machines he designed and constructed in the "Book of Knowledge of Ingenious Mechanical Devices" in 1206. His automaton was a boat with four automatic musicians that floated on a lake to entertain guests at royal drinking parties. His mechanism had a programmable drum machine with pegs (cams) that bump into little levers that operate the percussion. The drummer could be made to play different rhythms and different drum patterns if the pegs were moved around. According to Charles B. Fowler, the automata were a "robot band" which performed "more than fifty facial and body actions during each musical selection."
p5789
aVAl-Jazari also constructed a hand washing automaton first employing the flush mechanism now used in modern flush toilets. It features a female automaton standing by a basin filled with water. When the user pulls the lever, the water drains and the female automaton refills the basin. His "peacock fountain" was another more sophisticated hand washing device featuring humanoid automata as servants which offer soap and towels. Mark E. Rosheim describes it as follows: "Pulling a plug on the peacock's tail releases water out of the beak; as the dirty water from the basin fills the hollow base a float rises and actuates a linkage which makes a servant figure appear from behind a door under the peacock and offer soap. When more water is used, a second float at a higher level trips and causes the appearance of a second servant figure \u2014 with a towel!" Al-Jazari thus appears to have been the first inventor to display an interest in creating human-like machines for practical purposes such as manipulating the environment for human comfort.
p5790
aVVillard de Honnecourt, in his 1230s sketchbook, show plans for animal automata and an angel that perpetually turns to face the sun. At the end of the thirteenth century, Robert II, Count of Artois built a pleasure garden at his castle at Hesdin that incorporated several automata as entertainment in the walled park. The work was conducted by local workmen and overseen by the Italian knight Renaud Coignet. It included monkey marionettes, a sundial supported by lions and "wild men", mechanized birds, mechanized fountains and a bellows-operated organ. The park was famed for its automata well into the fifteenth century before it was destroyed by English soldiers in the sixteenth century.
p5791
aVThe Chinese author Xiao Xun wrote that when the Ming Dynasty founder Hongwu (r. 1368\u20131398) was destroying the palaces of Khanbaliq belonging to the previous Yuan Dynasty, there were\u2014amongst many other mechanical devices\u2014automatons found that were in the shape of tigers.
p5792
aVRenaissance and early modern automata.
p5793
aVThe Renaissance witnessed a considerable revival of interest in automata. Hero's treatises were edited and translated into Latin and Italian. Giovanni Fontana created mechanical devils and rocket-propelled animal automata. Numerous clockwork automata were manufactured in the 16th century, principally by the goldsmiths of the Free Imperial Cities of central Europe. These wondrous devices found a home in the cabinet of curiosities or "Wunderkammern" of the princely courts of Europe. Hydraulic and pneumatic automata, similar to those described by Hero, were created for garden grottoes.
p5794
aVLeonardo da Vinci sketched a more complex automaton around the year 1495. The design of Leonardo's robot was not rediscovered until the 1950s. The robot could, if built successfully, move its arms, twist its head, and sit up.
p5795
aVThe Smithsonian Institution has in its collection a clockwork monk, about high, possibly dating as early as 1560. The monk is driven by a key-wound spring and walks the path of a square, striking his chest with his right arm, while raising and lowering a small wooden cross and rosary in his left hand, turning and nodding his head, rolling his eyes, and mouthing silent obsequies. From time to time, he brings the cross to his lips and kisses it. It is believed that the monk was manufactured by Juanelo Turriano, mechanician to the Holy Roman Emperor Charles V.
p5796
aVA new attitude towards automata is to be found in Descartes when he suggested that the bodies of animals are nothing more than complex machines - the bones, muscles and organs could be replaced with cogs, pistons and cams. Thus mechanism became the standard to which Nature and the organism was compared. France in the 17th century was the birthplace of those ingenious mechanical toys that were to become prototypes for the engines of the Industrial Revolution. Thus, in 1649, when Louis XIV was still a child, an artisan named Camus designed for him a miniature coach, and horses complete with footmen, page and a lady within the coach; all these figures exhibited a perfect movement. According to P. Labat, General de Gennes constructed, in 1688, in addition to machines for gunnery and navigation, a peacock that walked and ate. Athanasius Kircher produced many automatons to create Jesuit shows, including a statue which spoke and listened via a speaking tube.
p5797
aVThe world's first successfully-built biomechanical automaton is considered to be "The Flute Player", invented by the French engineer Jacques de Vaucanson in 1737. He also constructed the Digesting Duck, a mechanical duck that gave the false illusion of eating and defecating, seeming to endorse Cartesian ideas that animals are no more than machines of flesh.
p5798
aVIn 1769, a chess-playing machine called the Turk, created by Wolfgang von Kempelen, made the rounds of the courts of Europe purporting to be an automaton. The Turk was operated from inside by a hidden human director, and was not a true automaton.
p5799
aVOther 18th century automaton makers include the prolific Frenchman Pierre Jaquet-Droz (see Jaquet-Droz automata) and his contemporary Henri Maillardet. Maillardet, a Swiss mechanic, created an automaton capable of drawing four pictures and writing three poems. Maillardet's Automaton is now part of the collections at the Franklin Institute Science Museum in Philadelphia. Belgian-born John Joseph Merlin created the mechanism of the Silver Swan automaton, now at Bowes Museum. Tipu's Tiger is a late-18th century example of automata, made for Tipu Sultan, featuring a European soldier being mauled by a tiger.
p5800
aVAccording to philosopher Michel Foucault, Frederick the Great, king of Prussia from 1740 to 1786, was "obsessed" with automata. According to Manuel de Landa, "he put together his armies as a well-oiled clockwork mechanism whose components were robot-like warriors".
p5801
aVJapan adopted automata during the Edo period (1603\u20131867); they were known as "karakuri ningy\u014d".
p5802
aVAutomata, particularly watches and clocks, were popular in China during the 18th and 19th centuries, and items were produced for the Chinese market. Strong interest by Chinese collectors in the 21st century brought many interesting items to market where they have had dramatic realizations.
p5803
aVModern automata.
p5804
aVThe famous magician Jean Eugène Robert-Houdin (1805\u20131871) was known for creating automata for his stage shows.
p5805
aVThe period 1860 to 1910 is known as "The Golden Age of Automata". During this period many small family based companies of Automata makers thrived in Paris. From their workshops they exported thousands of clockwork automata and mechanical singing birds around the world. It is these French automata that are collected today, although now rare and expensive they attract collectors worldwide. The main French makers were Bontems, Lambert, Phalibois, Renou, Roullet & Decamps, Theroude and Vichy.
p5806
aVContemporary automata continue this tradition with an emphasis on art, rather than technological sophistication. Contemporary automata are represented by the works of Cabaret Mechanical Theatre in the United Kingdom, Dug North and Chomick+Meder, Thomas Kuntz, Arthur Ganson, Joe Jones in the United States, Le Défenseur du Temps by French artist Jacques Monestier, and François Junod in Switzerland.
p5807
aVSome mechanized toys developed during the 18th and 19th centuries were automata made with paper. Despite the relative simplicity of the material, paper automata require a high degree of technical ingenuity.
p5808
aVIn education.
p5809
aVThe potential educational value of mechanical toys in teaching transversal skills has been recognised by the European Union education project "Clockwork objects, enhanced learning: Automata Toys Construction" (CLOHE).
p5810
aVIn contemporary culture.
p5811
aVIn the 2011 film "Hugo", the title character, Hugo Cabret, must fix a "mechanical man" automaton, which he and his father tried to fix, believing it holds a secret message from the latter before his father's untimely death. Near the end of the film, it is revealed that the automaton was created by the character of George Méliès, which he later donated to the museum where Hugo's father worked, after he could not fix it himself. The film is based on the 2007 book "The Invention of Hugo Cabret" by American author Brian Selznick.
p5812
aVIn the 2014 fantasy novel "The Automation" by the anonymous author "B.L.A. and G.B. Gabbler," many of the characters are Automatons that the god Hephaestus created.
p5813
asS'Equality (mathematics)'
p5814
(lp5815
VIn mathematics equality is a relationship between two quantities or, more generally two mathematical expressions, asserting that the quantities have the same value or that the expressions represent the same mathematical object. The equality between "A" and "B" is written "A" = "B", and pronounced "A" equals "B". The symbol "=" is called an "equals sign".
p5816
aVEtymology.
p5817
aVThe etymology of the word is from the Latin "aequ\u0101lis" (\u201cequal\u201d, \u201clike\u201d, \u201ccomparable\u201d, \u201csimilar\u201d) from "aequus" (\u201cequal\u201d, \u201clevel\u201d, \u201cfair\u201d, \u201cjust\u201d).
p5818
aVTypes of equalities.
p5819
aVIdentities.
p5820
aVWhen "A" and "B" may be viewed as functions of some variables, then "A" = "B" means that "A" and "B" define the same function. Such an equality of functions is sometimes called an identity. An example is ("x" + 1)2 = "x"2 + 2"x" + 1.
p5821
aVEqualities as predicates.
p5822
aVWhen "A" and "B" are not fully specified or depend on some variables, equality is a proposition, which may be true for some values and false for some other values. Equality is a binary relation, or, in other words, a two-arguments predicate, which may produce a truth value ("false" or "true") from its arguments. In computer programming, its computation from two expressions is known as comparison.
p5823
aVCongruences.
p5824
aVIn some cases, one may consider as equal two mathematical objects that are only equivalent for the properties that are considered. This is, in particular the case in geometry, where two geometric shapes are said equal when one may be moved to coincide with the other. The word congruence is also used for this kind of equality.
p5825
aVEquations.
p5826
aVAn equation is the problem of finding values of some variables, called "unknowns", for which the specified equality is true. "Equation" may also refer to an equality relation that is satisfied only for the values of the variables that one is interested on. For example "x"2 + "y"2 = 1 is the "equation" of the unit circle. There is no standard notation that distinguishes an equation from an identity or other use of the equality relation: a reader has to guess an appropriate interpretation from the semantic of expressions and the context.
p5827
aVEquivalence relations.
p5828
aVViewed as a relation, equality is the archetype of the more general concept of an equivalence relation on a set: those binary relations that are reflexive, symmetric, and transitive.
p5829
aVThe identity relation is an equivalence relation. Conversely, let "R" be an equivalence relation, and let us denote by "xR" the equivalence class of "x", consisting of all elements "z" such that "x R z". Then the relation "x R y" is equivalent with the equality "xR" = "yR". It follows that equality is the smallest equivalence relation on any set "S", in the sense that it is the relation that has the smallest equivalence classes (every class is reduced to a single element).
p5830
aVLogical formalizations of equality.
p5831
aVThere are several formalizations of the notion of equality in mathematical logic, usually by means of axioms, such as the first few Peano axioms, or the axiom of extensionality in ZF set theory). There are also some logic systems that do not have any notion of equality. This reflects the undecidability of the equality of two real numbers defined by formulas involving the integers, the basic arithmetic operations, the logarithm and the exponential function. In other words, 
p5832
aVthere cannot exist any algorithm for deciding such an equality.
p5833
aVLogical formulations.
p5834
aVEquality is always defined such that things that are equal have all and only the same properties. Some people define equality as congruence. Often equality is just defined as identity.
p5835
aVA stronger sense of equality is obtained if some form of Leibniz's law is added as an axiom; the assertion of this axiom rules out "bare particulars"\u2014things that have all and only the same properties but are not equal to each other\u2014which are possible in some logical formalisms. The axiom states that two things are equal if they have all and only the same properties. Formally:
p5836
aV Given any "x" and "y", "x" = "y" if, given any predicate "P", "P"("x") if and only if "P"("y").
p5837
aVIn this law, the connective "if and only if" can be weakened to "if"; the modified law is equivalent to the original.
p5838
aVInstead of considering Leibniz's law as an axiom, it can also be taken as the "definition" of equality. The property of being an equivalence relation, as well as the properties given below, can then be proved: they become theorems.
p5839
aVIf a=b, then a can replace b and b can replace a.
p5840
aVSome basic logical properties of equality.
p5841
aVThe substitution property states:
p5842
aVIn first-order logic, this is a schema, since we can't quantify over expressions like "F" (which would be a functional predicate).
p5843
aVSome specific examples of this are:
p5844
aVThe reflexive property states:
p5845
aVFor any quantity "a", "a" = "a".
p5846
aVThis property is generally used in mathematical proofs as an intermediate step.
p5847
aVThe symmetric property states:
p5848
aVThe transitive property states:
p5849
aVThe binary relation "is approximately equal" between real numbers or other things, even if more precisely defined, is not transitive (it may seem so at first sight, but many small differences can add up to something big).
p5850
aVHowever, equality almost everywhere "is" transitive.
p5851
aVAlthough the symmetric and transitive properties are often seen as fundamental, they can be proved, if the substitution and reflexive properties are assumed instead.
p5852
aVRelation with equivalence and isomorphism.
p5853
aVIn some contexts, equality is sharply distinguished from "equivalence" or "isomorphism." For example, one may distinguish "fractions" from "rational numbers," the latter being equivalence classes of fractions: the fractions formula_1 and formula_2 are distinct as fractions, as different strings of symbols, but they "represent" the same rational number, the same point on a number line. This distinction gives rise to the notion of a quotient set.
p5854
aVSimilarly, the sets
p5855
aVformula_3 and formula_4
p5856
aVare not equal sets \u2013 the first consists of letters, while the second consists of numbers \u2013 but they are both sets of three elements, and thus isomorphic, meaning that there is a bijection between them, for example
p5857
aVformula_5
p5858
aVHowever, there are other choices of isomorphism, such as
p5859
aVformula_6
p5860
aVand these sets cannot be identified without making such a choice \u2013 any statement that identifies them "depends on choice of identification". This distinction, between equality and isomorphism, is of fundamental importance in category theory, and is one motivation for the development of category theory.
p5861
asS"Hilbert's problems"
p5862
(lp5863
VHilbert's problems'" are a list of twenty-three problems in mathematics published by German mathematician David Hilbert in 1900. The problems were all unsolved at the time, and several of them were very influential for 20th century mathematics. Hilbert presented ten of the problems (1, 2, 6, 7, 8, 13, 16, 19, 21 and 22) at the Paris conference of the International Congress of Mathematicians, speaking on August 8 in the Sorbonne. The complete list of 23 problems was published later, most notably in English translation in 1902 by Mary Frances Winston Newson in the "Bulletin of the American Mathematical Society".
p5864
aVNature and influence of the problems.
p5865
aVHilbert's problems ranged greatly in topic and precision. Some of them are propounded precisely enough to enable a clear affirmative or negative answer, like the 3rd problem, which was the first to be solved, or the 8th problem (the Riemann hypothesis). For other problems, such as the 5th, experts have traditionally agreed on a single interpretation, and a solution to the accepted interpretation has been given, but closely related unsolved problems exist. Sometimes Hilbert's statements were not precise enough to specify a particular problem but were suggestive enough so that certain problems of more contemporary origin seem to apply, e.g. most modern number theorists would probably see the 9th problem as referring to the conjectural Langlands correspondence on representations of the absolute Galois group of a number field. Still other problems, such as the 11th and the 16th, concern what are now flourishing mathematical subdisciplines, like the theories of quadratic forms and real algebraic curves.
p5866
aVThere are two problems that are not only unresolved but may in fact be unresolvable by modern standards. The 6th problem concerns the axiomatization of physics, a goal that twentieth century developments of physics (including its recognition as a discipline independent from mathematics) seem to render both more remote and less important than in Hilbert's time. Also, the 4th problem concerns the foundations of geometry, in a manner that is now generally judged to be too vague to enable a definitive answer.
p5867
aVThe other twenty-one problems have all received significant attention, and late into the twentieth century work on these problems was still considered to be of the greatest importance. Paul Cohen received the Fields Medal during 1966 for his work on the first problem, and the negative solution of the tenth problem during 1970 by Yuri Matiyasevich (completing work of Martin Davis, Hilary Putnam and Julia Robinson) generated similar acclaim. Aspects of these problems are still of great interest today.
p5868
aVIgnorabimus.
p5869
aVFollowing Gottlob Frege and Bertrand Russell, Hilbert sought to define mathematics logically using the method of formal systems, i.e., finitistic proofs from an agreed-upon set of axioms. One of the main goals of Hilbert's program was a finitistic proof of the consistency of the axioms of arithmetic: that is his second problem.
p5870
aVHowever, Gödel's second incompleteness theorem gives a precise sense in which such a finitistic proof of the consistency of arithmetic is provably impossible. Hilbert lived for 12 years after Kurt Gödel published his theorem, but does not seem to have written any formal response to Gödel's work. The significance of Gödel's work to mathematics as a whole (and not just to formal logic) was illustrated by its applicability to one of Hilbert's problems.
p5871
aVHilbert's tenth problem does not ask whether there exists an algorithm for deciding the solvability of Diophantine equations, but rather asks for the "construction" of such an algorithm: "to devise a process according to which it can be determined in a finite number of operations whether the equation is solvable in rational integers." That this problem was solved by showing that there cannot be any such algorithm contradicted Hilbert's philosophy of mathematics.
p5872
aVIn discussing his opinion that every mathematical problem should have a solution, Hilbert allows for the possibility that the solution could be a proof that the original problem is impossible. He stated that the point is to know one way or the other what the solution is, and he believed that we always can know this, that in mathematics there is not any "ignorabimus" (statement whose truth can never be known). It seems unclear whether he would have regarded the solution of the tenth problem as an instance of ignorabimus: what is proved not to exist is not the integer solution, but (in a certain sense) the ability to discern in a specific way whether a solution exists.
p5873
aVOn the other hand, the status of the first and second problems is even more complicated: there is not any clear mathematical consensus as to whether the results of Gödel (in the case of the second problem), or Gödel and Cohen (in the case of the first problem) give definitive negative solutions or not, since these solutions apply to a certain formalization of the problems, which is not necessarily the only possible one.
p5874
aVThe 24th Problem.
p5875
aVHilbert originally included 24 problems on his list, but decided against including one of them in the published list. The "24th problem" (in proof theory, on a criterion for simplicity and general methods) was rediscovered in Hilbert's original manuscript notes by German historian Rüdiger Thiele in 2000.
p5876
aVSequels.
p5877
aVSince 1900, mathematicians and mathematical organizations have announced problem lists, but, with few exceptions, these collections have not had nearly as much influence nor generated as much work as Hilbert's problems.
p5878
aVOne of the exceptions is furnished by three conjectures made by André Weil during the late 1940s (the Weil conjectures). In the fields of algebraic geometry, number theory and the links between the two, the Weil conjectures were very important . The first of the Weil conjectures was proved by Bernard Dwork, and a completely different proof of the first two conjectures via l-adic cohomology was given by Alexander Grothendieck. The last and deepest of the Weil conjectures (an analogue of the Riemann hypothesis) was proven by Pierre Deligne. Both Grothendieck and Deligne were awarded the Fields medal. However, the Weil conjectures in their scope are more like a single Hilbert problem, and Weil never intended them as a programme for all mathematics. This is somewhat ironic, since arguably Weil was the mathematician of the 1940s and 1950s who best played the Hilbert role, being conversant with nearly all areas of (theoretical) mathematics and having been important in the development of many of them.
p5879
aVPaul Erd\u0151s is legendary for having posed hundreds, if not thousands, of mathematical problems, many of them profound. Erd\u0151s often offered monetary rewards; the size of the reward depended on the perceived difficulty of the problem.
p5880
aVThe end of the millennium, being also the centennial of Hilbert's announcement of his problems, was a natural occasion to propose "a new set of Hilbert problems." Several mathematicians accepted the challenge, notably Fields Medalist Steve Smale, who responded to a request of Vladimir Arnold by proposing a list of 18 problems.
p5881
aVSmale's problems have thus far not received much attention from the media, and it is unclear how much serious attention they are getting from the mathematical community.
p5882
aVAt least in the mainstream media, the "de facto" 21st century analogue of Hilbert's problems is the list of seven Millennium Prize Problems chosen during 2000 by the Clay Mathematics Institute. Unlike the Hilbert problems, where the primary award was the admiration of Hilbert in particular and mathematicians in general, each prize problem includes a million dollar bounty. As with the Hilbert problems, one of the prize problems (the Poincaré conjecture) was solved relatively soon after the problems were announced.
p5883
aVNoteworthy for its appearance on the list of Hilbert problems, Smale's list and the list of Millennium Prize Problems \u2014 and even, in its geometric guise, in the Weil Conjectures \u2014 is the Riemann hypothesis. Notwithstanding some famous recent assaults from major mathematicians of our day, many experts believe that the Riemann hypothesis will be included in problem lists for centuries yet. Hilbert himself declared: "If I were to awaken after having slept for a thousand years, my first question would be: has the Riemann hypothesis been proven?"
p5884
aVIn 2008, DARPA announced its own list of 23 problems which it hoped could cause major mathematical breakthroughs, "thereby strengthening the scientific and technological capabilities of DoD".
p5885
aVSummary.
p5886
aVOf the cleanly formulated Hilbert problems, problems 3, 7, 10, 11, 13, 14, 17, 19, 20, and 21 have a resolution that is accepted by consensus. On the other hand, problems 1, 2, 5, 9, 15, 18+, and 22 have solutions that have partial acceptance, but there exists some controversy as to whether they resolve the problems.
p5887
aVThe + on 18 denotes that the Kepler conjecture solution is a computer-assisted proof, a notion anachronistic for a Hilbert problem and to some extent controversial because of its lack of verifiability by a human reader in a reasonable time.
p5888
aVThat leaves 16, 8 (the Riemann hypothesis) and 12 unresolved. On this classification 4, 16, and 23 are too vague to ever be described as solved. The withdrawn 24 would also be in this class. 6 is considered as a problem in physics rather than in mathematics.
p5889
aVTable of problems.
p5890
aVHilbert's twenty-three problems are:
p5891
asS"Pascal's Triangle"
p5892
(lp5893
sS'Mental calculation'
p5894
(lp5895
VMental calculation comprises arithmetical calculations using only the human brain, with no help from calculators, computers, or pen and paper. People use mental calculation when computing tools are not available, when it is faster than other means of calculation (for example, conventional methods as taught in educational institutions), or in a competitive context. Mental calculation often involves the use of specific techniques devised for specific types of problems.
p5896
aVMany of these techniques take advantage of or rely on the decimal numeral system. Usually, the choice of radix determines what methods to use and also which calculations are easier to perform mentally. For example, multiplying or dividing by ten is an easy task when working in decimal (just move the decimal point), whereas multiplying or dividing by sixteen is not; however, the opposite is true when working in hexadecimal.
p5897
aVMethods and techniques.
p5898
aVCasting out nines.
p5899
aVAfter applying an arithmetic operation to two operands and getting a result, you can use this procedure to improve your confidence that the result is correct.
p5900
aVExample
p5901
aVYou can use the same procedure with multiple operations just repeat steps 1 and 2 for each operation.
p5902
aVEstimation.
p5903
aVWhile checking the mental calculation, it is useful to think of it in terms of scaling. For example, when dealing with large numbers, say 1531 × 19625, estimation instructs you to be aware of the number of digits expected for the final value. A useful way of checking is to estimate. 1531 is around 1500, and 19625 is around 20000, so a result of around 20000 × 1500 (30000000) would be a good estimate for the actual answer (30045875). So if the answer has too many digits, you know you've made a mistake.
p5904
aVFactors.
p5905
aVWhen multiplying, a useful thing to remember is that the factors of the operands still remain. For example, to say that 14 × 15 was 211 would be unreasonable. Since 15 is a multiple of 5, the product should be as well. Likewise, 14 is a multiple of 2, so the product should be even. Furthermore, any number which is a multiple of both 5 and 2 is necessarily a multiple of 10, and in the decimal system would end with a 0. The correct answer is 210. It is a multiple of 10, 7 (the other prime factor of 14) and 3 (the other prime factor of 15).
p5906
aVCalculating differences: "a" \u2212 "b".
p5907
aVDirect calculation.
p5908
aVWhen the digits of "b" are all smaller than the corresponding digits of "a", the calculation can be done digit by digit. For example, evaluate 872 \u2212 41 simply by subtracting 1 from 2 in the units place, and 4 from 7 in the tens place: 831.
p5909
aVIndirect calculation.
p5910
aVWhen the above situation does not apply, the problem can sometimes be modified:
p5911
aVYou may guess what is needed, and accumulate your guesses. Your guess is good as long as you haven't gone beyond the "target" number.
p5912
aV8192 \u2212 732, mentally, you want to add 8000 but that would be too much, so we add 7000, then 700 to 1100, is 400 (so far we have 7400), and 32 to 92 can easily be recognized as 60. The result is 7460.
p5913
aVLook-ahead borrow method.
p5914
aVThis method can be used to subtract numbers left to down, and if all that is required is to read the hamrilick aloud, it requires little of the user's memory even to subtract numbers of arbitrary size.
p5915
aVOne place at a time is handled, left to right.
p5916
aVCalculating products: "a" × "b".
p5917
aVMany of these methods work because of the distributive property.
p5918
aVMultiplying by 2 or other small numbers.
p5919
aVWhere one number being multiplied is sufficiently small to be multiplied with ease by any single digit, the product can be calculated easily digit by digit from right to left. This is particularly easy for multiplication by 2 since the carry digit cannot be more than 1.
p5920
aVFor example, to calculate 2 × 167:
p5921
aV2×7=14, so the final digit is 4, with a 1 carried and added to the 2×6 = 12 to give 13, so the next digit is 3 with a 1 carried and added to the 2×1=2 to give 3. Thus, the product is 334.
p5922
aVMultiplying by 5.
p5923
aVTo multiply a number by 5,
p5924
aV1. First multiply that number by 10, then divide it by 2.
p5925
aVThe following algorithm is a quick way to produce this result:
p5926
aV2. Add a zero to right side of the desired number. (A.)
p5927
aV3. Next, starting from the leftmost numeral, divide by 2 (B.)
p5928
aVand append each result in the respective order to form a new number;(fraction answers should be rounded down to the nearest whole number).
p5929
aVThe resulting number is 0330. (This is not the final answer, but a first approximation which will be adjusted in the following step:)
p5930
aVEXAMPLE: 176 (IN FIRST, SECOND THIRD PLACES):
p5931
aVMultiplying by 9.
p5932
aVSince 9 = 10 \u2212 1, to multiply a number by nine, multiply it by 10 and then subtract the original number from the result. For example, 9 × 27 = 270 \u2212 27 = 243.
p5933
aVThis method can be adjusted to multiply by eight instead of nine, by doubling the number being subtracted; 8 × 27 = 270 \u2212 (2×27) = 270 \u2212 54 = 216.
p5934
aVSimilarly, by adding instead of subtracting, the same methods can be used to multiply by 11 and 12, respectively (although simpler methods to multiply by 11 exist).
p5935
aVUsing hands: 1\u201310 multiplied by 9.
p5936
aVHold hands in front of you, palms facing you. Assign the left thumb to be 1, the left index to be 2, and so on all the way to right thumb is ten. Each "|" symbolizes a raised finger and a "\u2212" represents a bent finger.
p5937
aVBend the finger which represents the number to be multiplied by nine down.
p5938
aVEx: 6 × 9 would be
p5939
aVThe right little finger is down. Take the number of fingers still raised to the left of the bent finger and prepend it to the number of fingers to the right.
p5940
aVEx: There are five fingers left of the right little finger and four to the right of the right little finger. So 6 × 9 = 54.
p5941
aVMultiplying by 10 (and powers of ten).
p5942
aVTo multiply an integer by 10, simply add an extra 0 to the end of the number.
p5943
aVTo multiply a non-integer by 10, move the decimal point to the right one digit.
p5944
aVIn general for base ten, to multiply by 10"n" (where "n" is an integer), move the decimal point "n" digits to the right. If "n" is negative, move the decimal |"n"| digits to the left.
p5945
aVMultiplying by 11.
p5946
aVFor single digit numbers simply duplicate the number into the tens digit, for example: 1 × 11 = 11, 2 × 11 = 22, up to 9 × 11 = 99.
p5947
aVThe product for any larger non-zero integer can be found by a series of additions to each of its digits from right to left, two at a time.
p5948
aVFirst take the ones digit and copy that to the temporary result. Next, starting with the ones digit of the multiplier, add each digit to the digit to its left. Each sum is then added to the left of the result, in front of all others. If a number sums to 10 or higher take the tens digit, which will always be 1, and carry it over to the next addition. Finally copy the multipliers left-most (highest valued) digit to the front of the result, adding in the carried 1 if necessary, to get the final product.
p5949
aVIn the case of a negative 11, multiplier, or both apply the sign to the final product as per normal multiplication of the two numbers.
p5950
aVA step-by-step example of 759 × 11:
p5951
aVFurther examples:
p5952
aVAnother method is to simply multiply the number by 10, and add the original number to the result.
p5953
aVFor example:
p5954
aV17 × 11
p5955
aV170 + 17 = 187
p5956
aV17 × 11 = 187
p5957
aVMultiplying two 2 digit numbers between 11 and 19.
p5958
aVTo easily multiply 2 digit numbers together between 11 and 19 a simple algorithm is as follows (where a is the ones digit of the first number and b is the ones digit of the second number):
p5959
aVMultiplying any 2-digit numbers.
p5960
aVTo easily multiply any 2-digit numbers together a simple algorithm is as follows (where a is the tens digit of the first number, b is the ones digit of the first number, c is the tens digit of the second number and d is the ones digit of the second number):
p5961
aVformula_1
p5962
aVformula_2
p5963
aVFor example
p5964
aVformula_3
p5965
aVNote that this is the same thing as the conventional sum of partial products, just restated with brevity. To minimize the number of elements being retained in one's memory, it may be convenient to perform the sum of the "cross" multiplication product first, and then add the other two elements:
p5966
aVformula_4
p5967
aVformula_5 which only the tens digit will interfere with the first term
p5968
aVformula_6
p5969
aVi.e., in this example
p5970
aV(12 + 14) = 26, 26 × 10 = 260,
p5971
aVto which is it is easy to add 21: 281 and then 800: 1081
p5972
aVAn easy mnemonic to remember for this would be FOIL. F meaning first, O meaning outer, I meaning inner and L meaning last. For example:
p5973
aV formula_7
p5974
aVand
p5975
aV formula_8
p5976
aVwhere 7 is "a", 5 is "b", 2 is "c" and 3 is "d".
p5977
aVConsider
p5978
aV formula_9
p5979
aVthis expression is analogous to any number in base 10 with a hundreds, tens and ones place. FOIL can also be looked at as a number with F being the hundreds, OI being the tens and L being the ones.
p5980
aVformula_10 is the product of the first digit of each of the two numbers; F.
p5981
aVformula_11 is the addition of the product of the outer digits and the inner digits; OI.
p5982
aVformula_12 is the product of the last digit of each of the two numbers; L.
p5983
aVUsing hands: 6\u201310 multiplied by another number 6\u201310.
p5984
aVThis technique allows a number from 6 to 10 to be multiplied by another number from 6 to 10.
p5985
aVAssign 6 to the little finger, 7 to the ring finger, 8 to the middle finger, 9 to the index finger, and 10 to the thumb. Touch the two desired numbers together. The point of contact and below is considered the "bottom" section and everything above the two fingers that are touching are part of the "top" section. The answer is formed by adding ten times the total number of "bottom" fingers to the product of the number of left- and right-hand "top" fingers.
p5986
aVFor example, 9 × 6 would look like this, with the left index finger touching the right little finger:
p5987
aVIn this example, there are 5 "bottom" fingers (the left index, middle, ring, and little fingers, plus the right little finger), 1 left "top" finger (the left thumb), and 4 right "top" fingers (the right thumb, index finger, middle finger, and ring finger). So the computation goes as follows: 9 × 6 = (10 × 5) + (1 × 4) = 54.
p5988
aVConsider another example, 8 × 7:
p5989
aVFive bottom fingers make 5 tens, or 50. Two top left fingers and three top right fingers make the product 6. Summing these produces the answer, 56.
p5990
aVAnother example, this time using 6 × 8:
p5991
aVFour tens (bottom), plus two times four (top) gives 40 + 2 × 4 = 48.
p5992
aVHere's how it works: each finger represents a number between 6 and 10. When you join fingers representing "x" and "y", there will be 10 - "x" "top" fingers and "x" - 5 "bottom" fingers on the left hand; the right hand will have 10 - "y" "top" fingers and "y" - 5 "bottom" fingers.
p5993
aVLet
p5994
aVformula_13 (the number of "top" fingers on the left hand)
p5995
aVformula_14 (the number of "top" fingers on the right hand)
p5996
aVformula_15 (the number of "bottom" fingers on the left hand)
p5997
aVformula_16 (the number of "bottom" fingers on the right hand)
p5998
aVThen following the above instructions produces
p5999
aVformula_17
p6000
aVformula_18
p6001
aVformula_19
p6002
aVformula_20
p6003
aVformula_21
p6004
aVformula_22
p6005
aVwhich is the product we seek.
p6006
aVMultiplying two numbers close and below 100.
p6007
aVThis technique allows easy multiplication of numbers close and below 100.(90-99) The variables will be the two numbers you multiply.
p6008
aVThe product of two variables ranging from 99-99 will result in a 4-digit number. The first step is to find the ones-digit and the tens digit.
p6009
aVSubtract both variables from 100 which will result in 2 one-digit number. The product of the 2 one-digit numbers will be the last two digits of your final product.
p6010
aVNext, subtract one of the two variables from 100. Then subtract the difference from the other variable. That difference will be the first two digits of your final product. And the resulting 4 digit number will be the final product.
p6011
aVExample:
p6012
aVUsing square numbers.
p6013
aVThe products of small numbers may be calculated by using the squares of integers; for example, to calculate 13 × 17, you can remark 15 is the mean of the two factors, and think of it as (15 \u2212 2) × (15 + 2), "i.e." 15² \u2212 2². Knowing that 15² is 225 and 2² is 4, simple subtraction shows that 225 \u2212 4 = 221, which is the desired product.
p6014
aVThis method requires knowing by heart a certain number of squares:
p6015
aVSquaring numbers.
p6016
aVIt may be useful to be aware that the difference between two successive square numbers is the sum of their respective square roots. Hence if you know that 12 × 12 = 144 and wish to know 13 × 13, calculate 144 + 12 + 13 = 169.
p6017
aVThis is because ("x" + 1)2 \u2212 "x"2 = "x"2 + 2"x" + 1 \u2212 "x"2 = "x" + ("x" + 1)
p6018
aV"x"2 = ("x" \u2212 1)2 + (2"x" \u2212 1)
p6019
aVSquaring numbers near 50.
p6020
aVSuppose we need to square a number "x" near 50. This number may be expressed as "x" = 50 \u2212 "n", and hence the answer "x"2 is (50\u2212"n")2, which is 502 \u2212 100n + "n"2. We know that 502 is 2500. So we subtract 100"n" from 2500, and then add "n"2. Example, say we want to square 48, which is 50 \u2212 2. We subtract 200 from 2500 and add 4, and get "x"2 = 2304. For numbers larger than 50 ("x" = 50 + "n"), add "n" a hundred times instead of subtracting it.
p6021
aVSquaring an integer from 26 to 75.
p6022
aVThis method requires the memorization of squares from 1 to 25.
p6023
aVThe square of "n" (most easily calculated when "n" is between 26 and 75 inclusive) is
p6024
aV (50 \u2212 "n")2 + 100("n" \u2212 25)
p6025
aVIn other words, the square of a number is the square of its difference from fifty added to one hundred times the difference of the number and twenty five. For example, to square 62, we have:
p6026
aV (\u221212)2 + [(62-25) × 100]
p6027
aV = 144 + 3,700
p6028
aV = 3,844
p6029
aVSquaring an integer from 76 to 125.
p6030
aVThis method requires the memorization of squares from 1 to 25.
p6031
aVThe square of "n" (most easily calculated when "n" is between 76 and 125 inclusive) is
p6032
aV (100 \u2212 "n")2 + 100(100 \u2212 2(100 \u2212 "n"))
p6033
aVIn other words, the square of a number is the square of its difference from one hundred added to the product of one hundred and the difference of one hundred and the product of two and the difference of one hundred and the number. For example, to square 93, we have:
p6034
aV 72 + 100(100 \u2212 2(7))
p6035
aV = 49 + 100 × 86
p6036
aV = 49 + 8,600
p6037
aV = 8,649
p6038
aVAnother way to look at it would be like this:
p6039
aV 932 = ? (is \u22127 from 100)
p6040
aV 93 \u2212 7 = 86 (this gives us our first two digits)
p6041
aV (\u22127)2 = 49 (these are the second two digits)
p6042
aV 932 = 8649
p6043
aVAnother example:
p6044
aVSquaring any number.
p6045
aVTake a given number, and add and subtract a certain value to it that will make it easier to multiply. For example:
p6046
aV 4922
p6047
aV492 is close to 500, which is easy to multiply by. Add and subtract 8 (the difference between 500 and 492) to get
p6048
aV 492 -> 484, 500
p6049
aVMultiply these numbers together to get 242,000 (This can be done efficiently by dividing 484 by 2 = 242 and multiplying by 1000). Finally, add the difference (8) squared (82 = 64) to the result:
p6050
aV 4922 = 242,064
p6051
aVThe proof follows:
p6052
aV formula_23
p6053
aV formula_24
p6054
aV formula_25
p6055
aV formula_26
p6056
aVSquaring any 2-digit integers.
p6057
aVThis method requires memorization of the squares of the one-digit numbers 1 to 9.
p6058
aVThe square of "mn", "mn" being a two-digit integer, can be calculated as
p6059
aV 10 × "m"("mn" + "n") + "n"2
p6060
aVMeaning the square of "mn" can be found by adding "n" to "mn", multiplied by "m", adding 0 to the end and finally adding the square of "n".
p6061
aVFor example, we have 232:
p6062
aV 232
p6063
aV = 10 × 2(23 + 3) + 32
p6064
aV = 10 × 2(26) + 9
p6065
aV = 520 + 9
p6066
aV = 529
p6067
aVSo 232 = 529.
p6068
aVFinding roots.
p6069
aVApproximating square roots.
p6070
aVAn easy way to approximate the square root of a number is to use the following equation:
p6071
aV formula_27
p6072
aVThe closer the known square is to the unknown, the more accurate the approximation. For instance, to estimate the square root of 15, we could start with the knowledge that the nearest perfect square is 16 (42).
p6073
aV formula_28
p6074
aVSo we've estimated the square root of 15 to be 3.875. The actual square root of 15 is 3.872983...
p6075
aVDerivation
p6076
aVSay we want to find the square root of a number we'll call "x". By definition
p6077
aV formula_29
p6078
aVWe then redefine the root
p6079
aV formula_30
p6080
aVwhere "a" is a known root (4 from the above example) and "b" is the difference between the known root and the answer we seek.
p6081
aV formula_31
p6082
aVExpanding yields
p6083
aV formula_32
p6084
aVAnd here's the trick. If 'a' is close to your target, 'b' will be a small enough number to render the formula_33 element of the equation negligible. So we drop formula_33 out and rearrange the equation to
p6085
aV formula_35
p6086
aVand therefore
p6087
aV formula_36
p6088
aVthat can be reduced to
p6089
aV formula_37
p6090
aVExtracting roots of perfect powers.
p6091
aVExtracting roots of perfect powers is often practiced. The difficulty of the task does not depend on the number of digits of the perfect power but on the precision, i.e. the number of digits of the root.
p6092
aVExtracting cube roots.
p6093
aVAn easy task for the beginner is extracting cube roots from the cubes of 2 digit numbers. For example, given 74088, determine what two digit number, when multiplied by itself once and then multiplied by the number again, yields 74088. One who knows the method will quickly know the answer is 42, as 423 = 74088.
p6094
aVBefore learning the procedure, it is required that the performer memorize the cubes of the numbers 1-10:
p6095
aVObserve that there is a pattern in the rightmost digit: adding and subtracting with 1 or 3. Starting from zero: 
p6096
aVThere are two steps to extracting the cube root from the cube of a two digit number. Say you are asked to extract the cube root of 29791. Begin by determining the one's place (units) of the two digit number. You know it must be one, since the cube ends in 1, as seen above.
p6097
aVNote that every digit corresponds to itself except for 2, 3, 7 and 8, which are just subtracted from ten to obtain the corresponding digit.
p6098
aVThe second step is to determine the first digit of the two digit cube root by looking at the magnitude of the given cube. To do this, remove the last three digits of the given cube (29791 -> 29) and find the greatest cube it is greater than (this is where knowing the cubes of numbers 1-10 is needed). Here, 29 is greater than 1 cubed, greater than 2 cubed, greater than 3 cubed, but not greater than 4 cubed. The greatest cube it is greater than is 3, so the first digit of the two digit cube must be 3.
p6099
aVTherefore, the cube root of 29791 is 31.
p6100
aVAnother example:
p6101
aVApproximating common logs (log base 10).
p6102
aVTo approximate a common log (to at least one decimal point accuracy), a few log rules, and the memorization of a few logs is required. One must know:
p6103
aVFrom this information, one can find the log of any number 1-9.
p6104
aVThe first step in approximating the common log is to put the number given in scientific notation. For example, the number 45 in scientific notation is 4.5 x 10^1, but we will call it a x 10^b. Next, find the log of a, which is between 1 and 10. Start by finding the log of 4, which is .60, and then the log of 5, which is .70 because 4.5 is between these two. Next, and skill at this comes with practice, place a 5 on a logarithmic scale between .6 and .7, somewhere around .653 (NOTE: the actual value of the extra places will always be greater than if it were placed on a regular scale. i.e., you would expect it to go at .650 because it is halfway, but instead it will be a little larger, in this case .653) Once you have obtained the log of a, simply add b to it to get the approximation of the common log. In this case, a + b = .653 + 1 = 1.653. The actual value of log(45) ~ 1.65321.
p6105
aVThe same process applies for numbers between 0 and 1. For example, 0.045 would be written as 4.5 × 10\u22122. The only difference is that b is now negative, so when adding you are really subtracting. This would yield the result 0.653 \u2212 2, or \u22121.347.
p6106
aVApproximating Natural exponents (log base e).
p6107
aVNatural exponents are used in many important expressions in modern science and engineering, with applications not limited to quantum mechanics, thermodynamics and signal communications. Using the laws of Natural exponents, memorization of the approximations below, and combination with other mental calculation methods, create a powerful and elegant means for changing complicated problems in the physical sciences into simple sums and products. The laws of Natural exponents (Exponentiation) are:
p6108
aVea x eb = e (a+b) and e \u2212a = 1/ ea and also
p6109
aVea x e\u2212b = e (a-b) = ea / eb
p6110
aVTable of approximations:
p6111
aVWhere possible, single digit numbers, followed by zeros, are used for ease of memorization, accuracy and to eliminate redundancy: (e4.5)2 = e9, e3 x e4 = e7, and e8 are used instead of (e4)2.
p6112
aVOptimized Relations:
p6113
aVThis table presents optimized suggestions derived from the above table.
p6114
aVPhysical Science and Communication Approximations:
p6115
aVThe +/- superscript after the error represents if the actual number value is higher or lower than the approximation; for example the approximation of ln(400) is less than 6. The +/- symbols after errors may also be used to make the approximations more accurate by compensation, for example; 
p6116
aVe16 = e8 x e8, accurate to 12 parts in 1000, may be made more accurate by using 
p6117
aVe7 x e9 \u2248 1,100 x 8,100 or 8,910,000, accuracy 2 parts in 1000.
p6118
aVOther examples:
p6119
aVe(9 + \u03c0) = 8,100 x (20 + \u03c0) = 162,000 + ~25,500 = 187,500, (accurate to 1 part in 5000)
p6120
aVMental arithmetic as a psychological skill.
p6121
aVPhysical exertion of the proper level can lead to an increase in performance of a mental task, like doing mental calculations, performed afterward. It has been shown that during high levels of physical activity there is a negative effect on mental task performance. This means that too much physical work can decrease accuracy and output of mental math calculations. Physiological measures, specifically EEG, have been shown to be useful in indicating mental workload. Using an EEG as a measure of mental workload after different levels of physical activity can help determine the level of physical exertion that will be the most beneficial to mental performance. Previous work done at Michigan Technological University by Ranjana Mehta includes a recent study that involved participants engaging in concurrent mental and physical tasks. This study investigated the effects of mental demands on physical performance at different levels of physical exertion and ultimately found a decrease in physical performance when mental tasks were completed concurrently, with a more significant effect at the higher level of physical workload. The Brown-Peterson procedure is a widely known task using mental arithmetic. This procedure, mostly used in cognitive experiments, suggests mental subtraction is useful in testing the effects maintenance rehearsal can have on how long short-term memory lasts.
p6122
aVMental Calculations World Championship.
p6123
aVThe first Mental Calculations World Championship took place in 1997 at the Mind Sports Olympiad. This event repeats every year. It consists of a range of different tasks such as: addition of ten ten-digit numbers, multiplication of two eight-digit numbers, calculation of square roots, and calculation of weekdays for given dates, calculation of cube roots plus some surprise miscellaneous tasks.
p6124
aVMental Calculation World Cup.
p6125
aVThe first World Mental Calculation Championships (Mental Calculation World Cup) took place in 2004. They are repeated every second year. It consists of six different tasks: addition of ten ten-digit numbers, multiplication of two eight-digit numbers, calculation of square roots, and calculation of weekdays for given dates, calculation of cube roots plus some surprise miscellaneous tasks.
p6126
aVMemoriad - World Memory, Mental Calculation & Speed Reading Olympics.
p6127
aVMemoriad is the first platform combining "mental calculation", "memory" and "photographic reading" competitions. Games and competitions are held in the year of the Olympic games, every four years.
p6128
aVThe first Memoriad was held in Istanbul, Turkey, in 2008.
p6129
aVThe second Memoriad took place in Antalya, Turkey on 24\u201325 November 2012. 89 competitors from 20 countries participated. Awards and money prizes were given for 10 categories in total; of which 5 categories had to do about Mental Calculation (Mental addition, Mental Multiplication, Mental Square Roots (non-integer), Mental Calendar Dates calculation and Flash Anzan).
p6130
asS'Reductio ad absurdum'
p6131
(lp6132
VReductio ad absurdum (Latin: "reduction to absurdity"; "pl.": reductiones ad absurdum), also known as "argumentum ad absurdum" (Latin: argument to absurdity), is a common form of argument which seeks to demonstrate that a statement is true by showing that a false, untenable, or absurd result follows from its denial, or in turn to demonstrate that a statement is false by showing that a false, untenable, or absurd result follows from its acceptance. First recognized and studied in classical Greek philosophy (the Latin term derives from the Greek "\u03b5\u03b9\u03c2 \u03ac\u03c4\u03bf\u03c0\u03bf\u03bd \u03b1\u03c0\u03b1\u03b3\u03c9\u03b3\u03ae" or "eis atopon apagoge", "reduction to the impossible", for example in Aristotle's "Prior Analytics"), this technique has been used throughout history in both formal mathematical and philosophical reasoning, as well as informal debate.
p6133
aVThe "absurd" conclusion of a "reductio ad absurdum" argument can take a range of forms:
p6134
aVThe first example above argues that the denial of the assertion would have a ridiculous result; it would go against the evidence of our senses. The second argues denial of the assertion would be untenable; unpleasant or unworkable for society. The third is a mathematical proof by contradiction, arguing that the denial of the premise would result in a logical contradiction (there is a "smallest" number and yet there is a number smaller than it).
p6135
aVGreek philosophy.
p6136
aVThis technique is used throughout Greek philosophy, beginning with Presocratic philosophers. The earliest Greek example of a "reductio" argument is supposedly in fragments of a satirical poem attributed to Xenophanes of Colophon (c.570 \u2013 c.475 BC). Criticizing Homer's attribution of human faults to the Greek gods, he says that humans also believe that the gods' bodies have human form. But if horses and oxen could draw, they would draw the gods with horse and oxen bodies. The gods can't have both forms, so this is a contradiction. Therefore the attribution of other human characteristics to the gods, such as human faults, is also false.
p6137
aVThe earlier dialogs of Plato (424 \u2013 348 BC), relating the debates of his teacher Socrates, raised the use of "reductio" arguments to a formal dialectical method ("Elenchus"), now called the "Socratic method". Typically Socrates' opponent would make an innocuous assertion, then Socrates by a step-by-step train of reasoning, bringing in other background assumptions, would make the person admit that the assertion resulted in an absurd or contradictory conclusion, forcing him to abandon his assertion. The technique was also a focus of the work of Aristotle (384 \u2013 322 BC).
p6138
aVThe principle of non-contradiction.
p6139
aVAristotle clarified the connection between contradiction and falsity in his principle of non-contradiction. This states that an assertion cannot be both true and false. Therefore if the contradiction of an assertion (not-"P") can be derived logically from the assertion ("P") it can be concluded that a false assumption has been used. This technique, called "proof by contradiction" has formed the basis of "reductio ad absurdum" arguments in formal fields like logic and mathematics.
p6140
aVThe principle of non-contradiction has seemed absolutely undeniable to most philosophers. However a few philosophers such as Heraclitus and Hegel have accepted contradictions.
p6141
aVThe principle of explosion and Paraconsistent Logic.
p6142
aVA curious logical consequence of the principle of non-contradiction is that a contradiction implies any statement; if a contradiction is accepted, any proposition (or its negation) can be proved from it. This is known as the principle of explosion (Latin: "ex falso quodlibet", "from a falsehood, anything ", or "ex contradictione sequitur quodlibet", "from a contradiction, anything follows"), or the principle of Pseudo-Scotus. 
p6143
aVformula_1
p6144
aV"for all Q, P and not-P implies Q"
p6145
aVThe discovery of contradictions at the foundations of mathematics at the beginning of the 20th century, such as Russell's paradox, threatened the entire structure of mathematics due to the principle of explosion. This has led a few philosophers such as Newton da Costa, Walter Carnielli and Graham Priest to reject the principle of non-contradiction, giving rise to theories such as paraconsistent logic and its particular form, dialethism, which accepts that there exist statements that are both true and false.
p6146
aVParaconsistent logics usually deny that the principle of explosion holds for all sentences in logic, which amounts to denying that a contradiction entails everything (what is called \u201cdeductive explosion\u201d). The Logics of Formal Inconsistency (LFIs) are a family of paraconsistent logics where the notions of contradiction and consistency are not coincident; although the validity of the principle of explosion is not accepted for all sentences, it is accepted for consistent sentences. Most paraconsistent logics, as the LFIs, also reject the principle of non-contradiction.
p6147
aVStraw man argument.
p6148
aVA fallacious argument similar to "reductio ad absurdum" often seen in polemical debate is the "straw man" logical fallacy.
p6149
aVA straw man argument attempts to refute a given proposition by showing that a slightly different or inaccurate form of the proposition (the "straw man") has an absurd, unpleasant, or ridiculous consequence, relying on the audience not to notice that the argument does not actually apply to the original proposition. For example, in a 1977 appeal of a U.S. bank robbery conviction, a prosecuting attorney said in his closing argument
p6150
aVI submit to you that if you can't take this evidence and find these defendants guilty on this evidence then we might as well open all the banks and say, "Come on and get the money, boys", because we'll never be able to convict them.
p6151
aVThe prosecutor was using this "straw man" to attempt to alarm the appellate judges; the chance that any precedent set by this one particular case would literally make it impossible to convict "any" bank robbers was undoubtedly remote.
p6152
asS'Inverse function'
p6153
(lp6154
VIn mathematics, an inverse function is a function that "reverses" another function: if the function applied to an input gives a result of , then applying its inverse function to gives the result , and vice versa. i.e., if and only if . 
p6155
aVA function that has an inverse is said to be invertible. When it exists, the inverse function is uniquely determined by and is denoted by , read "f inverse". Superscripted "" does not, in general, refer to numerical exponentiation.
p6156
aVIn some situations, for instance when is an invertible real-valued function of a real variable, the relationship between and can be written more compactly, in this case, , meaning composed with , in either order, is the identity function on R.
p6157
aVDefinitions.
p6158
aVLet be a function whose domain is the set , and whose image (range) is the set . Then is "invertible" if there exists a function with domain and image , with the property:
p6159
aVformula_1
p6160
aVIf is invertible, the function is unique; in other words, there is exactly one function satisfying this property (no more, no less). That function is then called "the" inverse of , and usually denoted as .
p6161
aVStated otherwise, a function is invertible if and only if its inverse relation is a function on the range , in which case the inverse relation is the inverse function.
p6162
aVNot all functions have an inverse. For this rule to be applicable, each element must correspond to no more than one ; a function with this property is called one-to-one or an injection. If and are functions on and respectively, then both are bijections. The inverse of an injection that is not a bijection is a partial function, that means for some it is undefined.
p6163
aVExample: squaring and square root functions.
p6164
aVThe function may or may not be invertible, depending on what kinds of numbers are being considered (the "domain").
p6165
aVIf the domain is the real numbers, then each possible result "y" corresponds to two different starting points in : one positive and one negative (), and so this function is not invertible: as it is impossible to deduce from its output the sign of its input. Such a function is called non-injective or information-losing. Neither the square root nor the principal square root function is the inverse of because the first is not single-valued, and the second returns additive inverse when is negative.
p6166
aVIf only positive numbers (and zero) are being considered, then the function is injective and invertible.
p6167
aVInverses in higher mathematics.
p6168
aVThe definition given above is commonly adopted in set theory and calculus. In higher mathematics, the notation
p6169
aVformula_2
p6170
aVmeans " is a function mapping elements of a set to elements of a set ". The source, , is called the domain of , and the target, , is called the codomain. The codomain contains the range of as a subset, and is considered part of the definition of .
p6171
aVWhen using codomains, the inverse of a function is required to have domain and codomain . For the inverse to be defined on all of , every element of must lie in the range of the function . A function with this property is called "onto" or a "surjection". Thus, a function with a codomain is invertible if and only if it is both "injective" (one-to-one) and surjective (onto). Such a function is called a one-to-one correspondence or a bijection, and has the property that every element corresponds to exactly one element .
p6172
aVInverses and composition.
p6173
aVIf is an invertible function with domain and range , then
p6174
aVformula_3, for every formula_4
p6175
aVUsing the composition of functions we can rewrite this statement as follows:
p6176
aVformula_5
p6177
aVwhere is the identity function on the set ; that is, the function that leaves its argument unchanged. In category theory, this statement is used as the definition of an inverse morphism.
p6178
aVConsidering function composition helps to understand the notation . (Repeatedly) composing a function with itself is called iteration, and is denoted if is applied times, starting with the value ; so , etc. Since , composing and yields , "undoing" the effect of one application of .
p6179
aVThe notation can also be linked to regular multiplication, by considering multiplication functions . Applying to gives , which is the same as dividing by , or multiplying by .
p6180
aVNote on notation.
p6181
aVThe superscript notation for inverses can sometimes be confused with other uses of superscripts, especially when dealing with trigonometric and hyperbolic functions. To avoid this confusion, the notations or with the "" above the are sometimes used.
p6182
aVWhereas the notation might be misunderstood, certainly denotes the multiplicative inverse of and has nothing to do with inversion of .
p6183
aVThe expression does not represent the multiplicative inverse to , but the inverse of the sine function applied to (actually a partial inverse; see below). To avoid confusion, an inverse trigonometric function is often indicated by the prefix "arc" (for Latin "arcus"). For instance, the inverse of the sine function is typically called the arcsine function, written as arcsin, which is, like sin, conventionally denoted in roman type and not in italics (note that software libraries of mathematical functions often use the name asin):
p6184
aVformula_6
p6185
aVThe function is the multiplicative inverse to the sine, and is called the cosecant. It is usually denoted :
p6186
aVformula_7
p6187
aVHyperbolic functions behave similarly, using the prefix "ar" (for Latin "area") for their inverse functions, as in arsinh for the inverse function of sinh, and for the multiplicative inverse of .
p6188
aVNon-example: inverse operations that lead to inverse functions.
p6189
aVIn the context of proportionality, direct variation functions represent a relationship between x and y such that the quotient of the two variables equal a constant, k. Thus, the direct variation function is as follows: . An alternative view of this equation is the slope-intercept form, where k is the slope and always positive.
p6190
aVThe inverse variation function represents an inverted relationship between x and y when compared to their relationship in direct variation functions. This notion is not to be confused with finding the inverse function of the direct variation function. The inverse variation function simply implies that as the value of one variable increases the other variable decreases. The function for this relationship cannot be found by finding the inverse of the direct variation function because the result will yield another linear function with a slope of, which is a positive value. Instead, the product of the two variables should always produce a constant. Thus, the inverse variation function is as follows: . As x increases, a larger number is dividing the constant k, so y is approaching 0.
p6191
aVProperties.
p6192
aVUniqueness.
p6193
aVIf an inverse function exists for a given function , it is unique: it must be the inverse relation.
p6194
aVSymmetry.
p6195
aVThere is a symmetry between a function and its inverse. Specifically, if is an invertible function with domain and range , then its inverse has domain and range , and the inverse of is the original function . In symbols, for a function with domain and range , and a function with domain and range :
p6196
aVformula_8
p6197
aVThis follows from the connection between function inverse and relation inverse, because inversion of relations is an involution.
p6198
aVThis statement is an obvious consequence of the deduction that for to be invertible it must be injective (first definition of the inverse) or bijective (second definition). The property of involutive symmetry can be concisely expressed by the following formula:
p6199
aVformula_9
p6200
aVThe inverse of a composition of functions is given by the formula
p6201
aVformula_10
p6202
aVNotice that the order of and have been reversed; to undo followed by , we must first undo and then undo .
p6203
aVFor example, let and let . Then the composition is the function that first multiplies by three and then adds five:
p6204
aVformula_11
p6205
aVTo reverse this process, we must first subtract five, and then divide by three:
p6206
aVformula_12
p6207
aVThis is the composition
p6208
aVSelf-inverses.
p6209
aVIf is a set, then the identity function on is its own inverse:
p6210
aVformula_13
p6211
aVMore generally, a function is equal to its own inverse if and only if the composition is equal to . Such a function is called an involution.
p6212
aVInverses in calculus.
p6213
aVSingle-variable calculus is primarily concerned with functions that map real numbers to real numbers. Such functions are often defined through formulas, such as:
p6214
aVformula_14
p6215
aVA function from the real numbers to the real numbers possesses an inverse as long as it is one-to-one, i.e. as long as the graph of has, for each possible value only one corresponding value, and thus passes the horizontal line test.
p6216
aVThe following table shows several standard functions and their inverses:
p6217
aVFormula for the inverse.
p6218
aVOne approach to finding a formula for , if it exists, is to solve the equation for . For example, if is the function
p6219
aVformula_15
p6220
aVthen we must solve the equation for :
p6221
aVformula_16
p6222
aVThus the inverse function is given by the formula
p6223
aVformula_17
p6224
aVSometimes the inverse of a function cannot be expressed by a formula with a finite number of terms. For example, if is the function
p6225
aVformula_18
p6226
aVthen is one-to-one, and therefore possesses an inverse function . The formula for this inverse has an infinite number of terms:<br>
p6227
aVformula_19
p6228
aVGraph of the inverse.
p6229
aVIf is invertible, then the graph of the function
p6230
aVformula_20
p6231
aVis the same as the graph of the equation
p6232
aVformula_21
p6233
aVThis is identical to the equation that defines the graph of , except that the roles of and have been reversed. Thus the graph of can be obtained from the graph of by switching the positions of the and axes. This is equivalent to reflecting the graph across the line
p6234
aVInverses and derivatives.
p6235
aVA continuous function is one-to-one (and hence invertible) if and only if it is either strictly increasing or decreasing (with no local maxima or minima). For example, the function
p6236
aVformula_22
p6237
aVis invertible, since the derivative
p6238
aVIf the function is differentiable, then the inverse will be differentiable as long as . The derivative of the inverse is given by the inverse function theorem:
p6239
aVformula_23
p6240
aVIf we set , then the formula above can be written
p6241
aVformula_24
p6242
aVThis result follows from the chain rule (see the article on inverse functions and differentiation).
p6243
aVThe inverse function theorem can be generalized to functions of several variables. Specifically, a differentiable multivariable function is invertible in a neighborhood of a point as long as the Jacobian matrix of at is invertible. In this case, the Jacobian of at is the matrix inverse of the Jacobian of at .
p6244
aVReal-world examples.
p6245
aV1. Let be the function that converts a temperature in degrees Celsius to a temperature in degrees Fahrenheit:
p6246
aVformula_25
p6247
aVthen its inverse function converts degrees Fahrenheit to degrees Celsius:
p6248
aVformula_26
p6249
aVsince
p6250
aVformula_27
p6251
aV2. Suppose assigns each child in a family its birth year. An inverse function would output which child was born in a given year. However, if the family has twins (or triplets) then the output cannot be known when the input is the common birth year. As well, if a year is given in which no child was born then a child cannot be named. But if each child was born in a separate year, and if we restrict attention to the three years in which a child was born, then we do have an inverse function. For example,
p6252
aVformula_28
p6253
aV3. Let be the function that leads to an percentage rise of some quantity, and be the function producing an percentage fall. Applied to $100 with = 10%, we find that applying the first function followed by the second does not restore the original value of $100, demonstrating the fact that, despite appearances, these two functions are not inverses of each other.
p6254
aVGeneralizations.
p6255
aVPartial inverses.
p6256
aVEven if a function is not one-to-one, it may be possible to define a partial inverse of by restricting the domain. For example, the function
p6257
aVformula_29
p6258
aVis not one-to-one, since . However, the function becomes one-to-one if we restrict to the domain , in which case
p6259
aVformula_30
p6260
aV(If we instead restrict to the domain , then the inverse is the negative of the square root of .) Alternatively, there is no need to restrict the domain if we are content with the inverse being a multivalued function:
p6261
aVformula_31
p6262
aVSometimes this multivalued inverse is called the full inverse of , and the portions (such as and \u2212) are called "branches". The most important branch of a multivalued function (e.g. the positive square root) is called the "principal branch", and its value at is called the "principal value" of .
p6263
aVFor a continuous function on the real line, one branch is required between each pair of local extrema. For example, the inverse of a cubic function with a local maximum and a local minimum has three branches (see the picture to the right).
p6264
aVThese considerations are particularly important for defining the inverses of trigonometric functions. For example, the sine function is not one-to-one, since
p6265
aVformula_32
p6266
aVfor every real (and more generally for every integer ). However, the sine is one-to-one on the interval
p6267
aV, and the corresponding partial inverse is called the arcsine. This is considered the principal branch of the inverse sine, so the principal value of the inverse sine is always between \u2212 and . The following table describes the principal branch of each inverse trigonometric function:
p6268
aVLeft and right inverses.
p6269
aVIf , a left inverse for (or "retraction" of ) is a function such that
p6270
aVformula_33
p6271
aVThat is, the function satisfies the rule
p6272
aVIf formula_34, then formula_35
p6273
aVThus, must equal the inverse of on the image of , but may take any values for elements of not in the image. A function with a left inverse is necessarily injective. In classical mathematics, every injective function necessarily has a left inverse; however, this may fail in constructive mathematics. For instance, a left inverse of the inclusion of the two-element set in the reals violates indecomposability by giving a retraction of the real line to the set .
p6274
aVA right inverse for (or "section" of ) is a function such that
p6275
aVformula_36
p6276
aVThat is, the function satisfies the rule
p6277
aVIf formula_37, then formula_38
p6278
aVThus, may be any of the elements of that map to under . A function has a right inverse if and only if it is surjective (though constructing such an inverse in general requires the axiom of choice).
p6279
aVAn inverse which is both a left and right inverse must be unique. Likewise, if is a left inverse for , then may or may not be a right inverse for ; and if is a right inverse for , then is not necessarily a left inverse for . For example let denote the squaring map, such that for all in , and let denote the square root map, such that for all . Then for all in ; that is, is a right inverse to . However, is not a left inverse to , since, e.g., .
p6280
aVPreimages.
p6281
aVIf is any function (not necessarily invertible), the preimage (or inverse image) of an element is the set of all elements of that map to :
p6282
aVformula_39
p6283
aVThe preimage of can be thought of as the image of under the (multivalued) full inverse of the function .
p6284
aVSimilarly, if is any subset of , the preimage of is the set of all elements of that map to :
p6285
aVformula_40
p6286
aVFor example, take a function , where . This function is not invertible for reasons discussed . Yet preimages may be defined for subsets of the codomain:
p6287
aVformula_41
p6288
aVThe preimage of a single element \u2013 a singleton set \u2013 is sometimes called the "fiber" of . When is the set of real numbers, it is common to refer to as a "level set".
p6289
asS'Probability'
p6290
(lp6291
VProbability is the measure of the likeliness that an event will occur. Probability is quantified as a number between 0 and 1 (where 0 indicates impossibility and 1 indicates certainty). The higher the probability of an event, the more certain we are that the event will occur. A simple example is the toss of a fair coin. Since the two outcomes are equally probable, the probability of "heads" equals the probability of "tails", so the probability is 1/2 (or 50%) chance of either "heads" or "tails".
p6292
aVThese concepts have been given an axiomatic mathematical formalization in probability theory (see probability axioms), which is used widely in such areas of study as mathematics, statistics, finance, gambling, science (in particular physics), artificial intelligence/machine learning, computer science, and philosophy to, for example, draw inferences about the expected frequency of events. Probability theory is also used to describe the underlying mechanics and regularities of complex systems.
p6293
aVInterpretations.
p6294
aVWhen dealing with experiments that are random and well-defined in a purely theoretical setting (like tossing a fair coin), probabilities can be numerically described by the statistical number of outcomes considered favorable divided by the total number of all outcomes (tossing a fair coin twice will yield head-head with probability 1/4, because the four outcomes head-head, head-tails, tails-head and tails-tails are equally likely to occur). When it comes to practical application however there are two major competing categories of probability interpretations, whose adherents possess different views about the fundamental nature of probability:
p6295
aVEtymology.
p6296
aVThe word "probability" derives from the Latin "probabilitas", which can also mean "probity", a measure of the authority of a witness in a legal case in Europe, and often correlated with the witness's nobility. In a sense, this differs much from the modern meaning of "probability", which, in contrast, is a measure of the weight of empirical evidence, and is arrived at from inductive reasoning and statistical inference.
p6297
aVHistory.
p6298
aVThe scientific study of probability is a modern development. Gambling shows that there has been an interest in quantifying the ideas of probability for millennia, but exact mathematical descriptions arose much later. There are reasons of course, for the slow development of the mathematics of probability. Whereas games of chance provided the impetus for the mathematical study of probability, are still obscured by the superstitions of gamblers.
p6299
aVAccording to Richard Jeffrey, "Before the middle of the seventeenth century, the term 'probable' (Latin "probabilis") meant "approvable", and was applied in that sense, univocally, to opinion and to action. A probable action or opinion was one such as sensible people would undertake or hold, in the circumstances." However, in legal contexts especially, 'probable' could also apply to propositions for which there was good evidence.
p6300
aVThe sixteenth century polymath Gerolamo Cardano demonstrated the efficacy of defining odds as the ratio of favourable to unfavourable outcomes (which implies that the probability of an event is given by the ratio of favourable outcomes to the total number of possible outcomes ).
p6301
aVAside from the elementary work by Cardano, the doctrine of probabilities dates to the correspondence of Pierre de Fermat and Blaise Pascal (1654). Christiaan Huygens (1657) gave the earliest known scientific treatment of the subject. Jakob Bernoulli's "Ars Conjectandi" (posthumous, 1713) and Abraham de Moivre's "Doctrine of Chances" (1718) treated the subject as a branch of mathematics. See Ian Hacking's "The Emergence of Probability" and James Franklin's "The Science of Conjecture" for histories of the early development of the very concept of mathematical probability.
p6302
aVThe theory of errors may be traced back to Roger Cotes's "Opera Miscellanea" (posthumous, 1722), but a memoir prepared by Thomas Simpson in 1755 (printed 1756) first applied the theory to the discussion of errors of observation. The reprint (1757) of this memoir lays down the axioms that positive and negative errors are equally probable, and that certain assignable limits define the range of all errors. Simpson also discusses continuous errors and describes a probability curve.
p6303
aVThe first two laws of error that were proposed both originated with Pierre-Simon Laplace. The first law was published in 1774 and stated that the frequency of an error could be expressed as an exponential function of the numerical magnitude of the error, disregarding sign. The second law of error was proposed in 1778 by Laplace and stated that the frequency of the error is an exponential function of the square of the error. The second law of error is called the normal distribution or the Gauss law. "It is difficult historically to attribute that law to Gauss, who in spite of his well-known precocity had probably not made this discovery before he was two years old."
p6304
aVDaniel Bernoulli (1778) introduced the principle of the maximum product of the probabilities of a system of concurrent errors.
p6305
aVAdrien-Marie Legendre (1805) developed the method of least squares, and introduced it in his "Nouvelles méthodes pour la détermination des orbites des comètes" ("New Methods for Determining the Orbits of Comets"). In ignorance of Legendre's contribution, an Irish-American writer, Robert Adrain, editor of "The Analyst" (1808), first deduced the law of facility of error,
p6306
aVformula_1
p6307
aVwhere formula_2 is a constant depending on precision of observation, and formula_3 is a scale factor ensuring that the area under the curve equals 1. He gave two proofs, the second being essentially the same as John Herschel's (1850). Gauss gave the first proof that seems to have been known in Europe (the third after Adrain's) in 1809. Further proofs were given by Laplace (1810, 1812), Gauss (1823), James Ivory (1825, 1826), Hagen (1837), Friedrich Bessel (1838), W. F. Donkin (1844, 1856), and Morgan Crofton (1870). Other contributors were Ellis (1844), De Morgan (1864), Glaisher (1872), and Giovanni Schiaparelli (1875). Peters's (1856) formula for "r", the probable error of a single observation, is well known.
p6308
aVIn the nineteenth century authors on the general theory included Laplace, Sylvestre Lacroix (1816), Littrow (1833), Adolphe Quetelet (1853), Richard Dedekind (1860), Helmert (1872), Hermann Laurent (1873), Liagre, Didion, and Karl Pearson. Augustus De Morgan and George Boole improved the exposition of the theory.
p6309
aVAndrey Markov introduced the notion of Markov chains (1906), which played an important role in stochastic processes theory and its applications. The modern theory of probability based on the measure theory was developed by Andrey Kolmogorov (1931).
p6310
aVOn the geometric side (see integral geometry) contributors to "The Educational Times" were influential (Miller, Crofton, McColl, Wolstenholme, Watson, and Artemas Martin).
p6311
aVTheory.
p6312
aVLike other theories, the theory of probability is a representation of probabilistic concepts in formal terms\u2014that is, in terms that can be considered separately from their meaning. These formal terms are manipulated by the rules of mathematics and logic, and any results are interpreted or translated back into the problem domain.
p6313
aVThere have been at least two successful attempts to formalize probability, namely the Kolmogorov formulation and the Cox formulation. In Kolmogorov's formulation (see probability space), sets are interpreted as events and probability itself as a measure on a class of sets. In Cox's theorem, probability is taken as a primitive (that is, not further analyzed) and the emphasis is on constructing a consistent assignment of probability values to propositions. In both cases, the laws of probability are the same, except for technical details.
p6314
aVThere are other methods for quantifying uncertainty, such as the Dempster\u2013Shafer theory or possibility theory, but those are essentially different and not compatible with the laws of probability as usually understood.
p6315
aVApplications.
p6316
aVProbability theory is applied in everyday life in risk assessment and in trade on financial markets. Governments apply probabilistic methods in environmental regulation, where it is called pathway analysis.
p6317
aVA good example is the effect of the perceived probability of any widespread Middle East conflict on oil prices\u2014which have ripple effects in the economy as a whole. An assessment by a commodity trader that a war is more likely vs. less likely sends prices up or down, and signals other traders of that opinion. Accordingly, the probabilities are neither assessed independently nor necessarily very rationally. The theory of behavioral finance emerged to describe the effect of such groupthink on pricing, on policy, and on peace and conflict.
p6318
aVThe discovery of rigorous methods to assess and combine probability assessments has changed society. It is important for most citizens to understand how probability assessments are made, and how they contribute to decisions.
p6319
aVAnother significant application of probability theory in everyday life is reliability. Many consumer products, such as automobiles and consumer electronics, use reliability theory in product design to reduce the probability of failure. Failure probability may influence a manufacturer's decisions on a product's warranty.
p6320
aVThe cache language model and other statistical language models that are used in natural language processing are also examples of applications of probability theory.
p6321
aVMathematical treatment.
p6322
aVConsider an experiment that can produce a number of results. The collection of all results is called the sample space of the experiment. The power set of the sample space is formed by considering all different collections of possible results. For example, rolling a die can produce six possible results. One collection of possible results gives an odd number on the dice. Thus, the subset {1,3,5} is an element of the power set of the sample space of dice rolls. These collections are called "events." In this case, {1,3,5} is the event that the dice falls on some odd number. If the results that actually occur fall in a given event, the event is said to have occurred.
p6323
aVA probability is a way of assigning every event a value between zero and one, with the requirement that the event made up of all possible results (in our example, the event {1,2,3,4,5,6}) is assigned a value of one. To qualify as a probability, the assignment of values must satisfy the requirement that if you look at a collection of mutually exclusive events (events with no common results, e.g., the events {1,6}, {3}, and {2,4} are all mutually exclusive), the probability that at least one of the events will occur is given by the sum of the probabilities of all the individual events.
p6324
aVThe probability of an event "A" is written as "P"("A"), "p"("A") or Pr("A"). This mathematical definition of probability can extend to infinite sample spaces, and even uncountable sample spaces, using the concept of a measure.
p6325
aVThe "opposite" or "complement" of an event "A" is the event "A" (that is, the event of "A" not occurring); its probability is given by . As an example, the chance of not rolling a six on a six-sided die is formula_4. See Complementary event for a more complete treatment.
p6326
aVIf two events "A" and "B" occur on a single performance of an experiment, this is called the intersection or joint probability of "A" and "B", denoted as formula_5.
p6327
aVIndependent events.
p6328
aVIf two events, "A" and "B" are independent then the joint probability is
p6329
aVformula_6
p6330
aVfor example, if two coins are flipped the chance of both being heads is formula_7.
p6331
aVMutually exclusive events.
p6332
aVIf either event "A" or event "B" or both events occur on a single performance of an experiment this is called the union of the events "A" and "B" denoted as formula_8.
p6333
aVIf two events are mutually exclusive then the probability of either occurring is
p6334
aVformula_9
p6335
aVFor example, the chance of rolling a 1 or 2 on a six-sided is formula_10
p6336
aVNot mutually exclusive events.
p6337
aVIf the events are not mutually exclusive then
p6338
aVformula_11
p6339
aVFor example, when drawing a single card at random from a regular deck of cards, the chance of getting a heart or a face card (J,Q,K) (or one that is both) is formula_12, because of the 52 cards of a deck 13 are hearts, 12 are face cards, and 3 are both: here the possibilities included in the "3 that are both" are included in each of the "13 hearts" and the "12 face cards" but should only be counted once.
p6340
aVConditional probability.
p6341
aV"Conditional probability" is the probability of some event "A", given the occurrence of some other event "B".
p6342
aVConditional probability is written formula_13, and is read "the probability of "A", given "B"". It is defined by
p6343
aVformula_14
p6344
aVIf formula_15 then formula_13 is formally undefined by this expression. However, it is possible to define a conditional probability for some zero-probability events using a \u03c3-algebra of such events (such as those arising from a continuous random variable).
p6345
aVFor example, in a bag of 2 red balls and 2 blue balls (4 balls in total), the probability of taking a red ball is formula_17; however, when taking a second ball, the probability of it being either a red ball or a blue ball depends on the ball previously taken, such as, if a red ball was taken, the probability of picking a red ball again would be formula_18 since only 1 red and 2 blue balls would have been remaining.
p6346
aVInverse probability.
p6347
aVIn probability theory and applications, Bayes' rule relates the odds of event formula_19 to event formula_20, before (prior to) and after (posterior to) conditioning on another event formula_21. The odds on formula_19 to event formula_20 is simply the ratio of the probabilities of the two events. When arbitrarily many events formula_24 are of interest, not just two, the rule can be rephrased as posterior is proportional to prior times likelihood, formula_25 where the proportionality symbol means that the left hand side is proportional to (i.e., equals a constant times) the right hand side as formula_24 varies, for fixed or given formula_21 (Lee, 2012; Bertsch McGrayne, 2012). In this form it goes back to Laplace (1774) and to Cournot (1843); see Fienberg (2005). See Inverse probability and Bayes' rule.
p6348
aVRelation to randomness.
p6349
aVIn a deterministic universe, based on Newtonian concepts, there would be no probability if all conditions were known (Laplace's demon), (but there are situations in which sensitivity to initial conditions exceeds our ability to measure them, i.e. know them). In the case of a roulette wheel, if the force of the hand and the period of that force are known, the number on which the ball will stop would be a certainty (though as a practical matter, this would likely be true only of a roulette wheel that had not been exactly levelled \u2014 as Thomas A. Bass' Newtonian Casino revealed). Of course, this also assumes knowledge of inertia and friction of the wheel, weight, smoothness and roundness of the ball, variations in hand speed during the turning and so forth. A probabilistic description can thus be more useful than Newtonian mechanics for analyzing the pattern of outcomes of repeated rolls of a roulette wheel. Physicists face the same situation in kinetic theory of gases, where the system, while deterministic "in principle", is so complex (with the number of molecules typically the order of magnitude of Avogadro constant 6.02·1023) that only a statistical description of its properties is feasible.
p6350
aVProbability theory is required to describe quantum phenomena. A revolutionary discovery of early 20th century physics was the random character of all physical processes that occur at sub-atomic scales and are governed by the laws of quantum mechanics. The objective wave function evolves deterministically but, according to the Copenhagen interpretation, it deals with probabilities of observing, the outcome being explained by a wave function collapse when an observation is made. However, the loss of determinism for the sake of instrumentalism did not meet with universal approval. Albert Einstein famously remarked in a letter to Max Born: "I am convinced that God does not play dice". Like Einstein, Erwin Schrödinger, who discovered the wave function, believed quantum mechanics is a statistical approximation of an underlying deterministic reality. In modern interpretations, quantum decoherence accounts for subjectively probabilistic behavior.
p6351
asS'Scatter graph'
p6352
(lp6353
sS'Algebraic variety'
p6354
(lp6355
VIn mathematics, algebraic varieties (also called varieties) are one of the central objects of study in algebraic geometry. Classically, an algebraic variety was defined to be the set of solutions of a system of polynomial equations, over the real or complex numbers. Modern definitions of an algebraic variety generalize this notion in several different ways, while attempting to preserve the geometric intuition behind the original definition.
p6356
aVConventions regarding the definition of an algebraic variety differ slightly. For example, some authors require that an ""algebraic variety"" is, by definition, "irreducible" (which means that it is not the union of two smaller sets that are closed in the Zariski topology), while others do not. When the former convention is used, non-irreducible algebraic varieties are called algebraic sets.
p6357
aVThe notion of variety is similar to that of manifold, the difference being that a variety may have singular points, while a manifold will not. In many languages, both varieties and manifolds are named by the same word.
p6358
aVProven around the year 1800, the fundamental theorem of algebra establishes a link between algebra and geometry by showing that a monic polynomial (an algebraic object) in one variable with complex coefficients is determined by the set of its roots (a geometric object) in the complex plane. Generalizing this result, Hilbert's Nullstellensatz provides a fundamental correspondence between ideals of polynomial rings and algebraic sets. Using the Nullstellensatz and related results, mathematicians have established a strong correspondence between questions on algebraic sets and questions of ring theory. This correspondence is the specificity of algebraic geometry among the other subareas of geometry.
p6359
aVIntroduction and definitions.
p6360
aVAn "affine variety" over an algebraically closed field is conceptually the easiest type of variety to define, which will be done in this section. Next, one can define projective and quasi-projective varieties in a similar way. The most general definition of a variety is obtained by patching together smaller quasi-projective varieties. It is not obvious that one can construct genuinely new examples of varieties in this way, but Nagata gave an example of such a new variety in the 1950s.
p6361
aVAffine varieties.
p6362
aVLet be an algebraically closed field and let be an affine "n"-space over . The polynomials in the ring can be viewed as -valued functions on by evaluating at the points in , i.e. by choosing values in "A" for each "xi". For each set "S" of polynomials in , define the zero-locus "Z"("S") to be the set of points in on which the functions in "S" simultaneously vanish, that is to say
p6363
aVformula_1
p6364
aVA subset "V" of is called an affine algebraic set if "V" = "Z"("S") for some "S". A nonempty affine algebraic set "V" is called irreducible if it cannot be written as the union of two proper algebraic subsets. An irreducible affine algebraic set is also called an affine variety. (Many authors use the phrase "affine variety" to refer to any affine algebraic set, irreducible or not)
p6365
aVAffine varieties can be given a natural topology by declaring the closed sets to be precisely the affine algebraic sets. This topology is called the Zariski topology.
p6366
aVGiven a subset "V" of , we define "I"("V") to be the ideal of all polynomial functions vanishing on "V":
p6367
aVformula_2
p6368
aVFor any affine algebraic set "V", the coordinate ring or structure ring of "V" is the quotient of the polynomial ring by this ideal.
p6369
aVProjective varieties and quasi-projective varieties.
p6370
aVLet be an algebraically closed field and let be the projective "n"-space over . Let in be a homogeneous polynomial of degree "d". It is not well-defined to evaluate on points in in homogeneous coordinates. However, because is homogeneous, , it "does" make sense to ask whether vanishes at a point . For each set "S" of homogeneous polynomials, define the zero-locus of "S" to be the set of points in on which the functions in "S" vanish:
p6371
aVformula_3
p6372
aVA subset "V" of is called a projective algebraic set if "V" = "Z"("S") for some "S". An irreducible projective algebraic set is called a projective variety.
p6373
aVProjective varieties are also equipped with the Zariski topology by declaring all algebraic sets to be closed.
p6374
aVGiven a subset "V" of , let "I"("V") be the ideal generated by all homogeneous polynomials vanishing on "V". For any projective algebraic set "V", the coordinate ring of "V" is the quotient of the polynomial ring by this ideal.
p6375
aVA quasi-projective variety is a Zariski open subset of a projective variety. Notice that every affine variety is quasi-projective. Notice also that the complement of an algebraic set in an affine variety is a quasi-projective variety; in the context of affine varieties, such a quasi-projective variety is usually not called a variety but a constructible set.
p6376
aVAbstract varieties.
p6377
aVIn classical algebraic geometry, all varieties were by definition quasiprojective varieties, meaning that they were open subvarieties of closed subvarieties of projective space. For example, in Chapter 1 of Hartshorne a "variety" over an algebraically closed field is defined to be a quasi-projective variety, but from Chapter 2 onwards, the term variety (also called an abstract variety) refers to a more general object, which locally is a quasi-projective variety, but when viewed as a whole is not necessarily quasi-projective; i.e. it might not have an embedding into projective space. So classically the definition of an algebraic variety required an embedding into projective space, and this embedding was used to define the topology on the variety and the regular functions on the variety. The disadvantage of such a definition is that not all varieties come with natural embeddings into projective space. For example, under this definition, the product is not a variety until it is embedded into the projective space; this is usually done by the Segre embedding. However, any variety that admits one embedding into projective space admits many others by composing the embedding with the Veronese embedding. Consequently many notions that should be intrinsic, such as the concept of a regular function, are not obviously so.
p6378
aVThe earliest successful attempt to define an algebraic variety abstractly, without an embedding, was made by André Weil. In his "Foundations of Algebraic Geometry", Weil defined an abstract algebraic variety using valuations. Claude Chevalley made a definition of a scheme, which served a similar purpose, but was more general. However, it was Alexander Grothendieck's definition of a scheme that was both most general and found the most widespread acceptance. In Grothendieck's language, an abstract algebraic variety is usually defined to be an integral, separated scheme of finite type over an algebraically closed field, although some authors drop the irreducibility or the reducedness or the separateness condition or allow the underlying field to be not algebraically closed. Classical algebraic varieties are the quasiprojective integral separated finite type schemes over an algebraically closed field.
p6379
aVExistence of non-quasiprojective abstract algebraic varieties.
p6380
aVOne of the earliest examples of a non-quasiprojective algebraic variety were given by Nagata. Nagata's example was not complete (the analog of compactness), but soon afterwards he found an algebraic surface that was complete and non-projective. Since then other examples have been found.
p6381
aVExamples.
p6382
aVSubvariety.
p6383
aVA subvariety is a subset of a variety that is itself a variety (with the respect to the structure induced from the ambient variety). For example, every open subset of a variety is a variety. For the definition of a closed subvariety, see closed immersion.
p6384
aVHilbert's Nullstellensatz says that closed subvarieties of an affine or projective variety are in one-to-one correspondence with the prime ideals or homogeneous prime ideals of the coordinate ring of the variety.
p6385
aVAffine variety.
p6386
aVExample 1.
p6387
aVLet , and A2 be the two-dimensional affine space over C. Polynomials in the ring C["x", "y"] can be viewed as complex valued functions on A2 by evaluating at the points in A2. Let subset "S" of C["x", "y"] contain a single element :
p6388
aVformula_4
p6389
aVThe zero-locus of is the set of points in A2 on which this function vanishes: it is the set of all pairs of complex numbers ("x", "y") such that "y" = 1 \u2212 "x", commonly known as a line. This is the set :
p6390
aVformula_5
p6391
aVThus the subset of A2 is an algebraic set. The set "V" is not empty. It is irreducible, as it cannot be written as the union of two proper algebraic subsets. Thus it is an affine algebraic variety.
p6392
aVExample 2.
p6393
aVLet , and A2 be the two-dimensional affine space over C. Polynomials in the ring C["x", "y"] can be viewed as complex valued functions on A2 by evaluating at the points in A2. Let subset "S" of C["x", "y"] contain a single element "g"("x", "y"):
p6394
aVformula_6
p6395
aVThe zero-locus of "g"("x", "y") is the set of points in A2 on which this function vanishes, that is the set of points ("x","y") such that "x"2 + "y"2 = 1. As "g"("x", "y") is an absolutely irreducible polynomial, this is an algebraic variety. The set of its real points (that is the points for which "x" and "y" are real numbers), is known as the unit circle; this name is also often given to the whole variety.
p6396
aVExample 3.
p6397
aVThe following example is neither a hypersurface, nor a linear space, nor a single point. Let A3 be the three-dimensional affine space over C. The set of points ("x", "x"2, "x"3) for "x" in C is an algebraic variety, and more precisely an algebraic curve that is not contained in any plane. It is the twisted cubic shown in the above figure. It may be defined by the equations
p6398
aVformula_7
p6399
aVThe fact that the set of the solutions of this system of equations is irreducible needs a proof. The simplest results from the fact that the projection ("x", "y", "z") \u2192 ("x", "y") is injective on the set of the solutions and that its image is an irreducible plane curve.
p6400
aVFor more difficult examples, a similar proof may always be given, but may imply a difficult computation: first a Gröbner basis computation to compute the dimension, followed by a random linear change of variables (not always needed); then a Gröbner basis computation for another monomial ordering to compute the projection and to prove that it is injective, and finally a polynomial factorization to prove the irreducibility of the image.
p6401
aVProjective variety.
p6402
aVA projective variety is a closed subvariety of a projective space. That is, it is the zero locus of a set of homogeneous polynomials that generate a prime ideal.
p6403
aVExample 1.
p6404
aVA plane projective curve is the zero locus of an irreducible homogeneous polynomial in three indeterminates. The projective line P1 is an example of a projective curve, since it appears as the zero locus of one homogeneous coordinate in the projective plane. For another example, first consider the affine cubic curve:
p6405
aVformula_8.
p6406
aVin the 2-dimensional affine space (over a field of characteristic not two). It has the associated cubic homogeneous polynomial equation:
p6407
aVformula_9,
p6408
aVwhich defines a curve in P2 called an elliptic curve. The curve has genus one (genus formula); in particular, it is not isomorphic to the projective line P1, which has genus zero. Using genus to distinguish curves is very basic: in fact, the genus is the first invariant one uses to classify curves (see also the construction of moduli of algebraic curves).
p6409
aVExample 2.
p6410
aVLet "V" be a finite-dimensional vector space. The Grassmannian variety "G""n"("V") is the set of all "n"-dimensional subspaces of "V". It is a projective variety: it is embedded into a projective space via the Plücker embedding:
p6411
aVformula_10
p6412
aVwhere "b""i" are any set of linearly independent vectors in "V", formula_11 is the "n"-th exterior power of "V" and the bracket ["w"] means the line spanned by the nonzero vector "w".
p6413
aVThe Grassmannian variety comes with a natural vector bundle (or locally free sheaf to be precise) called the tautological bundle, which is important in the study of characteristic classes such as Chern classes.
p6414
aVIsomorphism of algebraic varieties.
p6415
aVLet be algebraic varieties. We say and are isomorphic, and write , if there are regular maps and such that the compositions and are the identity maps on and respectively.
p6416
aVDiscussion and generalizations.
p6417
aVThe basic definitions and facts above enable one to do classical algebraic geometry. To be able to do more \u2014 for example, to deal with varieties over fields that are not algebraically closed \u2014 some foundational changes are required. The modern notion of a variety is considerably more abstract than the one above, though equivalent in the case of varieties over algebraically closed fields. An "abstract algebraic variety" is a particular kind of scheme; the generalization to schemes on the geometric side enables an extension of the correspondence described above to a wider class of rings. A scheme is a locally ringed space such that every point has a neighbourhood that, as a locally ringed space, is isomorphic to a spectrum of a ring. Basically, a variety over is a scheme whose structure sheaf is a sheaf of -algebras with the property that the rings "R" that occur above are all integral domains and are all finitely generated -algebras, that is to say, they are quotients of polynomial algebras by prime ideals.
p6418
aVThis definition works over any field . It allows you to glue affine varieties (along common open sets) without worrying whether the resulting object can be put into some projective space. This also leads to difficulties since one can introduce somewhat pathological objects, e.g. an affine line with zero doubled. Such objects are usually not considered varieties, and are eliminated by requiring the schemes underlying a variety to be "separated". (Strictly speaking, there is also a third condition, namely, that one needs only finitely many affine patches in the definition above.)
p6419
aVSome modern researchers also remove the restriction on a variety having integral domain affine charts, and when speaking of a variety only require that the affine charts have trivial nilradical.
p6420
aVA complete variety is a variety such that any map from an open subset of a nonsingular curve into it can be extended uniquely to the whole curve. Every projective variety is complete, but not "vice versa".
p6421
aVThese varieties have been called 'varieties in the sense of Serre', since Serre's foundational paper FAC on sheaf cohomology was written for them. They remain typical objects to start studying in algebraic geometry, even if more general objects are also used in an auxiliary way.
p6422
aVOne way that leads to generalisations is to allow reducible algebraic sets (and fields that aren't algebraically closed), so the rings "R" may not be integral domains. A more significant modification is to allow nilpotents in the sheaf of rings. A nilpotent in a field must be 0: these if allowed in coordinate rings aren't seen as "coordinate functions".
p6423
aVFrom the categorical point of view, nilpotents must be allowed, in order to have finite limits of varieties (to get fiber products). Geometrically this says that fibres of good mappings may have 'infinitesimal' structure. In the theory of schemes of Grothendieck these points are all reconciled: but the general "scheme" is far from having the immediate geometric content of a "variety".
p6424
aVThere are further generalizations called algebraic spaces and stacks.
p6425
aVAlgebraic manifolds.
p6426
aVAn algebraic manifold is an algebraic variety that is also an "m"-dimensional manifold, and hence every sufficiently small local patch is isomorphic to "km". Equivalently, the variety is smooth (free from singular points). When is the real numbers, R, algebraic manifolds are called Nash manifolds. Algebraic manifolds can be defined as the zero set of a finite collection of analytic algebraic functions. Projective algebraic manifolds are an equivalent definition for projective varieties. The Riemann sphere is one example.
p6427
asS'Idempotence'
p6428
(lp6429
VIdempotence ( ) is the property of certain operations in mathematics and computer science, that can be applied multiple times without changing the result beyond the initial application. The concept of idempotence arises in a number of places in abstract algebra (in particular, in the theory of projectors and closure operators) and functional programming (in which it is connected to the property of referential transparency). The request methods of the Hypertext Transfer Protocol (HTTP) computer protocol are a common example of idempotence, in that data retrieval operations can be performed without changing or otherwise affecting the data.
p6430
aVThe term was introduced by Benjamin Peirce in the context of elements of algebras that remain invariant when raised to a positive integer power, and literally means "(the quality of having) the same power", from "idem" + "potence" (same + power).
p6431
aVThere are several meanings of idempotence, depending on what the concept is applied to:
p6432
aVDefinitions.
p6433
aVUnary operation.
p6434
aVA unary operation formula_1, that is, a map from some set formula_2 into itself, is called idempotent if, for all formula_3 in formula_2,
p6435
aVformula_5.
p6436
aVIn particular, the identity function formula_6, defined by formula_7, is idempotent, as is the constant function formula_8, where formula_9 is an element of formula_2, defined by formula_11.
p6437
aVAn important class of idempotent functions is given by projections in a vector space. An example of a projection is the function formula_12 defined by formula_13, which projects an arbitrary point in 3D space to a point on the formula_14-plane, where the third coordinate (formula_15) is equal to 0.
p6438
aVA unary operation formula_16 is idempotent if it maps each element of formula_2 to a fixed point of formula_1. We can partition a set with formula_19 elements into formula_20 chosen fixed points and formula_21 non-fixed points, and then formula_22 is the number of different idempotent functions. Hence, taking into account all possible partitions,
p6439
aVformula_23
p6440
aVis the total number of possible idempotent functions on the set. The integer sequence of the number of idempotent functions as given by the sum above for formula_24 starts with formula_25. 
p6441
aVNeither the property of being idempotent nor that of being not is preserved under composition of unary functions. As an example for the former, "f"("x") = "x" mod 3 and "g"("x") = max("x",5) are both idempotent, but "f"\u2218"g" is not, although "g"\u2218"f" happens to be. As an example for the latter, the negation function ¬ on truth values isn't idempotent, but ¬\u2218¬ is.
p6442
aVIdempotent elements and binary operations.
p6443
aVGiven a binary operation formula_26 on a set formula_2, an element formula_3 is said to be idempotent (with respect to formula_26) if:
p6444
aVformula_30.
p6445
aVIn particular an identity element of formula_26, if it exists, is idempotent with respect to the operation formula_26.
p6446
aVThe binary operation itself is called idempotent if every element of formula_2 is idempotent. That is, for all formula_34 when formula_35 denotes set membership:
p6447
aVformula_30.
p6448
aVFor example, the operations of set union and set intersection are both idempotent, as are logical conjunction and logical disjunction, and, in general, the meet and join operations of a lattice.
p6449
aVConnections.
p6450
aVThe connections between the three notions are as follows.
p6451
aVCommon examples.
p6452
aVFunctions.
p6453
aVAs mentioned above, the identity map and the constant maps are always idempotent maps. The absolute value function of a real or complex argument, and the floor function of a real argument are idempotent.
p6454
aVThe function that assigns to every subset formula_37 of some topological space formula_38" the closure of formula_37 is idempotent on the power set formula_40 of formula_38. It is an example of a closure operator; all closure operators are idempotent functions.
p6455
aVThe operation of subtracting the average of a list of numbers from every number in the list is idempotent. For example, consider the numbers formula_42. The average formula_43 is formula_44. Subtracting 7 from every number in the list yields formula_45. The average formula_43 of that list is formula_47. Subtracting 0 from every number in that list yields the same list.
p6456
aVFormal languages.
p6457
aVThe Kleene star and Kleene plus operators used to express repetition in formal languages are idempotent.
p6458
aVIdempotent ring elements.
p6459
aVAn idempotent element of a ring is, by definition, an element that is idempotent for the ring's multiplication. That is, for an idempotent element formula_48, formula_49.
p6460
aVIdempotent elements of rings yield direct decompositions of modules, and play a role in describing other homological properties of the ring. 
p6461
aVWhile "idempotent" usually refers to the multiplication operation of a ring, there are rings in which both operations are idempotent: Boolean algebras are such an example.
p6462
aVOther examples.
p6463
aVIn Boolean algebra, both the logical and and the logical or operations are idempotent. This implies that every element of Boolean algebra is idempotent with respect to both of these operations. Specifically, formula_50 and formula_51 for all formula_3. 
p6464
aVIn linear algebra, projections are idempotent. In fact, the projections of a vector space are exactly the idempotent elements of the ring of linear transformations of the vector space. After fixing a basis, it can be shown that the matrix of a projection with respect to this basis is an idempotent matrix.
p6465
aVAn idempotent semiring (also sometimes called a "dioid") is a semiring whose "addition" (not multiplication) is idempotent. If both operations of the semiring are idempotent, then the semiring is called "doubly idempotent".
p6466
aVComputer science meaning.
p6467
aVIn computer science, the term idempotent is used more comprehensively to describe an operation that will produce the same results if executed once or multiple times. This may have a different meaning depending on the context in which it is applied. In the case of methods or subroutine calls with side effects, for instance, it means that the modified state remains the same after the first call. In functional programming, though, an idempotent function is one that has the property for any value "x".
p6468
aVThis is a very useful property in many situations, as it means that an operation can be repeated or retried as often as necessary without causing unintended effects. With non-idempotent operations, the algorithm may have to keep track of whether the operation was already performed or not.
p6469
aVExamples.
p6470
aVLooking up some customer's name and address in a database are typically idempotent (in fact "nullipotent"), since this will not cause the database to change. Similarly, changing a customer's address is typically idempotent, because the final address will be the same no matter how many times it is submitted. However, placing an order for a car for the customer is typically not idempotent, since running the method/call several times will lead to several orders being placed. Canceling an order is idempotent, because the order remains canceled no matter how many requests are made.
p6471
aVA composition of idempotent methods or subroutines, however, is not necessarily idempotent if a later method in the sequence changes a value that an earlier method depends on \u2013 idempotence is not closed under composition. For example, suppose the initial value of a variable is 3 and there is a sequence that reads the variable, then changes it to 5, and then reads it again. Each step in the sequence is idempotent: both steps reading the variable have no side effects and changing a variable to 5 will always have the same effect no matter how many times it is executed. Nonetheless, executing the entire sequence once produces the output (3, 5), but executing it a second time produces the output (5, 5), so the sequence is not idempotent.
p6472
aVIn the HyperText Transfer Protocol (HTTP), idempotence and safety are the major attributes that separate HTTP verbs. Of the major HTTP verbs, GET, PUT, and DELETE are idempotent (if implemented according to the standard), but POST is not. These verbs represent very abstract operations in computer science: GET retrieves a resource; PUT stores content at a resource; and DELETE eliminates a resource. As in the example above, reading data usually has no side effects, so it is idempotent (in fact nullipotent). Storing a given set of content is usually idempotent, as the final value stored remains the same after each execution. And deleting something is generally idempotent, as the end result is always the absence of the thing deleted.
p6473
aVIn Event Stream Processing, idempotence refers to the ability of a system to produce the same outcome, even if an event or message is received more than once.
p6474
aVIn a load-store architecture, instructions that might possibly cause a page fault are idempotent. So if a page fault occurs, the OS can load the page from disk and then simply re-execute the faulted instruction.
p6475
aVIn a processor where such instructions are not idempotent, dealing with page faults is much more complex.
p6476
aVApplied examples.
p6477
aVApplied examples that many people could encounter in their day-to-day lives include elevator call buttons and crosswalk buttons. The initial activation of the button moves the system into a requesting state, until the request is satisfied. Subsequent activations of the button between the initial activation and the request being satisfied have no effect.
p6478
asS'Argument'
p6479
(lp6480
VIn logic and philosophy, an argument is a series of statements typically used to persuade someone of something or to present reasons for accepting a conclusion. The general form of an argument in a natural language is that of premises (typically in the form of propositions, statements or sentences) in support of a claim: the conclusion. The structure of some arguments can also be set out in a formal language, and formally defined "arguments" can be made independently of natural language arguments, as in math, logic and computer science.
p6481
aVIn a typical deductive argument, the premises are meant to provide a guarantee of the "truth" of the conclusion, while in an inductive argument, they are thought to provide reasons supporting the conclusion's "probable" truth. The standards for evaluating non-deductive arguments may rest on different or additional criteria than truth, for example, the persuasiveness of so-called "indispensability claims" in transcendental arguments, the quality of hypotheses in retroduction, or even the disclosure of new possibilities for thinking and acting.
p6482
aVThe standards and criteria used in evaluating arguments and their forms of reasoning are studied in logic. Ways of formulating arguments effectively are studied in rhetoric (see also: argumentation theory). An argument in a formal language shows the logical form of the symbolically represented or natural language arguments obtained by its interpretations.
p6483
aVFormal and informal.
p6484
aVInformal arguments as studied in "informal logic", are presented in ordinary language and are intended for everyday discourse. Conversely, formal arguments are studied in "formal logic" (historically called "symbolic logic", more commonly referred to as "mathematical logic" today) and are expressed in a formal language. Informal logic may be said to emphasize the study of argumentation, whereas formal logic emphasizes implication and inference. Informal arguments are sometimes implicit. That is, the rational structure \u2013the relationship of claims, premises, warrants, relations of implication, and conclusion \u2013is not always spelled out and immediately visible and must sometimes be made explicit by analysis.
p6485
aVStandard types.
p6486
aVThere are several kinds of arguments in logic, the best-known of which are "deductive" and "inductive." Deductive arguments are sometimes referred to as "truth-preserving" arguments, because the truth of the conclusion follows given that of the premises. A deductive argument asserts that the truth of the conclusion is a logical consequence of the premises. An inductive argument, on the other hand, asserts that the truth of the conclusion is otherwise supported by the premises. Each premise and the conclusion are truth bearers or "truth-candidates", capable of being either true or false (and not both). While statements in an argument are referred to as being either "true" or "false", arguments are referred to as being "valid" or "invalid" (see logical truth). A deductive argument is valid if and only if the truth of the conclusion is entailed by (is a logical consequence of) the premises, and its corresponding conditional is therefore a logical truth. A sound argument is a valid argument with true premises; a valid argument may well have false premises under a given interpretation, however, the truth value of a conclusion cannot be determined by an unsound argument.
p6487
aVDeductive.
p6488
aVA "deductive argument" is one that, if valid, has a conclusion that is entailed by its premises. In other words, the truth of the conclusion is a logical consequence of the premises\u2014if the premises are true, then the conclusion must be true. It would be self-contradictory to assert the premises and deny the conclusion, because the negation of the conclusion is contradictory to the truth of the premises.
p6489
aVValidity.
p6490
aVDeductive arguments may be either valid or invalid. If an argument is valid, it is a valid deduction, and if its premises are true, the conclusion must be true: a valid argument cannot have true premises and a false conclusion.
p6491
aVAn argument is formally valid if and only if the denial of the conclusion is incompatible with accepting all the premises.
p6492
aVThe validity of an argument depends, however, not on the actual truth or falsity of its premises and conclusion, but solely on whether or not the argument has a valid logical form. The validity of an argument is not a guarantee of the truth of its conclusion. Under a given interpretation, a valid argument may have false premises that render it inconclusive: the conclusion of a valid argument with one or more false premises may be either true or false.
p6493
aVLogic seeks to discover the valid forms, the forms that make arguments valid. A form of argument is valid if and only if the conclusion is true under all interpretations of that argument in which the premises are true. Since the validity of an argument depends solely on its form, an argument can be shown to be invalid by showing that its form is invalid. This can be done by giving a counter example of the same form of argument with premises that are true under a given interpretation, but a conclusion that is false under that interpretation. In informal logic this is called a counter argument.
p6494
aVThe form of argument can be shown by the use of symbols. For each argument form, there is a corresponding statement form, called a corresponding conditional, and an argument form is valid if and only its corresponding conditional is a logical truth. A statement form which is logically true is also said to be a valid statement form. A statement form is a logical truth if it is true under all interpretations. A statement form can be shown to be a logical truth by either (a) showing that it is a tautology or (b) by means of a proof procedure.
p6495
aVThe corresponding conditional of a valid argument is a necessary truth (true "in all possible worlds") and so the conclusion necessarily follows from the premises, or follows of logical necessity. The conclusion of a valid argument is not necessarily true, it depends on whether the premises are true. If the conclusion, itself, just so happens to be a necessary truth, it is so without regard to the premises.
p6496
aVSome examples:
p6497
aVIn the above second to last case (Some men are hawkers...), the counter-example follows the same logical form as the previous argument, (Premise 1: "Some "X" are "Y"." Premise 2: "Some "Y" are "Z"." Conclusion: "Some "X" are "Z".") in order to demonstrate that whatever hawkers may be, they may or may not be rich, in consideration of the premises as such. "(See also, existential import)."
p6498
aVThe forms of argument that render deductions valid are well-established, however some invalid arguments can also be persuasive depending on their construction (inductive arguments, for example). "(See also, formal fallacy and informal fallacy)."
p6499
aVSoundness.
p6500
aVA sound argument is a valid argument whose conclusion follows from its premise(s), and the premise(s) of which is/are true.
p6501
aVInductive.
p6502
aVNon-deductive logic is reasoning using arguments in which the premises support the conclusion but do not entail it. Forms of non-deductive logic include the statistical syllogism, which argues from generalizations true for the most part, and induction, a form of reasoning that makes generalizations based on individual instances. An inductive argument is said to be "cogent" if and only if the truth of the argument's premises would render the truth of the conclusion probable (i.e., the argument is "strong"), and the argument's premises are, in fact, true. Cogency can be considered inductive logic's analogue to deductive logic's "soundness." Despite its name, mathematical induction is not a form of inductive reasoning. The lack of deductive validity is known as the problem of induction.
p6503
aVDefeasible.
p6504
aVAn argument is defeasible when additional information (such as new counterreasons) can have the effect that it no longer justifies its conclusion. The term "defeasibility" goes back to the legal theorist H.L.A. Hart, although he focused on concepts instead of arguments. Stephen Toulmin's influential argument model includes the possibility of counterreasons that are characteristic of defeasible arguments, but he did not discuss the evaluation of defeasible arguments. Defeasible arguments give rise to defeasible reasoning.
p6505
aVBy analogy.
p6506
aVArgument by analogy may be thought of as argument from the particular to particular. An argument by analogy may use a particular truth in a premise to argue towards a similar particular truth in the conclusion. For example, if A. Plato was mortal, and B. Socrates was like Plato in other respects, then asserting that C. Socrates was mortal is an example of argument by analogy because the reasoning employed in it proceeds from a particular truth in a premise (Plato was mortal) to a similar particular truth in the conclusion, namely that Socrates was mortal.
p6507
aVTransitional.
p6508
aVIn epistemology, transitional arguments attempt to show that a particular explanation is better than another because it is able to make sense of a transition from old to new. That is, if explanation "b" can account for the problems that existed with explanation "a", but not vice versa, then "b" is regarded to be the more reasonable explanation. A common example in the history of science is the transition from pre-Galilean to Galilean understandings of physical motion.
p6509
aVOther kinds.
p6510
aVOther kinds of arguments may have different or additional standards of validity or justification. For example, Charles Taylor writes that so-called transcendental arguments are made up of a "chain of indispensability claims" that attempt to show why something is necessarily true based on its connection to our experience, while Nikolas Kompridis has suggested that there are two types of "fallible" arguments: one based on truth claims, and the other based on the time-responsive disclosure of possibility (see world disclosure). The late French philosopher Michel Foucault is said to have been a prominent advocate of this latter form of philosophical argument.
p6511
aVIn informal logic.
p6512
aVArgument is an informal calculus, relating an effort to be performed or sum to be spent, to possible future gain, either economic or moral. In informal logic, an argument is a connexion between
p6513
aVEx :
p6514
aV</ol></ol>
p6515
aVThe argument is neither a) "advice" nor b) "moral or economical judgement", but the connection between the two. 
p6516
aVAn argument always uses the connective because. 
p6517
aVAn argument is not an explanation. It does not connect two events, cause and effect, which already took place, but a possible individual action and its beneficial outcome. 
p6518
aVAn argument is not a proof. A proof is a logical and cognitive concept; an argument is a praxeologic concept. A proof changes our knowledge; an argument compels us to act.
p6519
aVLogical status.
p6520
aVArgument does not belong to logic, because it is connected to a real person, a real event, and a real effort to be made.
p6521
aVThe value of the argument is connected to the immediate circumstances of the person spoken to. 
p6522
aVIf, in the first case,(1) John has no money, or will die the next year, he will not be interested in buying the stock. If, in the second case (2) she is too heavy, or too old, she will not be interested in studying and becoming a dancer. The argument is not logical, but profitable.
p6523
aVWorld-disclosing.
p6524
aVWorld-disclosing arguments are a group of philosophical arguments that are said to employ a disclosive approach, to reveal features of a wider ontological or cultural-linguistic understanding \u2013 a "world," in a specifically ontological sense \u2013 in order to clarify or transform the background of meaning and "logical space" on which an argument implicitly depends.
p6525
aVExplanations.
p6526
aVWhile arguments attempt to show that something was, is, will be, or should be the case, explanations try to show "why" or "how" something is or will be. If Fred and Joe address the issue of "whether" or not Fred's cat has fleas, Joe may state: "Fred, your cat has fleas. Observe, the cat is scratching right now." Joe has made an "argument that" the cat has fleas. However, if Joe asks Fred, "Why is your cat scratching itself?" the explanation, "...because it has fleas." provides understanding.
p6527
aVBoth the above argument and explanation require knowing the generalities that a) fleas often cause itching, and b) that one often scratches to relieve itching. The difference is in the intent: an argument attempts to settle whether or not some claim is true, and an explanation attempts to provide understanding of the event. Note, that by subsuming the specific event (of Fred's cat scratching) as an instance of the general rule that "animals scratch themselves when they have fleas", Joe will no longer wonder "why" Fred's cat is scratching itself. Arguments address problems of believe, explanations address problems of understanding. Also note that in the argument above, the statement, "Fred's cat has fleas" is up for debate (i.e. is a claim), but in the explanation, the statement, "Fred's cat has fleas" is assumed to be true (unquestioned at this time) and just needs "explaining".
p6528
aVArguments and explanations largely resemble each other in rhetorical use. This is the cause of much difficulty in thinking critically about claims. There are several reasons for this difficulty.
p6529
aVExplanations and arguments are often studied in the field of Information Systems to help explain user acceptance of knowledge-based systems. Certain argument types may fit better with personality traits to enhance acceptance by individuals.
p6530
aVFallacies and nonarguments.
p6531
aVFallacies are types of argument or expressions which are held to be of an invalid form or contain errors in reasoning. There is not as yet any general theory of fallacy or strong agreement among researchers of their definition or potential for application but the term is broadly applicable as a label to certain examples of error, and also variously applied to ambiguous candidates.
p6532
aVIn Logic types of fallacy are firmly described thus:
p6533
aVFirst the premises and the conclusion must be statements, capable of being true or false. Secondly it must be asserted that the conclusion follows from the premises. In English the words "therefore", "so", "because" and "hence" typically separate the premises from the conclusion of an argument, but this is not necessarily so. Thus: "Socrates is a man, all men are mortal therefore Socrates is mortal" is clearly an argument (a valid one at that), because it is clear it is asserted that "Socrates is mortal" follows from the preceding statements. However "I was thirsty and therefore I drank" is NOT an argument, despite its appearance. It is not being claimed that "I drank" is logically entailed by "I was thirsty". The "therefore" in this sentence indicates "for that reason" not "it follows that".
p6534
aVOften an argument is invalid because there is a missing premise\u2014the supply of which would render it valid. Speakers and writers will often leave out a strictly necessary premise in their reasonings if it is widely accepted and the writer does not wish to state the blindingly obvious. Example: "All metals expand when heated, therefore iron will expand when heated." (Missing premise: iron is a metal). On the other hand, a seemingly valid argument may be found to lack a premise \u2013 a 'hidden assumption' \u2013 which if highlighted can show a fault in reasoning. Example: A witness reasoned: "Nobody came out the front door except the milkman; therefore the murderer must have left by the back door." (Hidden assumptions- the milkman was not the murderer, and the murderer has left by the front or back door).
p6535
asS'Charge conjugation'
p6536
(lp6537
sS'Stability'
p6538
(lp6539
VStability may refer to:
p6540
aV*Limit of Positive Stability
p6541
aV*Stability conditions (watercraft) of waterborne vessels.
p6542
aV*Thermal stability of a chemical compound
p6543
aV*stability of a chemical complex
p6544
asS"Pascal's simplex"
p6545
(lp6546
VIn mathematics, Pascal's simplex is a generalisation of Pascal's triangle into arbitrary number of dimensions, based on the multinomial theorem.
p6547
aVGeneric Pascal's "m"-simplex.
p6548
aVLet "m" ("m" > 0) be a number of terms of a polynomial and "n" ("n" \u2265 0) be a power the polynomial is raised to.
p6549
aVLet formula_1 denote a Pascal's "m"-simplex. Each Pascal's "m"-simplex is a semi-infinite object, which consists of an infinite series of its components.
p6550
aVLet formula_2 denote its "n"th component, itself a finite ("m \u2212 1")-simplex with the edge length "n", with a notational equivalent formula_3.
p6551
aV"n"th component.
p6552
aVformula_4 consists of the coefficients of multinomial expansion of a polynomial with "m" terms raised to the power of "n":
p6553
aVformula_5
p6554
aVwhere formula_6.
p6555
asS'Predicate logic'
p6556
(lp6557
VIn mathematical logic, predicate logic is the generic term for symbolic formal systems like first-order logic, second-order logic, many-sorted logic, or infinitary logic. This formal system is distinguished from other systems in that its formulae contain variables which can be quantified. Two common quantifiers are the existential \u2203 ("there exists") and universal \u2200 ("for all") quantifiers. The variables could be elements in the universe under discussion, or perhaps relations or functions over that universe. For instance, an existential quantifier over a function symbol would be interpreted as modifier "there is a function". The foundations of predicate logic were developed independently by Gottlob Frege and Charles Sanders Peirce.
p6558
aVIn informal usage, the term "predicate logic" occasionally refers to first-order logic. Some authors consider the predicate calculus to be an axiomatized form of predicate logic, and the predicate logic to be derived from an informal, more intuitive development.
p6559
aVPredicate logics also include logics mixing modal operators and quantifiers. See Modal logic, Saul Kripke, Barcan Marcus formulae, A. N. Prior, and Nicholas Rescher.
p6560
asS'Mathematical physics'
p6561
(lp6562
VMathematical physics refers to development of mathematical methods for application to problems in physics. The "Journal of Mathematical Physics" defines the field as "the application of mathematics to problems in physics and the development of mathematical methods suitable for such applications and for the formulation of physical theories". It is a branch of applied mathematics.
p6563
aVScope.
p6564
aVThere are several distinct branches of mathematical physics, and these roughly correspond to particular historical periods.
p6565
aVClassical mechanics.
p6566
aVThe rigorous, abstract and advanced re-formulation of Newtonian mechanics adopting the Lagrangian mechanics and the Hamiltonian mechanics even in the presence of constraints. Both formulations are embodied in the so-called analytical mechanics.
p6567
aVIt leads, for instance, to discover the deep interplay of the notion of symmetry and that of conserved quantities during the dynamical evolution, stated within the most elementary formulation of Noether's theorem. These approaches and ideas can be and, in fact, have been extended to other areas of physics as statistical mechanics, continuum mechanics, classical field theory and quantum field theory. Moreover they have provided several examples and basic ideas in differential geometry (e.g. the theory of vector bundles and several notions in symplectic geometry).
p6568
aVPartial differential equations.
p6569
aVThe theory of partial differential equations (and the related areas of variational calculus, Fourier analysis, potential theory, and vector analysis) are perhaps most closely associated with mathematical physics. These were developed intensively from the second half of the eighteenth century (by, for example, D'Alembert, Euler, and Lagrange) until the 1930s. Physical applications of these developments include hydrodynamics, celestial mechanics, continuum mechanics, elasticity theory, acoustics, thermodynamics, electricity, magnetism, and aerodynamics.
p6570
aVQuantum theory.
p6571
aVThe theory of atomic spectra (and, later, quantum mechanics) developed almost concurrently with the mathematical fields of linear algebra, the spectral theory of operators, operator algebras and more broadly, functional analysis. Nonrelativistic quantum mechanics includes Schrödinger operators, and it has connections to atomic and molecular physics. Quantum information theory is another subspecialty.
p6572
aVRelativity and Quantum Relativistic Theories.
p6573
aVThe special and general theories of relativity require a rather different type of mathematics. This was group theory, which played an important role in both quantum field theory and differential geometry. This was, however, gradually supplemented by topology and functional analysis in the mathematical description of cosmological as well as quantum field theory phenomena. In this area both homological algebra and category theory are important nowadays.
p6574
aVStatistical mechanics.
p6575
aVStatistical mechanics forms a separate field, which includes the theory of phase transitions. It relies upon the Hamiltonian mechanics (or its quantum version) and it is closely related with the more mathematical ergodic theory and some parts of probability theory. There are increasing interactions between combinatorics and physics, in particular statistical physics.
p6576
aVUsage.
p6577
aVThe usage of the term "mathematical physics" is sometimes idiosyncratic. Certain parts of mathematics that initially arose from the development of physics are not, in fact, considered parts of mathematical physics, while other closely related fields are. For example, ordinary differential equations and symplectic geometry are generally viewed as purely mathematical disciplines, whereas dynamical systems and Hamiltonian mechanics belong to mathematical physics.
p6578
aVMathematical vs. theoretical physics.
p6579
aVThe term "mathematical physics" is sometimes used to denote research aimed at studying and solving problems inspired by physics or thought experiments within a mathematically rigorous framework. In this sense, mathematical physics covers a very broad academic realm distinguished only by the blending of pure mathematics and physics. Although related to theoretical physics, mathematical physics in this sense emphasizes the mathematical rigour of the same type as found in mathematics.
p6580
aVOn the other hand, theoretical physics emphasizes the links to observations and experimental physics, which often requires theoretical physicists (and mathematical physicists in the more general sense) to use heuristic, intuitive, and approximate arguments. Such arguments are not considered rigorous by mathematicians. Arguably, rigorous mathematical physics is closer to mathematics, and theoretical physics is closer to physics. This is reflected institutionally: mathematical physicists are often members of the mathematics department.
p6581
aVSuch mathematical physicists primarily expand and elucidate physical theories. Because of the required level of mathematical rigour, these researchers often deal with questions that theoretical physicists have considered to already be solved. However, they can sometimes show (but neither commonly nor easily) that the previous solution was incomplete, incorrect, or simply, too naive. Issues about attempts to infer the second law of thermodynamics from statistical mechanics are examples. Other examples concerns all the subtleties involved with synchronisation procedures in special and general relativity (Sagnac effect and Einstein synchronisation)
p6582
aVThe effort to put physical theories on a mathematically rigorous footing has inspired many mathematical developments. For example, the development of quantum mechanics and some aspects of functional analysis parallel each other in many ways. The mathematical study of quantum mechanics, quantum field theory and quantum statistical mechanics has motivated results in operator algebras. The attempt to construct a rigorous quantum field theory has also brought about progress in fields such as representation theory. Use of geometry and topology plays an important role in string theory.
p6583
aVProminent mathematical physicists.
p6584
aVBefore Newton.
p6585
aVThe roots of mathematical physics can be traced back to the likes of Archimedes in Greece, Ptolemy in Egypt, Alhazen in Iraq, and Al-Biruni in Persia.
p6586
aVIn the first decade of the 16th century, amateur astronomer Nicolaus Copernicus proposed heliocentrism, and published a treatise on it in 1543. Not quite radical, Copernicus merely sought to simplify astronomy and achieve orbits of more perfect circles, stated by Aristotelian physics to be the intrinsic motion of Aristotle's fifth element\u2014the quintessence or universal essence known in Greek as "aither" for the English "pure air"\u2014that was the pure substance beyond the sublunary sphere, and thus was celestial entities' pure composition. The German Johannes Kepler [1571\u20131630], Tycho Brahe's assistant, modified Copernican orbits to "ellipses", however, formalized in the equations of Kepler's laws of planetary motion.
p6587
aVAn enthusiastic atomist, Galileo Galilei in his 1623 book "The Assayer" asserted that the "book of nature" is written in mathematics. His 1632 book, upon his telescopic observations, supported heliocentrism. Having introduced experimentation, Galileo then refuted geocentric cosmology by refuting Aristotelian physics itself. Galilei's 1638 book "Discourse on Two New Sciences" established law of equal free fall as well as the principles of inertial motion, founding the central concepts of what would become today's classical mechanics. By the Galilean law of inertia as well as the principle Galilean invariance, also called Galilean relativity, for any object experiencing inertia, there is empirical justification of knowing only its being at "relative" rest or "relative" motion\u2014rest or motion with respect to another object.
p6588
aVRené Descartes adopted Galilean principles and developed a complete system of heliocentric cosmology, anchored on the principle of vortex motion, Cartesian physics, whose widespread acceptance brought demise of Aristotelian physics. Descartes sought to formalize mathematical reasoning in science, and developed Cartesian coordinates for geometrically plotting locations in 3D space and marking their progressions along the flow of time.
p6589
aVNewtonian and post Newtonian.
p6590
aVIsaac Newton developed new mathematics, including calculus and several numerical methods such as Newton's method to solve problems in physics. Newton's theory of motion, published in 1687, modeled three Galilean laws of motion along with Newton's law of universal gravitation on a framework of absolute space\u2014hypothesized by Newton as a physically real entity of Euclidean geometric structure extending infinitely in all directions\u2014while presuming absolute time, supposedly justifying knowledge of absolute motion, the object's motion with respect to absolute space. The principle Galilean invariance/relativity was merely implicit in Newton's theory of motion. Having ostensibly reduced Keplerian celestial laws of motion as well as Galilean terrestrial laws of motion to a unifying force, Newton achieved great mathematic rigor if theoretical laxity.
p6591
aVIn the 18th century, the Swiss Daniel Bernoulli made contributions to fluid dynamics, and vibrating strings. The Swiss Leonhard Euler [1707\u20131783 did special work in variational calculus, dynamics, fluid dynamics, and other areas. Also notable was the Italian-born Frenchman, Joseph-Louis Lagrange for work in analytical mechanics (he formulated the so-called Lagrangian mechanics) and variational methods. A major contribution to the formulation of Analytical Dynamics called Hamiltonian Dynamics was also made by the Irish physicist, astronomer and mathematician, William Rowan Hamilton [1805-1865. Hamiltonian Dynamics had played an important role in the formulation of modern theories in physics including field theory and quantum mechanics.
p6592
aVThe French mathematical physicist Joseph Fourier \u2013 1830 introduced the notion of Fourier series to solve the heat equation giving rise to a new approach to handle partial differential equations by means of integral transforms.
p6593
aVInto the early 19th century, the French Pierre-Simon Laplace made paramount contributions to mathematical astronomy, potential theory, and probability theory. Siméon Denis Poisson [1781\u20131840 worked in analytical mechanics and potential theory. In Germany, Carl Friedrich Gauss [1777\u20131855] made key contributions to the theoretical foundations of electricity, magnetism, mechanics, and fluid dynamics.
p6594
aVA couple of decades ahead of Newton's publication of a particle theory of light, the Dutch Christiaan Huygens developed the wave theory of light, published in 1690. By 1804, Thomas Young's double-slit experiment revealed an interference pattern as though light were a wave, and thus Huygens's wave theory of light, as well as Huygens's inference that that light waves were vibrations of the luminiferous aether was accepted. Jean-Augustin Fresnel modeled hypothetical behavior of the aether. Michael Faraday introduced the theoretical concept of a field\u2014not action at a distance. Mid-19th century, the Scottish James Clerk Maxwell [1831\u20131879 reduced electricity and magnetism to Maxwell's electromagnetic field theory, whittled down by others to the four Maxwell's equations. Initially, optics was found consequent of Maxwell's field. Later, radiation and then today's known electromagnetic spectrum were found also consequent of this electromagnetic field.
p6595
aVThe English physicist Lord Rayleigh worked on sound. The Irishmen William Rowan Hamilton [1805\u20131865, George Gabriel Stokes and Lord Kelvin [1824\u20131907 did a lot of major work: Stokes was a leader in optics and fluid dynamics; Kelvin made substantial discoveries in thermodynamics; Hamilton did notable work on analytical mechanics finding out a new and powerful approach nowadays known as Hamiltonian mechanics. Very relevant contributions to this approach are due to his German colleague Carl Gustav Jacobi [1804\u20131851] in particular referring to the so-called canonical transformations.
p6596
aVThe German Hermann von Helmholtz is greatly contributed to electromagnetism, waves, fluids, and sound. In the United States, the pioneering work of Josiah Willard Gibbs [1839\u20131903 became the basis for statistical mechanics. Fundamental theoretical results in this area were achieved by the German Ludwig Boltzmann [1844-1906]. Together, these individuals laid the foundations of electromagnetic theory, fluid dynamics, and statistical mechanics.
p6597
aVRelativistic.
p6598
aVBy the 1880s, prominent was the paradox that an observer within Maxwell's electromagnetic field measured it at approximately constant speed regardless of the observer's speed relative to other objects within the electromagnetic field. Thus, although the observer's speed was continually lost relative to the electromagnetic field, it was preserved relative to other objects "in" the electromagnetic field. And yet no violation of Galilean invariance within physical interactions among objects was detected. As Maxwell's electromagnetic field was modeled as oscillations of the aether, physicists inferred that motion within the aether resulted in aether drift, shifting the electromagnetic field, explaining the observer's missing speed relative to it. Physicists' mathematical process to translate the positions in one reference frame to predictions of positions in another reference frame, all plotted on Cartesian coordinates, had been the Galilean transformation, which was newly replaced with Lorentz transformation, modeled by the Dutch Hendrik Lorentz [1853\u20131928].
p6599
aVIn 1887, experimentalists Michelson and Morley failed to detect aether drift, however. It was hypothesized that motion "into" the aether prompted aether's shortening, too, as modeled in the Lorentz contraction. Hypotheses at the aether thus kept Maxwell's electromagnetic field aligned with the principle Galilean invariance across all inertial frames of reference, while Newton's theory of motion was spared.
p6600
aVIn the 19th century, Gauss's contributions to non-Euclidean geometry, or geometry on curved surfaces, laid the groundwork for the subsequent development of Riemannian geometry by Bernhard Riemann Austrian theoretical physicist and philosopher Ernst Mach criticized Newton's postulated absolute space. Mathematician Jules-Henri Poincaré [1854\u20131912 questioned even absolute time. In 1905, Pierre Duhem published a devastating criticism of the foundation of Newton's theory of motion. Also in 1905, Albert Einstein [1879\u20131955] published special theory of relativity, newly explaining both the electromagnetic field's invariance and Galilean invariance by discarding all hypotheses at aether, including aether itself. Refuting the framework of Newton's theory\u2014absolute space and absolute time\u2014special relativity states "relative space" and "relative time", whereby "length" contracts and "time" dilates along the travel pathway of an object experiencing kinetic energy.
p6601
aVIn 1908, Einstein's former professor Hermann Minkowski modeled 3D space together with the 1D axis of time by treating the temporal axis like a fourth spatial dimension\u2014altogether 4D spacetime\u2014and declared the imminent demise of the separation of space and time. Einstein initially called this "superfluous learnedness", but later used Minkowski spacetime to great elegance in general theory of relativity, extending invariance to all reference frames\u2014whether perceived as inertial or as accelerated\u2014and thanked Minkowski, by then deceased. General relativity replaces Cartesian coordinates with Gaussian coordinates, and replaces Newton's claimed empty yet Euclidean space traversed instantly by Newton's vector of hypothetical gravitational force\u2014an instant action at a distance\u2014with a gravitational "field". The gravitational field is Minkowski spacetime itself, the 4D topology of Einstein aether modeled on a Lorentzian manifold that "curves" geometrically, according to the Riemann curvature tensor, in the vicinity of either mass or energy. (By special relativity\u2014a special case of general relativity\u2014even massless energy exerts gravitational effect by its mass equivalence locally "curving" the geometry of the four, unified dimensions of space and time.)
p6602
aVQuantum.
p6603
aVAnother revolutionary development of the twentieth century has been quantum theory, which emerged from the seminal contributions of Max Planck (on black body radiation) and Einstein's work on the photoelectric effect. This was, at first, followed by a heuristic framework devised by Arnold Sommerfeld [1868\u20131951 and Niels Bohr but this was soon replaced by the quantum mechanics developed by Max Born [1882\u20131970, Werner Heisenberg Paul Dirac [1902\u20131984, Erwin Schrödinger Satyendra Nath Bose [1894 \u20131974, and Wolfgang Pauli This revolutionary theoretical framework is based on a probabilistic interpretation of states, and evolution and measurements in terms of self-adjoint operators on an infinite dimensional vector space. That is the so-called Hilbert space, introduced in its elementary form by David Hilbert [1862\u20131943 and Frigyes Riesz [1880-1956], and rigorously defined within the axiomatic modern version by John von Neumann in his celebrated book on mathematical foundations of quantum mechanics, where he built up a relevant part of modern functional analysis on Hilbert spaces, the spectral theory in particular. Paul Dirac used algebraic constructions to produce a relativistic model for the electron, predicting its magnetic moment and the existence of its antiparticle, the positron.
p6604
aVList of important mathematical physicists in the 20th century.
p6605
aVProminent contributors to the 20th century's mathematical physics (although the list contains some typically theoretical, not mathematical, physicists and leaves many contributors out) include (ordered by birth date) Jules Henri Poincaré , David Hilbert [1862\u20131943, Arnold Sommerfeld Constantin Caratheodory [1873-1950, Albert Einstein Max Born [1882\u20131970, George David Birkhoff Niels Bohr [1885\u20131962, Hermann Weyl Satyendra Nath Bose [1894\u20131974, Wolfgang Pauli Werner Heisenberg [1901\u20131976, Paul Dirac Eugene Wigner [1902\u20131995, Lars Onsager John von Neumann [1903\u20131957, Sin-Itiro Tomonaga Hideki Yukawa [1907\u20131981, Lev Landau Nikolay Bogolyubov [1909\u20131992, Subrahmanyan Chandrasekhar Mark Kac [1914\u20131984, Julian Schwinger Richard Feynman [1918\u20131988, Irving Ezra Segal Arthur Strong Wightman [1922\u20132013, Chen-Ning Yang , Rudolf Haag , Freeman Dyson , Martin Gutzwiller Abdus Salam [1926\u20131996, Jürgen Moser Michael Francis Atiyah [1929\u2013 , Joel Louis Lebowitz , Roger Penrose , Elliott H. Lieb , Sheldon Lee Glashow , Steven Weinberg , Ludvig D. Faddeev , David Ruelle , Yakov G. Sinai , Vladimir Igorevich Arnold Arthur Jaffe [1937\u2013 , Roman Jackiw , Leonard Susskind , Rodney J. Baxter , Michael Victor Berry Giovanni Gallavotti , Stephen William Hawking , Alexander M. Polyakov , Barry Simon , Gerardus 't Hooft , John L. Cardy , Edward Witten , Herbert Spohn , and Juan M. Maldacena .
p6606
aV*
aV* (pbk.)
p6607
aV* (softcover)
p6608
aV* (This is a reprint of the second (1980) edition of this title.)
p6609
aV* (This is a reprint of the 1956 second edition.)
p6610
aV* (This is a reprint of the original (1953) edition of this title.)
p6611
aV*
aV*Sneed, Joseph, "The Logical Structure of Mathematical Physics"
p6612
aV* (This tome was reprinted in 1985.)
p6613
aV*
aV* (pbk.)
p6614
aV*
aV*
aV*
aV* (set : pbk.)
p6615
aV*
aV*
aV* (pbk.)
p6616
aV* (pbk.)
p6617
aV*
aV* (pbk.)
p6618
aV* (pbk.)
p6619
asS'Reflexive relation'
p6620
(lp6621
VIn mathematics, a reflexive relation is a binary relation on a set for which every element is related to itself. In other words, a relation ~ on a set "S" is reflexive when "x" ~ "x" holds true for every "x" in "S", formally: when \u2200"x"\u2208"S": "x"~"x" holds. An example of a reflexive relation is the relation "is equal to" on the set of real numbers, since every real number is equal to itself. A reflexive relation is said to have the reflexive property or is said to possess reflexivity.
p6622
aVRelated terms.
p6623
aVA relation that is , or anti-reflexive, is a binary relation on a set where no element is related to itself. An example is the "greater than" relation (x>y) on the real numbers. Note that not every relation which is not reflexive is irreflexive; it is possible to define relations where some elements are related to themselves but others are not (i.e., neither all nor none are). For example, the binary relation "the product of "x" and "y" is even" is reflexive on the set of even numbers, irreflexive on the set of odd numbers, and neither reflexive nor irreflexive on the set of natural numbers.
p6624
aVA relation ~ on a set "S" is called quasi-reflexive if every element that is related to some element is also related to itself, formally: if \u2200"x","y"\u2208"S": "x"~"y" \u21d2 "x"~"x" \u2227 "y"~"y". An example is the relation "has the same limit as" on the set of sequences of real numbers: not every sequence has a limit, and thus the relation is not reflexive, but if a sequence has the same limit as some sequence, then it has the same limit as itself.
p6625
aVThe reflexive closure \u2243 of a binary relation ~ on a set "S" is the smallest reflexive relation on "S" that is a superset of ~. Equivalently, it is the union of ~ and the identity relation on "S", formally: (\u2243) = (~) \u222a (=). For example, the reflexive closure of "x"<"y" is "x"\u2264"y".
p6626
aVThe reflexive reduction, or irreflexive kernel, of a binary relation ~ on a set "S" is the smallest relation \u2246 such that \u2246 shares the same reflexive closure as ~. It can be seen in a way as the opposite of the reflexive closure. It is equivalent to the complement of the identity relation on "S" with regard to ~, formally: (\u2246) = (~) \u005c (=). That is, it is equivalent to ~ except for where "x"~"x" is true. For example, the reflexive reduction of "x"\u2264"y" is "x"<"y".
p6627
aVExamples.
p6628
aVExamples of reflexive relations include:
p6629
aVExamples of irreflexive relations include:
p6630
aVNumber of reflexive relations.
p6631
aVThe number of reflexive relations on an "n"-element set is 2"n"2\u2212"n".
p6632
aVPhilosophical logic.
p6633
aVAuthors in philosophical logic often use deviating designations.
p6634
aVA reflexive and a quasi-reflexive relation in the mathematical sense is called a totally reflexive and a reflexive relation in philosophical logic sense, respectively.
p6635
asS'Canonical form'
p6636
(lp6637
VIn mathematics and computer science, a canonical, normal, or standard form of a mathematical object is a standard way of presenting that object as a mathematical expression. The distinction between "canonical" and "normal" forms varies by subfield. In most fields, a canonical form specifies a "unique" representation for every object, while a normal form simply specifies its form, without the requirement of uniqueness.
p6638
aVThe canonical form of a positive integer in decimal representation is a finite sequence of digits that does not begin with zero.
p6639
aVMore generally, for a class of objects on which an equivalence relation (which can differ from standard notions of equality, for instance by considering different forms of equal objects to be nonequivalent) is defined, a canonical form consists in the choice of a specific object in each class. For example, row echelon form and Jordan normal form are canonical forms for matrices.
p6640
aVIn computer science, and more specifically in computer algebra, when representing mathematical objects in a computer, there are usually many different ways to represent the same object. In this context, a canonical form is a representation such that every object has a unique representation. Thus, the equality of two objects can easily be tested by testing the equality of their canonical forms. However canonical forms frequently depend on arbitrary choices (like ordering the variables), and this introduces difficulties for testing the equality of two objects resulting on independent computations. Therefore, in computer algebra, "normal form" is a weaker notion: A normal form is a representation such that zero is uniquely represented. This allows to test equality by putting the difference of two objects in normal form (see Computer algebra#Equality).
p6641
aVCanonical form can also mean a differential form that is defined in a natural (canonical) way; see below.
p6642
aVIn computer science, data that has more than one possible representation can often be canonicalized into a completely unique representation called its canonical form. Putting something into canonical form is canonicalization.
p6643
aVDefinition.
p6644
aVSuppose we have some set "S" of objects, with an equivalence relation. A canonical form is given by designating some objects of "S" to be "in canonical form", such that every object under consideration is equivalent to exactly one object in canonical form. In other words, the canonical forms in "S" represent the equivalence classes, once and only once. To test whether two objects are equivalent, it then suffices to test their canonical forms for equality.
p6645
aVA canonical form thus provides a classification theorem and more, in that it not just classifies every class, but gives a distinguished (canonical) representative.
p6646
aVIn practical terms, one wants to be able to recognize the canonical forms. There is also a practical, algorithmic question to consider: how to pass from a given object "s" in "S" to its canonical form "s"*? Canonical forms are generally used to make operating with equivalence classes more effective. For example in modular arithmetic, the canonical form for a residue class is usually taken as the least non-negative integer in it. Operations on classes are carried out by combining these representatives and then reducing the result to its least non-negative residue.
p6647
aVThe uniqueness requirement is sometimes relaxed, allowing the forms to be unique up to some finer equivalence relation, like allowing reordering of terms (if there is no natural ordering on terms).
p6648
aVA canonical form may simply be a convention, or a deep theorem.
p6649
aVFor example, polynomials are conventionally written with the terms in descending powers: it is more usual to write "x"2 + "x" + 30 than "x" + 30 + "x"2, although the two forms define the same polynomial. By contrast, the existence of Jordan canonical form for a matrix is a deep theorem.
p6650
aVExamples.
p6651
aVNote: in this section, "up to" some equivalence relation E means that the canonical form is not unique in general, but that if one object has two different canonical forms, they are E-equivalent.
p6652
aVGeometry.
p6653
aVBy contrast, there are alternative forms for writing equations. For example, the equation of a line may be written as a linear equation in point-slope and slope-intercept form.
p6654
aVMathematical notation.
p6655
aVStandard form is used by many mathematicians and scientists to write extremely large numbers in a more concise and understandable way.
p6656
aVDifferential forms.
p6657
aVCanonical differential forms include the canonical one-form and canonical symplectic form, important in the study of Hamiltonian mechanics and symplectic manifolds.
p6658
asS'Monty Hall problem'
p6659
(lp6660
VThe Monty Hall problem is a brain teaser, in the form of a probability puzzle (Gruber, Krauss and others), loosely based on the American television game show "Let's Make a Deal" and named after its original host, Monty Hall. The problem was originally posed in a letter by Steve Selvin to the "American Statistician" in 1975 , . It became famous as a question from a reader's letter quoted in Marilyn vos Savant's "Ask Marilyn" column in "Parade" magazine in 1990 :
p6661
aVVos Savant's response was that the contestant should switch to the other door . Under the standard assumptions, contestants who switch have a 2/3 chance of winning the car, while contestants who stick to their choice have only a 1/3 chance.
p6662
aVMany readers of vos Savant's column refused to believe switching is beneficial despite her explanation. After the problem appeared in "Parade", approximately 10,000 readers, including nearly 1,000 with PhDs, wrote to the magazine, most of them claiming vos Savant was wrong . Even when given explanations, simulations, and formal mathematical proofs, many people still do not accept that switching is the best strategy . Paul Erd\u0151s, one of the most prolific mathematicians in history, remained unconvinced until he was shown a computer simulation confirming the predicted result (Vazsonyi 1999).
p6663
aVThe problem is a paradox of the "veridical" type, because the correct result (you should switch doors) is so counterintuitive it can seem absurd, but is nevertheless demonstrably true. The Monty Hall problem is mathematically closely related to the earlier Three Prisoners problem and to the much older Bertrand's box paradox.
p6664
aVThe paradox.
p6665
aVSteve Selvin wrote a letter to the "American Statistician" in 1975 describing a problem loosely based on the game show "Let's Make a Deal", , dubbing it the "Monty Hall problem" in a subsequent letter . The problem is mathematically equivalent to the Three Prisoners Problem described in Martin Gardner's "Mathematical Games" column in "Scientific American" in 1959 (Gardner 1959a) and the Three Shells Problem described in Gardner's book "Aha Gotcha" .
p6666
aVThe same problem was restated in a 1990 letter by Craig Whitaker to Marilyn vos Savant's "Ask Marilyn" column in "Parade ":
p6667
aVStandard assumptions.
p6668
aVThe behavior of the host is key to the 2/3 solution. Ambiguities in the "Parade" version do not explicitly define the protocol of the host. However Marilyn vos Savant's () solution printed alongside Whitaker's question implies and both and explicitly define the role of the host as follows:
p6669
aVWhen any of these assumptions is varied, it can change the probability of winning by switching doors as detailed in the section below. It is also typically presumed that the car is initially hidden behind a random door and that if the player initially picks the car, then the host's choice of which goat-hiding door to open is random. (Krauss and Wang, 2003:9) Some authors, independently or inclusively, assume the player's initial choice is random as well. 
p6670
aVSimple solutions.
p6671
aVThe solution presented by in "Parade" shows the three possible arrangements of one car and two goats behind three doors and the result of staying or switching after initially picking door 1 in each case:
p6672
aVA player who stays with the initial choice wins in only one out of three of these equally likely possibilities, while a player who switches wins in two out of three.
p6673
aVAn intuitive explanation is that if the contestant picks a goat (2 of 3 doors) the contestant "will" win the car by switching as the other goat can no longer be picked, while if the contestant picks the car (1 of 3 doors) the contestant "will not" win the car by switching (Carlton 2005, concluding remarks). The fact that the host subsequently reveals a goat in one of the unchosen doors changes nothing about the initial probability.
p6674
aVAnother way to understand the solution is to consider the two original unchosen doors together (Adams 1990; Devlin 2003, 2005; Williams 2004; Stibel et al., 2008). As Cecil Adams puts it (Adams 1990), "Monty is saying in effect: you can keep your one door or you can have the other two doors". The 2/3 chance of finding the car has not been changed by the opening of one of these doors because Monty, knowing the location of the car, is certain to reveal a goat. So the player's choice after the host opens a door is no different than if the host offered the player the option to switch from their original chosen door to the set of "both" remaining doors. The switch in this case clearly gives the player a 2/3 probability of choosing the car.
p6675
aVAs Keith Devlin says (Devlin 2003), "By opening his door, Monty is saying to the contestant 'There are two doors you did not choose, and the probability that the prize is behind one of them is 2/3. I'll help you by using my knowledge of where the prize is to open one of those two doors to show you that it does not hide the prize. You can now take advantage of this additional information. Your choice of door A has a chance of 1 in 3 of being the winner. I have not changed that. But by eliminating door C, I have shown you that the probability that door B hides the prize is 2 in 3.
p6676
aVVos Savant suggests that the solution will be more intuitive with 1,000,000 doors rather than 3. In this case there are 999,999 doors with goats behind them and one door with a prize. After the player picks a door the host opens all but 1 of the remaining doors. On average, in 999,999 times out of 1,000,000, the remaining door will contain the prize. Intuitively, the player should ask how likely is it, that given a million doors, he or she managed to pick the right one initially. Stibel et al. (2008) proposed working memory demand is taxed during the Monty Hall problem and that this forces people to "collapse" their choices into two equally probable options. They report that when increasing the number of options to over 7 choices (7 doors) people tend to switch more often; however most contestants still incorrectly judge the probability of success at 50/50.
p6677
aVVos Savant and the media furor.
p6678
aVVos Savant wrote in her first column on the Monty Hall problem that the player should switch . She received thousands of letters from her readers\u2014the vast majority of which, including many from readers with PhDs, disagreed with her answer. During 1990\u20131991 three more of her columns in Parade were devoted to the paradox (vos Savant 1990\u20131991), and the discussion was replayed in other venues (e.g., in Cecil Adams' "The Straight Dope" newspaper column, (Adams 1990)), and reported in major newspapers such as the New York Times .
p6679
aVIn an attempt to clarify her answer she proposed a shell game to illustrate: "You look away, and I put a pea under one of three shells. Then I ask you to put your finger on a shell. The odds that your choice contains a pea are 1/3, agreed? Then I simply lift up an empty shell from the remaining other two. As I can (and will) do this regardless of what you've chosen, we've learned nothing to allow us to revise the odds on the shell under your finger." She also proposed a similar simulation with three playing cards.
p6680
aVDespite further elaboration, many readers continued to disagree with her, but some changed their minds and agreed. Nearly 100% of those who carried out vos Savant's shell simulation changed their minds. About 56% of the general public and 71% of academics accepted the answer.
p6681
aVVos Savant commented that though some confusion was caused by "some" readers not realizing that they were supposed to assume that the host must always reveal a goat, almost all of her numerous correspondents had correctly understood the problem assumptions, and were still initially convinced that vos Savant's answer ("switch") was wrong.
p6682
aVConfusion and criticism.
p6683
aVSources of confusion.
p6684
aVWhen first presented with the Monty Hall problem an overwhelming majority of people assume that each door has an equal probability and conclude that switching does not matter (Mueser and Granberg, 1999). Out of 228 subjects in one study, only 13% chose to switch (Granberg and Brown, 1995:713). In her book "The Power of Logical Thinking", quotes cognitive psychologist Massimo Piattelli-Palmarini as saying "... no other statistical puzzle comes so close to fooling all the people all the time" and "that even Nobel physicists systematically give the wrong answer, and that they "insist" on it, and they are ready to berate in print those who propose the right answer". Pigeons repeatedly exposed to the problem show that they rapidly learn always to switch, unlike humans (Herbranson and Schroeder, 2010).
p6685
aVMost statements of the problem, notably the one in "Parade Magazine", do not match the rules of the actual game show (Krauss and Wang, 2003:9), and do not fully specify the host's behavior or that the car's location is randomly selected (Granberg and Brown, 1995:712). Krauss and Wang (2003:10) conjecture that people make the standard assumptions even if they are not explicitly stated.
p6686
aVAlthough these issues are mathematically significant, even when controlling for these factors nearly all people still think each of the two unopened doors has an equal probability and conclude switching does not matter (Mueser and Granberg, 1999). This "equal probability" assumption is a deeply rooted intuition (Falk 1992:202). People strongly tend to think probability is evenly distributed across as many unknowns as are present, whether it is or not (Fox and Levav, 2004:637). Indeed, if a player believes that sticking and switching are equally successful and therefore equally often decides to switch as to stay, they will win 50% of the time, reinforcing their original belief. Missing the unequal chances of those two doors, and in not considering that (1/3+2/3) / 2 gives a chance of 50%, similar to "the little green woman" example.
p6687
aVThe problem continues to attract the attention of cognitive psychologists. The typical behavior of the majority, i.e., not switching, may be explained by phenomena known in the psychological literature as: 1) the endowment effect (Kahneman et al., 1991); people tend to overvalue the winning probability of the already chosen \u2013 already "owned" \u2013 door; 2) the status quo bias (Samuelson and Zeckhauser, 1988); people prefer to stick with the choice of door they have already made; 3) the errors of omission vs. errors of commission effect (Gilovich et al., 1995); all else considered equal, people prefer that any errors that they are responsible for to have occurred through 'omission' of taking action rather than through having taken an explicit action that later becomes known to have been erroneous. Experimental evidence confirms that these are plausible explanations which do not depend on probability intuition (Kaivanto et al., 2014; Morone and Fiore, 2007).
p6688
aVSolutions using conditional probability and other solutions.
p6689
aVThe simple solutions above show that a player with a strategy of switching wins the car with overall probability 2/3, i.e., without taking account of which door was opened by the host (Grinstead and Snell 2006:137\u2013138 Carlton 2005). In contrast most sources in the field of probability calculate the conditional probabilities that the car is behind door 1 and door 2 are 1/3 and 2/3 given the contestant initially picks door 1 and the host opens door 3 (, Morgan et al. 1991, Chun 1991, Gillman 1992, Carlton 2005, Grinstead and Snell 2006:137\u2013138, Lucas et al. 2009). The solutions in this section consider just those cases in which the player picked door 1 and the host opened door 3.
p6690
aVRefining the simple solution.
p6691
aVIf we assume the host opens a door at random, when given a choice, then which door the host opens gives us no information at all as to whether or not the car is behind door 1. In the simple solutions, we already observed that the probability that the car is behind door 1, the door initially chosen by the player, is initially 1/3. Moreover, the host is certainly going to open "a" (different) door, so opening "a" door ("which" door unspecified) does not change this. 1/3 must be the average probability that the car is behind door 1 given the host picked door 2 and given the host picked door 3 because these are the only two possibilities. But these two probabilities are the same. Therefore they are both equal to 1/3 (Morgan et al. 1991). This shows that the chance that the car is behind door 1 given that the player initially chose this door and given that the host opened door 3 is 1/3, and it follows that the chance that the car is behind door 2 given the player initially chose door 1 and the host opened door 3 is 2/3. The analysis also shows that the overall success rate of 2/3, achieved by "always switching", cannot be improved, and underlines what already may well have been intuitively obvious: the choice facing the player is that between the door initially chosen, and the other door left closed by the host, the specific numbers on these doors are irrelevant.
p6692
aVConditional probability by direct calculation.
p6693
aVBy definition, the conditional probability of winning by switching given the contestant initially picks door 1 and the host opens door 3 is the probability for the event "car is behind door 2 and host opens door 3" divided by the probability for "host opens door 3". These probabilities can be determined referring to the conditional probability table below, or to an equivalent decision tree as shown to the right (Chun 1991; Carlton 2005; Grinstead and Snell 2006:137\u2013138). The conditional probability of winning by switching is (1/3)/(1/3 + 1/6), which is 2/3 .
p6694
aVThe conditional probability table below shows how 300 cases, in all of which the player initially chooses door 1, would be split up, on average, according to the location of the car and the choice of door to open by the host.
p6695
aVBayes' theorem.
p6696
aVMany probability text books and articles in the field of probability theory derive the conditional probability solution through a formal application of Bayes' theorem; among them Gill, 2002 and Henze, 1997. Use of the odds form of Bayes' theorem, often called Bayes' rule, makes such a derivation more transparent (Rosenthal, 2005a), (Rosenthal, 2005b).
p6697
aVInitially, the car is equally likely behind any of the three doors: the odds on door 1, door 2, and door 3 are 1:1:1. This remains the case after the player has chosen door 1, by independence. According to Bayes' rule, the posterior odds on the location of the car, given the host opens door 3, are equal to the prior odds multiplied by the Bayes factor or likelihood, which is by definition the probability of the new piece of information (host opens door 3) under each of the hypotheses considered (location of the car). Now, since the player initially chose door 1, the chance the host opens door 3 is 50% if the car is behind door 1, 100% if the car is behind door 2, 0% if the car is behind door 3. Thus the Bayes factor consists of the ratios 1/2 : 1 : 0 or equivalently 1 : 2 : 0, while the prior odds were 1 : 1 : 1. Thus the posterior odds become equal to the Bayes factor 1 : 2 : 0. Given the host opened door 3, the probability the car is behind door 3 is zero, and it is twice as likely to be behind door 2 than door 1.
p6698
aVRichard Gill (2011) analyzes the likelihood for the host to open door 3 as follows. Given the car is "not" behind door 1, it is equally likely that it is behind door 2 or 3. Therefore, the chance that the host opens door 3 is 50%. Given the car "is" behind door 1 the chance that the host opens door 3 is also 50%, because when the host has a choice, either choice is equally likely. Therefore, whether or not the car is behind door 1, the chance the host opens door 3 is 50%. The information "host opens door 3" contributes a Bayes factor or likelihood ratio of 1 : 1, on whether or not the car is behind door 1. Initially, the odds against door 1 hiding the car were 2 : 1. Therefore the posterior odds against door 1 hiding the car remain the same as the prior odds, 2 : 1.
p6699
aVIn words, the information "which" door is opened by the host (door 2 or door 3?) reveals no information at all about whether or not the car is behind door 1, and this is precisely what is alleged to be intuitively obvious by supporters of simple solutions, or using the idioms of mathematical proofs, "obviously true, by symmetry" (Bell 1992).
p6700
aVDirect calculation.
p6701
aVConsider the events "C1", "C2" and "C3" indicating the car is behind respectively door 1,2 or 3. All these 3 events have probability 1/3.
p6702
aVThe player picking door 1 is described by the event "X1". As the first choice of the player is independent of the position of the car, also the conditional probabilities are "P"("Ci"|"X1")=1/3. 
p6703
aVThe host opening door 3 is described by "H3". For this event it holds:
p6704
aVformula_1
p6705
aVformula_2
p6706
aVformula_3
p6707
aVThen, if the player initially selects door 1, and the host opens door 3, the conditional probability of winning by switching is
p6708
aVformula_4
p6709
aV:::::formula_5
p6710
aV:::::formula_6
p6711
aVStrategic dominance solution.
p6712
aVGoing back to Nalebuff (1987), the Monty Hall problem is also much studied in the literature on game theory and decision theory, and also some popular solutions correspond to this point of view. Vos Savant asks for a decision, not a chance. And the chance aspects of how the car is hidden and how an unchosen door is opened are unknown. From this point of view, one has to remember that the player has two opportunities to make choices: first of all, which door to choose initially; and secondly, whether or not to switch. Since he does not know how the car is hidden nor how the host makes choices, he may be able to make use of his first choice opportunity, as it were to neutralize the actions of the team running the quiz show, including the host.
p6713
aVFollowing Gill, 2011 a "strategy" of contestant involves two actions: the initial choice of a door and the decision to switch (or to stick) which may depend on both the door initially chosen and the door to which the host offers switching. For instance, one contestant's strategy is "choose door 1, then switch to door 2 when offered, and do not switch to door 3 when offered". Twelve such deterministic strategies of the contestant exist.
p6714
aVElementary comparison of contestant's strategies shows that for every strategy A there is another strategy B "pick a door then switch no matter what happens" which dominates it (Gnedin, 2011). No matter how the car is hidden and no matter which rule the host uses when he has a choice between two goats, if A wins the car then B also does. For example, strategy A "pick door 1 then always stick with it" is dominated by the strategy B "pick door 2 then always switch after the host reveals a door": A wins when door 1 conceals the car, while B wins when one of the doors 1 and 3 conceals the car.
p6715
aVSimilarly, strategy A "pick door 1 then switch to door 2 (if offered), but do not switch to door 3 (if offered)" is dominated by strategy B "pick door 3 then always switch".
p6716
aVDominance is a strong reason to seek for a solution among always-switching strategies, under fairly general assumptions on the environment in which the contestant is making decisions. In particular, if the car is hidden by means of some randomization device \u2013 like tossing symmetric or asymmetric three-sided die \u2013 the dominance implies that a strategy maximizing the probability of winning the car will be among three always-switching strategies, namely it will be the strategy which initially picks the least likely door then switches no matter which door to switch is offered by the host.
p6717
aVStrategic dominance links the Monty Hall problem to the game theory. In the zero-sum game setting of Gill, 2011, discarding the non-switching strategies reduces the game to the following simple variant: the host (or the TV-team) decides on the door to hide the car, and the contestant chooses two doors (i.e., the two doors remaining after the player's first, nominal, choice). The contestant wins (and her opponent loses) if the car is behind one of the two doors she chose.
p6718
aVSolutions by simulation.
p6719
aVA simple way to demonstrate that a switching strategy really does win two out of three times with the standard assumptions is to simulate the game with playing cards (Gardner 1959b; ). Three cards from an ordinary deck are used to represent the three doors; one 'special' card represents the door with the car and two other cards represent the goat doors.
p6720
aVThe simulation can be repeated several times to simulate multiple rounds of the game. The player picks one of the three cards, then, looking at the remaining two cards the 'host' discards a goat card. If the card remaining in the host's hand is the car card, this is recorded as a switching win; if the host is holding a goat card, the round is recorded as a staying win. As this experiment is repeated over several rounds, the observed win rate for each strategy is likely to approximate its theoretical win probability.
p6721
aVRepeated plays also make it clearer why switching is the better strategy. After the player picks his card, it is "already determined" whether switching will win the round for the player. If this is not convincing, the simulation can be done with the entire deck. (Gardner 1959b; Adams 1990). In this variant the car card goes to the host 51 times out of 52, and stays with the host no matter how many "non"-car cards are discarded.
p6722
aVCriticism of the simple solutions.
p6723
aVAs already remarked, most sources in the field of probability, including many introductory probability textbooks, solve the problem by showing the conditional probabilities the car is behind door 1 and door 2 are 1/3 and 2/3 (not 1/2 and 1/2) given the contestant initially picks door 1 and the host opens door 3; various ways to derive and understand this result were given in the previous subsections.
p6724
aVAmong these sources are several that explicitly criticize the popularly presented "simple" solutions, saying these solutions are "correct but ... shaky" (Rosenthal 2005a), or do not "address the problem posed" (Gillman 1992), or are "incomplete" (Lucas et al. 2009), or are "unconvincing and misleading" (Eisenhauer 2001) or are (most bluntly) "false" (Morgan et al. 1991).
p6725
aVSome say that these solutions answer a slightly different question \u2013 one phrasing is "you have to announce "before a door has been opened" whether you plan to switch" (Gillman 1992, emphasis in the original).
p6726
aVThe simple solutions show in various ways that a contestant who is determined to switch will win the car with probability 2/3, and hence that switching is the winning strategy, if the player has to choose in advance between "always switching", and "always staying". However, the probability of winning by "always" switching is a logically distinct concept from the probability of winning by switching "given the player has picked door 1 and the host has opened door 3". As one source says, "the distinction between questions seems to confound many" (Morgan et al. 1991). This fact that these are different can be shown by varying the problem so that these two probabilities have different numeric values. For example, assume the contestant knows that Monty does not pick the second door randomly among all legal alternatives but instead, when given an opportunity to pick between two losing doors, Monty will open the one on the right. In this situation the following two questions have different answers:
p6727
aVThe answer to the first question is 2/3, as is correctly shown by the "simple" solutions. But the answer to the second question is now different: the conditional probability the car is behind door 1 or door 2 given the host has opened door 3 (the door on the right) is 1/2. This is because Monty's preference for rightmost doors means he opens door 3 if the car is behind door 1 (which it is originally with probability 1/3) or if the car is behind door 2 (also originally with probability 1/3). For this variation, the two questions yield different answers. However as long as the initial probability the car is behind each door is 1/3, it is never to the contestant's disadvantage to switch, as the conditional probability of winning by switching is always at least 1/2. (Morgan et al. 1991)
p6728
aVFour university professors published an article (Morgan et al., 1991) in "The American Statistician" claiming vos Savant gave the correct advice but the wrong argument. They believed the question asked for the chance of the car behind door 2 "given" the player's initial pick for door 1 and the opened door 3, and they showed this chance was anything between 1/2 and 1 depending on the host's decision process given the choice. Only when the decision is completely randomized is the chance 2/3.
p6729
aVIn an invited comment (Seymann, 1991) and in subsequent letters to the editor, (vos Savant, 1991c; Rao, 1992; Bell, 1992; Hogbin and Nijdam, 2010) Morgan et al. were supported by some writers, criticized by others; in each case a response by Morgan et al. is published alongside the letter or comment in "The American Statistician". In particular, vos Savant defended herself vigorously. Morgan et al. complained in their response to vos Savant (1991c) that vos Savant still had not actually responded to their own main point. Later in their response to Hogbin and Nijdam (2011) they did agree that it was natural to suppose that the host chooses a door to open completely at random, when he does have a choice, and hence that the conditional probability of winning by switching (i.e., conditional given the situation the player is in when he has to make his choice) has the same value, 2/3, as the unconditional probability of winning by switching (i.e., averaged over all possible situations). This equality was already emphasized by Bell (1992) who suggested that Morgan et al.'s mathematically involved solution would only appeal to statisticians, whereas the equivalence of the conditional and unconditional solutions in the case of symmetry was intuitively obvious.
p6730
aVThere is disagreement in the literature regarding whether vos Savant's formulation of the problem, as presented in "Parade" magazine, is asking the first or second question, and whether this difference is significant (Rosenhouse 2009). Behrends (2008) concludes that "One must consider the matter with care to see that both analyses are correct"; which is not to say that they are the same. One analysis for one question, another analysis for the other question. Several discussants of the paper by (Morgan et al. 1991), whose contributions were published alongside the original paper, strongly criticized the authors for altering vos Savant's wording and misinterpreting her intention (Rosenhouse 2009). One discussant (William Bell) considered it a matter of taste whether or not one explicitly mentions that (under the standard conditions), "which" door is opened by the host is independent of whether or not one should want to switch.
p6731
aVAmong the simple solutions, the "combined doors solution" comes closest to a conditional solution, as we saw in the discussion of approaches using the concept of odds and Bayes theorem. It is based on the deeply rooted intuition that "revealing information that is already known does not affect probabilities". But knowing the host can open one of the two unchosen doors to show a goat does not mean that opening a specific door would not affect the probability that the car is behind the initially chosen door. The point is, though we know in advance that the host will open a door and reveal a goat, we do not know "which" door he will open. If the host chooses uniformly at random between doors hiding a goat (as is the case in the standard interpretation) this probability indeed remains unchanged, but if the host can choose non-randomly between such doors then the specific door that the host opens reveals additional information. The host can always open a door revealing a goat "and" (in the standard interpretation of the problem) the probability that the car is behind the initially chosen door does not change, but it is "not because" of the former that the latter is true. Solutions based on the assertion that the host's actions cannot affect the probability that the car is behind the initially chosen appear persuasive, but the assertion is simply untrue unless each of the host's two choices are equally likely, if he has a choice (Falk 1992:207,213). The assertion therefore needs to be justified; without justification being given, the solution is at best incomplete. The answer can be correct but the reasoning used to justify it is defective.
p6732
aVSome of the confusion in the literature undoubtedly arises because the writers are using different concepts of probability, in particular, Bayesian versus frequentist probability. For the Bayesian, probability represents knowledge. For us and for the player, the car is initially equally likely to be behind each of the three doors because we know absolutely nothing about how the organizers of the show decided where to place it. For us and for the player, the host is equally likely to make either choice (when he has one) because we know absolutely nothing about how he makes his choice. These "equally likely" probability assignments are determined by symmetries in the problem. The same symmetry can be used to argue in advance that specific door numbers are irrelevant, as we saw above.
p6733
aVVariants.
p6734
aVA common variant of the problem, assumed by several academic authors as the canonical problem, does not make the simplifying assumption that the host must uniformly choose the door to open, but instead that he uses some other strategy. The confusion as to which formalization is authoritative has led to considerable acrimony, particularly because this variant makes proofs more involved without altering the optimality of the always-switch strategy for the player. In this variant, the player can have different probabilities of winning depending on the observed choice of the host, but in any case the probability of winning by switching is at least 1/2 (and can be as high as 1), while the overall probability of winning by switching is still exactly 2/3. The variants are sometimes presented in succession in textbooks and articles intended to teach the basics of probability theory and game theory. A considerable number of other generalizations have also been studied.
p6735
aVOther host behaviors.
p6736
aVThe version of the Monty Hall problem published in "Parade" in 1990 did not specifically state that the host would always open another door, or always offer a choice to switch, or even never open the door revealing the car. However, vos Savant made it clear in her second follow-up column that the intended host's behavior could only be what led to the 2/3 probability she gave as her original answer. "Anything else is a different question". "Virtually all of my critics understood the intended scenario. I personally read nearly three thousand letters (out of the many additional thousands that arrived) and found nearly every one insisting simply that because two options remained (or an equivalent error), the chances were even. Very few raised questions about ambiguity, and the letters actually published in the column were not among those few." The answer follows if the car is placed randomly behind any door, the host must open a door revealing a goat regardless of the player's initial choice and, if two doors are available, chooses which one to open randomly (Mueser and Granberg, 1999). The table below shows a variety of "other" possible host behaviors and the impact on the success of switching.
p6737
aVDetermining the player's best strategy within a given set of other rules the host must follow is the type of problem studied in game theory. For example, if the host is not required to make the offer to switch the player may suspect the host is malicious and makes the offers more often if the player has initially selected the car. In general, the answer to this sort of question depends on the specific assumptions made about the host's behavior, and might range from "ignore the host completely" to "toss a coin and switch if it comes up heads"; see the last row of the table below.
p6738
aVMorgan et al. (1991) and Gillman (1992) both show a more general solution where the car is (uniformly) randomly placed but the host is not constrained to pick uniformly randomly if the player has initially selected the car, which is how they both interpret the statement of the problem in "Parade" despite the author's disclaimers. Both changed the wording of the "Parade" version to emphasize that point when they restated the problem. They consider a scenario where the host chooses between revealing two goats with a preference expressed as a probability "q", having a value between 0 and 1. If the host picks randomly "q" would be 1/2 and switching wins with probability 2/3 regardless of which door the host opens. If the player picks door 1 and the host's preference for door 3 is "q", then the probability the host opens door 3 and the car is behind door 2 is 1/3 while the probability the host opens door 3 and the car is behind door 1 is (1/3)"q". These are the only cases where the host opens door 3, so the conditional probability of winning by switching "given the host opens door 3" is (1/3)/(1/3 + (1/3)"q") which simplifies to 1/(1+"q"). Since "q" can vary between 0 and 1 this conditional probability can vary between 1/2 and 1. This means even without constraining the host to pick randomly if the player initially selects the car, the player is never worse off switching. However neither source suggests the player knows what the value of "q" is so the player cannot attribute a probability other than the 2/3 that vos Savant assumed was implicit.
p6739
aV"N"-doors.
p6740
aVD. L. Ferguson (1975 in a letter to Selvin cited in ) suggests an "N"-door generalization of the original problem in which the host opens "p" losing doors and then offers the player the opportunity to switch; in this variant switching wins with probability ("N"\u22121)/["N"("N"\u2212"p"\u22121)]. If the host opens even a single door, the player is better off switching, but, if the host opens only one door, the advantage approaches zero as "N" grows large (Granberg 1996:188). At the other extreme, if the host opens all but one losing door the advantage increases as "N" grows large (the probability of winning by switching approaches 1 as "N" grows very large).
p6741
aVQuantum version.
p6742
aVA quantum version of the paradox illustrates some points about the relation between classical or non-quantum information and quantum information, as encoded in the states of quantum mechanical systems. The formulation is loosely based on quantum game theory. The three doors are replaced by a quantum system allowing three alternatives; opening a door and looking behind it is translated as making a particular measurement. The rules can be stated in this language, and once again the choice for the player is to stick with the initial choice, or change to another "orthogonal" option. The latter strategy turns out to double the chances, just as in the classical case. However, if the show host has not randomized the position of the prize in a fully quantum mechanical way, the player can do even better, and can sometimes even win the prize with certainty (Flitney and Abbott 2002, D'Ariano et al. 2002).
p6743
aVHistory.
p6744
aVThe earliest of several probability puzzles related to the Monty Hall problem is Bertrand's box paradox, posed by Joseph Bertrand in 1889 in his "Calcul des probabilités" (Barbeau 1993). In this puzzle there are three boxes: a box containing two gold coins, a box with two silver coins, and a box with one of each. After choosing a box at random and withdrawing one coin at random that happens to be a gold coin, the question is what is the probability that the other coin is gold. As in the Monty Hall problem the intuitive answer is 1/2, but the probability is actually 2/3.
p6745
aVThe Three Prisoners problem, published in Martin Gardner's "Mathematical Games" column in "Scientific American" in 1959 (1959a, 1959b), is equivalent to the Monty Hall problem. This problem involves three condemned prisoners, a random one of whom has been secretly chosen to be pardoned. One of the prisoners begs the warden to tell him the name of one of the others to be executed, arguing that this reveals no information about his own fate but increases his chances of being pardoned from 1/3 to 1/2. The warden obliges, (secretly) flipping a coin to decide which name to provide if the prisoner who is asking is the one being pardoned. The question is whether knowing the warden's answer changes the prisoner's chances of being pardoned. This problem is equivalent to the Monty Hall problem; the prisoner asking the question still has a 1/3 chance of being pardoned but his unnamed colleague has a 2/3 chance.
p6746
aVSteve Selvin posed the Monty Hall problem in a pair of letters to the "American Statistician" in 1975 , . The first letter presented the problem in a version close to its presentation in "Parade" 15 years later. The second appears to be the first use of the term "Monty Hall problem". The problem is actually an extrapolation from the game show. Monty Hall "did" open a wrong door to build excitement, but offered a known lesser prize \u2013 such as $100 cash \u2013 rather than a choice to switch doors. As Monty Hall wrote to Selvin:
p6747
aVA version of the problem very similar to the one that appeared three years later in "Parade" was published in 1987 in the Puzzles section of "The Journal of Economic Perspectives" (Nalebuff 1987). Nalebuff, as later writers in mathematical economics, sees the problem as a simple and amusing exercise in game theory.
p6748
aVPhillip Martin's article in a 1989 issue of "Bridge Today" magazine titled "The Monty Hall Trap" (Martin 1989) presented Selvin's problem as an example of what Martin calls the probability trap of treating non-random information as if it were random, and relates this to concepts in the game of bridge.
p6749
aVA restated version of Selvin's problem appeared in Marilyn vos Savant's "Ask Marilyn" question-and-answer column of "Parade" in September 1990. Though vos Savant gave the correct answer that switching would win two-thirds of the time, she estimates the magazine received 10,000 letters including close to 1,000 signed by PhDs, many on letterheads of mathematics and science departments, declaring that her solution was wrong. Due to the overwhelming response, "Parade" published an unprecedented four columns on the problem. As a result of the publicity the problem earned the alternative name Marilyn and the Goats.
p6750
aVIn November 1990, an equally contentious discussion of vos Savant's article took place in Cecil Adams's column "The Straight Dope" (Adams 1990). Adams initially answered, incorrectly, that the chances for the two remaining doors must each be one in two. After a reader wrote in to correct the mathematics of Adams's analysis, Adams agreed that mathematically, he had been wrong, but said that the "Parade" version left critical constraints unstated, and without those constraints, the chances of winning by switching were not necessarily 2/3. Numerous readers, however, wrote in to claim that Adams had been "right the first time" and that the correct chances were one in two.
p6751
aVThe "Parade" column and its response received considerable attention in the press, including a front page story in the "New York Times" in which Monty Hall himself was interviewed. Hall appeared to understand the problem, giving the reporter a demonstration with car keys and explaining how actual game play on "Let's Make a Deal" differed from the rules of the puzzle.
p6752
aVThe Monty Hall problem is a plot element in the 2012 novel Sweet Tooth by Ian McEwan.
p6753
asS'Eye of Horus'
p6754
(lp6755
VThe Eye of Horus is an ancient Egyptian symbol of protection, royal power and good health. The eye is personified in the goddess "Wadjet" (also written as "Wedjat", or ""Udjat"", "Uadjet", "Wedjoyet", "Edjo" or "Uto"). It is also known as "The Eye of Ra". 
p6756
aVThe name Wadjet is derived from "wadj" meaning "green", hence "the green one", and was known to the Greeks and Romans as "uraeus" from the Egyptian "iaret" meaning "risen one" from the image of a cobra rising up in protection. Wadjet was one of the earliest of Egyptian deities who later became associated with other goddesses such as Bast, Sekhmet, Mut, and Hathor. She was the tutelary deity of Lower Egypt and the major Delta shrine the "per-nu" was under her protection. Hathor is also depicted with this eye. 
p6757
aVFunerary amulets were often made in the shape of the Eye of Horus. The Wadjet or Eye of Horus is "the central element" of seven "gold, faience, carnelian and lapis lazuli" bracelets found on the mummy of Shoshenq II. The Wedjat "was intended to protect the pharaoh in the afterlife" and to ward off evil. Ancient Egyptian and Near Eastern sailors would frequently paint the symbol on the bow of their vessel to ensure safe sea travel.
p6758
aVHorus.
p6759
aVHorus was the ancient Egyptian sky god who was usually depicted as a falcon, most likely a lanner or peregrine falcon. His right eye was associated with the sun god, Ra. The eye symbol represents the marking around the eye of the falcon, including the "teardrop" marking sometimes found below the eye. The mirror image, or left eye, sometimes represented the moon and the god Djehuti (Thoth).
p6760
aVIn one myth, when Set and Horus were fighting for the throne after Osiris's death, Set gouged out Horus's left eye. The majority of the eye was restored by either Hathor or Thoth (with the last portion possibly being supplied magically). When Horus's eye was recovered, he offered it to his father, Osiris, in hopes of restoring his life. Hence, the eye of Horus was often used to symbolise sacrifice, healing, restoration, and protection.
p6761
aVAs hieroglyph and symbol.
p6762
aVThere are seven different hieroglyphs used to represent the eye, most commonly "ir.t" in Egyptian, which also has the meaning "to make or do" or "one who does". In Egyptian myth the eye was not the passive organ of sight but more an agent of action, protection or wrath.
p6763
aVThe Eye of Horus was represented as a hieroglyph, designated D10 in Gardiner's sign list. It is represented in the Unicode character block for Egyptian hieroglyphs as U+13080 ().
p6764
aVMathematics.
p6765
aVIn Ancient Egyptian most fractions were written as the sum of two or more unit fractions (a fraction with 1 as the numerator), with scribes possessing tables of answers (see Rhind Mathematical Papyrus 2/n table). Thus instead of 3/4, one would write 1/2 + 1/4.
p6766
aVDifferent parts of the Eye of Horus were thought to be used by the ancient Egyptians to represent one divided by the first six powers of two:
p6767
aV The right side of the eye = 1/2
p6768
aV The pupil = 1/4
p6769
aV The eyebrow = 1/8
p6770
aV The left side of the eye = 1/16
p6771
aV The curved tail = 1/32
p6772
aV The teardrop = 1/64
p6773
aVThe Rhind Mathematical Papyrus contains tables of 'Horus Eye Fractions'.
p6774
aVStudies from the 1970s to this day in Egyptian mathematics have clearly shown this theory was fallacious and Jim Ritter definitely showed it to be false in 2003. The evolution of the symbols used in mathematics, although similar to the different parts of the Eye of Horus, is now known to be distinct.
p6775
asS'Pseudovector'
p6776
(lp6777
VIn physics and mathematics, a pseudovector (or axial vector) is a quantity that transforms like a vector under a proper rotation, but in three dimensions gains an additional sign flip under an improper rotation such as a reflection. Geometrically it is the opposite, of equal magnitude but in the opposite direction, of its mirror image. This is as opposed to a "true" or "polar" vector, which on reflection matches its mirror image.
p6778
aVIn three dimensions the pseudovector p is associated with the cross product of two polar vectors a and b:
p6779
aVformula_1
p6780
aVThe vector p calculated this way is a pseudovector. One example is the normal to an oriented plane. An oriented plane can be defined by two non-parallel vectors, a and b, which can be said to span the plane. The vector is a normal to the plane (there are two normals, one on each side \u2013 the right-hand rule will determine which), and is a pseudovector. This has consequences in computer graphics where it has to be considered when transforming surface normals.
p6781
aVA number of quantities in physics behave as pseudovectors rather than polar vectors, including magnetic field and angular velocity. In mathematics pseudovectors are equivalent to three-dimensional bivectors, from which the transformation rules of pseudovectors can be derived. More generally in "n"-dimensional geometric algebra pseudovectors are the elements of the algebra with dimension , written \u039b"n"\u22121R"n". The label 'pseudo' can be further generalized to pseudoscalars and pseudotensors, both of which gain an extra sign flip under improper rotations compared to a true scalar or tensor.
p6782
aVPhysical examples.
p6783
aVPhysical examples of pseudovectors include magnetic field, torque, vorticity, and the angular momentum.
p6784
aVConsider the pseudovector angular momentum . Driving in a car, and looking forward, each of the wheels has an angular momentum vector pointing to the left. If the world is reflected in a mirror which switches the left and right side of the car, the "reflection" of this angular momentum "vector" (viewed as an ordinary vector) points to the right, but the "actual" angular momentum vector of the wheel (which is still turning forward in the reflection) still points to the left, corresponding to the extra minus sign in the reflection of a pseudovector.
p6785
aVThe distinction between vectors and pseudovectors becomes important in understanding the effect of symmetry on the solution to physical systems. Consider an electrical current loop in the plane that inside the loop generates a magnetic field oriented in the "z" direction. This system is symmetric (invariant) under mirror reflections through this plane, with the magnetic field unchanged by the reflection. But reflecting the magnetic field as a vector through that plane would be expected to reverse it; this expectation is corrected by realizing that the magnetic field is a pseudovector, with the extra sign flip leaving it unchanged.
p6786
aVDetails.
p6787
aVThe definition of a "vector" in physics (including both polar vectors and pseudovectors) is more specific than the mathematical definition of "vector" (namely, any element of an abstract vector space). Under the physics definition, a "vector" is required to have components that "transform" in a certain way under a proper rotation: In particular, if everything in the universe were rotated, the vector would rotate in exactly the same way. (The coordinate system is fixed in this discussion; in other words this is the perspective of active transformations.) Mathematically, if everything in the universe undergoes a rotation described by a rotation matrix "R", so that a displacement vector x is transformed to , then any "vector" v must be similarly transformed to . This important requirement is what distinguishes a "vector" (which might be composed of, for example, the "x"-, "y"-, and "z"-components of velocity) from any other triplet of physical quantities (For example, the length, width, and height of a rectangular box "cannot" be considered the three components of a vector, since rotating the box does not appropriately transform these three components.)
p6788
aVThe discussion so far only relates to proper rotations, i.e. rotations about an axis. However, one can also consider improper rotations, i.e. a mirror-reflection possibly followed by a proper rotation. (One example of an improper rotation is inversion.) Suppose everything in the universe undergoes an improper rotation described by the rotation matrix "R", so that a position vector x is transformed to . If the vector v is a polar vector, it will be transformed to . If it is a pseudovector, it will be transformed to .
p6789
aVThe transformation rules for polar vectors and pseudovectors can be compactly stated as
p6790
aVformula_2 (polar vector)
p6791
aVformula_3 (pseudovector)
p6792
aVwhere the symbols are as described above, and the rotation matrix "R" can be either proper or improper. The symbol det denotes determinant; this formula works because the determinant of proper and improper rotation matrices are +1 and -1, respectively.
p6793
aVBehavior under addition, subtraction, scalar multiplication.
p6794
aVSuppose v1 and v2 are known pseudovectors, and v3 is defined to be their sum, . If the universe is transformed by a rotation matrix "R", then v3 is transformed to
p6795
aVformula_4
p6796
aVSo v3 is also a pseudovector. Similarly one can show that the difference between two pseudovectors is a pseudovector, that the sum or difference of two polar vectors is a polar vector, that multiplying a polar vector by any real number yields another polar vector, and that multiplying a pseudovector by any real number yields another pseudovector.
p6797
aVOn the other hand, suppose v1 is known to be a polar vector, v2 is known to be a pseudovector, and v3 is defined to be their sum, . If the universe is transformed by a rotation matrix "R", then v3 is transformed to
p6798
aVformula_5
p6799
aVTherefore, v3 is neither a polar vector nor a pseudovector. For an improper rotation, v3 does not in general even keep the same magnitude:
p6800
aVformula_6 but formula_7.
p6801
aVIf the magnitude of v3 were to describe a measurable physical quantity, that would mean that the laws of physics would not appear the same if the universe was viewed in a mirror. In fact, this is exactly what happens in the weak interaction: Certain radioactive decays treat "left" and "right" differently, a phenomenon which can be traced to the summation of a polar vector with a pseudovector in the underlying theory. (See parity violation.)
p6802
aVBehavior under cross products.
p6803
aV[product onder inversie.svg|thumb|Under inversion the two vectors change sign, but their cross product is invariant [black are the two original vectors, grey are the inverted vectors, and red is their mutual cross product.]]
p6804
aVFor a rotation matrix "R", either proper or improper, the following mathematical equation is always true:
p6805
aVformula_8,
p6806
aVwhere v1 and v2 are any three-dimensional vectors. (This equation can be proven either through a geometric argument or through an algebraic calculation.)
p6807
aVSuppose v1 and v2 are known polar vectors, and v3 is defined to be their cross product, . If the universe is transformed by a rotation matrix "R", then v3 is transformed to
p6808
aVformula_9
p6809
aVSo v3 is a pseudovector. Similarly, one can show:
p6810
aVExamples.
p6811
aVFrom the definition, it is clear that a displacement vector is a polar vector. The velocity vector is a displacement vector (a polar vector) divided by time (a scalar), so is also a polar vector. Likewise, the momentum vector is the velocity vector (a polar vector) times mass (a scalar), so is a polar vector. Angular momentum is the cross product of a displacement (a polar vector) and momentum (a polar vector), and is therefore a pseudovector. Continuing this way, it is straightforward to classify any vector as either a pseudovector or polar vector.
p6812
aVThe right-hand rule.
p6813
aVAbove, pseudovectors have been discussed using active transformations. An alternate approach, more along the lines of passive transformations, is to keep the universe fixed, but switch "right-hand rule" with "left-hand rule" everywhere in math and physics, including in the definition of the cross product. Any polar vector (e.g., a translation vector) would be unchanged, but pseudovectors (e.g., the magnetic field vector at a point) would switch signs. Nevertheless, there would be no physical consequences, apart from in the parity-violating phenomena such as certain radioactive decays.
p6814
aVFormalization.
p6815
aVOne way to formalize pseudovectors is as follows: if "V" is an "n"-dimensional vector space, then a "pseudovector" of "V" is an element of the ("n"\u22121)-st exterior power of "V": \u039b"n"\u22121("V"). The pseudovectors of "V" form a vector space with the same dimension as "V".
p6816
aVThis definition is not equivalent to that requiring a sign flip under improper rotations, but it is general to all vector spaces. In particular, when "n" is even, such a pseudovector does not experience a sign flip, and when the characteristic of the underlying field of "V" is 2, a sign flip has no effect. Otherwise, the definitions coincide, though it should be borne in mind that without additional structure (specifically, a volume form), there is no natural identification of \u039b"n"\u22121("V") with "V".
p6817
aVGeometric algebra.
p6818
aVIn geometric algebra the basic elements are vectors, and these are used to build a hierarchy of elements using the definitions of products in this algebra. In particular, the algebra builds pseudovectors from vectors.
p6819
aVThe basic multiplication in the geometric algebra is the geometric product, denoted by simply juxtaposing two vectors as in ab. This product is expressed as:
p6820
aVformula_10
p6821
aVwhere the leading term is the customary vector dot product and the second term is called the wedge product. Using the postulates of the algebra, all combinations of dot and wedge products can be evaluated. A terminology to describe the various combinations is provided. For example, a multivector is a summation of "k"-fold wedge products of various "k"-values. A "k"-fold wedge product also is referred to as a "k"-blade.
p6822
aVIn the present context the "pseudovector" is one of these combinations. This term is attached to a different multivector depending upon the dimensions of the space (that is, the number of linearly independent vectors in the space). In three dimensions, the most general 2-blade or bivector can be expressed as the wedge product of two vectors and is a pseudovector. In four dimensions, however, the pseudovectors are trivectors. In general, it is a -blade, where "n" is the dimension of the space and algebra. An "n"-dimensional space has "n" basis vectors and also "n" basis pseudovectors. Each basis pseudovector is formed from the outer (wedge) product of all but one of the "n" basis vectors. For instance, in four dimensions where the basis vectors are taken to be {e1, e2, e3, e4}, the pseudovectors can be written as: {e234, e134, e124, e123}.
p6823
aVTransformations in three dimensions.
p6824
aVThe transformation properties of the pseudovector in three dimensions has been compared to that of the vector cross product by Baylis. He says: "The terms "axial vector" and "pseudovector" are often treated as synonymous, but it is quite useful to be able to distinguish a bivector from its dual." To paraphrase Baylis: Given two polar vectors (that is, true vectors) a and b in three dimensions, the cross product composed from a and b is the vector normal to their plane given by . Given a set of right-handed orthonormal basis vectors , the cross product is expressed in terms of its components as:
p6825
aVformula_11
p6826
aVwhere superscripts label vector components. On the other hand, the plane of the two vectors is represented by the exterior product or wedge product, denoted by . In this context of geometric algebra, this bivector is called a pseudovector, and is the "dual" of the cross product. The "dual" of e1 is introduced as e23 \u2261 e2e3 = , and so forth. That is, the dual of e1 is the subspace perpendicular to e1, namely the subspace spanned by e2 and e3. With this understanding,
p6827
aVformula_12
p6828
aVFor details see Hodge dual. Comparison shows that the cross product and wedge product are related by:
p6829
aVformula_13
p6830
aVwhere "i" = is called the "unit pseudoscalar". It has the property:
p6831
aVformula_14
p6832
aVUsing the above relations, it is seen that if the vectors a and b are inverted by changing the signs of their components while leaving the basis vectors fixed, both the pseudovector and the cross product are invariant. On the other hand, if the components are fixed and the basis vectors e\u2113 are inverted, then the pseudovector is invariant, but the cross product changes sign. This behavior of cross products is consistent with their definition as vector-like elements that change sign under transformation from a right-handed to a left-handed coordinate system, unlike polar vectors.
p6833
aVNote on usage.
p6834
aVAs an aside, it may be noted that not all authors in the field of geometric algebra use the term pseudovector, and some authors follow the terminology that does not distinguish between the pseudovector and the cross product. However, because the cross product does not generalize beyond three dimensions, the notion of pseudovector based upon the cross product also cannot be extended to higher dimensions. The pseudovector as the -blade of an "n"-dimensional space is not so restricted.
p6835
aVAnother important note is that pseudovectors, despite their name, are "vectors" in the common mathematical sense, i.e. elements of a vector space. The idea that "a pseudovector is different from a vector" is only true with a different and more specific definition of the term "vector" as discussed above.
p6836
asS'Surface area to volume ratio'
p6837
(lp6838
sS'Reed-Solomon error correction'
p6839
(lp6840
sS'Random sampling'
p6841
(lp6842
sS'Category theory'
p6843
(lp6844
VCategory theory is used to formalize mathematical structure and its concepts as a collection of "objects" and "arrows" (also called morphisms). A category has two basic properties: the ability to compose the arrows associatively and the existence of an identity arrow for each object. Category theory can be used to formalize concepts of other high-level abstractions such as set theory, ring theory, and group theory. 
p6845
aVSeveral terms used in category theory, including the term "morphism", differ from their uses within mathematics itself. In category theory, a "morphism" obeys a set of conditions specific to category theory itself. Thus, care must be taken to understand the context in which statements are made.
p6846
aVAn abstraction of other mathematical concepts.
p6847
aVMany significant areas of mathematics can be formalised by category theory as categories. Category theory is an abstraction of mathematics itself that allows many intricate and subtle mathematical results in these fields to be stated, and proved, in a much simpler way than without the use of categories.
p6848
aVThe most accessible example of a category is the category of sets, where the objects are sets and the arrows are functions from one set to another. However, the objects of a category need not be sets, and the arrows need not be functions; any way of formalising a mathematical concept such that it meets the basic conditions on the behaviour of objects and arrows is a valid category, and all the results of category theory will apply to it.
p6849
aVThe "arrows" of category theory are often said to represent a process connecting two objects, or in many cases a "structure-preserving" transformation connecting two objects. There are however many applications where much more abstract concepts are represented by objects and morphisms. The most important property of the arrows is that they can be "composed", in other words, arranged in a sequence to form a new arrow.
p6850
aVCategories now appear in most branches of mathematics, some areas of theoretical computer science where they can correspond to types, and mathematical physics where they can be used to describe vector spaces. Categories were first introduced by Samuel Eilenberg and Saunders Mac Lane in 1942\u201345, in connection with algebraic topology.
p6851
aVCategory theory has several faces known not just to specialists, but to other mathematicians. A term dating from the 1940s, "general abstract nonsense", refers to its high level of abstraction, compared to more classical branches of mathematics. Homological algebra is category theory in its aspect of organising and suggesting manipulations in abstract algebra.
p6852
aVUtility.
p6853
aVCategories, objects, and morphisms.
p6854
aVThe study of categories is an attempt to "axiomatically" capture what is commonly found in various classes of related mathematical structures by relating them to the "structure-preserving functions" between them. A systematic study of category theory then allows us to prove general results about any of these types of mathematical structures from the axioms of a category.
p6855
aVConsider the following example. The class Grp of groups consists of all objects having a "group structure". One can proceed to prove theorems about groups by making logical deductions from the set of axioms. For example, it is immediately proven from the axioms that the identity element of a group is unique.
p6856
aVInstead of focusing merely on the individual objects (e.g., groups) possessing a given structure, category theory emphasizes the morphisms \u2013 the structure-preserving mappings \u2013 "between" these objects; by studying these morphisms, we are able to learn more about the structure of the objects. In the case of groups, the morphisms are the group homomorphisms. A group homomorphism between two groups "preserves the group structure" in a precise sense \u2013 it is a "process" taking one group to another, in a way that carries along information about the structure of the first group into the second group. The study of group homomorphisms then provides a tool for studying general properties of groups and consequences of the group axioms.
p6857
aVA similar type of investigation occurs in many mathematical theories, such as the study of continuous maps (morphisms) between topological spaces in topology (the associated category is called Top), and the study of smooth functions (morphisms) in manifold theory.
p6858
aVNot all categories arise as "structure preserving (set) functions", however; the standard example is the category of homotopies between pointed topological spaces.
p6859
aVIf one axiomatizes relations instead of functions, one obtains the theory of allegories.
p6860
aVFunctors.
p6861
aVA category is "itself" a type of mathematical structure, so we can look for "processes" which preserve this structure in some sense; such a process is called a functor.
p6862
aVDiagram chasing is a visual method of arguing with abstract "arrows" joined in diagrams. Functors are represented by arrows between categories, subject to specific defining commutativity conditions. Functors can define (construct) categorical diagrams and sequences (viz. Mitchell, 1965). A functor associates to every object of one category an object of another category, and to every morphism in the first category a morphism in the second.
p6863
aVIn fact, what we have done is define a category "of categories and functors" \u2013 the objects are categories, and the morphisms (between categories) are functors.
p6864
aVBy studying categories and functors, we are not just studying a class of mathematical structures and the morphisms between them; we are studying the "relationships between various classes of mathematical structures". This is a fundamental idea, which first surfaced in algebraic topology. Difficult "topological" questions can be translated into "algebraic" questions which are often easier to solve. Basic constructions, such as the fundamental group or the fundamental groupoid of a topological space, can be expressed as functors to the category of groupoids in this way, and the concept is pervasive in algebra and its applications.
p6865
aVNatural transformations.
p6866
aVAbstracting yet again, some diagrammatic and/or sequential constructions are often "naturally related" \u2013 a vague notion, at first sight. This leads to the clarifying concept of natural transformation, a way to "map" one functor to another. Many important constructions in mathematics can be studied in this context. "Naturality" is a principle, like general covariance in physics, that cuts deeper than is initially apparent. An arrow between two functors is a natural transformation when it is subject to certain naturality or commutativity conditions.
p6867
aVFunctors and natural transformations ('naturality') are the key concepts in category theory.
p6868
aVCategories, objects, and morphisms.
p6869
aVCategories.
p6870
aVA "category" "C" consists of the following three mathematical entities:
p6871
aV:From the axioms, it can be proved that there is exactly one identity morphism for every object. Some authors deviate from the definition just given by identifying each object with its identity morphism.
p6872
aVMorphisms.
p6873
aVRelations among morphisms (such as ) are often depicted using commutative diagrams, with "points" (corners) representing objects and "arrows" representing morphisms.
p6874
aVMorphisms can have any of the following properties. A morphism is a:
p6875
aVEvery retraction is an epimorphism, and every section is a monomorphism. Furthermore, the following three statements are equivalent:
p6876
aVFunctors.
p6877
aVFunctors are structure-preserving maps between categories. They can be thought of as morphisms in the category of all (small) categories.
p6878
aVA (covariant) functor "F" from a category "C" to a category "D", written , consists of:
p6879
aVsuch that the following two properties hold:
p6880
aVA contravariant functor , is like a covariant functor, except that it "turns morphisms around" ("reverses all the arrows"). More specifically, every morphism in "C" must be assigned to a morphism in "D". In other words, a contravariant functor acts as a covariant functor from the opposite category "C"op to "D".
p6881
aVNatural transformations.
p6882
aVA "natural transformation" is a relation between two functors. Functors often describe "natural constructions" and natural transformations then describe "natural homomorphisms" between two such constructions. Sometimes two quite different constructions yield "the same" result; this is expressed by a natural isomorphism between the two functors.
p6883
aVIf "F" and "G" are (covariant) functors between the categories "C" and "D", then a natural transformation \u03b7 from "F" to "G" associates to every object "X" in "C" a morphism in "D" such that for every morphism in "C", we have ; this means that the following diagram is commutative:
p6884
aVThe two functors "F" and "G" are called "naturally isomorphic" if there exists a natural transformation from "F" to "G" such that \u03b7"X" is an isomorphism for every object "X" in "C".
p6885
aVOther concepts.
p6886
aVUniversal constructions, limits, and colimits.
p6887
aVUsing the language of category theory, many areas of mathematical study can be categorized. Categories include sets, groups, topologies, and so on.
p6888
aVEach category is distinguished by properties that all its objects have in common, such as the empty set or the product of two topologies, yet in the definition of a category, objects are considered to be atomic, i.e., we "do not know" whether an object "A" is a set, a topology, or any other abstract concept. Hence, the challenge is to define special objects without referring to the internal structure of those objects. To define the empty set without referring to elements, or the product topology without referring to open sets, one can characterize these objects in terms of their relations to other objects, as given by the morphisms of the respective categories. Thus, the task is to find "universal properties" that uniquely determine the objects of interest.
p6889
aVIndeed, it turns out that numerous important constructions can be described in a purely categorical way. The central concept which is needed for this purpose is called categorical "limit", and can be dualized to yield the notion of a "colimit".
p6890
aVEquivalent categories.
p6891
aVIt is a natural question to ask: under which conditions can two categories be considered to be "essentially the same", in the sense that theorems about one category can readily be transformed into theorems about the other category? The major tool one employs to describe such a situation is called "equivalence of categories", which is given by appropriate functors between two categories. Categorical equivalence has found numerous applications in mathematics.
p6892
aVFurther concepts and results.
p6893
aVThe definitions of categories and functors provide only the very basics of categorical algebra; additional important topics are listed below. Although there are strong interrelations between all of these topics, the given order can be considered as a guideline for further reading.
p6894
aVHigher-dimensional categories.
p6895
aVMany of the above concepts, especially equivalence of categories, adjoint functor pairs, and functor categories, can be situated into the context of "higher-dimensional categories". Briefly, if we consider a morphism between two objects as a "process taking us from one object to another", then higher-dimensional categories allow us to profitably generalize this by considering "higher-dimensional processes".
p6896
aVFor example, a (strict) 2-category is a category together with "morphisms between morphisms", i.e., processes which allow us to transform one morphism into another. We can then "compose" these "bimorphisms" both horizontally and vertically, and we require a 2-dimensional "exchange law" to hold, relating the two composition laws. In this context, the standard example is Cat, the 2-category of all (small) categories, and in this example, bimorphisms of morphisms are simply natural transformations of morphisms in the usual sense. Another basic example is to consider a 2-category with a single object; these are essentially monoidal categories. Bicategories are a weaker notion of 2-dimensional categories in which the composition of morphisms is not strictly associative, but only associative "up to" an isomorphism.
p6897
aVThis process can be extended for all natural numbers "n", and these are called "n"-categories. There is even a notion of "\u03c9-category" corresponding to the ordinal number \u03c9.
p6898
aVHigher-dimensional categories are part of the broader mathematical field of higher-dimensional algebra, a concept introduced by Ronald Brown. For a conversational introduction to these ideas, see John Baez, 'A Tale of "n"-categories' (1996).
p6899
aVHistorical notes.
p6900
aVIn 1942\u201345, Samuel Eilenberg and Saunders Mac Lane introduced categories, functors, and natural transformations as part of their work in topology, especially algebraic topology. Their work was an important part of the transition from intuitive and geometric homology to axiomatic homology theory. Eilenberg and Mac Lane later wrote that their goal was to understand natural transformations; in order to do that, functors had to be defined, which required categories.
p6901
aVStanislaw Ulam, and some writing on his behalf, have claimed that related ideas were current in the late 1930s in Poland. Eilenberg was Polish, and studied mathematics in Poland in the 1930s. Category theory is also, in some sense, a continuation of the work of Emmy Noether (one of Mac Lane's teachers) in formalizing abstract processes; Noether realized that in order to understand a type of mathematical structure, one needs to understand the processes preserving that structure. In order to achieve this understanding, Eilenberg and Mac Lane proposed an axiomatic formalization of the relation between structures and the processes preserving them.
p6902
aVThe subsequent development of category theory was powered first by the computational needs of homological algebra, and later by the axiomatic needs of algebraic geometry, the field most resistant to being grounded in either axiomatic set theory or the Russell-Whitehead view of united foundations. General category theory, an extension of universal algebra having many new features allowing for semantic flexibility and higher-order logic, came later; it is now applied throughout mathematics.
p6903
aVCertain categories called topoi (singular "topos") can even serve as an alternative to axiomatic set theory as a foundation of mathematics. A topos can also be considered as a specific type of category with two additional topos axioms. These foundational applications of category theory have been worked out in fair detail as a basis for, and justification of, constructive mathematics. Topos theory is a form of abstract sheaf theory, with geometric origins, and leads to ideas such as pointless topology.
p6904
aVCategorical logic is now a well-defined field based on type theory for intuitionistic logics, with applications in functional programming and domain theory, where a cartesian closed category is taken as a non-syntactic description of a lambda calculus. At the very least, category theoretic language clarifies what exactly these related areas have in common (in some sense).
p6905
aVCategory theory has been applied in other fields as well. For example, John Baez has shown a link between Feynman diagrams in Physics and monoidal categories. Another application of category theory, more specifically: topos theory, has been made in mathematical music theory, see for example the book "The Topos of Music, Geometric Logic of 
p6906
aVConcepts, Theory, and Performance" by Guerino Mazzola.
p6907
aVMore recent efforts to introduce undergraduates to categories as a foundation for mathematics include William Lawvere and Rosebrugh (2003) and Lawvere and Stephen Schanuel (1997) and Mirroslav Yotov (2012).
p6908
asS'Exponent'
p6909
(lp6910
sS'Gradient'
p6911
(lp6912
VIn mathematics, the gradient is a generalization of the usual concept of derivative of a function in one dimension to a function in several dimensions. If is a differentiable, scalar-valued function of standard Cartesian coordinates in Euclidean space, its gradient is the vector whose components are the "n" partial derivatives of "f". It is thus a vector-valued function.
p6913
aVSimilarly to the usual derivative, the gradient represents the slope of the tangent of the graph of the function. More precisely, the gradient points in the direction of the greatest rate of increase of the function and its magnitude is the slope of the graph in that direction. The components of the gradient in coordinates are the coefficients of the variables in the equation of the tangent space to the graph. This characterizing property of the gradient allows it to be defined independently of a choice of coordinate system, as a vector field whose components in a coordinate system will transform when going from one coordinate system to another.
p6914
aVThe Jacobian is the generalization of the gradient for vector-valued functions of several variables and differentiable maps between Euclidean spaces or, more generally, manifolds. A further generalization for a function between Banach spaces is the Fréchet derivative.
p6915
aVMotivation.
p6916
aVConsider a room in which the temperature is given by a scalar field, , so at each point the temperature is . (We will assume that the temperature does not change over time.) At each point in the room, the gradient of "T" at that point will show the direction the temperature rises most quickly. The magnitude of the gradient will determine how fast the temperature rises in that direction.
p6917
aVConsider a surface whose height above sea level at a point ("x", "y") is "H"("x", "y"). The gradient of "H" at a point is a vector pointing in the direction of the steepest slope or grade at that point. The steepness of the slope at that point is given by the magnitude of the gradient vector.
p6918
aVThe gradient can also be used to measure how a scalar field changes in other directions, rather than just the direction of greatest change, by taking a dot product. Suppose that the steepest slope on a hill is 40%. If a road goes directly up the hill, then the steepest slope on the road will also be 40%. If, instead, the road goes around the hill at an angle, then it will have a shallower slope. For example, if the angle between the road and the uphill direction, projected onto the horizontal plane, is 60°, then the steepest slope along the road will be 20%, which is 40% times the cosine of 60°.
p6919
aVThis observation can be mathematically stated as follows. If the hill height function "H" is differentiable, then the gradient of "H" dotted with a unit vector gives the slope of the hill in the direction of the vector. More precisely, when "H" is differentiable, the dot product of the gradient of "H" with a given unit vector is equal to the directional derivative of "H" in the direction of that unit vector.
p6920
aVDefinition.
p6921
aVThe gradient (or gradient vector field) of a scalar function "f"("x"1, "x"2, "x"3, ..., "xn") is denoted \u2207"f" or formula_1 where \u2207 (the nabla symbol) denotes the vector differential operator, del. The notation "grad(f)" is also commonly used for the gradient. The gradient of "f" is defined as the unique vector field whose dot product with any vector v at each point "x" is the directional derivative of "f" along v. That is,
p6922
aVformula_2
p6923
aVIn a rectangular coordinate system, the gradient is the vector field whose components are the partial derivatives of "f":
p6924
aVformula_3
p6925
aVwhere the e"i" are the orthogonal unit vectors pointing in the coordinate directions. When a function also depends on a parameter such as time, the gradient often refers simply to the vector of its spatial derivatives only.
p6926
aVIn the three-dimensional Cartesian coordinate system, this is given by
p6927
aVformula_4
p6928
aVwhere i, j, k are the standard unit vectors. For example, the gradient of the function
p6929
aV formula_5
p6930
aVis:
p6931
aVformula_6
p6932
aVIn some applications it is customary to represent the gradient as a row vector or column vector of its components in a rectangular coordinate system.
p6933
aVGradient and the derivative or differential.
p6934
aVLinear approximation to a function.
p6935
aVThe gradient of a function "f" from the Euclidean space \u211d"n" to \u211d at any particular point "x"0 in \u211d"n" characterizes the best linear approximation to "f" at "x"0. The approximation is as follows:
p6936
aVformula_7
p6937
aVfor "x" close to "x"0, where formula_8 is the gradient of "f" computed at "x"0, and the dot denotes the dot product on \u211d"n". This equation is equivalent to the first two terms in the multi-variable Taylor Series expansion of "f" at "x"0.
p6938
aVDifferential or (exterior) derivative.
p6939
aVThe best linear approximation to a function 
p6940
aVformula_9 
p6941
aVat a point "x" in \u211d"n" is a linear map from \u211d"n" to \u211d which is often denoted by d"fx" or "Df"("x") and called the differential or (total) derivative of "f" at "x". The gradient is therefore related to the differential by the formula
p6942
aVformula_10
p6943
aVfor any "v" \u2208 \u211d"n". The function d"f", which maps "x" to d"f""x", is called the differential or exterior derivative of "f" and is an example of a differential 1-form.
p6944
aVIf \u211d"n" is viewed as the space of (length "n") column vectors (of real numbers), then one can regard d"f" as the row vector with components
p6945
aVformula_11
p6946
aVso that d"f""x"("v") is given by matrix multiplication. The gradient is then the corresponding column vector, i.e., 
p6947
aVformula_12.
p6948
aVGradient as a derivative.
p6949
aVLet "U" be an open set in R"n". If the function is differentiable, then the differential of "f" is the (Fréchet) derivative of "f". Thus \u2207"f" is a function from "U" to the space R such that
p6950
aVformula_13
p6951
aVwhere \u22c5 is the dot product.
p6952
aVAs a consequence, the usual properties of the derivative hold for the gradient:
p6953
aVThe gradient is linear in the sense that if "f" and "g" are two real-valued functions differentiable at the point , and \u03b1 and \u03b2 are two constants, then is differentiable at "a", and moreover
p6954
aV formula_14
p6955
aVIf "f" and "g" are real-valued functions differentiable at a point , then the product rule asserts that the product of the functions "f" and "g" is differentiable at "a", and
p6956
aVformula_15
p6957
aVSuppose that is a real-valued function defined on a subset "A" of R"n", and that "f" is differentiable at a point "a". There are two forms of the chain rule applying to the gradient. First, suppose that the function "g" is a parametric curve; that is, a function maps a subset into R"n". If "g" is differentiable at a point such that , then
p6958
aVformula_16
p6959
aVwhere \u2218 is the composition operator : (g\u2009\u2218\u2009f\u2009)(x) = g(f(x)).
p6960
aVMore generally, if instead , then the following holds:
p6961
aVformula_17
p6962
aVwhere ("Dg")T denotes the transpose Jacobian matrix.
p6963
aVFor the second form of the chain rule, suppose that is a real valued function on a subset "I" of R, and that "h" is differentiable at the point . Then
p6964
aVformula_18
p6965
aVFurther properties and applications.
p6966
aVLevel sets.
p6967
aVA level surface, or isosurface, is the set of all points where some function has a given value.
p6968
aVIf "f" is differentiable, then the dot product of the gradient at a point "x" with a vector "v" gives the directional derivative of "f" at "x" in the direction "v". It follows that in this case the gradient of "f" is orthogonal to the level sets of "f". For example, a level surface in three-dimensional space is defined by an equation of the form . The gradient of "F" is then normal to the surface.
p6969
aVMore generally, any embedded hypersurface in a Riemannian manifold can be cut out by an equation of the form such that d"F" is nowhere zero. The gradient of "F" is then normal to the hypersurface.
p6970
aVSimilarly, an affine algebraic hypersurface may be defined by an equation , where "F" is a polynomial. The gradient of "F" is zero at a singular point of the hypersurface (this is the definition of a singular point). At a non-singular point, it is a nonzero normal vector.
p6971
aVConservative vector fields and the gradient theorem.
p6972
aVThe gradient of a function is called a gradient field. A (continuous) gradient field is always a conservative vector field: its line integral along any path depends only on the endpoints of the path, and can be evaluated by the gradient theorem (the fundamental theorem of calculus for line integrals). Conversely, a (continuous) conservative vector field is always the gradient of a function.
p6973
aVRiemannian manifolds.
p6974
aVFor any smooth function f on a Riemannian manifold ("M","g"), the gradient of "f" is the vector field \u2207"f" such that for any vector field "X",
p6975
aVformula_19
p6976
aVwhere denotes the inner product of tangent vectors at "x" defined by the metric "g" and \u2202"X""f" (sometimes denoted "X"("f")) is the function that takes any point to the directional derivative of "f" in the direction "X", evaluated at "x". In other words, in a coordinate chart \u03c6 from an open subset of "M" to an open subset of R"n", (\u2202"X""f")("x") is given by:
p6977
aVformula_20
p6978
aVwhere "X""j" denotes the "j"th component of "X" in this coordinate chart.
p6979
aVSo, the local form of the gradient takes the form:
p6980
aVformula_21
p6981
aVGeneralizing the case , the gradient of a function is related to its exterior derivative, since 
p6982
aVformula_22
p6983
aVMore precisely, the gradient \u2207"f" is the vector field associated to the differential 1-form d"f" using the musical isomorphism 
p6984
aVformula_23 
p6985
aV(called "sharp") defined by the metric "g". The relation between the exterior derivative and the gradient of a function on R"n" is a special case of this in which the metric is the flat metric given by the dot product.
p6986
aVCylindrical and spherical coordinates.
p6987
aVIn cylindrical coordinates, the gradient is given by :
p6988
aVformula_24
p6989
aVwhere \u03d5 is the azimuthal angle, "z" is the axial coordinate, and e\u03c1, e\u03c6 and e"z" are unit vectors pointing along the coordinate directions.
p6990
aVIn spherical coordinates :
p6991
aVformula_25
p6992
aVwhere \u03d5 is the azimuth angle and \u03b8 is the zenith angle.
p6993
aVFor the gradient in other orthogonal coordinate systems, see Orthogonal coordinates (Differential operators in three dimensions).
p6994
aVGradient of a vector.
p6995
aVIn rectangular coordinates, the gradient of a vector field is defined by
p6996
aVformula_26
p6997
aVwhere the Einstein summation notation is used and the product of the vectors ei, ek is a tensor of type (2,0), or the Jacobian matrix
p6998
aVformula_27.
p6999
aVIn curvilinear coordinates, or more generally on a curved manifold, the gradient involves Christoffel symbols:
p7000
aVformula_28
p7001
aVwhere "g""jk" are the components of the metric tensor and the e"i" are the coordinate vectors.
p7002
aVExpressed more invariantly, the gradient of a vector field f can be defined by the Levi-Civita connection and metric tensor:
p7003
aVformula_29
p7004
aVwhere formula_30 is the connection.
p7005
asS'Graph'
p7006
(lp7007
VGraph may refer to:
p7008
aVIn mathematics:
p7009
aVIn computer science:
p7010
aVOther uses:
p7011
asS'Correlation'
p7012
(lp7013
sS'Lorenz attractor'
p7014
(lp7015
sS'Interval (mathematics)'
p7016
(lp7017
VIn mathematics, an (real) interval is a set of real numbers with the property that any number that lies between two numbers in the set is also included in the set. For example, the set of all numbers satisfying is an interval which contains and , as well as all numbers between them. Other examples of intervals are the set of all real numbers formula_1, the set of all negative real numbers, and the empty set.
p7018
aVReal intervals play an important role in the theory of integration, because they are the simplest sets whose "size" or "measure" or "length" is easy to define. The concept of measure can then be extended to more complicated sets of real numbers, leading to the Borel measure and eventually to the Lebesgue measure.
p7019
aVIntervals are central to interval arithmetic, a general numerical computing technique that automatically provides guaranteed enclosures for arbitrary formulas, even in the presence of uncertainties, mathematical approximations, and arithmetic roundoff.
p7020
aVIntervals are likewise defined on an arbitrary totally ordered set, such as integers or rational numbers. The notation of integer intervals is considered in the special section below.
p7021
aVNotations for intervals.
p7022
aVThe interval of numbers between and , including and , is often denoted . The two numbers are called the "endpoints" of the interval. In countries where numbers are written with a decimal comma, a semicolon may be used as a separator, to avoid ambiguity.
p7023
aVIncluding or excluding endpoints.
p7024
aVTo indicate that one of the endpoints is to be excluded from the set, the corresponding square bracket can be either replaced with a parenthesis, or reversed. Both notations are described in International standard ISO 31-11. Thus, in set builder notation,
p7025
aV formula_2
p7026
aVNote that , , and represent the empty set, whereas denotes the set . When , all four notations are usually assumed to represent the empty set.
p7027
aVBoth notations may overlap with other uses of parentheses and brackets in mathematics. For instance, the notation formula_3 is often used to denote an ordered pair in set theory, the coordinates of a point or vector in analytic geometry and linear algebra, or (sometimes) a complex number in algebra. That's why Bourbaki introduced the notation formula_4 to denote the open interval. The notation formula_5 too is occasionally used for ordered pairs, especially in computer science.
p7028
aVSome authors use formula_4 to denote the complement of the interval ; namely, the set of all real numbers that are either less than or equal to , or greater than or equal to .
p7029
aVInfinite endpoints.
p7030
aVIn both styles of notation, one may use an infinite endpoint to indicate that there is no bound in that direction. Specifically, one may use formula_7 or formula_8 (or both). For example, is the set of all positive real numbers, and is the set of real numbers.
p7031
aVThe extended real number line includes and as elements. The notations \u2009, \u2009, \u2009, and may be used in this context. For example means the extended real numbers excluding only .
p7032
aVInteger intervals.
p7033
aVThe notation when and are integers, or , or just is sometimes used to indicate the interval of all "integers" between and , including both. This notation is used in some programming languages; in Pascal, for example, it is used to formally define a subrange type, most frequently used to specify lower and upper bounds of valid indices of an array.
p7034
aVAn integer interval that has a finite lower or upper endpoint always includes that endpoint. Therefore, the exclusion of endpoints can be explicitly denoted by writing \u2009, \u2009, or . Alternate-bracket notations like or are rarely used for integer intervals.
p7035
aVTerminology.
p7036
aVAn open interval does not include its endpoints, and is indicated with parentheses. For example means greater than and less than . A closed interval includes its endpoints, and is denoted with square brackets. For example means greater than or equal to and less than or equal to .
p7037
aVA degenerate interval is any set consisting of a single real number. Some authors include the empty set in this definition. A real interval that is neither empty nor degenerate is said to be proper, and has infinitely many elements.
p7038
aVAn interval is said to be left-bounded or right-bounded if there is some real number that is, respectively, smaller than or larger than all its elements. An interval is said to be bounded if it is both left- and right-bounded; and is said to be unbounded otherwise. Intervals that are bounded at only one end are said to be half-bounded. The empty set is bounded, and the set of all reals is the only interval that is unbounded at both ends. Bounded intervals are also commonly known as finite intervals.
p7039
aVBounded intervals are bounded sets, in the sense that their diameter (which is equal to the absolute difference between the endpoints) is finite. The diameter may be called the length, width, measure, or size of the interval. The size of unbounded intervals is usually defined as , and the size of the empty interval may be defined as or left undefined.
p7040
aVThe centre (midpoint) of bounded interval with endpoints and is , and its radius is the half-length . These concepts are undefined for empty or unbounded intervals.
p7041
aVAn interval is said to be left-open if and only if it has no minimum (an element that is smaller than all other elements); right-open if it has no maximum; and open if it has both properties. The interval  = , for example, is left-closed and right-open. The empty set and the set of all reals are open intervals, while the set of non-negative reals, for example, is a right-open but not left-open interval. The open intervals coincide with the open sets of the real line in its standard topology.
p7042
aVAn interval is said to be left-closed if it has a minimum element, right-closed if it has a maximum, and simply closed if it has both. These definitions are usually extended to include the empty set and to the (left- or right-) unbounded intervals, so that the closed intervals coincide with closed sets in that topology.
p7043
aVThe interior of an interval is the largest open interval that is contained in ; it is also the set of points in which are not endpoints of . The closure of is the smallest closed interval that contains ; which is also the set augmented with its finite endpoints.
p7044
aVFor any set of real numbers, the interval enclosure or interval span of is the unique interval that contains and does not properly contain any other interval that also contains .
p7045
aVClassification of intervals.
p7046
aVThe intervals of real numbers can be classified into eleven different types, listed below; where and are real numbers, with formula_9:
p7047
aV empty: formula_10
p7048
aV degenerate: formula_11
p7049
aV proper and bounded:
p7050
aV: open: formula_12
p7051
aV: closed: formula_13
p7052
aV: left-closed, right-open: formula_14
p7053
aV: left-open, right-closed: formula_15
p7054
aV left-bounded and right-unbounded:
p7055
aV: left-open: formula_16
p7056
aV: left-closed: formula_17
p7057
aV left-unbounded and right-bounded:
p7058
aV: right-open: formula_18
p7059
aV: right-closed: formula_19
p7060
aV unbounded at both ends: formula_20
p7061
aVIntervals of the extended real line.
p7062
aVIn some contexts, an interval may be defined as a subset of the extended real numbers, the set of all real numbers augmented with and .
p7063
aVIn this interpretation, the notations \u2009, \u2009, \u2009, and are all meaningful and distinct. In particular, denotes the set of all ordinary real numbers, while denotes the extended reals.
p7064
aVThis choice affects some of the above definitions and terminology. For instance, the interval  = formula_1 is closed in the realm of ordinary reals, but not in the realm of the extended reals.
p7065
aVProperties of intervals.
p7066
aVThe intervals are precisely the connected subsets of formula_1. It follows that the image of an interval by any continuous function is also an interval. This is one formulation of the intermediate value theorem.
p7067
aVThe intervals are also the convex subsets of formula_1. The interval enclosure of a subset formula_24 is also the convex hull of formula_25.
p7068
aVThe intersection of any collection of intervals is always an interval. The union of two intervals is an interval if and only if they have a non-empty intersection or an open end-point of one interval is a closed end-point of the other (e.g., formula_26).
p7069
aVIf formula_1 is viewed as a metric space, its open balls are the open bounded sets , and its closed balls are the closed bounded sets .
p7070
aVAny element  of an interval  defines a partition of  into three disjoint intervals 1,\u20092,\u20093: respectively, the elements of  that are less than , the singleton formula_28, and the elements that are greater than . The parts 1 and 3 are both non-empty (and have non-empty interiors) if and only if is in the interior of . This is an interval version of the trichotomy principle.
p7071
aVDyadic intervals.
p7072
aVA "dyadic interval" is a bounded real interval whose endpoints are formula_29 and formula_30, where formula_31 and formula_32 are integers. Depending on the context, either endpoint may or may not be included in the interval.
p7073
aVDyadic intervals have the following properties:
p7074
aVThe dyadic intervals consequently have a structure that reflects that of an infinite binary tree.
p7075
aVDyadic intervals are relevant to several areas of numerical analysis, including adaptive mesh refinement, multigrid methods and wavelet analysis. Another way to represent such a structure is p-adic analysis (for ).
p7076
aVGeneralizations.
p7077
aVMulti-dimensional intervals.
p7078
aVIn many contexts, an formula_32-dimensional interval is defined as a subset of formula_34 that is the Cartesian product of formula_32 intervals, formula_36, one on each coordinate axis.
p7079
aVFor formula_37, this generally defines a rectangle whose sides are parallel to the coordinate axes; for formula_38, it defines an axis-aligned rectangular box.
p7080
aVA facet of such an interval formula_39 is the result of replacing any non-degenerate interval factor formula_40 by a degenerate interval consisting of a finite endpoint of formula_40. The faces of formula_39 comprise formula_39 itself and all faces of its facets. The corners of formula_39 are the faces that consist of a single point of formula_34.
p7081
aVComplex intervals.
p7082
aVIntervals of complex numbers can be defined as regions of the complex plane, either rectangular or circular.
p7083
aVTopological algebra.
p7084
aVIntervals can be associated with points of the plane and hence regions of intervals can be associated with regions of the plane. Generally, an interval in mathematics corresponds to an ordered pair ("x,y") taken from the direct product R × R of real numbers with itself. Often it is assumed that "y" > "x". For purposes of mathematical structure, this restriction is discarded, and "reversed intervals" where "y" \u2212 "x" < 0 are allowed. Then the collection of all intervals ["x,y"] can be identified with the topological ring formed by the direct sum of R with itself where addition and multiplication are defined component-wise.
p7085
aVThe direct sum algebra formula_46 has two ideals, { ["x",0] : "x" \u2208 R } and { : "y" \u2208 R }. The identity element of this algebra is the condensed interval [1,1. If interval ["x,y"] is not in one of the ideals, then it has multiplicative inverse 1/"y". Endowed with the usual topology, the algebra of intervals forms a topological ring. The group of units of this ring consists of four quadrants determined by the axes, or ideals in this case. The identity component of this group is quadrant I.
p7086
aVEvery interval can be considered a symmetric interval around its midpoint. In a reconfiguration published in 1956 by M Warmus, the axis of "balanced intervals" ["x", \u2212"x"] is used along with the axis of intervals ["x,x"] that reduce to a point.
p7087
aVInstead of the direct sum formula_47, the ring of intervals has been identified with the split-complex number plane by M. Warmus and D. H. Lehmer through the identification
p7088
aV "z" = ("x" + "y")/2 + j ("x" \u2212 "y")/2.
p7089
aVThis linear mapping of the plane, which amounts of a ring isomorphism, provides the plane with a multiplicative structure having some analogies to ordinary complex arithmetic, such as polar decomposition.
p7090
asVNavier\u2013Stokes equations
p7091
(lp7092
VIn physics, the Navier\u2013Stokes equations [], named after Claude-Louis Navier and George Gabriel Stokes, describe the motion of viscous fluid substances. These balance equations arise from applying Newton's second law to fluid motion, together with the assumption that the stress in the fluid is the sum of a diffusing viscous term (proportional to the gradient of velocity) and a pressure term\u2014hence describing "viscous flow". The main difference between them and the simpler Euler equations for inviscid flow is that Navier\u2013Stokes equations also in the Froude limit (no external field) are not conservation equations (but rather a dissipative system) in the sense they cannot be put into the quasilinear homogeneous form:
p7093
aVformula_1
p7094
aVNavier\u2013Stokes equations are useful because they describe the physics of many things of scientific and engineering interest. They may be used to model the weather, ocean currents, water flow in a pipe and air flow around a wing. The Navier\u2013Stokes equations in their full and simplified forms help with the design of aircraft and cars, the study of blood flow, the design of power stations, the analysis of pollution, and many other things. Coupled with Maxwell's equations they can be used to model and study magnetohydrodynamics.
p7095
aVThe Navier\u2013Stokes equations are also of great interest in a purely mathematical sense. Somewhat surprisingly, given their wide range of practical uses, it has not yet been proven that in three dimensions solutions always exist (existence), or that if they do exist, then they do not contain any singularity (they are smooth). These are called the Navier\u2013Stokes existence and smoothness problems. The Clay Mathematics Institute has called this one of the seven most important open problems in mathematics and has offered a US$1,000,000 prize for a solution or a counter-example.
p7096
aVFlow velocity.
p7097
aVThe solution of the Navier\u2013Stokes equations is a flow velocity. It is a field, since it is defined at every point in a region space and an interval of time. Once the velocity field is calculated, other quantities of interest, such as pressure or temperature, may be found. This is different from what one normally sees in classical mechanics, where solutions are typically trajectories of position of a particle or deflection of a continuum. Studying velocity instead of position makes more sense for a fluid; however for visualization purposes one can compute various trajectories.
p7098
aVGeneral continuum equations.
p7099
aVThe Navier\u2013Stokes momentum equation can be derived as a particular form of the Cauchy momentum equation. 
p7100
aVIn an inertial frame of reference, the Eulerian form of the equations of continuum motion is:
p7101
aVwhere
p7102
aV formula_2 is the density,
p7103
aV formula_3 is the flow velocity,
p7104
aV formula_4 is the del operator.
p7105
aV formula_5 is the pressure
p7106
aV formula_6 is the identity matrix
p7107
aV formula_7 is the deviatoric stress tensor, which has order two,
p7108
aV formula_8 represents body accelerations (per unit mass) acting on the continuum, for example gravity, inertial accelerations, electric field acceleration, and so on.
p7109
aVThe left side of the equation describes acceleration, and may be composed of time-dependent, convective, and hydrostatic effects (also the effects of non-inertial coordinates if present). The right side of the equation is in effect a summation of body forces (such as gravity) and divergence of deviatoric stress.
p7110
aVIn the Eulerian forms it is apparent that the assumption of no deviatoric stress brings Cauchy equations to the Euler equations.
p7111
aVAll non-relativistic balance equations, such as the Navier\u2013Stokes equations, can be derived by beginning with the Cauchy equations and specifying the stress tensor through a constitutive relation. By expressing the shear tensor in terms of viscosity and fluid velocity, and assuming constant density and viscosity, the Cauchy equations will lead to the Navier\u2013Stokes equations.
p7112
aVThe incompressible case is simpler than the compressile one so for didactical purpose it should be presented before. However, the compressible case is the most general framework of Navier\u2013Stokes equations so where not specified, Navier\u2013Stokes equations are intended to be "compressible" Navier\u2013Stokes equations.
p7113
aVConvective acceleration.
p7114
aVA significant feature of Cauchy equation and consequently all other continuum equations (including Euler and Navier\u2013Stokes) is the presence of convective acceleration: the effect of time-independent acceleration of a flow with respect to space. While individual fluid particles indeed experience time-dependent acceleration, the convective acceleration of the flow field is a spatial effect, one example being fluid speeding up in a nozzle.
p7115
aVIncompressible flow.
p7116
aVThe incompressible momentum Navier\u2013Stokes equation result from the following assumptions on the Cauchy stress tensor:
p7117
aVwhere I is the identity tensor, and
p7118
aV:formula_11
p7119
aVis the rate-of-strain tensor. So this decomposition can be explicited as:
p7120
aVDynamic viscosity need not be constant \u2013 in incompressible flows it can depend on density and on pressure. Any equation expliciting one of these transport coefficient in the conservative variables is called an equation of state.
p7121
aVThe divergence of the deviatoric stress is given by:
p7122
aVformula_12
p7123
aVIncompressibility rules out density and pressure waves like sound or shock waves, so this simplification is not useful if these phenomena are of interest. The incompressible flow assumption typically holds well with all fluids at low Mach numbers (say up to about Mach 0.3), such as for modelling air winds at normal temperatures. For incompressible (uniform density \u03c10) flows the following identity holds:
p7124
aVformula_13
p7125
aVwhere is the specific (with the sense of "per unit mass") thermodynamic work, the internal source term. Then the incompressible Navier\u2013Stokes equations are best visualised by dividing for the density:
p7126
aVVelocity profile (laminar flow)
p7127
aVu\u27e8x\u27e9 = 0, u(y) = u, u(z) = 0
p7128
aVfor the y- direction, simplify Navier-Stokes equation
p7129
aV0 = -(dP/dx) + \u03bc(d^2u/dy^2)
p7130
aVintegrate twice to find velocity profile with boundary conditions: y = h, u = 0 y = -h, u = 0
p7131
aVu = (1/2\u03bc)(dP/dx) y^2 + Ay + B
p7132
aVFrom this equation, sub in your two boundary conditions to get 2 equations
p7133
aV1. 0 = (1/2\u03bc)(dP/dx) h^2 + Ah + B 
p7134
aV2. 0 = (1/2\u03bc)(dP/dx) h^2 - Ah + B
p7135
aVAdd and solve for B
p7136
aVB = -(1/2\u03bc)(dP/dx) h^2
p7137
aVSubstitute and solve for A
p7138
aVA = 0
p7139
aVFinally you get the velocity profile
p7140
aVu = (1/2\u03bc)(dP/dx)( y^2 - h^2 )
p7141
aVin tensor notation:
p7142
aVwhere:
p7143
aVIt is well worth observing the meaning of each term (compare to the Cauchy momentum equation):
p7144
aVformula_14
p7145
aVThe higher-order term, namely the shear stress divergence , has simply reduced to the vector laplacian term . This laplacian term can be interpreted as the difference between the velocity at a point and the mean velocity in a small surrounding volume. This implies that \u2013 for a Newtonian fluid \u2013 viscosity operates as a "diffusion of momentum", in much the same way as the heat conduction. In fact neglecting the convection term, incompressible Navier\u2013Stokes equations lead to a vector diffusion equation (namely Stokes equations), but in general the convection term is present, so incompressible Navier\u2013Stokes equations belong to the class of convection-diffusion equations.
p7146
aVIn the usual case of an external field being a conservative field:
p7147
aVformula_15
p7148
aVby defining the hydraulic head:
p7149
aVformula_16
p7150
aVone can finally condense the whole source in one term, arriving to the incompressible Navier-Stokes equation with conservative external field:
p7151
aVformula_17
p7152
aVThe incompressible Navier\u2013Stokes equations with conservative external field is the fundamental equation of hydraulics. The domain for these equations is commonly a 3 or less euclidean space, for which an orthogonal coordinate reference frame is usually set to explicit the system of scalar partial derivative equations to be solved. In 3D orthogonal coordinate systems are 3: Cartesian, cylindrical, and spherical. Expressing the Navier-Stokes vector equation in Cartesian coordinates is quite straightforward and not much influenced by the number of dimensions of the euclidean space employed, and this is the case also for the first-order terms (like the variation and convection ones) also in non-cartesian orthogonal coordinate systems. But for the higher order terms (the two coming from the divergence of the deviatoric stress that distinguish Navier\u2013Stokes equations from Euler equations) some tensor calculus is required for deducing an expression in non-cartesian orthogonal coordinate systems.
p7153
aVThe incompressible Navier\u2013Stokes equation is composite, the sum of two orthogonal equations,
p7154
aVformula_18
p7155
aVwhere and are solenoidal and irrotational projection operators satisfying and formula_19 and are the non-conservative and conservative parts of the body force. This result follows from the Helmholtz Theorem (also known as the fundamental theorem of vector calculus). The first equation is a pressureless governing equation for the velocity, while the second equation for the pressure is a functional of the velocity and is related to the pressure Poisson equation.
p7156
aVThe explicit functional form of the projection operator in 3D is found from the Helmholtz Theorem:
p7157
aVformula_20
p7158
aVwith a similar structure in 2D. Thus the governing equation is an integro-differential equation similar to Coulomb and Biot-Savart law, not convenient for numerical computation.
p7159
aVAn equivalent weak or variational form of the equation, proved to produce the same velocity solution as the Navier\u2013Stokes equation, is given by,
p7160
aVformula_21
p7161
aVfor divergence-free test functions satisfying appropriate boundary conditions. Here, the projections are accomplished by the orthogonality of the solenoidal and irrotational function spaces. The discrete form of this is imminently suited to finite element computation of divergence-free flow, as we shall see in the next section. There we will be able to address the question, "How does one specify pressure-driven (Poiseuille) problems with a pressureless governing equation?"
p7162
aVThe absence of pressure forces from the governing velocity equation demonstrates that the equation is not a dynamic one, but rather a kinematic equation where the divergence-free condition serves the role of a conservation equation. This all would seem to refute the frequent statements that the incompressible pressure enforces the divergence-free condition.
p7163
aVDiscrete velocity.
p7164
aVWith partitioning of the problem domain and defining basis functions on the partitioned domain, the discrete form of the governing equation is,
p7165
aVformula_22
p7166
aVIt is desirable to choose basis functions which reflect the essential feature of incompressible flow \u2013 the elements must be divergence-free. While the velocity is the variable of interest, the existence of the stream function or vector potential is necessary by the Helmholtz Theorem. Further, to determine fluid flow in the absence of a pressure gradient, one can specify the difference of stream function values across a 2D channel, or the line integral of the tangential component of the vector potential around the channel in 3D, the flow being given by Stokes' Theorem. Discussion will be restricted to 2D in the following.
p7167
aVWe further restrict discussion to continuous Hermite finite elements which have at least first-derivative degrees-of-freedom. With this, one can draw a large number of candidate triangular and rectangular elements from the plate-bending literature.
p7168
aVThese elements have derivatives as components of the gradient. In 2D, the gradient and curl of a scalar are clearly orthogonal, given by the expressions,
p7169
aVformula_23
p7170
aVAdopting continuous plate-bending elements, interchanging the derivative degrees-of-freedom and changing the sign of the appropriate one gives many families of stream function elements.
p7171
aVTaking the curl of the scalar stream function elements gives divergence-free velocity elements. The requirement that the stream function elements be continuous assures that the normal component of the velocity is continuous across element interfaces, all that is necessary for vanishing divergence on these interfaces.
p7172
aVBoundary conditions are simple to apply. The stream function is constant on no-flow surfaces, with no-slip velocity conditions on surfaces.
p7173
aVStream function differences across open channels determine the flow. No boundary conditions are necessary on open boundaries, though consistent values may be used with some problems. These are all Dirichlet conditions.
p7174
aVThe algebraic equations to be solved are simple to set up, but of course are non-linear, requiring iteration of the linearized equations.
p7175
aVSimilar considerations apply to three-dimensions, but extension from 2D is not immediate because of the vector nature of the potential, and there exists no simple relation between the gradient and the curl as was the case in 2D.
p7176
aVPressure recovery.
p7177
aVRecovering pressure from the velocity field is easy. The discrete weak equation for the pressure gradient is,
p7178
aVformula_24
p7179
aVwhere the test/weight functions are irrotational. Any conforming scalar finite element may be used. However, the pressure gradient field may also be of interest. In this case one can use scalar Hermite elements for the pressure. For the test/weight functions one would choose the irrotational vector elements obtained from the gradient of the pressure element.
p7180
aVCompressible flow.
p7181
aVThe Navier\u2013Stokes equations result from the following assumptions on the stress tensor:
p7182
aV where is the identity tensor, is the rate-of-strain tensor and is the rate of expansion of the flow. So this decomposition can be explicited as:
p7183
aV: formula_26
p7184
aVSince the trace of the rate-of-strain tensor in three dimensions is:
p7185
aV formula_27
p7186
aVThe trace of the stress tensor in three dimensions becomes:
p7187
aV formula_28
p7188
aVSo by alternatively decomposing the stress tensor is into isotropic and deviatoric parts, as usual in fluid dynamics:
p7189
aV formula_29
p7190
aVIntroducing the second viscosity ,
p7191
aV formula_30
p7192
aVwe arrive to the linear constitutive equation in the form usually employed in thermal hydraulics:
p7193
aVBoth bulk viscosity and dynamic viscosity need not be constant \u2013 in general, they depend on density, on each other (the viscosity is expressed in pressure), and in compressible flows also on temperature. Any equation expliciting one of these transport coefficient in the conservation variables is called an equation of state.
p7194
aVBy computing the divergence of the stress tensor,
p7195
aVsince the divergence of tensor is and
p7196
aVthe divergence of tensor is , one finally arrives to the compressible (most general) Navier-Stokes momentum equation:
p7197
aVBulk viscosity is assumed to be constant, otherwise it should not be taken out of the last derivative. The effect of the volume viscosity it that the mechanical pressure is not equivalent to the thermodynamic pressure:
p7198
aV formula_31
p7199
aVThis difference is usually neglected, sometimes by explicitly assuming = 0, but it could have an impact in sound absorption and attenuation and shock waves , see 
p7200
aVFor the special case of an incompressible flow, the pressure constrains the flow so that the volume of fluid elements is constant: isochoric flow resulting in a solenoidal velocity field with 
p7201
aVOther equations.
p7202
aVThe Navier\u2013Stokes equations are strictly a statement of the balance of momentum. To fully describe fluid flow, more information is needed, how much depending on the assumptions made. This additional information may include boundary data (no-slip, capillary surface, etc.), conservation of mass, balance of energy, and/or an equation of state.
p7203
aVContinuity equation.
p7204
aVRegardless of the flow assumptions, a statement of the conservation of mass is generally necessary. This is achieved through the mass continuity equation, given in its most general form as:
p7205
aVformula_32
p7206
aVor, using the substantive derivative:
p7207
aVformula_33
p7208
aVIt can be derived from using the Navier-Stokes Equation above.
p7209
aVIn the example below we can assume to have a Newtonian Fluid as well as having formula_2 and formula_35 both be constant
p7210
aVRecall that mass continuity is simply the summation of the rate of mass in and the rate of mass out.
p7211
aV: of Mass Accumulated = of Mass In - of Mass Out
p7212
aV:formula_36
p7213
aVSeparate formula_37 by dividing by formula_38.
p7214
aVSince there is no change in Pressure (P) overtime, formula_39.
p7215
aVThis Simplifies to
p7216
aV:formula_40
p7217
aVRecall that formula_2 is a constant thus proving the divergence theorem above.
p7218
aVStream function for 2D equations.
p7219
aVTaking the curl of the Navier\u2013Stokes equation results in the elimination of pressure. This is especially easy to see if 2D Cartesian flow is assumed (like in the degenerate 3D case with formula_42 and no dependence of anything on "z"), where the equations reduce to:
p7220
aVformula_43
p7221
aVDifferentiating the first with respect to "y", the second with respect to "x" and subtracting the resulting equations will eliminate pressure and any conservative force. Defining the stream function formula_44 through
p7222
aVformula_45
p7223
aVresults in mass continuity being unconditionally satisfied (given the stream function is continuous), and then incompressible Newtonian 2D momentum and mass conservation condense into one equation:
p7224
aVformula_46
p7225
aVwhere formula_47 is the (2D) biharmonic operator and formula_48 is the kinematic viscosity, formula_49. We can also express this compactly using the Jacobian determinant:
p7226
aVformula_50
p7227
aVThis single equation together with appropriate boundary conditions describes 2D fluid flow, taking only kinematic viscosity as a parameter. Note that the equation for creeping flow results when the left side is assumed zero.
p7228
aVIn axisymmetric flow another stream function formulation, called the Stokes stream function, can be used to describe the velocity components of an incompressible flow with one scalar function.
p7229
aVThe incompressible Navier\u2013Stokes equation is a differential algebraic equation, having the inconvenient feature that there is no explicit mechanism for advancing the pressure in time. Consequently, much effort has been expended to eliminate the pressure from all or part of the computational process. The stream function formulation eliminates the pressure but only in two dimensions and at the expense of introducing higher derivatives and elimination of the velocity, which is the primary variable of interest.
p7230
aVProperties.
p7231
aVNonlinearity.
p7232
aVThe Navier\u2013Stokes equations are nonlinear partial differential equations in the general case and so remain in almost every real situation. In some cases, such as one-dimensional flow and Stokes flow (or creeping flow), the equations can be simplified to linear equations. The nonlinearity makes most problems difficult or impossible to solve and is the main contributor to the turbulence that the equations model.
p7233
aVThe nonlinearity is due to convective acceleration, which is an acceleration associated with the change in velocity over position. Hence, any convective flow, whether turbulent or not, will involve nonlinearity. An example of convective but laminar (nonturbulent) flow would be the passage of a viscous fluid (for example, oil) through a small converging nozzle. Such flows, whether exactly solvable or not, can often be thoroughly studied and understood.
p7234
aVTurbulence.
p7235
aVTurbulence is the time-dependent chaotic behavior seen in many fluid flows. It is generally believed that it is due to the inertia of the fluid as a whole: the culmination of time-dependent and convective acceleration; hence flows where inertial effects are small tend to be laminar (the Reynolds number quantifies how much the flow is affected by inertia). It is believed, though not known with certainty, that the Navier\u2013Stokes equations describe turbulence properly.
p7236
aVThe numerical solution of the Navier\u2013Stokes equations for turbulent flow is extremely difficult, and due to the significantly different mixing-length scales that are involved in turbulent flow, the stable solution of this requires such a fine mesh resolution that the computational time becomes significantly infeasible for calculation or direct numerical simulation. Attempts to solve turbulent flow using a laminar solver typically result in a time-unsteady solution, which fails to converge appropriately. To counter this, time-averaged equations such as the Reynolds-averaged Navier\u2013Stokes equations (RANS), supplemented with turbulence models, are used in practical computational fluid dynamics (CFD) applications when modeling turbulent flows. Some models include the Spalart-Allmaras, k-\u03c9 (k-omega), k-\u03b5 (k-epsilon), and SST models, which add a variety of additional equations to bring closure to the RANS equations. Large eddy simulation (LES) can also be used to solve these equations numerically. This approach is computationally more expensive\u2014in time and in computer memory\u2014than RANS, but produces better results because it explicitly resolves the larger turbulent scales.
p7237
aVApplicability.
p7238
aVTogether with supplemental equations (for example, conservation of mass) and well formulated boundary conditions, the Navier\u2013Stokes equations seem to model fluid motion accurately; even turbulent flows seem (on average) to agree with real world observations.
p7239
aVThe Navier\u2013Stokes equations assume that the fluid being studied is a continuum (it is infinitely divisible and not composed of particles such as atoms or molecules), and is not moving at relativistic velocities. At very small scales or under extreme conditions, real fluids made out of discrete molecules will produce results different from the continuous fluids modeled by the Navier\u2013Stokes equations. Depending on the Knudsen number of the problem, the Boltzmann equation may be a suitable replacement; failing that, one may find the techniques of statistical mechanics sufficient or have to resort to molecular dynamics.
p7240
aVAnother limitation is simply the complicated nature of the equations. Time-tested formulations exist for common fluid families, but the application of the Navier\u2013Stokes equations to less common families tends to result in very complicated formulations and often to open research problems. For this reason, these equations are usually rewritten for Newtonian fluids where the viscosity model is linear; truly general models for the flow of other kinds of fluids (such as blood) do not, as of 2012, exist .
p7241
aVApplication to specific problems.
p7242
aVThe Navier\u2013Stokes equations, even when written explicitly for specific fluids, are rather generic in nature and their proper application to specific problems can be very diverse. This is partly because there is an enormous variety of problems that may be modeled, ranging from as simple as the distribution of static pressure to as complicated as multiphase flow driven by surface tension.
p7243
aVGenerally, application to specific problems begins with some flow assumptions and initial/boundary condition formulation, this may be followed by scale analysis to further simplify the problem.
p7244
aVa)
p7245
aVAssume steady, parallel, one dimensional, non-convective pressure-driven flow between parallel plates, the resulting scaled (dimensionless) boundary value problem is:
p7246
aVformula_51
p7247
aVThe boundary condition is the no slip condition. This problem is easily solved for the flow field:
p7248
aVformula_52
p7249
aVFrom this point onward more quantities of interest can be easily obtained, such as viscous drag force or net flow rate.
p7250
aVb)
p7251
aVDifficulties may arise when the problem becomes slightly more complicated. A seemingly modest twist on the parallel flow above would be the "radial" flow between parallel plates; this involves convection and thus non-linearity. The velocity field may be represented by a function formula_53 that must satisfy:
p7252
aVformula_54
p7253
aVThis ordinary differential equation is what is obtained when the Navier\u2013Stokes equations are written and the flow assumptions applied (additionally, the pressure gradient is solved for). The nonlinear term makes this a very difficult problem to solve analytically (a lengthy implicit solution may be found which involves elliptic integrals and roots of cubic polynomials). Issues with the actual existence of solutions arise for R > 1.41 (approximately; this is not the square root of 2), the parameter R being the Reynolds number with appropriately chosen scales. This is an example of flow assumptions losing their applicability, and an example of the difficulty in "high" Reynolds number flows.
p7254
aVExact solutions of the Navier\u2013Stokes equations.
p7255
aVSome exact solutions to the Navier\u2013Stokes equations exist. Examples of degenerate cases \u2014 with the non-linear terms in the Navier\u2013Stokes equations equal to zero \u2014 are Poiseuille flow, Couette flow and the oscillatory Stokes boundary layer. But also more interesting examples, solutions to the full non-linear equations, exist; for example the Taylor\u2013Green vortex.
p7256
aVNote that the existence of these exact solutions does not imply they are stable: turbulence may develop at higher Reynolds numbers.
p7257
aVA three-dimensional steady-state vortex solution.
p7258
aVA nice steady-state example with no singularities comes from considering the flow along the lines of a Hopf fibration. Let r be a constant radius to the inner coil. One set of solutions is given by:
p7259
aVformula_55
p7260
aVfor arbitrary constants A and B. This is a solution in a non-viscous gas (compressible fluid) whose density, velocities and pressure goes to zero far from the origin. (Note this is not a solution to the Clay Millennium problem because that refers to incompressible fluids where formula_2 is a constant, neither does it deal with the uniqueness of the Navier\u2013Stokes equations with respect to any turbulence properties.) It is also worth pointing out that the components of the velocity vector are exactly those from the Pythagorean quadruple parametrization. Other choices of density and pressure are possible with the same velocity field:
p7261
aVWyld diagrams.
p7262
aVWyld diagrams are bookkeeping graphs that correspond to the Navier\u2013Stokes equations via a perturbation expansion of the fundamental continuum mechanics. Similar to the Feynman diagrams in quantum field theory, these diagrams are an extension of Keldysh's technique for nonequilibrium processes in fluid dynamics. In other words, these diagrams assign graphs to the (often) turbulent phenomena in turbulent fluids by allowing correlated and interacting fluid particles to obey stochastic processes associated to pseudo-random functions in probability distributions.
p7263
aVNavier\u2013Stokes equations use in games.
p7264
aVThe Navier\u2013Stokes equations are used extensively in video games in order to model a wide variety of natural phenomena. Simulations of small-scale gaseous fluids, such as fire and smoke, are often based on the seminal paper "Real-Time Fluid Dynamics for Games" by Jos Stam, which elaborates one of the methods proposed in Stam's earlier, more famous paper "Stable Fluids" from 1999. Stam proposes stable fluid simulation using a Navier\u2013Stokes solution method from 1968, coupled with an unconditionally stable semi-Lagrangian advection scheme, as first proposed in 1992.
p7265
aVMore recent implementations based upon this work run on the GPU as opposed to the CPU and achieve a much higher degree of performance.
p7266
aVMany improvements have been proposed to Stam's original work, which suffers inherently from high numerical dissipation in both velocity and mass.
p7267
aVAn introduction to interactive fluid simulation can be found in the 2007 ACM SIGGRAPH course, Fluid Simulation for Computer Animation.
p7268
asS'Postulate'
p7269
(lp7270
sS'Cryptanalysis'
p7271
(lp7272
VCryptanalysis (from the Greek "kryptós", "hidden", and "analýein", "to loosen" or "to untie") is the study of analyzing information systems in order to study the hidden aspects of the systems. Cryptanalysis is used to breach cryptographic security systems and gain access to the contents of encrypted messages, even if the cryptographic key is unknown.
p7273
aVIn addition to mathematical analysis of cryptographic algorithms, cryptanalysis also includes the study of side-channel attacks that do not target weaknesses in the cryptographic algorithms themselves, but instead exploit weaknesses in their implementation.
p7274
aVEven though the goal has been the same, the methods and techniques of cryptanalysis have changed drastically through the history of cryptography, adapting to increasing cryptographic complexity, ranging from the pen-and-paper methods of the past, through machines like the British Bombes and Colossus computers at Bletchley Park in World War II, to the mathematically advanced computerized schemes of the present. Methods for breaking modern cryptosystems often involve solving carefully constructed problems in pure mathematics, the best-known being integer factorization.
p7275
aVOverview.
p7276
aVGiven some encrypted data ("ciphertext"), the goal of the "cryptanalyst" is to gain as much information as possible about the original, unencrypted data ("plaintext").
p7277
aVAmount of information available to the attacker.
p7278
aVAttacks can be classified based on what type of information the attacker has available. As a basic starting point it is normally assumed that, for the purposes of analysis, the general algorithm is known; this is Shannon's Maxim "the enemy knows the system"\u2014in its turn, equivalent to Kerckhoffs' principle. This is a reasonable assumption in practice \u2014 throughout history, there are countless examples of secret algorithms falling into wider knowledge, variously through espionage, betrayal and reverse engineering. (And on occasion, ciphers have been reconstructed through pure deduction; for example, the German Lorenz cipher and the Japanese Purple code, and a variety of classical schemes).:
p7279
aVComputational resources required.
p7280
aVAttacks can also be characterised by the resources they require. Those resources include:
p7281
aVIt's sometimes difficult to predict these quantities precisely, especially when the attack isn't practical to actually implement for testing. But academic cryptanalysts tend to provide at least the estimated "order of magnitude" of their attacks' difficulty, saying, for example, "SHA-1 collisions now 252."
p7282
aVBruce Schneier notes that even computationally impractical attacks can be considered breaks: "Breaking a cipher simply means finding a weakness in the cipher that can be exploited with a complexity less than brute force. Never mind that brute-force might require 2128 encryptions; an attack requiring 2110 encryptions would be considered a break...simply put, a break can just be a certificational weakness: evidence that the cipher does not perform as advertised."
p7283
aVPartial breaks.
p7284
aVThe results of cryptanalysis can also vary in usefulness. For example, cryptographer Lars Knudsen (1998) classified various types of attack on block ciphers according to the amount and quality of secret information that was discovered:
p7285
aVAcademic attacks are often against weakened versions of a cryptosystem, such as a block cipher or hash function with some rounds removed. Many, but not all, attacks become exponentially more difficult to execute as rounds are added to a cryptosystem, so it's possible for the full cryptosystem to be strong even though reduced-round variants are weak. Nonetheless, partial breaks that come close to breaking the original cryptosystem may mean that a full break will follow; the successful attacks on DES, MD5, and SHA-1 were all preceded by attacks on weakened versions.
p7286
aVIn academic cryptography, a "weakness" or a "break" in a scheme is usually defined quite conservatively: it might require impractical amounts of time, memory, or known plaintexts. It also might require the attacker be able to do things many real-world attackers can't: for example, the attacker may need to choose particular plaintexts to be encrypted or even to ask for plaintexts to be encrypted using several keys related to the secret key. Furthermore, it might only reveal a small amount of information, enough to prove the cryptosystem imperfect but too little to be useful to real-world attackers. Finally, an attack might only apply to a weakened version of cryptographic tools, like a reduced-round block cipher, as a step towards breaking of the full system.
p7287
aVHistory of cryptanalysis.
p7288
aVCryptanalysis has coevolved together with cryptography, and the contest can be traced through the history of cryptography\u2014new ciphers being designed to replace old broken designs, and new cryptanalytic techniques invented to crack the improved schemes. In practice, they are viewed as two sides of the same coin: in order to create secure cryptography, you have to design against possible cryptanalysis.
p7289
aVSuccessful cryptanalysis has undoubtedly influenced history; the ability to read the presumed-secret thoughts and plans of others can be a decisive advantage. For example, in England in 1587, Mary, Queen of Scots was tried and executed for treason as a result of her involvement in three plots to assassinate Elizabeth I of England. The plans came to light after her coded correspondence with fellow conspirators was deciphered by Thomas Phelippes.
p7290
aVIn World War I, the breaking of the Zimmermann Telegram was instrumental in bringing the United States into the war. In World War II, the Allies benefitted enormously from their joint success cryptanalysis of the German ciphers \u2014 including the Enigma machine and the Lorenz cipher \u2014 and Japanese ciphers, particularly 'Purple' and JN-25. 'Ultra' intelligence has been credited with everything between shortening the end of the European war by up to two years, to determining the eventual result. The war in the Pacific was similarly helped by 'Magic' intelligence.
p7291
aVGovernments have long recognized the potential benefits of cryptanalysis for intelligence, both military and diplomatic, and established dedicated organizations devoted to breaking the codes and ciphers of other nations, for example, GCHQ and the NSA, organizations which are still very active today. In 2004, it was reported that the United States had broken Iranian ciphers. (It is unknown, however, whether this was pure cryptanalysis, or whether other factors were involved:).
p7292
aVClassical ciphers.
p7293
aVAlthough the actual word ""cryptanalysis"" is relatively recent (it was coined by William Friedman in 1920), methods for breaking codes and ciphers are much older. The first known recorded explanation of cryptanalysis was given by 9th-century Arabian polymath, Al-Kindi (also known as "Alkindus" in Europe), in "A Manuscript on Deciphering Cryptographic Messages". This treatise includes a description of the method of frequency analysis (Ibrahim Al-Kadi, 1992- ref-3). Italian scholar Giambattista della Porta was author of a seminal work on cryptanalysis ""De Furtivis Literarum Notis"."
p7294
aVFrequency analysis is the basic tool for breaking most classical ciphers. In natural languages, certain letters of the alphabet appear more frequently than others; in English, "E" is likely to be the most common letter in any sample of plaintext. Similarly, the digraph "TH" is the most likely pair of letters in English, and so on. Frequency analysis relies on a cipher failing to hide these statistics. For example, in a simple substitution cipher (where each letter is simply replaced with another), the most frequent letter in the ciphertext would be a likely candidate for "E". Frequency analysis of such a cipher is therefore relatively easy, provided that the ciphertext is long enough to give a reasonably representative count of the letters of the alphabet that it contains.
p7295
aVIn Europe during the 15th and 16th centuries, the idea of a polyalphabetic substitution cipher was developed, among others by the French diplomat Blaise de Vigenère (1523\u201396). For some three centuries, the Vigenère cipher, which uses a repeating key to select different encryption alphabets in rotation, was considered to be completely secure ("le chiffre indéchiffrable"\u2014"the indecipherable cipher"). Nevertheless, Charles Babbage (1791\u20131871) and later, independently, Friedrich Kasiski (1805\u201381) succeeded in breaking this cipher. During World War I, inventors in several countries developed rotor cipher machines such as Arthur Scherbius' Enigma, in an attempt to minimise the repetition that had been exploited to break the Vigenère system.
p7296
aVCiphers from World War I and World War II.
p7297
aVCryptanalysis of enemy messages played a significant part in the Allied victory in World War II. F. W. Winterbotham, quoted the western Supreme Allied Commander, Dwight D. Eisenhower, at the war's end as describing Ultra intelligence as having been "decisive" to Allied victory. Sir Harry Hinsley, official historian of British Intelligence in World War II, made a similar assessment about Ultra, saying that it shortened the war "by not less than two years and probably by four years"; moreover, he said that in the absence of Ultra, it is uncertain how the war would have ended.
p7298
aVIn practice, frequency analysis relies as much on linguistic knowledge as it does on statistics, but as ciphers became more complex, mathematics became more important in cryptanalysis. This change was particularly evident before and during World War II, where efforts to crack Axis ciphers required new levels of mathematical sophistication. Moreover, automation was first applied to cryptanalysis in that era with the Polish Bomba device, the British Bombe, the use of punched card equipment, and in the Colossus computers \u2014 the first electronic digital computers to be controlled by a program.
p7299
aVIndicator.
p7300
aVWith reciprocal machine ciphers such as the Lorenz cipher and the Enigma machine used by Nazi Germany during World War II, each message had its own key. Usually, the transmitting operator informed the receiving operator of this message key by transmitting some plaintext and/or ciphertext before the enciphered message. This is termed the "indicator", as it indicates to the receiving operator how to set his machine to decipher the message.
p7301
aVPoorly designed and implemented indicator systems allowed first the Poles and then the British at Bletchley Park to break the Enigma cipher system. Similar poor indicator systems allowed the British to identify "depths" that led to the diagnosis of the Lorenz SZ40/42 cipher system, and the comprehensive breaking of its messages without the cryptanalysts seeing the cipher machine.
p7302
aVDepth.
p7303
aVSending two or more messages with the same key is an insecure process. To a cryptanalyst the messages are then said to be "in depth". This may be detected by the messages having the same "indicator" by which the sending operator informs the receiving operator about the key generator initial settings for the message.
p7304
aVGenerally, the cryptanalyst may benefit from lining up identical enciphering operations among a set of messages. For example the Vernam cipher enciphers by bit-for-bit combining plaintext with a long key using the "exclusive or" operator, which is also known as "modulo-2 addition" (symbolized by \u2295 ):
p7305
aV:::Plaintext \u2295 Key = Ciphertext
p7306
aVDeciphering combines the same key bits with the ciphertext to reconstruct the plaintext:
p7307
aV:::Ciphertext \u2295 Key = Plaintext 
p7308
aV(In modulo-2 arithmetic, addition is the same as subtraction.) When two such ciphertexts are aligned in depth, combining them eliminates the common key, leaving just a combination of the two plaintexts: 
p7309
aV:::Ciphertext1 \u2295 Ciphertext2 = Plaintext1 \u2295 Plaintext2
p7310
aVThe individual plaintexts can then be worked out linguistically by trying "probable words" (or phrases) at various locations; a correct guess, when combined with the merged plaintext stream, produces intelligible text from the other plaintext component:
p7311
aV:::(Plaintext1 \u2295 Plaintext2) \u2295 Plaintext1 = Plaintext2
p7312
aVThe recovered fragment of the second plaintext can often be extended in one or both directions, and the extra characters can be combined with the merged plaintext stream to extend the first plaintext. Working back and forth between the two plaintexts, using the intelligibility criterion to check guesses, the analyst may recover much or all of the original plaintexts. (With only two plaintexts in depth, the analyst may not know which one corresponds to which ciphertext, but in practice this is not a large problem.) When a recovered plaintext is then combined with its ciphertext, the key is revealed: 
p7313
aV:::Plaintext1 \u2295 Ciphertext1 = Key
p7314
aVKnowledge of a key of course allows the analyst to read other messages encrypted with the same key, and knowledge of a set of related keys may allow cryptanalysts to diagnose the system used for constructing them.
p7315
aVThe development of modern cryptography.
p7316
aVEven though computation was used to great effect in Cryptanalysis of the Lorenz cipher and other systems during World War II, it also made possible new methods of cryptography orders of magnitude more complex than ever before. Taken as a whole, modern cryptography has become much more impervious to cryptanalysis than the pen-and-paper systems of the past, and now seems to have the upper hand against pure cryptanalysis. The historian David Kahn notes:
p7317
aVKahn goes on to mention increased opportunities for interception, bugging, side channel attacks, and quantum computers as replacements for the traditional means of cryptanalysis. In 2010, former NSA technical director Brian Snow said that both academic and government cryptographers are "moving very slowly forward in a mature field."
p7318
aVHowever, any postmortems for cryptanalysis may be premature. While the effectiveness of cryptanalytic methods employed by intelligence agencies remains unknown, many serious attacks against both academic and practical cryptographic primitives have been published in the modern era of computer cryptography:
p7319
aVThus, while the best modern ciphers may be far more resistant to cryptanalysis than the Enigma, cryptanalysis and the broader field of information security remain quite active.
p7320
aVCryptanalysis of asymmetric ciphers.
p7321
aVAsymmetric cryptography (or public key cryptography) is cryptography that relies on using two (mathematically related) keys; one private, and one public. Such ciphers invariably rely on "hard" mathematical problems as the basis of their security, so an obvious point of attack is to develop methods for solving the problem. The security of two-key cryptography depends on mathematical questions in a way that single-key cryptography generally does not, and conversely links cryptanalysis to wider mathematical research in a new way.
p7322
aVAsymmetric schemes are designed around the (conjectured) difficulty of solving various mathematical problems. If an improved algorithm can be found to solve the problem, then the system is weakened. For example, the security of the Diffie-Hellman key exchange scheme depends on the difficulty of calculating the discrete logarithm. In 1983, Don Coppersmith found a faster way to find discrete logarithms (in certain groups), and thereby requiring cryptographers to use larger groups (or different types of groups). RSA's security depends (in part) upon the difficulty of integer factorization \u2014 a breakthrough in factoring would impact the security of RSA.
p7323
aVIn 1980, one could factor a difficult 50-digit number at an expense of 1012 elementary computer operations. By 1984 the state of the art in factoring algorithms had advanced to a point where a 75-digit number could be factored in 1012 operations. Advances in computing technology also meant that the operations could be performed much faster, too. Moore's law predicts that computer speeds will continue to increase. Factoring techniques may continue to do so as well, but will most likely depend on mathematical insight and creativity, neither of which has ever been successfully predictable. 150-digit numbers of the kind once used in RSA have been factored. The effort was greater than above, but was not unreasonable on fast modern computers. By the start of the 21st century, 150-digit numbers were no longer considered a large enough key size for RSA. Numbers with several hundred digits were still considered too hard to factor in 2005, though methods will probably continue to improve over time, requiring key size to keep pace or other methods such as elliptic curve cryptography to be used.
p7324
aVAnother distinguishing feature of asymmetric schemes is that, unlike attacks on symmetric cryptosystems, any cryptanalysis has the opportunity to make use of knowledge gained from the public key.
p7325
aVQuantum computing applications for cryptanalysis.
p7326
aVQuantum computers, which are still in the early phases of research, have potential use in cryptanalysis. For example, Shor's Algorithm could factor large numbers in polynomial time, in effect breaking some commonly used forms of public-key encryption.
p7327
aVBy using Grover's algorithm on a quantum computer, brute-force key search can be made quadratically faster. However, this could be countered by doubling the key length.
p7328
asS'On-Line Encyclopedia of Integer Sequences'
p7329
(lp7330
VThe On-Line Encyclopedia of Integer Sequences (OEIS), also cited simply as Sloane's, is an online database of integer sequences. It was created and maintained by Neil Sloane while a researcher at AT&T Labs. Foreseeing his retirement from AT&T Labs in 2012 and the need for an independent foundation, Sloane agreed to transfer the intellectual property and hosting of the OEIS to the OEIS Foundation'" in October 2009. Sloane continues to be involved in the OEIS in his role as President of the OEIS Foundation.
p7331
aVOEIS records information on integer sequences of interest to both professional mathematicians and amateurs, and is widely cited. it contains over 250,000 sequences, making it the largest database of its kind.
p7332
aVEach entry contains the leading terms of the sequence, keywords, mathematical motivations, literature links, and more, including the option to generate a graph or play a musical representation of the sequence. The database is searchable by keyword and by subsequence.
p7333
aVHistory.
p7334
aVNeil Sloane started collecting integer sequences as a graduate student in 1965 to support his work in combinatorics. The database was at first stored on punch cards. He published selections from the database in book form twice:
p7335
aVThese books were well received and, especially after the second publication, mathematicians supplied Sloane with a steady flow of new sequences. The collection became unmanageable in book form, and when the database had reached 16,000 entries Sloane decided to go online\u2014first as an e-mail service (August 1994), and soon after as a web site (1996). As a spin-off from the database work, Sloane founded the Journal of Integer Sequences in 1998.
p7336
aVIn 2004, Sloane celebrated the addition of the 100,000th sequence to the database, , which counts the marks on the Ishango bone. In 2006, the user interface was overhauled and more advanced search capabilities were added. In 2010 an [//oeis.org/wiki/ OEIS wiki] at [//oeis.org/ OEIS.org] was created to simplify the collaboration of the OEIS editors and contributors. The 200,000th sequence, , was added to the database in November 2011; it was initially entered as A200715, and moved to A200000 after a week of discussion on the SeqFan mailing list, following a proposal by OEIS Editor-in-Chief Charles Greathouse to choose a special sequence for A200000.
p7337
aVNon-integers.
p7338
aVBesides integer sequences, the OEIS also catalogs sequences of fractions, the digits of transcendental numbers, complex numbers and so on by transforming them into integer sequences.
p7339
aVSequences of rationals are represented by two sequences (named with the keyword 'frac'): the sequence of numerators and the sequence of denominators. For example, the fifth order Farey sequence, formula_1, is catalogued as the numerator sequence 1, 1, 1, 2, 1, 3, 2, 3, 4 () and the denominator sequence 5, 4, 3, 5, 2, 5, 3, 4, 5 ().
p7340
aVImportant irrational numbers such as \u03c0 = 3.1415926535897... are catalogued under representative integer sequences such as decimal expansions (here 3, 1, 4, 1, 5, 9, 2, 6, ... ()), binary expansions (here 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, ... ()), or continued fraction expansions (here 3, 7, 15, 1, 292, 1, ... ()).
p7341
aVConventions.
p7342
aVThe OEIS was limited to plain ASCII text until 2011, yet still, it frequently uses a linear form of conventional mathematical notation (such as "f"("n") for functions, "n" for running variables, etc.). Greek letters are usually represented by their full names, "e.g.", mu for \u03bc, phi for \u03c6.
p7343
aVEvery sequence is identified by the letter A followed by six digits, sometimes referred to without the leading zeros, "e.g.", A315 rather than A000315.
p7344
aVIndividual terms of sequences are separated by commas. Digit groups are not separated by commas, periods, or spaces.
p7345
aVIn comments, formulas, etc., a(n) represents the "n"th term of the sequence.
p7346
aVSpecial meaning of zero.
p7347
aVZero is often used to represent non-existent sequence elements. For example, enumerates the "smallest prime of "n"² consecutive primes to form an "n"×"n" magic square of least magic constant, or 0 if no such magic square exists." The value of "a"(1) (a 1×1 magic square) is 2; "a"(3) is 1480028129. But there is no such 2×2 magic square, so "a"(2) is 0.
p7348
aVThis special usage has a solid mathematical basis in certain counting functions. For example, the totient valence function "N"\u03c6("m") () counts the solutions of \u03c6("x") = "m". There are 4 solutions for 4, but no solutions for 14, hence "a"(14) of A014197 is 0\u2014there are no solutions.
p7349
aVOccasionally \u22121 is used for this purpose instead, as in .
p7350
aVLexicographical ordering.
p7351
aVThe OEIS maintains the lexicographical order of the sequences, so each sequence has a predecessor and a successor (its "context"). OEIS normalizes the sequences for lexicographical ordering, (usually) ignoring all initial zeros and ones, and also the sign of each element. Sequences of weight distribution codes often omit periodically recurring zeros.
p7352
aVFor example, consider: the prime numbers, the palindromic primes, the Fibonacci sequence, the lazy caterer's sequence, and the coefficients in the series expansion of formula_2. In OEIS lexicographic order, they are:
p7353
aVwhereas unnormalized lexicographic ordering would order these sequences thus: #3, #5, #4, #1, #2.
p7354
aVSelf-referential sequences.
p7355
aVVery early in the history of the OEIS, sequences defined in terms of the numbering of sequences in the OEIS itself were proposed. "I resisted adding these sequences for a long time, partly out of a desire to maintain the dignity of the database, and partly because A22 was only known to 11 terms!", Sloane reminisced.
p7356
aVOne of the earliest self-referential sequences Sloane accepted into the OEIS was (later ) ""a"("n") = "n"-th term of sequence A"n"". This sequence spurred progress on finding more terms of . Some sequences are both finite and listed in full (keywords "fini" and "full"); these sequences will never be long enough to contain a term that corresponds to their OEIS sequence number. In this case the corresponding term "a"("n") of A091967 is undefined (the first case is "n" = 53)
p7357
aVThis line of thought leads to the question "Does sequence A"n" contain the number "n" ?" and the sequences , "Numbers "n" such that OEIS sequence A"n" contains "n", and , "n" is in this sequence if and only if "n" is not in sequence A"n"". Thus, the composite number 2808 is in A053873 because is the sequence of composite numbers, while the non-prime 40 is in A053169 because it's not in , the prime numbers. Each "n" is a member of exactly one of these two sequences, and in principle it can be determined "which" sequence each "n" belongs to, with two exceptions (related to the two sequences themselves):
p7358
aVAn abridged example of a typical OEIS entry.
p7359
aVThis entry, , was chosen because it contains every field an OEIS entry can have.
p7360
aVEntry fields.
p7361
aVSee [//oeis.org/eishelp2.html Format of OEIS Pages].
p7362
aV Every sequence in the OEIS has a serial number, a six-digit positive integer, prefixed by A (and zero-padded on the left prior to November 2004). The letter "A" stands for "absolute." Numbers are either assigned by the editor(s) or by an A number dispenser, which is handy for when contributors wish to send in related sequences at once and be able to create cross-references. An A number from the dispenser expires a month from issue if not used. But as the following table of arbitrarily selected sequences show, the rough correspondence holds.
p7363
aV Even for sequences in the book predecessors to the OEIS, the ID numbers are not the same. The 1973 "Handbook of Integer Sequences" contained about 2400 sequences, which were numbered by lexicographic order (the letter M plus 4 digits, zero-padded where necessary), and the 1995 "Encyclopedia of Integer Sequences" contained 5487 sequences, also numbered by lexicographic order (the letter N plus 4 digits, zero-padded where necessary). These old M and N numbers, as applicable, are contained in the ID number field in parentheses after the modern A number.
p7364
aV The sequence field lists the numbers themselves, or at least about four lines' worth. The sequence field makes no distinction between sequences that are finite but still too long to display and sequences that are infinite. To help make that determination, you need to look at the keywords field for "fini," "full," or "more." To determine to which "n" the values given correspond, see the offset field, which gives the "n" for the first term given.
p7365
aV The name field usually contains the most common name for the sequence, and sometimes also the formula. For example, 1, 8, 27, 64, 125, 216, 343, 512, () is named "The cubes: a(n) = n^3.".
p7366
aV The comments field is for information about the sequence that doesn't quite fit in any of the other fields. The comments field often points out interesting relationships between different sequences and less obvious applications for a sequence. For example, Lekraj Beedassy in a comment to A000578 notes that the cube numbers also count the "total number of triangles resulting from criss-crossing cevians within a triangle so that two of its sides are each n-partitioned," while Sloane points out the unexpected relationship between centered hexagonal numbers () and second Bessel polynomials () in a comment to A003215.
p7367
aV References to printed documents (books, papers, ...).
p7368
aV Links, i.e. URLs, to online resources. These may be:
p7369
aV# references to applicable articles in journals
p7370
aV# links to the index
p7371
aV# links to text files which hold the sequence terms (in a two column format) over a wider range of indices than held by the main database lines
p7372
aV# links to images in the local database directories which often provide combinatorial background related to graph theory
p7373
aV# others related to computer codes, more extensive tabulations in specific research areas provided by individuals or research groups
p7374
aV Formulae, recurrences, generating functions, etc. for the sequence.
p7375
aV Some examples of sequence member values.
p7376
aV Maple code.
p7377
aV Wolfram Language code.
p7378
aV Maple and Mathematica were the preferred programs for calculating sequences in the OEIS, and they both got their own field labels, "Maple" and "Mathematica." As of Jan 2009, Mathematica was the most popular choice with over 25,000 Mathematica programs followed by 13,000 Maple programs. As of 2012, there are over 25,000 programs in PARI and more than 3000 in other languages, all of which are entered in the generic "Program" field and labelled with the name of the programming language in parentheses.
p7379
aV As for any other part of the record, if there is no name given, the contribution (here: program) was written by the original submitter of the sequence.
p7380
aV Sequence cross-references originated by the original submitter are usually denoted by "Cf."
p7381
aV Except for new sequences, the see also field also includes information on the lexicographic order of the sequence (its "context") and provides links to sequences with close A numbers (A046967, A046968, A046969, A046971, A046972, A046973, in our example). The following table shows the context of our example sequence, A046970:
p7382
aV The OEIS has its own standard set of four or five letter keywords that characterize each sequence:
p7383
aV* base The results of the calculation depend on a specific positional base. For example, 2, 3, 5, 7, 11, 101, 131, 151, 181 ... are prime numbers regardless of base, but they are palindromic specifically in base 10. Most of them are not palindromic in binary. Some sequences rate this keyword depending on how they're defined. For example, the Mersenne primes 3, 7, 31, 127, 8191, 131071, ... does not rate "base" if defined as "primes of the form 2^n - 1." However, defined as "repunit primes in binary," the sequence would rate the keyword "base."
p7384
aV* bref "sequence is too short to do any analysis with", for example, , Number of isomorphism classes of associative non-commutative non-anti-associative anti-commutative closed binary operations on a set of order n.
p7385
aV* cofr The sequence represents a continued fraction, for example, continued fraction expansion of "e" () or \u03c0 ().
p7386
aV* cons The sequence is a decimal expansion of an important mathematical constant, like "e" () or \u03c0 ().
p7387
aV* core A sequence that is of foundational importance to a branch of mathematics, such as the prime numbers (), the Fibonacci sequence (), etc.
p7388
aV* dead This keyword used for erroneous sequences that have appeared in papers or books, or for duplicates of existing sequences. For example, is the same as .
p7389
aV* dumb One of the more subjective keywords, for "unimportant sequences," which may or may not directly relate to mathematics. , "Mix digits of pi and e." is one example of the former, and , "Numbers on a computer numpad, read in a spiral." is an example of the latter.
p7390
aV* easy The terms of the sequence can be easily calculated. Perhaps the sequence most deserving of this keyword is 1, 2, 3, 4, 5, 6, 7, ... , where each term is 1 more than the previous term. The keyword "easy" is sometimes given to sequences "primes of the form f(m)" where f(m) is an easily calculated function. (Though even if f(m) is easy to calculate for large m, it might be very difficult to determine if f(m) is prime).
p7391
aV* eigen A sequence of eigenvalues.
p7392
aV* fini The sequence is finite, although it might still contain more terms than can be displayed. For example, the sequence field of shows only about a quarter of all the terms, but a comment notes that the last term is 3888.
p7393
aV* frac A sequence of either numerators or denominators of a sequence of fractions representing rational numbers. Any sequence with this keyword ought to be cross-referenced to its matching sequence of numerators or denominators, though this may be dispensed with for sequences of Egyptian fractions, such as , where the sequence of numerators would be . This keyword should not be used for sequences of continued fractions, cofr should be used instead for that purpose.
p7394
aV* full The sequence field displays the complete sequence. If a sequence has the keyword "full," it should also have the keyword "fini." One example of a finite sequence given in full is that of the supersingular primes , of which there are precisely fifteen.
p7395
aV* hard The terms of the sequence cannot be easily calculated, even with raw number crunching power. This keyword is most often used for sequences corresponding to unsolved problems, such as "How many "n"-spheres can touch another "n"-sphere of the same size?" lists the first ten known solutions.
p7396
aV* less A "less interesting sequence".
p7397
aV* more More terms of the sequence are wanted. Readers can submit an extension.
p7398
aV* mult The sequence corresponds to a multiplicative function. Term a(1) should be 1, and term a(mn) can be calculated by multiplying a(m) by a(n) if m and n are coprime. For example, in , a(12) = a(3)a(4) = -8 × -3.
p7399
aV* new For sequences that were added in the last couple of weeks, or had a major extension recently. This keyword is not given a checkbox in the Web form for submitting new sequences, Sloane's program adds it by default where applicable.
p7400
aV* nice Perhaps the most subjective keyword of all, for "exceptionally nice sequences."
p7401
aV* nonn The sequence consists of nonnegative integers (it may include zeroes). No distinction is made between sequences that consist of nonnegative numbers only because of the chosen offset (e.g., "n"3, the cubes, which are all positive from "n" = 0 forwards) and those that by definition are completely nonnegative (e.g., "n"2, the squares).
p7402
aV* obsc The sequence is considered obscure and needs a better definition.
p7403
aV* probation Sequences that "may be deleted later at the discretion of the editor."
p7404
aV* sign Some (or all) of the values of the sequence are negative. The entry includes both a Signed field with the signs and a Sequence field consisting of all the values passed through the absolute value function.
p7405
aV* tabf "An irregular (or funny-shaped) array of numbers made into a sequence by reading it row by row." For example, , "Triangle read by rows giving successive states of cellular automaton generated by "rule 62."
p7406
aV* tabl A sequence obtained by reading a geometric arrangement of numbers, such as a triangle or square, row by row. The quintessential example is Pascal's triangle read by rows, .
p7407
aV* uned Sloane has not edited the sequence but believes it could be worth including in the OEIS. The sequence could contain computational or typographical errors. Contributors are invited to ponder the sequence and send Sloane their edition.
p7408
aV* unkn "Little is known" about the sequence, not even the formula that produces it. For example, , which was presented to the Internet Oracle to ponder.
p7409
aV* walk "Counts walks (or self-avoiding paths)."
p7410
aV* word Depends on the words of a specific language. For example, zero, one, two, three, four, five, etc. For example, 4, 3, 3, 5, 4, 4, 3, 5, 5, 4, 3, 6, 6, 8, 8, 7, 7, 9, 8, 8 ... , "Number of letters in the English name of n, excluding spaces and hyphens."
p7411
aV Some keywords are mutually exclusive, namely: core and dumb, easy and hard, full and more, less and nice, and nonn and sign.
p7412
aV The offset is the index of the first term given. For some sequences, the offset is obvious. For example, if we list the sequence of square numbers as 0, 1, 4, 9, 16, 25 ..., the offset is 0; while if we list it as 1, 4, 9, 16, 25 ..., the offset is 1. The default offset is 0, and most sequences in the OEIS have offset of either 0 or 1. Sequence , the magic constant for "n"×"n" magic square with prime entries (regarding 1 as a prime) with smallest row sums, is an example of a sequence with offset 3, and , "Number of stars of visual magnitude "n"." is an example of a sequence with offset -1. Sometimes there can be disagreement over what the initial terms of the sequence are, and correspondingly what the offset should be. In the case of the lazy caterer's sequence, the maximum number of pieces you can cut a pancake into with "n" cuts, the OEIS gives the sequence as 1, 2, 4, 7, 11, 16, 22, 29, 37, ... , with offset 0, while Mathworld gives the sequence as 2, 4, 7, 11, 16, 22, 29, 37, ... (implied offset 1). It can be argued that making no cuts to the pancake is technically a number of cuts, namely "n" = 0. But it can also be argued that an uncut pancake is irrelevant to the problem. Although the offset is a required field, some contributors don't bother to check if the default offset of 0 is appropriate to the sequence they are sending in. The internal format actually shows two numbers for the offset. The first is the number described above, while the second represents the index of the first entry (counting from 1) that has an absolute value greater than 1. This second value is used to speed up the process of searching for a sequence. Thus , which starts 1, 1, 1, 2 with the first entry representing a(1) has 1, 4 as the internal value of the offset field.
p7413
aV The author(s) of the sequence is (are) the person(s) who submitted the sequence, even if the sequence has been known since ancient times. The name of the submitter(s) is given first name (spelled out in full), middle initial(s) (if applicable) and last name; this in contrast to the way names are written in the reference fields. The e-mail address of the submitter is also given, with the @ character replaced by "(AT)" with some exceptions such as for associate editors or if an e-mail address does not exist. For most sequences after A055000, the author field also includes the date the submitter sent in the sequence.
p7414
aV Names of people who extended (added more terms to) the sequence, followed by date of extension.
p7415
aVSearching the OEIS.
p7416
aVThe previous version of the main look-up page of the OEIS offered three ways to look up sequences, and the right radio button had to be selected. There was an advanced look-up page, but its usefulness has been integrated into the main look-up page in a major redesign of the interface in January 2006.
p7417
aVEnter a sequence.
p7418
aVEnter a few terms of the sequence, separated by either spaces or commas (or both).
p7419
aVYou can enter negative signs, but they will be ignored. For example, 0, 3, 7, 13, 20, 28, 36, 43, 47, 45, 32, 0, \u221264, "n"2 minus the "n"th Fibonacci number, is a sequence that is technically not in the OEIS, but the very similar sequence 0, \u22123, \u22127, \u221213, \u221220, \u221228, \u221236, \u221243, \u221247, \u221245, \u221232, 0, 64, is in the OEIS and will come up when one searches for its reversed signs counterpart.
p7420
aVHowever, the search can be forced to match signs by using the prefix "signed:" in the search string. This is especially useful for sequences like that consist exclusively of positive and negative ones.
p7421
aVOne can enter as little as a single integer or as much as four lines of terms. Sloane recommends entering six terms, "a"(2) to "a"(7), in order to get enough results, but not too many results. There are cases where entering just one integer gives precisely one result, such as 6610199 brings up just (the strobogrammatic primes which are not palindromic). There are also cases where one can enter many terms and still not narrow the results down very much.
p7422
aVEnter a word.
p7423
aVEnter a string of alphanumerical characters. Certain characters, like accented foreign letters, are not allowed. Thus, to search for sequences relating to Znám's problem, try enter it without the accents: "Znam's problem." The handling of apostrophes has been greatly improved in the 2006 redesign. The search strings "Pascal's triangle," "Pascals triangle" and "Pascal triangle" all give the desired results.
p7424
aVTo look up most polygonal numbers by word, try "n-gonal numbers" rather than "Greek prefix-gonal numbers" (e.g., "47-gonal numbers" instead of "heptaquartagonal numbers"). Beyond "dodecagonal numbers," word searching with the Greek prefixes might fail to yield the desired results.
p7425
aVEnter a sequence number.
p7426
aVEnter the modern OEIS A number of the sequence, with the letter A and with or without zero-padding. As of 2006, the old M and N sequence numbers will yield the proper result as search strings, e.g., a search for M0422 will correctly bring up , the number of entries in "n"th row of Pascal's triangle not divisible by 3 (M0422 in the book "The Encyclopedia of Integer Sequences") and not , concatenation of numbers from "n" down to 1.
p7427
asS'Power series'
p7428
(lp7429
VIn mathematics, a power series (in one variable) is an infinite series of the form
p7430
aVformula_1formula_2
p7431
aVwhere "an" represents the coefficient of the "n"th term, "c" is a constant, and "x" varies around "c" (for this reason one sometimes speaks of the series as being "centered" at "c"). This series usually arises as the Taylor series of some known function.
p7432
aVIn many situations "c" is equal to zero, for instance when considering a Maclaurin series. In such cases, the power series takes the simpler form
p7433
aVformula_3
p7434
aVThese power series arise primarily in analysis, but also occur in combinatorics (as generating functions, a kind of formal power series) and in electrical engineering (under the name of the Z-transform). The familiar decimal notation for real numbers can also be viewed as an example of a power series, with integer coefficients, but with the argument "x" fixed at . In number theory, the concept of p-adic numbers is also closely related to that of a power series.
p7435
aVExamples.
p7436
aVAny polynomial can be easily expressed as a power series around any center "c", although most of the coefficients will be zero since a power series has infinitely many terms by definition. For instance, the polynomial formula_4 can be written as a power series around the center formula_5 as
p7437
aV:formula_6
p7438
aVor around the center formula_7 as
p7439
aV:formula_8formula_9
p7440
aVor indeed around any other center "c". One can view power series as being like "polynomials of infinite degree," although power series are not polynomials.
p7441
aVThe geometric series formula
p7442
aV:formula_10
p7443
aVwhich is valid for formula_11, is one of the most important examples of a power series, as are the exponential function
p7444
aVformula
p7445
aV:formula_12
p7446
aVand the sine formula
p7447
aV:formula_13
p7448
aVvalid for all real x.
p7449
aVThese power series are also examples of Taylor series.
p7450
aVNegative powers are not permitted in a power series, for instance formula_14
p7451
aVis not considered a power series (although it is a Laurent series). Similarly, fractional powers such as formula_15 are not permitted (but see Puiseux series). The coefficients formula_16 are not allowed to depend on formula_17, thus for instance:
p7452
aVformula_18 is not a power series.
p7453
aVRadius of convergence.
p7454
aVA power series will converge for some values of the variable "x" and may diverge for others. All power series "f"("x") in powers of ("x"-"c") will converge at "x" = "c". (The correct value "f"("c") = "a"0 requires interpreting the expression 00 as equal to 1.) If "c" is not the only convergent point, then there is always a number "r" with 0 < "r" \u2264 \u221e such that the series converges whenever |"x" \u2212 "c"| < "r" and diverges whenever |"x" \u2212 "c"| > "r". The number "r" is called the radius of convergence of the power series; in general it is given as
p7455
aVformula_19
p7456
aVor, equivalently,
p7457
aVformula_20
p7458
aV(this is the Cauchy\u2013Hadamard theorem; see limit superior and limit inferior for an explanation of the notation). A fast way to compute it is
p7459
aVformula_21
p7460
aVif this limit exists.
p7461
aVThe series converges absolutely for |"x" \u2212 "c"| < "r" and converges uniformly on every compact subset of {"x" : |"x" \u2212 "c"| < "r"}. That is, the series is absolutely and compactly convergent on the interior of the disc of convergence.
p7462
aVFor |"x" \u2212 "c"| = "r", we cannot make any general statement on whether the series converges or diverges. However, for the case of real variables, Abel's theorem states that the sum of the series is continuous at "x" if the series converges at "x". In the case of complex variables, we can only claim continuity along the line segment starting at "c" and ending at "x".
p7463
aVOperations on power series.
p7464
aVAddition and subtraction.
p7465
aVWhen two functions "f" and "g" are decomposed into power series around the same center "c", the power series of the sum or difference of the functions can be obtained by termwise addition and subtraction. That is, if:
p7466
aVformula_22
p7467
aVformula_23
p7468
aVthen
p7469
aVformula_24
p7470
aVMultiplication and division.
p7471
aVWith the same definitions above, for the power series of the product and quotient of the functions can be obtained as follows:
p7472
aVformula_25
p7473
aVformula_26
p7474
aVformula_27
p7475
aVThe sequence formula_28 is known as the convolution of the sequences formula_16 and formula_30.
p7476
aVFor division, observe:
p7477
aVformula_31
p7478
aVformula_32
p7479
aVand then use the above, comparing coefficients.
p7480
aVDifferentiation and integration.
p7481
aVOnce a function is given as a power series, it is differentiable on the interior of the domain of convergence. It can be differentiated and integrated quite easily, by treating every term separately:
p7482
aV:formula_33
p7483
aV:formula_34
p7484
aVBoth of these series have the same radius of convergence as the original one.
p7485
aVAnalytic functions.
p7486
aVA function "f" defined on some open subset "U" of R or C is called analytic if it is locally given by a convergent power series. This means that every "a" \u2208 "U" has an open neighborhood "V" \u2286 "U", such that there exists a power series with center "a" which converges to "f"("x") for every "x" \u2208 "V".
p7487
aVEvery power series with a positive radius of convergence is analytic on the interior of its region of convergence. All holomorphic functions are complex-analytic. Sums and products of analytic functions are analytic, as are quotients as long as the denominator is non-zero.
p7488
aVIf a function is analytic, then it is infinitely often differentiable, but in the real case the converse is not generally true. For an analytic function, the coefficients "a""n" can be computed as
p7489
aV:formula_35
p7490
aVwhere formula_36 denotes the "n"th derivative of "f" at "c", and formula_37. This means that every analytic function is locally represented by its Taylor series.
p7491
aVThe global form of an analytic function is completely determined by its local behavior in the following sense: if "f" and "g" are two analytic functions defined on the same connected open set "U", and if there exists an element "c"\u2208"U" such that "f" ("n")("c") = "g" ("n")("c") for all "n" \u2265 0, then "f"("x") = "g"("x") for all "x" \u2208 "U".
p7492
aVIf a power series with radius of convergence "r" is given, one can consider analytic continuations of the series, i.e. analytic functions "f" which are defined on larger sets than { "x" : |"x" \u2212 "c"| < "r" } and agree with the given power series on this set. The number "r" is maximal in the following sense: there always exists a complex number "x" with |"x" \u2212 "c"| = "r" such that no analytic continuation of the series can be defined at "x".
p7493
aVThe power series expansion of the inverse function of an analytic function can be determined using the Lagrange inversion theorem.
p7494
aVFormal power series.
p7495
aVIn abstract algebra, one attempts to capture the essence of power series without being restricted to the fields of real and complex numbers, and without the need to talk about convergence. This leads to the concept of formal power series, a concept of great utility in algebraic combinatorics.
p7496
aVPower series in several variables.
p7497
aVAn extension of the theory is necessary for the purposes of multivariable calculus. A power series is here defined to be an infinite series of the form
p7498
aV:formula_38
p7499
aVwhere "j" = ("j"1, ..., "j""n") is a vector of natural numbers, the coefficients
p7500
aV"a"("j1...,jn") are usually real or complex numbers, and the center "c" = ("c"1, ..., "c""n") and argument "x" = ("x"1, ..., "x""n") are usually real or complex vectors. In the more convenient multi-index notation this can be written
p7501
aV:formula_39
p7502
aVThe theory of such series is trickier than for single-variable series, with more complicated regions of convergence. For instance, the power series formula_40 is absolutely convergent in the set formula_41 between two hyperbolas. (This is an example of a "log-convex set", in the sense that the set of points formula_42, where formula_43 lies in the above region, is a convex set. More generally, one can show that when c=0, the interior of the region of absolute convergence is always a log-convex set in this sense.) On the other hand, in the interior of this region of convergence one may differentiate and integrate under the series sign, just as one may with ordinary power series.
p7503
aVOrder of a power series.
p7504
aVLet \u03b1 be a multi-index for a power series "f"("x"1, "x"2, \u2026, "x""n"). The order of the power series "f" is defined to be the least value |\u03b1| such that "a"\u03b1 \u2260 0, or 0 if "f" \u2261 0. In particular, for a power series "f"("x") in a single variable "x", the order of "f" is the smallest power of "x" with a nonzero coefficient. This definition readily extends to Laurent series.
p7505
asS'Logarithmic spiral'
p7506
(lp7507
VA logarithmic spiral, equiangular spiral or growth spiral is a self-similar spiral curve which often appears in nature. The logarithmic spiral was first described by Descartes and later extensively investigated by Jacob Bernoulli, who called it "Spira mirabilis", "the marvelous spiral".
p7508
aVDefinition.
p7509
aVIn polar coordinates formula_1 the logarithmic curve can be written as
p7510
aVformula_2
p7511
aVor
p7512
aVformula_3
p7513
aVwith formula_4 being the base of natural logarithms, and formula_5 and formula_6 being arbitrary positive real constants.
p7514
aVIn parametric form, the curve is
p7515
aVformula_7
p7516
aVformula_8
p7517
aVwith real numbers formula_5 and formula_6.
p7518
aVThe spiral has the property that the angle "\u03c6" between the tangent and radial line at the point formula_1 is constant. This property can be expressed in differential geometric terms as
p7519
aVformula_12
p7520
aVThe derivative of formula_13 is proportional to the parameter formula_6. In other words, it controls how "tightly" and in which direction the spiral spirals. In the extreme case that formula_15 (formula_16) the spiral becomes a circle of radius formula_5. Conversely, in the limit that formula_6 approaches infinity ("\u03c6" \u2192 0) the spiral tends toward a straight half-line. The complement of "\u03c6" is called the "pitch".
p7521
aV"Spira mirabilis" and Jacob Bernoulli.
p7522
aVSpira mirabilis, Latin for "miraculous spiral", is another name for the logarithmic spiral. Although this curve had already been named by other mathematicians, the specific name ("miraculous" or "marvelous" spiral) was given to this curve by Jacob Bernoulli, because he was fascinated by one of its unique mathematical properties: the size of the spiral increases but its shape is unaltered with each successive curve, a property known as self-similarity. Possibly as a result of this unique property, the spira mirabilis has evolved in nature, appearing in certain growing forms such as nautilus shells and sunflower heads. Jacob Bernoulli wanted such a spiral engraved on his headstone along with the phrase "Eadem mutata resurgo" ("Although changed, I shall arise the same."), but, by error, an Archimedean spiral was placed there instead.
p7523
aVProperties.
p7524
aVThe logarithmic spiral can be distinguished from the Archimedean spiral by the fact that the distances between the turnings of a logarithmic spiral increase in geometric progression, while in an Archimedean spiral these distances are constant.
p7525
aVLogarithmic spirals are self-similar in that the result of applying any similarity transformation to the spiral is congruent to the original untransformed spiral. Scaling by a factor formula_19, for an integer "b", with the center of scaling at the origin, gives the same curve as the original; other scale factors give a curve that is rotated from the original position of the spiral. Logarithmic spirals are also congruent to their own involutes, evolutes, and the pedal curves based on their centers.
p7526
aVStarting at a point formula_20 and moving inward along the spiral, one can circle the origin an unbounded number of times without reaching it; yet, the total distance covered on this path is finite; that is, the limit as formula_21 goes toward formula_22 is finite. This property was first realized by Evangelista Torricelli even before calculus had been invented.
p7527
aVThe total distance covered is formula_23, where formula_24 is the straight-line distance from formula_20 to the origin.
p7528
aVThe exponential function exactly maps all lines not parallel with the real or imaginary axis in the complex plane, to all logarithmic spirals in the complex plane with centre at 0. (Up to adding integer multiples of formula_26 to the lines, the mapping of all lines to all logarithmic spirals is onto.) The pitch angle of the logarithmic spiral is the angle between the line and the imaginary axis.
p7529
aVThe function formula_27, where the constant formula_28 is a complex number with non-zero imaginary part, maps the real line to a logarithmic spiral in the complex plane.
p7530
aVThe golden spiral is a logarithmic spiral that grows outward by a factor of the golden ratio for every 90 degrees of rotation (pitch about 17.03239 degrees). It can be approximated by a "Fibonacci spiral", made of a sequence of quarter circles with radii proportional to Fibonacci numbers.
p7531
aVLogarithmic spirals in nature.
p7532
aVIn several natural phenomena one may find curves that are close to being logarithmic spirals. Here follows some examples and reasons:
p7533
asS'Riemann sphere'
p7534
(lp7535
VIn mathematics, the Riemann sphere, named after the 19th century mathematician Bernhard Riemann, is a model of the extended complex plane, the complex plane plus a point at infinity. This extended plane represents the extended complex numbers, that is, the complex numbers plus a value \u221e for infinity. With the Riemann model, the point "\u221e" is near to very large numbers, just as the point "0" is near to very small numbers.
p7536
aVThe extended complex numbers are useful in complex analysis because they allow for division by zero in some circumstances, in a way that makes expressions such as 1/0 = \u221e well-behaved. For example, any rational function on the complex plane can be extended to a continuous function on the Riemann sphere, with the poles of the rational function mapping to infinity. More generally, any meromorphic function can be thought of as a continuous function whose codomain is the Riemann sphere.
p7537
aVIn geometry, the Riemann sphere is the prototypical example of a Riemann surface, and is one of the simplest complex manifolds. In projective geometry, the sphere can be thought of as the complex projective line P1(C), the projective space of all complex lines in C2. As with any compact Riemann surface, the sphere may also be viewed as a projective algebraic curve, making it a fundamental example in algebraic geometry. It also finds utility in other disciplines that depend on analysis and geometry, such as quantum mechanics and other branches of physics.
p7538
aVExtended complex numbers.
p7539
aVThe extended complex numbers consist of the complex numbers C together with \u221e. The set of extended complex numbers may be written as C \u222a {\u221e}, and is often denoted by adding some decoration to the letter C, such as
p7540
aVformula_1
p7541
aVGeometrically, the set of extended complex numbers is referred to as the Riemann sphere (or extended complex plane).
p7542
aVArithmetic operations.
p7543
aVAddition of complex numbers may be extended by defining, for "z" \u2208 C,
p7544
aVformula_2
p7545
aVfor any complex number "z", and multiplication may be defined by
p7546
aVformula_3
p7547
aVfor all nonzero complex numbers "z", with \u221e \u22c5 \u221e = \u221e. Note that \u221e + \u221e, \u221e \u2013 \u221e and 0 \u22c5 \u221e are left undefined. Unlike the complex numbers, the extended complex numbers do not form a field, since \u221e does not have a multiplicative inverse. Nonetheless, it is customary to define division on C \u222a {\u221e} by
p7548
aVformula_4
p7549
aVfor all nonzero complex numbers "z", with \u221e/0 = \u221e and 0/\u221e = 0. The quotients 0/0 and \u221e/\u221e are left undefined.
p7550
aVRational functions.
p7551
aVAny rational function "f(z)" = "g(z)/h(z)" (in other words, "f(z)" is the ratio of polynomial functions "g(z)" and "h(z)" of z with complex coefficients, such that "g(z)" and "h(z)" have no common factor) can be extended to a continuous function on the Riemann sphere. Specifically, if formula_5 is a complex number such that the denominator formula_6 is zero but the numerator formula_7 is nonzero, then formula_8 can be defined as \u221e. Moreover, "f"(\u221e) can be defined as the limit of "f(z)" as "z" \u2192 \u221e, which may be finite or infinite.
p7552
aVThe set of complex rational functions that are not everywhere zero \u2014 whose mathematical symbol is C(z) form all possible holomorphic functions from the Riemann sphere to itself, when it is viewed as a Riemann surface, except for the constant function taking the value \u221e everywhere. The functions of C(z) form an algebraic field, known as "the field of rational functions on the sphere".
p7553
aVFor example, given the function
p7554
aVformula_9
p7555
aVwe may define "f"(5) = \u221e, since the denominator is zero at "z" = 5, and "f"(\u221e) = 3 since "f(z)" \u2192 3 as "z" \u2192 \u221e. Using these definitions, "f" becomes a continuous function from the Riemann sphere to itself.
p7556
aVAs a complex manifold.
p7557
aVAs a one-dimensional complex manifold, the Riemann sphere can be described by two charts, both with domain equal to the complex number plane C. Let \u03b6 be a complex number in one copy of C, and let \u03be be a complex number in another copy of C. Identify each nonzero complex number \u03b6 of the first C with the nonzero complex number 1/\u03be of the second C. Then the map
p7558
aVformula_10
p7559
aVis called the transition map between the two copies of C \u2014 the so-called charts \u2014 glueing them together. Since the transition maps are holomorphic, they define a complex manifold, called the Riemann sphere. As a complex manifold of 1 complex dimension (i.e., 2 real dimensions), this is also called a Riemann surface.
p7560
aVIntuitively, the transition maps indicate how to glue two planes together to form the Riemann sphere. The planes are glued in an "inside-out" manner, so that they overlap almost everywhere, with each plane contributing just one point (its origin) missing from the other plane. In other words, (almost) every point in the Riemann sphere has both a \u03b6 value and a \u03be value, and the two values are related by \u03b6 = 1/\u03be. The point where \u03be = 0 should then have \u03b6-value "1/0"; in this sense, the origin of the \u03be-chart plays the role of "\u221e" in the \u03b6-chart. Symmetrically, the origin of the \u03b6-chart plays the role of \u221e in the \u03be-chart.
p7561
aVTopologically, the resulting space is the one-point compactification of a plane into the sphere. However, the Riemann sphere is not merely a topological sphere. It is a sphere with a well-defined complex structure, so that around every point on the sphere there is a neighborhood that can be biholomorphically identified with C.
p7562
aVOn the other hand, the uniformization theorem, a central result in the classification of Riemann surfaces, states that the only simply-connected one-dimensional complex manifolds are the complex plane, the hyperbolic plane, and the Riemann sphere. Of these, the Riemann sphere is the only one that is a closed surface (a compact surface without boundary). Hence the two-dimensional sphere admits a unique complex structure turning it into a one-dimensional complex manifold.
p7563
aVAs the complex projective line.
p7564
aVThe Riemann sphere can also be defined as the complex projective line. This is the subset of C2 consisting of all pairs (\u03b1, \u03b2) of complex numbers, not both zero, modulo the equivalence relation
p7565
aVformula_11
p7566
aVfor all nonzero complex numbers \u03bb. The complex plane C, with coordinate \u03b6, can be mapped into the complex projective line by
p7567
aVformula_12
p7568
aVAnother copy of C with coordinate \u03be can be mapped in by
p7569
aVformula_13
p7570
aVThese two complex charts cover the projective line. For nonzero \u03be and \u03b6 the following identifications
p7571
aVformula_14
p7572
aVdemonstrate that the transition maps are \u03b6 = 1/\u03be and \u03be = 1/\u03b6, as above.
p7573
aVThis treatment of the Riemann sphere connects most readily to projective geometry. For example, any line (or smooth conic) in the complex projective plane is biholomorphic to the complex projective line. It is also convenient for studying the sphere's automorphisms, later in this article.
p7574
aVAs a sphere.
p7575
aVThe Riemann sphere can be visualized as the unit sphere "x"2 + "y"2 + "z"2 = 1 in the three-dimensional real space R3. To this end, consider the stereographic projection from the unit sphere minus the point (0, 0, 1) onto the plane "z" = 0, which we identify with the complex plane by \u03b6 = "x" + "iy". In Cartesian coordinates ("x", "y", "z") and spherical coordinates (\u03c6, \u03b8) on the sphere (with \u03c6 the zenith and \u03b8 the azimuth), the projection is
p7576
aVformula_15
p7577
aVSimilarly, stereographic projection from (0, 0, \u22121) onto the plane "z" = 0, identified with another copy of the complex plane by \u03be = "x" \u2212 "i y", is written
p7578
aVformula_16
p7579
aVIn order to cover the unit sphere, one needs the two stereographic projections: the first will cover the whole sphere except the point (0, 0, 1) and the second except the point (0, 0, \u22121). Hence, one needs two complex planes, one for each projection, which can be intuitively seen as glued back-to-back at "z" = 0. Note that the two complex planes are identified differently with the plane "z" = 0. An orientation-reversal is necessary to maintain consistent orientation on the sphere, and in particular complex conjugation causes the transition maps to be holomorphic.
p7580
aVThe transition maps between \u03b6-coordinates and \u03be-coordinates are obtained by composing one projection with the inverse of the other. They turn out to be \u03b6 = 1/\u03be and \u03be = 1/\u03b6, as described above. Thus the unit sphere is diffeomorphic to the Riemann sphere.
p7581
aVUnder this diffeomorphism, the unit circle in the \u03b6-chart, the unit circle in the \u03be-chart, and the equator of the unit sphere are all identified. The unit disk |\u03b6| < 1 is identified with the southern hemisphere "z" < 0, while the unit disk |\u03be| < 1 is identified with the northern hemisphere "z" > 0.
p7582
aVMetric.
p7583
aVA Riemann surface does not come equipped with any particular Riemannian metric. The Riemann surface's conformal structure does, however, determine a class of metrics: all those whose subordinate conformal structure is the given one. In more detail: The complex structure of the Riemann surface does uniquely determine a metric up to conformal equivalence. (Two metrics are said to be conformally equivalent if they differ by multiplication by a positive smooth function.) Conversely, any metric on an oriented surface uniquely determines a complex structure, which depends on the metric only up to conformal equivalence. Complex structures on an oriented surface are therefore in one-to-one correspondence with conformal classes of metrics on that surface.
p7584
aVWithin a given conformal class, one can use conformal symmetry to find a representative metric with convenient properties. In particular, there is always a complete metric with constant curvature in any given conformal class.
p7585
aVIn the case of the Riemann sphere, the Gauss\u2013Bonnet theorem implies that a constant-curvature metric must have positive curvature "K". It follows that the metric must be isometric to the sphere of radius formula_17 in R3 via stereographic projection. In the \u03b6-chart on the Riemann sphere, the metric with "K" = 1 is given by
p7586
aVformula_18
p7587
aVIn real coordinates \u03b6 = "u" + "iv", the formula is
p7588
aVformula_19
p7589
aVUp to a constant factor, this metric agrees with the standard Fubini\u2013Study metric on complex projective space (of which the Riemann sphere is an example).
p7590
aVUp to scaling, this is the only metric on the sphere whose group of orientation-preserving isometries is 3-dimensional (and none is more than 3-dimensional); that group is called SO(3). In this sense, this is by far the most symmetric metric on the sphere. (The group of all isometries, known as O(3), is also 3-dimensional, but unlike SO(3) is not a connected space.)
p7591
aVConversely, let "S" denote the sphere (as an abstract smooth or topological manifold). By the uniformization theorem there exists a unique complex structure on "S", up to conformal equivalence. It follows that any metric on "S" is conformally equivalent to the round metric. All such metrics determine the same conformal geometry. The round metric is therefore not intrinsic to the Riemann sphere, since "roundness" is not an invariant of conformal geometry. The Riemann sphere is only a conformal manifold, not a Riemannian manifold. However, if one needs to do Riemannian geometry on the Riemann sphere, the round metric is a natural choice (with any fixed radius, though radius = 1 is the simplest and most common choice). That is because only a round metric on the Riemann sphere has its isometry group be a 3-dimensional group. (Namely, the group known as SO(3), a continuous ("Lie") group that is topologically the 3-dimensional projective space P3.)
p7592
aVAutomorphisms.
p7593
aVThe study of any mathematical object is aided by an understanding of its group of automorphisms, meaning the maps from the object to itself that preserve the essential structure of the object. In the case of the Riemann sphere, an automorphism is an invertible biholomorphic map from the Riemann sphere to itself. It turns out that the only such maps are the Möbius transformations. These are functions of the form
p7594
aVformula_20
p7595
aVwhere "a", "b", "c", and "d" are complex numbers such that formula_21. Examples of Möbius transformations include dilations, rotations, translations, and complex inversion. In fact, any Möbius transformation can be written as a composition of these.
p7596
aVThe Möbius transformations are profitably viewed as transformations on the complex projective line. In projective coordinates, the transformation "f can be written
p7597
aVformula_22
p7598
aVThus the Möbius transformations can be described as 2 × 2 complex matrices with nonzero determinant; two matrices yield the same Möbius transformation if and only if they differ by a nonzero factor. Thus the Möbius transformations exactly correspond to the projective linear transformations PGL(2, C).
p7599
aVIf one endows the Riemann sphere with the Fubini\u2013Study metric, then not all Möbius transformations are isometries; for example, the dilations and translations are not. The isometries form a proper subgroup of PGL(2, C), namely PSU(2). This subgroup is isomorphic to the rotation group SO(3), which is the group of symmetries of the unit sphere in R"'3 (which, when restricted to the sphere, become the isometries of the sphere).
p7600
aVApplications.
p7601
aVIn complex analysis, a meromorphic function on the complex plane (or on any Riemann surface, for that matter) is a ratio "f/g" of two holomorphic functions "f" and "g". As a map to the complex numbers, it is undefined wherever "g" is zero. However, it induces a holomorphic map "(f, g)" to the complex projective line that is well-defined even where "g" = 0. This construction is helpful in the study of holomorphic and meromorphic functions. For example, on a compact Riemann surface there are no non-constant holomorphic maps to the complex numbers, but holomorphic maps to the complex projective line are abundant.
p7602
aVThe Riemann sphere has many uses in physics. In quantum mechanics, points on the complex projective line are natural values for photon polarization states, spin states of massive particles of spin 1/2, and 2-state particles in general (see also Quantum bit). The Riemann sphere has been suggested as a relativistic model for the celestial sphere. In string theory, the worldsheets of strings are Riemann surfaces, and the Riemann sphere, being the simplest Riemann surface, plays a significant role. It is also important in twistor theory.
p7603
asS'Infinity'
p7604
(lp7605
VInfinity (symbol: ) is an abstract concept describing something "without any limit" and is relevant in a number of fields, predominantly mathematics and physics. In mathematics, "infinity" is often treated as if it were a number (i.e., it counts or measures things: "an infinite number of terms") but it is not the same sort of number as the real numbers. In number systems incorporating infinitesimals, the reciprocal of an infinitesimal is an infinite number, i.e., a number greater than any real number; see 1/\u221e. Georg Cantor formalized many ideas related to infinity and infinite sets during the late 19th and early 20th centuries. In the theory he developed, there are infinite sets of different sizes (called cardinalities). For example, the set of integers is countably infinite, while the infinite set of real numbers is uncountable.
p7606
aVHistory.
p7607
aVAncient cultures had various ideas about the nature of infinity. The ancient Indians and Greeks did not define infinity in precise formalism as does modern mathematics, and instead approached infinity as a philosophical concept.
p7608
aVEarly Greek.
p7609
aVThe earliest recorded idea of infinity comes from Anaximander, a pre-Socratic Greek philosopher who lived in Miletus. He used the word apeiron which means infinite or limitless. However, the earliest attestable accounts of mathematical infinity come from Zeno of Elea (c. 490 BCE? \u2013 c. 430 BCE?), a pre-Socratic Greek philosopher of southern Italy and member of the Eleatic School founded by Parmenides. Aristotle called him the inventor of the dialectic. He is best known for his paradoxes, described by Bertrand Russell as "immeasurably subtle and profound".
p7610
aVIn accordance with the traditional view of Aristotle, the Hellenistic Greeks generally preferred to distinguish the potential infinity from the actual infinity; for example, instead of saying that there are an infinity of primes, Euclid prefers instead to say that there are more prime numbers than contained in any given collection of prime numbers (Elements, Book IX, Proposition 20).
p7611
aVHowever, recent readings of the Archimedes Palimpsest have hinted that Archimedes at least had an intuition about actual infinite quantities.
p7612
aVEarly Indian.
p7613
aVThe Indian mathematical text Surya Prajnapti (c. 3rd\u20134th century BCE) classifies all numbers into three sets: enumerable, innumerable, and infinite. Each of these was further subdivided into three orders:
p7614
aVIn this work, two basic types of infinite numbers are distinguished. On both physical and ontological grounds, a distinction was made between Asa\u1e43khyeya ("countless, innumerable") and "ananta" ("endless, unlimited"), between rigidly bounded and loosely bounded infinities.
p7615
aV17th century.
p7616
aVEuropean mathematicians started using infinite numbers in a systematic fashion in the 17th century. John Wallis first used the notation formula_1 for such a number, and exploited it in area calculations by dividing the region into infinitesimal strips of width on the order of formula_2. Euler used the notation formula_3 for an infinite number, and exploited it by applying the binomial formula to the formula_3'th power, and infinite products of formula_3 factors.
p7617
aVMathematics.
p7618
aVInfinity symbol.
p7619
aVThe infinity symbol formula_1 (sometimes called the lemniscate) is a mathematical symbol representing the concept of infinity. The symbol is encoded in Unicode at and in LaTeX as codice_1.
p7620
aVIt was introduced in 1655 by John Wallis, and, since its introduction, has also been used outside mathematics in modern mysticism and literary symbology.
p7621
aVCalculus.
p7622
aVLeibniz, one of the co-inventors of infinitesimal calculus, speculated widely about infinite numbers and their use in mathematics. To Leibniz, both infinitesimals and infinite quantities were ideal entities, not of the same nature as appreciable quantities, but enjoying the same properties in accordance with the Law of Continuity.
p7623
aVReal analysis.
p7624
aVIn real analysis, the symbol formula_1, called "infinity", is used to denote an unbounded limit. formula_8 means that "x" grows without bound, and formula_9 means the value of "x" is decreasing without bound. If "f"("t") \u2265 0 for every "t", then
p7625
aVInfinity is also used to describe infinite series:
p7626
aVInfinity can be used not only to define a limit but as a value in the extended real number system. Points labeled formula_19 and formula_20 can be added to the topological space of the real numbers, producing the two-point compactification of the real numbers. Adding algebraic properties to this gives us the extended real numbers. We can also treat formula_19 and formula_20 as the same, leading to the one-point compactification of the real numbers, which is the real projective line. Projective geometry also refers to a line at infinity in plane geometry, a plane at infinity in three-dimensional space, and so forth for higher dimensions.
p7627
aVComplex analysis.
p7628
aVIn complex analysis the symbol formula_1, called "infinity", denotes an unsigned infinite limit. formula_8 means that the magnitude formula_25 of "x" grows beyond any assigned value. A point labeled formula_1 can be added to the complex plane as a topological space giving the one-point compactification of the complex plane. When this is done, the resulting space is a one-dimensional complex manifold, or Riemann surface, called the extended complex plane or the Riemann sphere. Arithmetic operations similar to those given above for the extended real numbers can also be defined, though there is no distinction in the signs (therefore one exception is that infinity cannot be added to itself). On the other hand, this kind of infinity enables division by zero, namely formula_27 for any nonzero complex number "z". In this context it is often useful to consider meromorphic functions as maps into the Riemann sphere taking the value of formula_1 at the poles. The domain of a complex-valued function may be extended to include the point at infinity as well. One important example of such functions is the group of Möbius transformations.
p7629
aVNonstandard analysis.
p7630
aVThe original formulation of infinitesimal calculus by Isaac Newton and Gottfried Leibniz used infinitesimal quantities. In the twentieth century, it was shown that this treatment could be put on a rigorous footing through various logical systems, including smooth infinitesimal analysis and nonstandard analysis. In the latter, infinitesimals are invertible, and their inverses are infinite numbers. The infinities in this sense are part of a hyperreal field; there is no equivalence between them as with the Cantorian transfinites. For example, if H is an infinite number, then H + H = 2H and H + 1 are distinct infinite numbers. This approach to non-standard calculus is fully developed in .
p7631
aVSet theory.
p7632
aVA different form of "infinity" are the ordinal and cardinal infinities of set theory. Georg Cantor developed a system of transfinite numbers, in which the first transfinite cardinal is aleph-null (\u21350), the cardinality of the set of natural numbers. This modern mathematical conception of the quantitative infinite developed in the late nineteenth century from work by Cantor, Gottlob Frege, Richard Dedekind and others, using the idea of collections, or sets.
p7633
aVDedekind's approach was essentially to adopt the idea of one-to-one correspondence as a standard for comparing the size of sets, and to reject the view of Galileo (which derived from Euclid) that the whole cannot be the same size as the part. An infinite set can simply be defined as one having the same size as at least one of its proper parts; this notion of infinity is called Dedekind infinite. The diagram gives an example: viewing lines as infinite sets of points, the left half of the lower blue line can be mapped in a one-to-one manner (green correspondences) to the higher blue line, and, in turn, to the whole lower blue line (red correspondences); therefore the whole lower blue line and its left half have the same cardinality, i.e. "size".
p7634
aVCantor defined two kinds of infinite numbers: ordinal numbers and cardinal numbers. Ordinal numbers may be identified with well-ordered sets, or counting carried on to any stopping point, including points after an infinite number have already been counted. Generalizing finite and the ordinary infinite sequences which are maps from the positive integers leads to mappings from ordinal numbers, and transfinite sequences. Cardinal numbers define the size of sets, meaning how many members they contain, and can be standardized by choosing the first ordinal number of a certain size to represent the cardinal number of that size. The smallest ordinal infinity is that of the positive integers, and any set which has the cardinality of the integers is countably infinite. If a set is too large to be put in one to one correspondence with the positive integers, it is called "uncountable". Cantor's views prevailed and modern mathematics accepts actual infinity. Certain extended number systems, such as the hyperreal numbers, incorporate the ordinary (finite) numbers and infinite numbers of different sizes.
p7635
aVCardinality of the continuum.
p7636
aVOne of Cantor's most important results was that the cardinality of the continuum formula_29 is greater than that of the natural numbers formula_30; that is, there are more real numbers R than natural numbers N. Namely, Cantor showed that formula_31 (see Cantor's diagonal argument or Cantor's first uncountability proof).
p7637
aVThe continuum hypothesis states that there is no cardinal number between the cardinality of the reals and the cardinality of the natural numbers, that is, formula_32 (see Beth one). However, this hypothesis can neither be proved nor disproved within the widely accepted Zermelo\u2013Fraenkel set theory, even assuming the Axiom of Choice.
p7638
aVCardinal arithmetic can be used to show not only that the number of points in a real number line is equal to the number of points in any segment of that line, but that this is equal to the number of points on a plane and, indeed, in any finite-dimensional space.
p7639
aVThe first of these results is apparent by considering, for instance, the tangent function, which provides a one-to-one correspondence between the interval (\u2212\u03c0/2, \u03c0/2) and R (see also Hilbert's paradox of the Grand Hotel). The second result was proved by Cantor in 1878, but only became intuitively apparent in 1890, when Giuseppe Peano introduced the space-filling curves, curved lines that twist and turn enough to fill the whole of any square, or cube, or hypercube, or finite-dimensional space. These curves can be used to define a one-to-one correspondence between the points in the side of a square and those in the square.
p7640
aVGeometry and topology.
p7641
aVInfinite-dimensional spaces are widely used in geometry and topology, particularly as classifying spaces, notably Eilenberg\u2212MacLane spaces. Common examples are the infinite-dimensional complex projective space K(Z,2) and the infinite-dimensional real projective space K(Z/2Z,1).
p7642
aVFractals.
p7643
aVThe structure of a fractal object is reiterated in its magnifications. Fractals can be magnified indefinitely without losing their structure and becoming "smooth"; they have infinite perimeters\u2014some with infinite, and others with finite surface areas. One such fractal curve with an infinite perimeter and finite surface area is the Koch snowflake.
p7644
aVMathematics without infinity.
p7645
aVLeopold Kronecker was skeptical of the notion of infinity and how his fellow mathematicians were using it in the 1870s and 1880s. This skepticism was developed in the philosophy of mathematics called finitism, an extreme form of the philosophical and mathematical schools of constructivism and intuitionism.
p7646
aVPhysics.
p7647
aVIn physics, approximations of real numbers are used for continuous measurements and natural numbers are used for discrete measurements (i.e. counting). It is therefore assumed by physicists that no measurable quantity could have an infinite value, for instance by taking an infinite value in an extended real number system, or by requiring the counting of an infinite number of events. It is, for example, presumed impossible for any type of body to have infinite mass or infinite energy. Concepts of infinite things such as an infinite plane wave exist, but there are no experimental means to generate them.
p7648
aVTheoretical applications of physical infinity.
p7649
aVThe practice of refusing infinite values for measurable quantities does not come from "a priori" or ideological motivations, but rather from more methodological and pragmatic motivations. One of the needs of any physical and scientific theory is to give usable formulas that correspond to or at least approximate reality. As an example if any object of infinite gravitational mass were to exist, any usage of the formula to calculate the gravitational force would lead to an infinite result, which would be of no benefit since the result would be always the same regardless of the position and the mass of the other object. The formula would be useful neither to compute the force between two objects of finite mass nor to compute their motions. If an infinite mass object were to exist, any object of finite mass would be attracted with infinite force (and hence acceleration) by the infinite mass object, which is not what we can observe in reality. Sometimes infinite result of a physical quantity may mean that the theory being used to compute the result may be approaching the point where it fails. This may help to indicate the limitations of a theory.
p7650
aVThis point of view does not mean that infinity cannot be used in physics. For convenience's sake, calculations, equations, theories and approximations often use infinite series, unbounded functions, etc., and may involve infinite quantities. Physicists however require that the end result be physically meaningful. In quantum field theory infinities arise which need to be interpreted in such a way as to lead to a physically meaningful result, a process called renormalization.
p7651
aVHowever, there are some theoretical circumstances where the end result is infinity. One example is the singularity in the description of black holes. Some solutions of the equations of the general theory of relativity allow for finite mass distributions of zero size, and thus infinite density. This is an example of what is called a mathematical singularity, or a point where a physical theory breaks down. This does not necessarily mean that physical infinities exist; it may mean simply that the theory is incapable of describing the situation properly. Two other examples occur in inverse-square force laws of the gravitational force equation of Newtonian gravity and Coulomb's law of electrostatics. At r=0 these equations evaluate to infinities.
p7652
aVCosmology.
p7653
aVThe first published proposal that the universe is infinite came from Thomas Digges in 1576. Eight years later, in 1584, the Italian philosopher and astronomer Giordano Bruno proposed an unbounded universe in "On the Infinite Universe and Worlds": "Innumerable suns exist; innumerable earths revolve around these suns in a manner similar to the way the seven planets revolve around our sun. Living beings inhabit these worlds."
p7654
aVCosmologists have long sought to discover whether infinity exists in our physical universe: Are there an infinite number of stars? Does the universe have infinite volume? Does space "go on forever"? This is an open question of cosmology. Note that the question of being infinite is logically separate from the question of having boundaries. The two-dimensional surface of the Earth, for example, is finite, yet has no edge. By travelling in a straight line one will eventually return to the exact spot one started from. The universe, at least in principle, might have a similar topology. If so, one might eventually return to one's starting point after travelling in a straight line through the universe for long enough.
p7655
aVIf, on the other hand, the universe were not curved like a sphere but had a flat topology, it could be both unbounded and infinite. The curvature of the universe can be measured through multipole moments in the spectrum of the cosmic background radiation. As to date, analysis of the radiation patterns recorded by the WMAP spacecraft hints that the universe has a flat topology. This would be consistent with an infinite physical universe. 
p7656
aVHowever, the universe could also be finite, even if its curvature is flat. An easy way to understand this is to consider two-dimensional examples, such as video games where items that leave one edge of the screen reappear on the other. The topology of such games is toroidal and the geometry is flat. Many possible bounded, flat possibilities also exist for three-dimensional space.
p7657
aVThe concept of infinity also extends to the multiverse hypothesis, which, when explained by astrophysicists such as Michio Kaku, posits that there are an infinite number and variety of universes.
p7658
aVLogic.
p7659
aVIn logic an infinite regress argument is "a distinctively philosophical kind of argument purporting to show that a thesis is defective because it generates an infinite series when either (form A) no such series exists or (form B) were it to exist, the thesis would lack the role (e.g., of justification) that it is supposed to play."
p7660
aVComputing.
p7661
aVThe IEEE floating-point standard (IEEE 754) specifies the positive and negative infinity values. These are defined as the result of arithmetic overflow, division by zero, and other exceptional operations.
p7662
aVSome programming languages, such as Java and J, allow the programmer an explicit access to the positive and negative infinity values as language constants. These can be used as greatest and least elements, as they compare (respectively) greater than or less than all other values. They are useful as sentinel values in algorithms involving sorting, searching, or windowing.
p7663
aVIn languages that do not have greatest and least elements, but do allow overloading of relational operators, it is possible for a programmer to "create" the greatest and least elements. In languages that do not provide explicit access to such values from the initial state of the program, but do implement the floating point data type, the infinity values might still be accessible and usable as the result of certain operations.
p7664
aVArts and cognitive sciences.
p7665
aVPerspective artwork utilizes the concept of imaginary vanishing points, or points at infinity, located at an infinite distance from the observer. This allows artists to create paintings that realistically render space, distances, and forms. Artist M. C. Escher is specifically known for employing the concept of infinity in his work in this and other ways.
p7666
aVCognitive scientist George Lakoff considers the concept of infinity in mathematics and the sciences as a metaphor. This perspective is based on the basic metaphor of infinity (BMI), defined as the ever-increasing sequence <1,2,3...>.
p7667
aVThe symbol is often used romantically to represent eternal love. Several types of jewelry are fashioned into the infinity shape for this purpose.
p7668
asS'Direct proof'
p7669
(lp7670
VIn mathematics and logic, a direct proof is a way of showing the
p7671
aVtruth or falsehood of a given statement by a straightforward combination of
p7672
aVestablished facts, usually axioms, existing lemmas and theorems, without making any further assumptions. In order to directly prove a conditional statement of the form "If "p", then "q"", it suffices to consider the situations in which the statement "p" is true. Logical deduction is employed to reason from assumptions to conclusion. The type of logic employed is almost invariably first-order logic, employing the quantifiers "for all" and "there exists". Common proof rules used are modus ponens and universal instantiation.
p7673
aVIn contrast, an indirect proof may begin with certain hypothetical scenarios and then proceed to eliminate the uncertainties in each of these scenarios until an inescapable conclusion is forced. For example instead of showing directly "p" \u21d2 "q", one proves its contrapositive ~"q" \u21d2 ~"p" (one assumes ~"q" and shows that it leads to ~"p"). Since "p" \u21d2 "q" and ~"q" \u21d2 ~"p" are equivalent by the principle of transposition (see law of excluded middle), "p" \u21d2 "q" is indirectly proved. Proof methods that are not direct include proof by contradiction, including proof by infinite descent. Direct proof methods include proof by exhaustion and proof by induction.
p7674
aVHistory and etymology.
p7675
aVA direct proof is the simplest form of proof there is. The word \u2018proof\u2019 comes from the Latin word probare, which means \u201cto test\u201d. The earliest use of proofs was prominent in legal proceedings. A person with authority, such as a nobleman, was said to have probity, which means that the evidence was by his relative authority, which outweighed empirical testimony. In days gone by, mathematics and proof was often intertwined with practical questions \u2013 with populations like the Egyptians and the Greeks showing an interest in surveying land. This lead to a natural curiosity with regards to geometry and trigonometry \u2013 particularly triangles and rectangles. These were the shapes which provided the most questions in terms of practical things, so early geometrical concepts were focused on these shapes, for example, the likes of buildings and pyramids used these shapes in abundance. Another shape which is crucial in the history of direct proof is the circle, which was crucial for the design of arenas and water tanks. This meant that ancient geometry (and Euclidean Geometry) discussed circles.
p7676
aVThe earliest form of mathematics was phenomenological. For example, if someone could draw a reasonable picture, or give a convincing description, then that met all the criteria for something to be described as a mathematical \u201cfact\u201d. On occasion, analogical arguments took place, or even by \u201cinvoking the gods\u201d. The idea that mathematical statements could be proven had not been developed yet, so these were the earliest forms of the concept of proof, despite not being actual proof at all.
p7677
aVProof as we know it came about with one specific question: \u201cwhat is a proof?\u201d Traditionally, a proof is a platform which convinces someone beyond reasonable doubt that a statement is mathematically true. Naturally, one would assume that the best way to prove the truth of something like this (B) would be to draw up a comparison with something old (A) that has already been proven as true. Thus was created the concept of deriving a new result from an old result.
p7678
aVExamples.
p7679
aVThe sum of two even integers equals an even integer.
p7680
aVConsider two even integers "x" and "y". Since they are even, they can be written as
p7681
aVformula_1
p7682
aVformula_2
p7683
aVrespectively for integers "a" and "b". 
p7684
aVThen the sum can be written as
p7685
aVformula_3
p7686
aVFrom this it is clear "x" + "y" has 2 as a factor and therefore is even, so the sum of any two even integers is even.
p7687
aVPythagoras' Theorem.
p7688
aVObserve that we have four right-angled triangles and a square packed into a large square. Each of the triangles has sides "a" and "b" and hypotenuse "c". The area of a square is defined as the square of the length of its sides - in this case, "(a + b)2". However, the area of the large square can also be expressed as the sum of the areas of its components. In this case, that would be the sum of the areas of the four triangles and the small square in the middle.
p7689
aVWe know that the area of the large square is equal to "(a + b)2"
p7690
aVThe area of a triangle is equal to formula_4
p7691
aVWe know that the area of the large square is also equal to the sum of the areas of the triangles, plus the area of the small square, and thus the area of the large square equals formula_5
p7692
aVThese are equal, and so:
p7693
aV:formula_6
p7694
aVAfter some simplifying:
p7695
aV:formula_7
p7696
aVRemoving the ab that appears on both sides gives
p7697
aV:formula_8
p7698
aVWhich proves Pythagoras' theorem. 
p7699
aVIf n is an odd integer, n2 is also an odd integer..
p7700
aVBy definition, if n is an odd integer, it can be expressed as:
p7701
aVformula_9
p7702
aVfor some integer k. Thus:
p7703
aVformula_10
p7704
aVAs formula_11 is an integer, our answer can be expressed as:
p7705
aV:formula_12
p7706
aVAnd hence we have shown that n2 is odd. 
p7707
asS'Mathematical induction'
p7708
(lp7709
VMathematical induction is a method of mathematical proof typically used to establish a given statement for all natural numbers. It is a form of direct proof, and it is done in two steps. The first step, known as the base case, is to prove the given statement for the first natural number. The second step, known as the inductive step, is to prove that the given statement for any one natural number implies the given statement for the next natural number. From these two steps, mathematical induction is the rule from which we infer that the given statement is established for all natural numbers.
p7710
aVThe method can be extended to prove statements about more general well-founded structures, such as trees; this generalization, known as structural induction, is used in mathematical logic and computer science. Mathematical induction in this extended sense is closely related to recursion. Mathematical induction, in some form, is the foundation of all correctness proofs for computer programs.
p7711
aVAlthough its name may suggest otherwise, mathematical induction should not be misconstrued as a form of inductive reasoning (also see Problem of induction). Mathematical induction is an inference rule used in proofs. In mathematics, proofs including those using mathematical induction are examples of deductive reasoning, and inductive reasoning is excluded from proofs.
p7712
aVHistory.
p7713
aVIn 370 BC, Plato's Parmenides may have contained an early example of an implicit inductive proof. The earliest implicit traces of mathematical induction can be found in Euclid's proof that the number of primes is infinite and in Bhaskara's "cyclic method". An opposite iterated technique, counting "down" rather than up, is found in the Sorites paradox, where one argued that if 1,000,000 grains of sand formed a heap, and removing one grain from a heap left it a heap, then a single grain of sand (or even no grains) forms a heap.
p7714
aVAn implicit proof by mathematical induction for arithmetic sequences was introduced in the "al-Fakhri" written by al-Karaji around 1000 AD, who used it to prove the binomial theorem and properties of Pascal's triangle.
p7715
aVNone of these ancient mathematicians, however, explicitly stated the inductive hypothesis. Another similar case (contrary to what Vacca has written, as Freudenthal carefully showed) was that of Francesco Maurolico in his "Arithmeticorum libri duo" (1575), who used the technique to prove that the sum of the first "n" odd integers is "n"2. The first explicit formulation of the principle of induction was given by Pascal in his "Traité du triangle arithmétique" (1665). Another Frenchman, Fermat, made ample use of a related principle, indirect proof by infinite descent. The inductive hypothesis was also employed by the Swiss Jakob Bernoulli, and from then on it became more or less well known. The modern rigorous and systematic treatment of the principle came only in the 19th century, with George Boole, Augustus de Morgan, Charles Sanders Peirce, Giuseppe Peano, and Richard Dedekind.
p7716
aVDescription.
p7717
aVThe simplest and most common form of mathematical induction infers that a statement involving a natural number "n" holds for all values of "n". The proof consists of two steps:
p7718
aVThe hypothesis in the inductive step that the statement holds for some "n" is called the induction hypothesis (or inductive hypothesis). To perform the inductive step, one assumes the induction hypothesis and then uses this assumption to prove the statement for "n" + 1.
p7719
aVWhether "n" = 0 or "n" = 1 depends on the definition of the natural numbers. If 0 is considered a natural number, as is common in the fields of combinatorics and mathematical logic, the base case is given by "n" = 0. If, on the other hand, 1 is taken as the first natural number, then the base case is given by "n" = 1.
p7720
aVExample.
p7721
aVMathematical induction can be used to prove that the following statement, which we will call "P"("n"), holds for all natural numbers "n".
p7722
aVformula_1
p7723
aV"P"("n") gives a formula for the sum of the natural numbers less than or equal to number "n". The proof that "P"("n") is true for each natural number "n" proceeds as follows.
p7724
aVBasis: Show that the statement holds for "n" = 0. <br>
p7725
aV"P"(0) amounts to the statement:
p7726
aVformula_2
p7727
aVIn the left-hand side of the equation, the only term is 0, and so the left-hand side is simply equal to 0. <br>
p7728
aVIn the right-hand side of the equation, 0·(0 + 1)/2 = 0. <br>
p7729
aVThe two sides are equal, so the statement is true for "n" = 0. Thus it has been shown that "P"(0) holds.
p7730
aVInductive step: Show that "if" "P"("k") holds, then also holds. This can be done as follows.
p7731
aVAssume "P"("k") holds (for some unspecified value of "k"). It must then be shown that holds, that is:
p7732
aVformula_3
p7733
aVUsing the induction hypothesis that "P"("k") holds, the left-hand side can be rewritten to:
p7734
aVformula_4
p7735
aVAlgebraically:
p7736
aV formula_5
p7737
aVthereby showing that indeed holds.
p7738
aVSince both the basis and the inductive step have been performed, by mathematical induction, the statement "P"("n") holds for all natural "n". Q.E.D.
p7739
aVAxiom of induction.
p7740
aVMathematical induction as an inference rule can be formalized as a second-order axiom. The "axiom of induction" is, in logical symbols,
p7741
aV formula_6
p7742
aVwhere "P" is any predicate and "k" and "n" are both natural numbers.
p7743
aVIn words, the basis "P"(0) and the inductive step (namely, that the inductive hypothesis "P"("k") implies "P"("k" + 1)) together imply that "P"("n") for any natural number "n". The axiom of induction asserts that the validity of inferring that "P"("n") holds for any natural number "n" from the basis and the inductive step.
p7744
aVNote that the first quantifier in the axiom ranges over "predicates" rather than over individual numbers. This is a second-order quantifier, which means that this axiom is stated in second-order logic. Axiomatizing arithmetic induction in first-order logic requires an axiom schema containing a separate axiom for each possible predicate. The article Peano axioms contains further discussion of this issue.
p7745
aVCharacterizing the structure of formula_7 by the induction axiom.
p7746
aVHaving proven the base case and the inductive step, then the structure of formula_7 is such that any value can be obtained by performing the inductive step repeatedly. It may be helpful to think of the domino effect. Consider a half line of dominoes each standing on end, and extending infinitely to the right (see picture). Suppose that:
p7747
aVWith these assumptions one can conclude (using mathematical induction) that all of the dominoes will fall right.
p7748
aVIf the dominoes are arranged in another way, this conclusion needn't hold (see Peano axioms#Formulation for a counter example). Similarly, the induction axiom describes an essential property of formula_7, viz. that each of its members can be reached from 0 by sufficiently often adding 1. While there is only one structure that satisfies all Peano axioms (including induction), there is no set of only first-order axioms that fulfils the same task.
p7749
aVVariants.
p7750
aVIn practice, proofs by induction are often structured differently, depending on the exact nature of the property to be proved.
p7751
aVInduction basis other than 0 or 1.
p7752
aVIf we want to prove a statement not for all natural numbers but only for all numbers greater than or equal to a certain number "b" then the proof by induction consists of:
p7753
aVThis can be used, for example, to show that "n"2 \u2265 3"n" for "n" \u2265 3. A more substantial example is a proof that
p7754
aVformula_10
p7755
aVIn this way we can prove that "P"("n") holds for all "n" \u22651, or even "n" \u2265\u22125. This form of mathematical induction is actually a special case of the previous form because if the statement that we intend to prove is "P"("n") then proving it with these two rules is equivalent with proving "P"("n" + "b") for all natural numbers "n" with the first two steps.
p7756
aVInduction basis equal to 2.
p7757
aVIn mathematics, many standard functions, including operations such as "+" and relations such as "=", are binary, meaning that they take two arguments. Often these functions possess properties that implicitly extend them to more than two arguments. For example, once addition "a" + "b" is defined and is known to satisfy the associativity property ("a" + "b") + "c" = "a" + ("b" + "c"), then the ternary addition "a" + "b" + "c" makes sense, either as ("a" + "b") + "c" or as "a" + ("b" + "c"). Similarly, many axioms and theorems in mathematics are stated only for the binary versions of mathematical operations and relations, and implicitly extend to higher-arity versions.
p7758
aVSuppose that we wish to prove a statement about an "n"-ary operation implicitly defined from a binary operation, using mathematical induction on "n". In this case it is natural to take 2 for the induction basis.
p7759
aVExample: product rule for the derivative.
p7760
aVIn this example, the binary operation in question is multiplication (of functions). The usual product rule for the derivative taught in calculus states:
p7761
aVformula_11
p7762
aVor in logarithmic derivative form
p7763
aVformula_12
p7764
aVThis can be generalized to a product of "n" functions. One has
p7765
aVformula_13
p7766
aV:formula_14
p7767
aVor in logarithmic derivative form
p7768
aVformula_15
p7769
aV:formula_16
p7770
aVIn each of the "n" terms of the usual form, just one of the factors is a derivative; the others are not.
p7771
aVWhen this general fact is proved by mathematical induction, the "n" = 0 case is trivial,formula_17 (since the empty product is 1, and the empty sum is 0). The "n" = 1 case is also trivial, formula_18 And for each "n" \u2265 3, the case is easy to prove from the preceding "n" \u2212 1 case. The real difficulty lies in the "n" = 2 case, which is why that is the one stated in the standard product rule.
p7772
aVInduction on more than one counter.
p7773
aVIt is sometimes desirable to prove a statement involving two natural numbers, "n" and "m", by iterating the induction process. That is, one performs a basis step and an inductive step for "n", and in each of those performs a basis step and an inductive step for "m". See, for example, the proof of commutativity accompanying "addition of natural numbers". More complicated arguments involving three or more counters are also possible.
p7774
aVInfinite descent.
p7775
aVThe method of infinite descent was one of Pierre de Fermat's favorites. This method of proof can assume several slightly different forms. For example, it might begin by showing that if a statement is true for a natural number "n" it must also be true for some smaller natural number "m" ("m" < "n"). Using mathematical induction (implicitly) with the inductive hypothesis being that the statement is false for all natural numbers less than or equal to "m", we can conclude that the statement cannot be true for any natural number "n".
p7776
aVAlthough this particular form of infinite-descent proof is clearly a mathematical induction, whether one holds all proofs "by infinite descent" to be mathematical inductions depends on how one defines the term "proof by infinite descent." One might, for example, use the term to apply to proofs in which the well-ordering of the natural numbers is assumed, but not the principle of induction. Such, for example, is the usual proof that 2 has no rational square root (see Infinite descent).
p7777
aVPrefix induction.
p7778
aVThe most common form of induction requires proving that 
p7779
aVor equivalently
p7780
aVwhereupon the induction principle "automates" n applications of this inference in getting from P(0) to P(n). This could be called "predecessor induction" because each step proves something about a number from something about that number's predecessor.
p7781
aVA variant of interest in computational complexity is "prefix induction", in which one needs to prove
p7782
aVor equivalently 
p7783
aVThe induction principle then "automates" log(n) applications of this inference in getting from P(0) to P(n). (It's called "prefix induction" because each step proves something about a number from something about the "prefix" of that number formed by truncating the low bit of its binary representation.)
p7784
aVIf traditional predecessor induction is interpreted computationally as an n-step loop, prefix induction corresponds to a log(n)-step loop, and thus proofs using prefix induction are "more feasibly constructive" than proofs using predecessor induction.
p7785
aVPredecessor induction can trivially simulate prefix induction on the same statement. Prefix induction can simulate predecessor induction, but only at the cost of making the statement more syntactically complex (adding a bounded universal quantifier), so the interesting results relating prefix induction to polynomial-time computation depend on excluding unbounded quantifiers entirely, and limiting the alternation of bounded universal and existential quantifiers allowed in the statement. See 
p7786
aVOne could take it a step farther to "prefix of prefix induction": one must prove
p7787
aVwhereupon the induction principle "automates" log(log(n)) applications of this inference in getting from P(0) to P(n). This form of induction has been used, analogously, to study log-time parallel computation.
p7788
aVComplete induction.
p7789
aVAnother variant, called complete induction (or strong induction or course of values induction), says that in the second step we may assume not only that the statement holds for "n" = "m" but also that it is true for all "n" less than or equal to "m".
p7790
aVComplete induction is most useful when several instances of the inductive hypothesis are required for each inductive step. For example, complete induction can be used to show that
p7791
aVformula_19
p7792
aVwhere "Fn" is the "n"th Fibonacci number, \u03c6 = (1 + \u221a5)/2 (the golden ratio) and \u03c8 = (1 \u2212 \u221a5)/2 are the roots of the polynomial "x"2 \u2212 "x" \u2212 1. By using the fact that "F""n" + 2 = "F""n" + 1 + "F""n" for each "n" \u2208 N, the identity above can be verified by direct calculation for "F""n" + 2 if we assume that it already holds for both "F""n" + 1 and "F""n". To complete the proof, the identity must be verified in the two base cases "n" = 0 and "n" = 1.
p7793
aVAnother proof by complete induction uses the hypothesis that the statement holds for "all" smaller "n" more thoroughly. Consider the statement that "every natural number greater than 1 is a product of (one or more) prime numbers", and assume that for a given "m" > 1 it holds for all smaller "n" > 1. If "m" is prime then it is certainly a product of primes, and if not, then by definition it is a product: "m" = "n"1 "n"2, where neither of the factors is equal to 1; hence neither is equal to "m", and so both are smaller than "m". The induction hypothesis now applies to "n"1 and "n"2, so each one is a product of primes. Then "m" is a product of products of primes; i.e. a product of primes.
p7794
aVThis generalization, complete induction, is equivalent to the ordinary mathematical induction described above. Suppose P("n") is the statement that we intend to prove by complete induction. Let Q("n") mean P("m") holds for all "m" such that 0 \u2264 "m" \u2264 "n". Then Q("n") is true for all "n" if and only if P("n") is true for all "n", and a proof of P("n") by complete induction is just the same thing as a proof of Q("n") by (ordinary) induction.
p7795
aVTransfinite induction.
p7796
aVThe last two steps can be reformulated as one step:
p7797
aVThis form of mathematical induction is not only valid for statements about natural numbers, but for statements about elements of any well-founded set, that is, a set with an irreflexive relation < that contains no infinite descending chains.
p7798
aVThis form of induction, when applied to ordinals (which form a well-ordered and hence well-founded class), is called "transfinite induction". It is an important proof technique in set theory, topology and other fields.
p7799
aVProofs by transfinite induction typically distinguish three cases:
p7800
aVStrictly speaking, it is not necessary in transfinite induction to prove the basis, because it is a vacuous special case of the proposition that if "P" is true of all "n" < "m", then "P" is true of "m". It is vacuously true precisely because there are no values of "n" < "m" that could serve as counterexamples.
p7801
aVEquivalence with the well-ordering principle.
p7802
aVThe principle of mathematical induction is usually stated as an axiom of the natural numbers; see Peano axioms. However, it can be proved from the well-ordering principle. Indeed, suppose the following:
p7803
aVTo derive simple induction from these axioms, we must show that if P("n") is some proposition predicated of "n", and if:
p7804
aVthen P("n") holds for all "n".
p7805
aV"Proof." Let S be the set of all natural numbers for which P("n") is false. Let us see what happens if we assert that S is nonempty. Well-ordering tells us that S has a least element, say "t". Moreover, since P(0) is true, "t" is not 0. Since every natural number is either zero or some "n"+1, there is some natural number "n" such that "n"+1="t". Now "n" is less than "t", and "t" is the least element of S. It follows that "n" is not in S, and so P("n") is true. This means that P("n"+1) is true, and so P("t") is true. This is a contradiction, since "t" was in S. Therefore, S is empty.
p7806
aVIt can also be proved that induction, given the other axioms, implies the well-ordering principle.
p7807
aVExample of error in the inductive step.
p7808
aVThis example demonstrated a subtle error in the proof of the inductive step.
p7809
aVJoel E. Cohen proposed the following argument, which purports to prove by mathematical induction that all horses are of the same color:
p7810
aVThe basis case "n" = 1 is trivial (as any horse is the same color as itself), and the inductive step is correct in all cases "n" > 1. However, the logic of the inductive step is incorrect for "n" = 1, because the statement that "the two sets overlap" is false (there are only "n" + 1 = 2 horses prior to either removal, and after removal the sets of one horse each do not overlap).
p7811
asS'Factorial'
p7812
(lp7813
VIn mathematics, the factorial of a non-negative integer "n", denoted by "n"!, is the product of all positive integers less than or equal to "n". For example,
p7814
aVformula_1
p7815
aVThe value of 0! is 1, according to the convention for an empty product.
p7816
aVThe factorial operation is encountered in many areas of mathematics, notably in combinatorics, algebra, and mathematical analysis. Its most basic occurrence is the fact that there are "n"! ways to arrange "n" distinct objects into a sequence (i.e., permutations of the set of objects). This fact was known at least as early as the 12th century, to Indian scholars. Fabian Stedman in 1677 described factorials as applied to change ringing. After describing a recursive approach, Stedman gives a statement of a factorial (using the language of the original):
p7817
aVNow the nature of these methods is such, that the changes on one number comprehends the changes on all lesser numbers, ... insomuch that a compleat Peal of changes on one number seemeth to be formed by uniting of the compleat Peals on all lesser numbers into one entire body;
p7818
aVThe notation "n"! was introduced by Christian Kramp in 1808.
p7819
aVThe definition of the factorial function can also be extended to non-integer arguments, while retaining its most important properties; this involves more advanced mathematics, notably techniques from mathematical analysis.
p7820
aVDefinition.
p7821
aVThe factorial function is formally defined by the product
p7822
aVformula_2
p7823
aVor by the recurrence relation
p7824
aVformula_3
p7825
aVThe factorial function can also be defined by using the power rule as
p7826
aVformula_4
p7827
aVAll of the above definitions incorporate the instance
p7828
aVformula_5
p7829
aVin the first case by the convention that the product of no numbers at all is 1. This is convenient because:
p7830
aV: formula_6
p7831
aVThe factorial function can also be defined for non-integer values using more advanced mathematics, detailed in the section below. This more generalized definition is used by advanced calculators and mathematical software such as Maple or Mathematica.
p7832
aVApplications.
p7833
aVAlthough the factorial function has its roots in combinatorics, formulas involving factorials occur in many areas of mathematics.
p7834
aV:formula_9
p7835
aVpossibilities. This however produces the "k"-combinations in a particular order that one wishes to ignore; since each "k"-combination is obtained in "k"! different ways, the correct number of "k"-combinations is
p7836
aV:formula_10
p7837
aVThis number is known as the binomial coefficient formula_11, because it is also the coefficient of "X""k" in .
p7838
aV:formula_12
p7839
aVwhile this is inefficient as a means to compute that number, it may serve to prove a symmetry property of binomial coefficients:
p7840
aV:formula_13
p7841
aVNumber theory.
p7842
aVFactorials have many applications in number theory. In particular, "n"! is necessarily divisible by all prime numbers up to and including "n". As a consequence, "n" > 5 is a composite number if and only if
p7843
aVformula_14
p7844
aVA stronger result is Wilson's theorem, which states that
p7845
aVformula_15
p7846
aVif and only if "p" is prime.
p7847
aVLegendre's formula gives the multiplicity of the prime "p" occurring in the prime factorization of formula_16 as
p7848
aVformula_17
p7849
aVor, equivalently, 
p7850
aVformula_18
p7851
aVwhere formula_19 denotes the sum of the standard base-"p" digits of "n".
p7852
aVThe only factorial that is also a prime number is 2, but there are many primes of the form "n"! ± 1, called factorial primes.
p7853
aVAll factorials greater than 1! are even, as they are all multiples of 2. Also, all factorials from 5! upwards are multiples of 10 (and hence have a trailing zero as their final digit), because they are multiples of 5 and 2.
p7854
aVSeries of reciprocals.
p7855
aVThe reciprocals of factorials produce a convergent series: (see "e")
p7856
aVformula_20
p7857
aVAlthough the sum of this series is an irrational number, it is possible to multiply the factorials by positive integers to produce a convergent series with a rational sum:
p7858
aVformula_21
p7859
aVThe convergence of this series to 1 can be seen from the fact that its partial sums are less than one by an inverse factorial.
p7860
aVTherefore, the factorials do not form an irrationality sequence.
p7861
aVRate of growth and approximations for large n.
p7862
aVAs "n" grows, the factorial "n"! increases faster than all polynomials and exponential functions (but slower than double exponential functions) in "n".
p7863
aVMost approximations for "n"! are based on approximating its natural logarithm
p7864
aVformula_22
p7865
aVThe graph of the function "f"("n") = log "n"! is shown in the figure on the right. It looks approximately linear for all reasonable values of "n", but this intuition is false.
p7866
aVWe get one of the simplest approximations for log "n"! by bounding the sum with an integral from above and below as follows:
p7867
aVformula_23
p7868
aVwhich gives us the estimate
p7869
aVformula_24
p7870
aVHence log "n"! is \u0398("n" log "n") (see Big "O" notation). This result plays a key role in the analysis of the computational complexity of sorting algorithms (see comparison sort). From the bounds on log "n"! deduced above we get that
p7871
aVformula_25
p7872
aVIt is sometimes practical to use weaker but simpler estimates. Using the above formula it is easily shown that for all "n" we have formula_26, and for all "n" \u2265 6 we have formula_27.
p7873
aVFor large "n" we get a better estimate for the number "n"! using Stirling's approximation:
p7874
aVformula_28
p7875
aVIn fact, it can be proved that for all "n" we have
p7876
aVformula_29 
p7877
aVAnother approximation for is given by Srinivasa Ramanujan 
p7878
aVformula_30
p7879
aVformula_31
p7880
aVThus it is even smaller than the next correction term formula_32 of Stirling's formula.
p7881
aVComputation.
p7882
aVIf efficiency is not a concern, computing factorials is trivial from an algorithmic point of view: successively multiplying a variable initialized to 1 by the integers 2 up to "n" (if any) will compute "n"!, provided the result fits in the variable. In functional languages, the recursive definition is often implemented directly to illustrate recursive functions.
p7883
aVThe main practical difficulty in computing factorials is the size of the result. To assure that the exact result will fit for all legal values of even the smallest commonly used integral type (8-bit signed integers) would require more than 700 bits, so no reasonable specification of a factorial function using fixed-size types can avoid questions of overflow. The values 12! and 20! are the largest factorials that can be stored in, respectively, the 32-bit and 64-bit integers commonly used in personal computers. Floating-point representation of an approximated result allows going a bit further, but this also remains quite limited by possible overflow. Most calculators use scientific notation with 2-digit decimal exponents, and the largest factorial that fits is then 69!, because 69! < 10100 < 70!. Calculators that use 3-digit exponents can compute larger factorials, up to, for example, 253! \u2248 5.2 on HP calculators and 449! \u2248 3.9 on the TI-86. The calculator seen in Mac OS X handles up to 92!, Apple's Numbers, Microsoft Excel and Google Calculator, as well as the freeware Fox Calculator, can handle factorials up to 170!, which is the largest factorial whose floating-point approximation can be represented as a 64-bit IEEE 754 floating-point value. The scientific calculator in Windows 7 and Windows 8 is able to calculate factorials up to 3248!.
p7884
aVMost software applications will compute small factorials by direct multiplication or table lookup. Larger factorial values can be approximated using Stirling's formula. Wolfram Alpha can calculate exact results for the ceiling function and floor function applied to the binary, natural and common logarithm of "n"! for values of "n" up to 249999, and up to 20,000,000! for the integers.
p7885
aVIf the exact values of large factorials are needed, they can be computed using arbitrary-precision arithmetic. Instead of doing the sequential multiplications formula_33, a program can partition the sequence into two parts, whose products are roughly the same size, and multiply them using a divide-and-conquer method. This is often more efficient.
p7886
aVThe asymptotically best efficiency is obtained by computing "n"! from its prime factorization. As documented by Peter Borwein, prime factorization allows "n"! to be computed in time O("n"(log "n" log log "n")2), provided that a fast multiplication algorithm is used (for example, the Schönhage\u2013Strassen algorithm). Peter Luschny presents source code and benchmarks for several efficient factorial algorithms, with or without the use of a prime sieve.
p7887
aVExtension of factorial to non-integer values of argument.
p7888
aVThe Gamma and Pi functions.
p7889
aVBesides nonnegative integers, the factorial function can also be defined for non-integer values, but this requires more advanced tools from mathematical analysis. One function that "fills in" the values of the factorial (but with a shift of 1 in the argument) is called the Gamma function, denoted \u0393("z"), defined for all complex numbers "z" except the non-positive integers, and given when the real part of "z" is positive by
p7890
aVformula_34
p7891
aVIts relation to the factorials is that for any natural number "n"
p7892
aVformula_35
p7893
aVEuler's original formula for the Gamma function was
p7894
aVformula_36
p7895
aVAn alternative notation, originally introduced by Gauss, is sometimes used. The Pi function, denoted \u03a0("z") for real numbers "z" no less than 0, is defined by
p7896
aVformula_37
p7897
aVIn terms of the Gamma function it is
p7898
aVformula_38
p7899
aVIt truly extends the factorial in that
p7900
aVformula_39
p7901
aVIn addition to this, the Pi function satisfies the same recurrence as factorials do, but at every complex value "z" where it is defined
p7902
aVformula_40
p7903
aVIn fact, this is no longer a recurrence relation but a functional equation.
p7904
aVExpressed in terms of the Gamma function this functional equation takes the form
p7905
aVformula_41
p7906
aVSince the factorial is extended by the Pi function, for every complex value "z" where it is defined, we can write:
p7907
aVformula_42
p7908
aVThe values of these functions at half-integer values is therefore determined by a single one of them; one has
p7909
aVformula_43
p7910
aVfrom which it follows that for "n" \u2208 N,
p7911
aVformula_44
p7912
aVFor example,
p7913
aVformula_45
p7914
aVIt also follows that for "n" \u2208 N,
p7915
aVformula_46
p7916
aVFor example,
p7917
aVformula_47
p7918
aVThe Pi function is certainly not the only way to extend factorials to a function defined at almost all complex values, and not even the only one that is analytic wherever it is defined. Nonetheless it is usually considered the most natural way to extend the values of the factorials to a complex function. For instance, the Bohr\u2013Mollerup theorem states that the Gamma function is the only function that takes the value 1 at 1, satisfies the functional equation \u0393("n" + 1) = "n"\u0393("n"), is meromorphic on the complex numbers, and is log-convex on the positive real axis. A similar statement holds for the Pi function as well, using the \u03a0("n") = "n"\u03a0("n" \u2212 1) functional equation.
p7919
aVHowever, there exist complex functions that are probably simpler in the sense of analytic function theory and which interpolate the factorial values. For example, Hadamard's 'Gamma'-function which, unlike the Gamma function, is an entire function.
p7920
aVEuler also developed a convergent product approximation for the non-integer factorials, which can be seen to be equivalent to the formula for the Gamma function above:
p7921
aVformula_48
p7922
aVHowever, this formula does not provide a practical means of computing the Pi or Gamma function, as its rate of convergence is slow.
p7923
aVApplications of the Gamma function.
p7924
aVThe volume of an "n"-dimensional hypersphere of radius "R" is
p7925
aVformula_49
p7926
aVFactorial at the complex plane.
p7927
aVRepresentation through the Gamma-function allows evaluation of factorial of complex argument. Equilines of amplitude and phase of factorial are shown in figure. Let formula_50. Several levels of constant modulus (amplitude) formula_51 and constant phase formula_52 are shown. The grid covers range
p7928
aVformula_53,
p7929
aVformula_54
p7930
aVwith unit step. The scratched line shows the level formula_55.
p7931
aVThin lines show intermediate levels of constant modulus and constant phase. At poles formula_56, phase and amplitude are not defined. Equilines are dense in vicinity of singularities along negative integer values of the argument.
p7932
aVFor formula_57, the Taylor expansions can be used:
p7933
aVformula_58
p7934
aVThe first coefficients of this expansion are
p7935
aVwhere formula_59 is the Euler constant and formula_60 is the Riemann zeta function. Computer algebra systems such as Sage can generate many terms of this expansion.
p7936
aVApproximations of factorial.
p7937
aVFor the large values of the argument,
p7938
aVfactorial can be approximated through the integral of the
p7939
aVdigamma function, using the continued fraction representation.
p7940
aVThis approach is due to T. J. Stieltjes (1894). Writing "z"! = exp(P("z")) where P("z") is
p7941
aV formula_61
p7942
aVStieltjes gave a continued fraction for p("z")
p7943
aV formula_62
p7944
aVThe first few coefficients an are
p7945
aVThere is a misconception that formula_63 or formula_64
p7946
aVfor any complex "z" \u2260 0. Indeed, the relation through the logarithm is valid only for specific range of values of "z" in vicinity of the real axis, while formula_65. The larger is the real part of the argument, the smaller should be the imaginary part. However, the inverse relation, "z"! = exp("P"("z")), is valid for the whole complex plane apart from zero. The convergence is poor in vicinity of the negative part of the real axis. (It is difficult to have good convergence of any approximation in vicinity of the singularities). While formula_66 or formula_67, the 6 coefficients above are sufficient for the evaluation of the factorial with the complex<double> precision. For higher precision more coefficients can be computed by a rational QD-scheme (H. Rutishauser's QD algorithm).
p7947
aVNon-extendability to negative integers.
p7948
aVThe relation "n"! = "n" × ("n" \u2212 1)! allows one to compute the factorial for an integer given the factorial for a "smaller" integer. The relation can be inverted so that one can compute the factorial for an integer given the factorial for a "larger" integer:
p7949
aVformula_68
p7950
aVNote, however, that this recursion does not permit us to compute the factorial of a negative integer; use of the formula to compute (\u22121)! would require a division by zero, and thus blocks us from computing a factorial value for every negative integer. (Similarly, the Gamma function is not defined for non-positive integers, though it is defined for all other complex numbers.)
p7951
aVFactorial-like products and functions.
p7952
aVThere are several other integer sequences similar to the factorial that are used in mathematics:
p7953
aVDouble factorial.
p7954
aVThe product of all the odd integers up to some odd positive integer "n" is called the double factorial of "n", and denoted by "n"!!. That is,
p7955
aVformula_69
p7956
aVFor example, 9!! = 1 × 3 × 5 × 7 × 9 = 945.
p7957
aVThe sequence of double factorials for "n" = 1, 3, 5, 7, ... starts as
p7958
aV 1, 3, 15, 105, 945, 10395, 135135, ... 
p7959
aVDouble factorial notation may be used to simplify the expression of certain trigonometric integrals, to provide an expression for the values of the Gamma function at half-integer arguments and the volume of hyperspheres, and to solve many counting problems in combinatorics including counting binary trees with labeled leaves and perfect matchings in complete graphs.
p7960
aVMultifactorials.
p7961
aVA common related notation is to use multiple exclamation points to denote a multifactorial, the product of integers in steps of two (formula_70), three (formula_71), or more. The double factorial is the most commonly used variant, but one can similarly define the triple factorial (formula_71) and so on. One can define the "k"-th factorial, denoted by formula_73, recursively for non-negative integers as
p7962
aVformula_74
p7963
aVthough see the alternative definition below.
p7964
aVSome mathematicians have suggested an alternative notation of formula_75 for the double factorial and similarly formula_76 for other multifactorials, but this has not come into general use.
p7965
aVIn the same way that formula_16 is not defined for negative integers, and formula_70 is not defined for negative even integers, formula_73 is not defined for negative integers divisible by formula_80.
p7966
aVAlternative extension of the multifactorial.
p7967
aVAlternatively, the multifactorial "z"!("k") can be extended to most real and complex numbers "z" by noting that when "z" is one more than a positive multiple of "k" then
p7968
aVformula_81
p7969
aVThis last expression is defined much more broadly than the original; with this definition, "z"!("k") is defined for all complex numbers except the negative real numbers evenly divisible by "k". This definition is consistent with the earlier definition only for those integers "z" satisfying "z" \u2261 1 mod "k".
p7970
aVIn addition to extending "z"!("k") to most complex numbers "z", this definition has the feature of working for all positive real values of "k". Furthermore, when "k" = 1, this definition is mathematically equivalent to the \u03a0("z") function, described above. Also, when "k" = 2, this definition is mathematically equivalent to the alternative extension of the double factorial.
p7971
aVPrimorial.
p7972
aVThe primorial is similar to the factorial, but with the product taken only over the prime numbers.
p7973
aVQuadruple factorial.
p7974
aVThe quadruple factorial is not the multifactorial "n"!(4); it is a much larger number given by (2"n")!/"n"!, starting as
p7975
aV1, 2, 12, 120, 1680, 30240, 665280, ... .
p7976
aVIt is also equal to
p7977
aV formula_82
p7978
aVSuperfactorial.
p7979
aVNeil Sloane and Simon Plouffe defined a superfactorial in The Encyclopedia of Integer Sequences (Academic Press, 1995) to be the product of the first formula_83 factorials. So the superfactorial of 4 is
p7980
aVformula_84
p7981
aVIn general
p7982
aVformula_85) as
p7983
aV1, 1, 2, 12, 288, 34560, 24883200, 125411328000, ... 
p7984
aVAlternative definition.
p7985
aVClifford Pickover in his 1995 book "Keys to Infinity" used a new notation, "n$", to define the superfactorial
p7986
aVformula_86
p7987
aVor as,
p7988
aVformula_87
p7989
aVwhere the notation denotes the hyper4 operator, or using Knuth's up-arrow notation,
p7990
aVformula_88
p7991
aVThis sequence of superfactorials starts:
p7992
aVformula_89
p7993
aVformula_90
p7994
aVformula_91
p7995
aVHere, as is usual for compound exponentiation, the grouping is understood to be from right to left:
p7996
aVformula_92
p7997
aVHyperfactorial.
p7998
aVOccasionally the hyperfactorial of "n" is considered. It is written as "H"("n") and defined by
p7999
aVformula_93
p8000
aVwhere "A" = 1.2824... is the Glaisher\u2013Kinkelin constant. "H"(14) = 1.8474...×1099 is already almost equal to a googol, and "H"(15) = 8.0896...×10116 is almost of the same magnitude as the Shannon number, the theoretical number of possible chess games. Compared to the Pickover definition of the superfactorial, the hyperfactorial grows relatively slowly.
p8001
aVThe hyperfactorial function can be generalized to complex numbers in a similar way as the factorial function. The resulting function is called the K-function.
p8002
asS'Dimensionless quantity'
p8003
(lp8004
VIn dimensional analysis, a dimensionless quantity is a quantity to which no physical dimension is applicable. It is thus a bare number, and is therefore also known as a quantity of dimension one. Dimensionless quantities are widely used in many fields, such as mathematics, physics, engineering, and economics. Numerous well-known quantities, such as pi, Euler's number, and Golden ratio, are dimensionless. By contrast, examples of quantities with dimensions are length, time, and speed, which are measured in dimensional units, such as meter, second and meter/second.
p8005
aVDimensionless quantities are often obtained as products or ratios of quantities that are not dimensionless, but whose dimensions cancel in the mathematical operation. This is the case, for instance, with the engineering strain, a measure of deformation. It is defined as change in length, divided by initial length, but because these quantities both have dimensions "L" (length), the result is a dimensionless quantity.
p8006
aVBuckingham \u03c0 theorem.
p8007
aVAnother consequence of the Buckingham \u03c0 theorem of dimensional analysis is that the functional dependence between a certain number (say, "n") of variables can be reduced by the number (say, "k") of independent dimensions occurring in those variables to give a set of "p" = "n" \u2212 "k" independent, dimensionless quantities. For the purposes of the experimenter, different systems that share the same description by dimensionless quantity are equivalent.
p8008
aVExample.
p8009
aVThe power consumption of a stirrer with a given shape is a function of the density and the viscosity of the fluid to be stirred, the size of the stirrer given by its diameter, and the speed of the stirrer. Therefore, we have "n" = 5 variables representing our example.
p8010
aVThose "n" = 5 variables are built up from "k" = 3 dimensions:
p8011
aVAccording to the \u03c0-theorem, the "n" = 5 variables can be reduced by the "k" = 3 dimensions to form "p" = "n" \u2212 "k" = 5 \u2212 3 = 2 independent dimensionless numbers, which are, in case of the stirrer:
p8012
aVStandards efforts.
p8013
aVThe International Committee for Weights and Measures contemplated defining the unit of 1 as the 'uno', but the idea was dropped.
p8014
aVDimensionless physical constants.
p8015
aVCertain fundamental physical constants, such as the speed of light in a vacuum, the universal gravitational constant, Planck's constant and Boltzmann's constant can be normalized to 1 if appropriate units for time, length, mass, charge, and temperature are chosen. The resulting system of units is known as the natural units. However, not all physical constants can be normalized in this fashion. For example, the values of the following constants are independent of the system of units and must be determined experimentally:
p8016
aVList of dimensionless quantities.
p8017
aVAll numbers are dimensionless quantities. Certain dimensionless quantities of some importance are given below:
p8018
asS'Algebraic geometry'
p8019
(lp8020
VAlgebraic geometry is a branch of mathematics, classically studying zeros of polynomial equations. Modern algebraic geometry is based on more abstract techniques of abstract algebra, especially commutative algebra, with the language and the problems of geometry.
p8021
aVThe fundamental objects of study in algebraic geometry are algebraic varieties, which are geometric manifestations of solutions of systems of polynomial equations. Examples of the most studied classes of algebraic varieties are: plane algebraic curves, which include lines, circles, parabolas, ellipses, hyperbolas, cubic curves like elliptic curves and quartic curves like lemniscates, and Cassini ovals. A point of the plane belongs to an algebraic curve if its coordinates satisfy a given polynomial equation. Basic questions involve the study of the points of special interest like the singular points, the inflection points and the points at infinity. More advanced questions involve the topology of the curve and relations between the curves given by different equations.
p8022
aVAlgebraic geometry occupies a central place in modern mathematics and has multiple conceptual connections with such diverse fields as complex analysis, topology and number theory. Initially a study of systems of polynomial equations in several variables, the subject of algebraic geometry starts where equation solving leaves off, and it becomes even more important to understand the intrinsic properties of the totality of solutions of a system of equations, than to find a specific solution; this leads into some of the deepest areas in all of mathematics, both conceptually and in terms of technique.
p8023
aVIn the 20th century, algebraic geometry has split into several subareas.
p8024
aVMuch of the development of the main stream of algebraic geometry in the 20th century occurred within an abstract algebraic framework, with increasing emphasis being placed on "intrinsic" properties of algebraic varieties not dependent on any particular way of embedding the variety in an ambient coordinate space; this parallels developments in topology, differential and complex geometry. One key achievement of this abstract algebraic geometry is Grothendieck's scheme theory which allows one to use sheaf theory to study algebraic varieties in a way which is very similar to its use in the study of differential and analytic manifolds. This is obtained by extending the notion of point: In classical algebraic geometry, a point of an affine variety may be identified, through Hilbert's Nullstellensatz, with a maximal ideal of the coordinate ring, while the points of the corresponding affine scheme are all prime ideals of this ring. This means that a point of such a scheme may be either a usual point or a subvariety. This approach also enables a unification of the language and the tools of classical algebraic geometry, mainly concerned with complex points, and of algebraic number theory. Wiles's proof of the longstanding conjecture called Fermat's last theorem is an example of the power of this approach.
p8025
aVBasic notions.
p8026
aVZeros of simultaneous polynomials.
p8027
aVIn classical algebraic geometry, the main objects of interest are the vanishing sets of collections of polynomials, meaning the set of all points that simultaneously satisfy one or more polynomial equations. For instance, the two-dimensional sphere in three-dimensional Euclidean space R3 could be defined as the set of all points ("x","y","z") with
p8028
aVformula_1
p8029
aVA "slanted" circle in R3 can be defined as the set of all points ("x","y","z") which satisfy the two polynomial equations
p8030
aVformula_2
p8031
aVformula_3
p8032
aVAffine varieties.
p8033
aVFirst we start with a field "k". In classical algebraic geometry, this field was always the complex numbers C, but many of the same results are true if we assume only that "k" is algebraically closed. We consider the affine space of dimension "n" over "k", denoted An("k") (or more simply A"n", when "k" is clear from the context). When one fixes a coordinates system, one may identify An("k") with "k""n". The purpose of not working with "k""n" is to emphasize that one "forgets" the vector space structure that "k"n carries.
p8034
aVA function "f" : A"n" \u2192 A1 is said to be "polynomial" (or "regular") if it can be written as a polynomial, that is, if there is a polynomial "p" in "k"["x"1...,"x""n"] such that "f"("M") = "p"("t"1...,"t""n") for every point "M" with coordinates ("t"1...,"t""n") in A"n". The property of a function to be polynomial (or regular) does not depend on the choice of a coordinate system in A"n".
p8035
aVWhen a coordinate system is chosen, the regular functions on the affine "n"-space may be identified with the ring of polynomial functions in "n" variables over "k". Therefore the set of the regular functions on A"n" is a ring, which is denoted "k"[A"n"].
p8036
aVWe say that a polynomial "vanishes" at a point if evaluating it at that point gives zero. Let "S" be a set of polynomials in "k"[An]. The "vanishing set of S" (or "vanishing locus" or "zero set") is the set "V"("S") of all points in A"n" where every polynomial in "S" vanishes. In other words,
p8037
aVformula_4
p8038
aVA subset of A"n" which is "V"("S"), for some "S", is called an "algebraic set". The "V" stands for "variety" (a specific type of algebraic set to be defined below).
p8039
aVGiven a subset "U" of A"n", can one recover the set of polynomials which generate it? If "U" is "any" subset of A"n", define "I"("U") to be the set of all polynomials whose vanishing set contains "U". The "I" stands for ideal: if two polynomials "f" and "g" both vanish on "U", then "f"+"g" vanishes on "U", and if "h" is any polynomial, then "hf" vanishes on "U", so "I"("U") is always an ideal of the polynomial ring "k"[A"n"].
p8040
aVTwo natural questions to ask are:
p8041
aVThe answer to the first question is provided by introducing the Zariski topology, a topology on A"n" whose closed sets are the algebraic sets, and which directly reflects the algebraic structure of "k"[A"n"]. Then "U" = "V"("I"("U")) if and only if "U" is an algebraic set or equivalently a Zariski-closed set. The answer to the second question is given by Hilbert's Nullstellensatz. In one of its forms, it says that "I"("V"("S")) is the radical of the ideal generated by "S". In more abstract language, there is a Galois connection, giving rise to two closure operators; they can be identified, and naturally play a basic role in the theory; the example is elaborated at Galois connection.
p8042
aVFor various reasons we may not always want to work with the entire ideal corresponding to an algebraic set "U". Hilbert's basis theorem implies that ideals in "k"[A"n"] are always finitely generated.
p8043
aVAn algebraic set is called "irreducible" if it cannot be written as the union of two smaller algebraic sets. Any algebraic set is a finite union of irreducible algebraic sets and this decomposition is unique. Thus its elements are called the "irreducible components" of the algebraic set. An irreducible algebraic set is also called a "variety". It turns out that an algebraic set is a variety if and only if it may be defined as the vanishing set of a prime ideal of the polynomial ring.
p8044
aVSome authors do not make a clear distinction between algebraic sets and varieties and use "irreducible variety" to make the distinction when needed.
p8045
aVRegular functions.
p8046
aVJust as continuous functions are the natural maps on topological spaces and smooth functions are the natural maps on differentiable manifolds, there is a natural class of functions on an algebraic set, called "regular functions" or "polynomial functions". A regular function on an algebraic set "V" contained in An is the restriction to "V" of a regular function on An. For an algebraic set defined on the field of the complex numbers, the regular functions are smooth and even analytic.
p8047
aVIt may seem unnaturally restrictive to require that a regular function always extend to the ambient space, but it is very similar to the situation in a normal topological space, where the Tietze extension theorem guarantees that a continuous function on a closed subset always extends to the ambient topological space.
p8048
aVJust as with the regular functions on affine space, the regular functions on "V" form a ring, which we denote by "k"["V"]. This ring is called the "coordinate ring of V".
p8049
aVSince regular functions on V come from regular functions on An, there is a relationship between the coordinate rings. Specifically, if a regular function on "V" is the restriction of two functions "f" and "g" in "k"[An], then "f" \u2212 "g" is a polynomial function which is null on "V" and thus belongs to "I"("V"). Thus "k"["V"] may be identified with "k"[An]/"I"("V").
p8050
aVMorphism of affine varieties.
p8051
aVUsing regular functions from an affine variety to A1, we can define regular maps from one affine variety to another. First we will define a regular map from a variety into affine space: Let "V" be a variety contained in An. Choose "m" regular functions on "V", and call them "f"1, ..., "f""m". We define a "regular map" "f" from "V" to Am by letting "f" = ("f"1, ..., "f""m"). In other words, each "f""i" determines one coordinate of the range of "f".
p8052
aVIf "V"' is a variety contained in Am, we say that "f" is a "regular map" from "V" to "V"' if the range of "f" is contained in "V"'.
p8053
aVThe definition of the regular maps apply also to algebraic sets.
p8054
aVThe regular maps are also called "morphisms", as they make the collection of all affine algebraic sets into a category, where the objects are the affine algebraic sets and the morphisms are the regular maps. The affine varieties is a subcategory of the category of the algebraic sets.
p8055
aVGiven a regular map "g " from "V" to "V"' and a regular function "f" of "k"["V"'], then "f"\u2218"g"\u2208"k"["V"]. The map "f"\u2192"f"\u2218"g" is a ring homomorphism from "k"["V"'] to "k"["V"]. Conversely, every ring homomorphism from "k"["V"'] to "k"["V"] defines a regular map from "V" to "V"'. This defines an equivalence of categories between the category of algebraic sets and the opposite category of the finitely generated reduced "k"-algebras. This equivalence is one of the starting points of scheme theory.
p8056
aVRational function and birational equivalence.
p8057
aVContrarily to the preceding ones, this section concerns only varieties and not algebraic sets. On the other hand the definitions extend naturally to projective varieties (next section), as an affine variety and its projective completion have the same field of functions.
p8058
aVIf "V" is an affine variety, its coordinate ring is an integral domain and has thus a field of fractions which is denoted "k"("V") and called the "field of the rational functions" on "V" or, shortly, the "function field" of "V". Its elements are the restrictions to "V" of the rational functions over the affine space containing "V". The domain of a rational function "f" is not "V" but the complement of the subvariety (a hypersurface) where the denominator of "f" vanishes.
p8059
aVLike for regular maps, one may define a "rational map" from a variety "V" to a variety "V"'. Like for the regular maps, the rational maps from "V" to "V"' may be identified to the field homomorphisms from "k"("V"') to "k"("V").
p8060
aVTwo affine varieties are "birationally equivalent" if there are two rational functions between them which are inverse one to the other in the regions where both are defined. Equivalently, they are birationally equivalent if their function fields are isomorphic.
p8061
aVAn affine variety is a "rational variety" if it is birationally equivalent to an affine space. This means that the variety admits a rational parameterization. For example, the circle of equation formula_5 is a rational curve, as it has the parameterization
p8062
aVformula_6
p8063
aVformula_7
p8064
aVwhich may also be viewed as a rational map from the line to the circle.
p8065
aVThe problem of resolution of singularities is to know if every algebraic variety is birationally equivalent to a variety whose projective completion is nonsingular (see also smooth completion). It has been positively solved in characteristic 0 by Heisuke Hironaka in 1964 and is yet unsolved in finite characteristic.
p8066
aVProjective variety.
p8067
aVJust as the formulas for the roots of 2nd, 3rd and 4th degree polynomials suggest extending real numbers to the more algebraically complete setting of the complex numbers, many properties of algebraic varieties suggest extending affine space to a more geometrically complete projective space. Whereas the complex numbers are obtained by adding the number i, a root of the polynomial x^2 + 1, projective space is obtained by adding in appropriate points "at infinity", points where parallel lines may meet.
p8068
aVTo see how this might come about, consider the variety "V"("y" \u2212 "x"2). If we draw it, we get a parabola. As "x" goes to positive infinity, the slope of the line from the origin to the point ("x", "x"2) also goes to positive infinity. As "x" goes to negative infinity, the slope of the same line goes to negative infinity.
p8069
aVCompare this to the variety "V"("y" \u2212 "x"3). This is a cubic curve. As "x" goes to positive infinity, the slope of the line from the origin to the point ("x", "x"3) goes to positive infinity just as before. But unlike before, as "x" goes to negative infinity, the slope of the same line goes to positive infinity as well; the exact opposite of the parabola. So the behavior "at infinity" of "V"("y" \u2212 "x"3) is different from the behavior "at infinity" of "V"("y" \u2212 "x"2).
p8070
aVThe consideration of the "projective completion" of the two curves, which is their prolongation "at infinity" in the projective plane, allows to quantify this difference: the point at infinity of the parabola is a regular point, whose tangent is the line at infinity, while the point at infinity of the cubic curve is a cusp. Also, both curves are rational, as they are parameterized by "x", and Riemann-Roch theorem implies that the cubic curve must have a singularity, which must be at infinity, as all its points in the affine space are regular.
p8071
aVThus many of the properties of algebraic varieties, including birational equivalence and all the topological properties, depends on the behavior "at infinity" and so it is natural to study the varieties in projective space. Furthermore, the introduction of projective techniques made many theorems in algebraic geometry simpler and sharper: For example, Bézout's theorem on the number of intersection points between two varieties can be stated in its sharpest form only in projective space. For these reasons, projective space plays a fundamental role in algebraic geometry.
p8072
aVNowadays, the "projective space" P"n" of dimension "n" is usually defined as the set of the lines passing through a point, considered as the origin, in the affine space of dimension "n"+1, or equivalently to the set of the vector lines in a vector space of dimension "n"+1. When a coordinate system has been chosen in the space of dimension "n"+1, all the points of a line have the same set of coordinates, up to the multiplication by an element of "k". This defines the homogeneous coordinates of a point of P"n" as a sequence of "n"+1 elements of the base field "k", defined up to the multiplication by a nonzero element of "k" (the same for the whole sequence).
p8073
aVGiven a polynomial in "n"+1 variables, it vanishes at all the point of a line passing through the origin if and only if it is homogeneous. In this case, one says that the polynomial "vanishes" at the corresponding point of P"n". This allows to define a "projective algebraic set" in P"n" as the set "V"("f"1, ..., "f""k") where a finite set of homogeneous polynomials {"f"1, ..., "f""k"} vanishes. Like for affine algebraic sets, there is a bijection between the projective algebraic sets and the reduced homogeneous ideals which define them. The "projective varieties" are the projective algebraic sets whose defining ideal is prime. In other words, a projective variety is a projective algebraic set, whose homogeneous coordinate ring is an integral domain, the "projective coordinates ring" being defined as the quotient of the graded ring or the polynomials in "n"+1 variables by the homogeneous (reduced) ideal defining the variety. Every projective algebraic set may be uniquely decomposed into a finite union of projective varieties.
p8074
aVThe only regular functions which may be defined properly on a projective variety are the constant functions. Thus this notion is not used in projective situations. On the other hand the "field of the rational functions" or "function field " is a useful notion, which, similarly as in the affine case, is defined as the set of the quotients of two homogeneous elements of the same degree in the homogeneous coordinate ring.
p8075
aVReal algebraic geometry.
p8076
aVThe real algebraic geometry is the study of the real points of the algebraic geometry.
p8077
aVThe fact that the field of the reals number is an ordered field may not be occulted in such a study. For example, the curve of equation formula_8 is a circle if formula_9, but does not have any real point if formula_10. It follows that real algebraic geometry is not only the study of the real algebraic varieties, but has been generalized to the study of the "semi-algebraic sets", which are the solutions of systems of polynomial equations and polynomial inequalities. For example, a branch of the hyperbola of equation formula_11 is not an algebraic variety, but is a semi-algebraic set defined by formula_12 and formula_13 or by formula_12 and formula_15.
p8078
aVOne of the challenging problems of real algebraic geometry is the unsolved Hilbert's sixteenth problem: Decide which respective positions are possible for the ovals of a nonsingular plane curve of degree 8.
p8079
aVComputational algebraic geometry.
p8080
aVOne may date the origin of computational algebraic geometry to meeting EUROSAM'79 (International Symposium on Symbolic and Algebraic Manipulation) held at Marseille, France in June 1979. At this meeting,
p8081
aVSince then, most results in this area are related to one or several of these items either by using or improving one of these algorithms, or by finding algorithms whose complexity is simply exponential in the number of the variables.
p8082
aVGröbner basis.
p8083
aVA Gröbner basis is a system of generators of a polynomial ideal whose computation allows the deduction of many properties of the affine algebraic variety defined by the ideal.
p8084
aVGiven an ideal "I" defining an algebraic set "V":
p8085
aVGröbner basis computations do not allow to compute directly the primary decomposition of "I" nor the prime ideals defining the irreducible components of "V", but most algorithms for this involve Gröbner basis computation. The algorithms which are not based on Gröbner bases use regular chains but may need Gröbner bases in some exceptional situations.
p8086
aVGröbner base are deemed to be difficult to compute. In fact they may contain, in the worst case, polynomials whose degree is doubly exponential in the number of variables and a number of polynomials which is also doubly exponential. However, this is only a worst case complexity, and the complexity bound of Lazard's algorithm of 1979 may frequently apply. Faugère's F4 and F5 algorithms realize this complexity, as F5 algorithm may be viewed as an improvement of Lazard's 1979 algorithm. It follows that the best implementations allow to compute almost routinely with algebraic sets of degree more than 100. This means that, presently, the difficulty of computing a Gröbner basis is strongly related to the intrinsic difficulty of the problem.
p8087
aVCylindrical Algebraic Decomposition (CAD).
p8088
aVCAD is an algorithm which had been introduced in 1973 by G. Collins to implement with an acceptable complexity the Tarski\u2013Seidenberg theorem on quantifier elimination over the real numbers.
p8089
aVThis theorem concerns the formulas of the first-order logic whose atomic formulas are polynomial equalities or inequalities between polynomials with real coefficients. These formulas are thus the formulas which may be constructed from the atomic formulas by the logical operators "and" (\u2227), "or" (\u2228), "not" (¬), "for all" (\u2200) and "exists" (\u2203). Tarski's theorem asserts that, from such a formula, one may compute an equivalent formula without quantifier (\u2200, \u2203).
p8090
aVThe complexity of CAD is doubly exponential in the number of variables. This means that CAD allow, in theory, to solve every problem of real algebraic geometry which may be expressed by such a formula, that is almost every problem concerning explicitly given varieties and semi-algebraic sets.
p8091
aVWhile Gröbner basis computation has doubly exponential complexity only in rare cases, CAD has almost always this high complexity. This implies that, unless if most polynomials appearing in the input are linear, it may not solve problems with more than four variables.
p8092
aVSince 1973, most of the research on this subject is devoted either to improve CAD or to find alternate algorithms in special cases of general interest.
p8093
aVAs an example of the state of art, there are efficient algorithms to find at least a point in every connected component of a semi-algebraic set, and thus to test if a semi-algebraic set is empty. On the other hand CAD is yet, in practice, the best algorithm to count the number of connected components.
p8094
aVAsymptotic complexity vs. practical efficiency.
p8095
aVThe basic general algorithms of computational geometry have a double exponential worst case complexity. More precisely, if "d" is the maximal degree of the input polynomials and "n" the number of variables, their complexity is at most formula_16 for some constant "c", and, for some inputs, the complexity is at least formula_17 for another constant "c"\u2032.
p8096
aVDuring the last 20 years of 20th century, various algorithms have been introduced to solve specific subproblems with a better complexity. Most of these algorithms have a complexity formula_18.
p8097
aVAmong these algorithms which solve a sub problem of the problems solved by Gröbner bases, one may cite "testing if an affine variety is empty" and "solving nonhomogeneous polynomial systems which have a finite number of solutions." Such algorithms are rarely implemented because, on most entries Faugère's F4 and F5 algorithms have a better practical efficiency and probably a similar or better complexity ("probably" because the evaluation of the complexity of Gröbner basis algorithms on a particular class of entries is a difficult task which has be done only in few special cases).
p8098
aVThe main algorithms of real algebraic geometry which solve a problem solved by CAD are related to the topology of semi-algebraic sets. One may cite "counting the number of connected components", "testing if two points are in the same components" or "computing a Whitney stratification of a real algebraic set". They have a complexity of
p8099
aVformula_18, but the constant involved by "O" notation is so high that using them to solve any nontrivial problem effectively solved by CAD, is impossible even if one could use all the existing computing power in the world. Therefore these algorithms have never been implemented and this is an active research area to search for algorithms with have together a good asymptotic complexity and a good practical efficiency.
p8100
aVAbstract modern viewpoint.
p8101
aVThe modern approaches to algebraic geometry redefine and effectively extend the range of basic objects in various levels of generality to schemes, formal schemes, ind-schemes, algebraic spaces, algebraic stacks and so on. The need for this arises already from the useful ideas within theory of varieties, e.g. the formal functions of Zariski can be accommodated by introducing nilpotent elements in structure rings; considering spaces of loops and arcs, constructing quotients by group actions and developing formal grounds for natural intersection theory and deformation theory lead to some of the further extensions.
p8102
aVMost remarkably, in late 1950s, algebraic varieties were subsumed into Alexander Grothendieck's concept of a scheme. Their local objects are affine schemes or prime spectra which are locally ringed spaces which form a category which is antiequivalent to the category of commutative unital rings, extending the duality between the category of affine algebraic varieties over a field "k", and the category of finitely generated reduced "k"-algebras. The gluing is along Zariski topology; one can glue within the category of locally ringed spaces, but also, using the Yoneda embedding, within the more abstract category of presheaves of sets over the category of affine schemes. The Zariski topology in the set theoretic sense is then replaced by a Grothendieck topology. Grothendieck introduced Grothendieck topologies having in mind more exotic but geometrically finer and more sensitive examples than the crude Zariski topology, namely the étale topology, and the two flat Grothendieck topologies: fppf and fpqc; nowadays some other examples became prominent including Nisnevich topology. Sheaves can be furthermore generalized to stacks in the sense of Grothendieck, usually with some additional representability conditions leading to Artin stacks and, even finer, Deligne-Mumford stacks, both often called algebraic stacks.
p8103
aVSometimes other algebraic sites replace the category of affine schemes. For example, Nikolai Durov has introduced commutative algebraic monads as a generalization of local objects in a generalized algebraic geometry. Versions of a tropical geometry, of an absolute geometry over a field of one element and an algebraic analogue of Arakelov's geometry were realized in this setup.
p8104
aVAnother formal generalization is possible to Universal algebraic geometry in which every variety of algebras has its own algebraic geometry. The term "variety of algebras" should not be confused with "algebraic variety".
p8105
aVThe language of schemes, stacks and generalizations has proved to be a valuable way of dealing with geometric concepts and became cornerstones of modern algebraic geometry.
p8106
aVAlgebraic stacks can be further generalized and for many practical questions like deformation theory and intersection theory, this is often the most natural approach. One can extend the Grothendieck site of affine schemes to a higher categorical site of derived affine schemes, by replacing the commutative rings with an infinity category of differential graded commutative algebras, or of simplicial commutative rings or a similar category with an appropriate variant of a Grothendieck topology. One can also replace presheaves of sets by presheaves of simplicial sets (or of infinity groupoids). Then, in presence of an appropriate homotopic machinery one can develop a notion of derived stack as such a presheaf on the infinity category of derived affine schemes, which is satisfying certain infinite categorical version of a sheaf axiom (and to be algebraic, inductively a sequence of representability conditions). Quillen model categories, Segal categories and quasicategories are some of the most often used tools to formalize this yielding the "derived algebraic geometry", introduced by the school of Carlos Simpson, including Andre Hirschowitz, Bertrand Toën, Gabrielle Vezzosi, Michel Vaquié and others; and developed further by Jacob Lurie, Bertrand Toën, and Gabrielle Vezzosi. Another (noncommutative) version of derived algebraic geometry, using A-infinity categories has been developed from early 1990-s by Maxim Kontsevich and followers.
p8107
aVHistory.
p8108
aVPrehistory: before the 19th century.
p8109
aVSome of the roots of algebraic geometry date back to the work of the Hellenistic Greeks from the 5th century BC. The Delian problem, for instance, was to construct a length "x" so that the cube of side "x" contained the same volume as the rectangular box "a"2"b" for given sides "a" and "b". Menaechmus (circa 350 BC) considered the problem geometrically by intersecting the pair of plane conics "ay" = "x"2 and "xy" = "ab". The later work, in the 3rd century BC, of Archimedes and Apollonius studied more systematically problems on conic sections, and also involved the use of coordinates. The Arab mathematicians were able to solve by purely algebraic means certain cubic equations, and then to interpret the results geometrically. This was done, for instance, by Ibn al-Haytham in the 10th century AD. Subsequently, Persian mathematician Omar Khayyám (born 1048 A.D.) discovered the general method of solving cubic equations by intersecting a parabola with a circle. Each of these early developments in algebraic geometry dealt with questions of finding and describing the intersections of algebraic curves.
p8110
aVSuch techniques of applying geometrical constructions to algebraic problems were also adopted by a number of Renaissance mathematicians such as Gerolamo Cardano and Niccolò Fontana "Tartaglia" on their studies of the cubic equation. The geometrical approach to construction problems, rather than the algebraic one, was favored by most 16th and 17th century mathematicians, notably Blaise Pascal who argued against the use of algebraic and analytical methods in geometry. The French mathematicians Franciscus Vieta and later René Descartes and Pierre de Fermat revolutionized the conventional way of thinking about construction problems through the introduction of coordinate geometry. They were interested primarily in the properties of "algebraic curves", such as those defined by Diophantine equations (in the case of Fermat), and the algebraic reformulation of the classical Greek works on conics and cubics (in the case of Descartes).
p8111
aVDuring the same period, Blaise Pascal and Gérard Desargues approached geometry from a different perspective, developing the synthetic notions of projective geometry. Pascal and Desargues also studied curves, but from the purely geometrical point of view: the analog of the Greek "ruler and compass construction". Ultimately, the analytic geometry of Descartes and Fermat won out, for it supplied the 18th century mathematicians with concrete quantitative tools needed to study physical problems using the new calculus of Newton and Leibniz. However, by the end of the 18th century, most of the algebraic character of coordinate geometry was subsumed by the "calculus of infinitesimals" of Lagrange and Euler.
p8112
aV19th and early 20th century.
p8113
aVIt took the simultaneous 19th century developments of non-Euclidean geometry and Abelian integrals in order to bring the old algebraic ideas back into the geometrical fold. The first of these new developments was seized up by Edmond Laguerre and Arthur Cayley, who attempted to ascertain the generalized metric properties of projective space. Cayley introduced the idea of "homogeneous polynomial forms", and more specifically quadratic forms, on projective space. Subsequently, Felix Klein studied projective geometry (along with other types of geometry) from the viewpoint that the geometry on a space is encoded in a certain class of transformations on the space. By the end of the 19th century, projective geometers were studying more general kinds of transformations on figures in projective space. Rather than the projective linear transformations which were normally regarded as giving the fundamental Kleinian geometry on projective space, they concerned themselves also with the higher degree birational transformations. This weaker notion of congruence would later lead members of the 20th century Italian school of algebraic geometry to classify algebraic surfaces up to birational isomorphism.
p8114
aVThe second early 19th century development, that of Abelian integrals, would lead Bernhard Riemann to the development of Riemann surfaces.
p8115
aVIn the same period began the algebraization of the algebraic geometry through commutative algebra. The prominent results in this direction are David Hilbert's basis theorem and Nullstellensatz, which are the basis of the connexion between algebraic geometry and commutative algebra, and Francis Sowerby Macaulay's multivariate resultant, which is the basis of elimination theory. Probably because of the size of the computation which is implied by multivariate resultants, elimination theory was forgotten during the middle of the 20th century until it was renewed by singularity theory and computational algebraic geometry.
p8116
aV20th century.
p8117
aVB. L. van der Waerden, Oscar Zariski and André Weil developed a foundation for algebraic geometry based on contemporary commutative algebra, including valuation theory and the theory of ideals. One of the goals was to give a rigorous framework for proving the results of Italian school of algebraic geometry. In particular, this school used systematically the notion of generic point without any precise definition, which was first given by these authors during the 1930s.
p8118
aVIn the 1950s and 1960s Jean-Pierre Serre and Alexander Grothendieck recast the foundations making use of sheaf theory. Later, from about 1960, and largely lead by Grothendieck, the idea of schemes was worked out, in conjunction with a very refined apparatus of homological techniques. After a decade of rapid development the field stabilized in the 1970s, and new applications were made, both to number theory and to more classical geometric questions on algebraic varieties, singularities and moduli.
p8119
aVAn important class of varieties, not easily understood directly from their defining equations, are the abelian varieties, which are the projective varieties whose points form an abelian group. The prototypical examples are the elliptic curves, which have a rich theory. They were instrumental in the proof of Fermat's last theorem and are also used in elliptic curve cryptography.
p8120
aVIn parallel with the abstract trend of the algebraic geometry, which is concerned with general statements about varieties, methods for effective computation with concretely-given varieties have also been developed, which lead to the new area of computational algebraic geometry. One of the founding methods of this area is the theory of Gröbner bases, introduced by Bruno Buchberger in 1965. Another founding method, more specially devoted to real algebraic geometry, is the cylindrical algebraic decomposition, introduced by George E. Collins in 1973.
p8121
aVAnalytic geometry.
p8122
aVAn analytic variety is defined locally as the set of common solutions of several equations involving analytic functions. It is analogous to the included concept of real or complex algebraic variety. Any complex manifold is an analytic variety. Since analytic varieties may have singular points, not all analytic varieties are manifolds.
p8123
aVModern analytic geometry is essentially equivalent to real and complex algebraic geometry, as has been shown by Jean-Pierre Serre in his paper "GAGA", the name of which is French for "Algebraic geometry and analytic geometry". Nevertheless, the two fields remain distinct, as the methods of proof are quite different and algebraic geometry includes also geometry in finite characteristic.
p8124
aVApplications.
p8125
aVAlgebraic geometry now finds applications in statistics, control theory, robotics, error-correcting codes, phylogenetics and geometric modelling. There are also connections to string theory, game theory, graph matchings, solitons and integer programming.
p8126
asS'Discriminant'
p8127
(lp8128
VIn algebra, the discriminant of a polynomial is a function of its coefficients, typically denoted by a capital 'D' or the capital Greek letter Delta (\u0394). It gives information about the nature of its roots. Typically, the discriminant is zero if and only if the polynomial has a multiple root. For example, the discriminant of the quadratic polynomial
p8129
aVformula_1
p8130
aVis
p8131
aVformula_2
p8132
aVHere for real a, b and c, if \u0394 > 0, the polynomial has two real roots, if \u0394 = 0, the polynomial has one real double root, and if \u0394 < 0, the two roots of the polynomial are complex conjugates.
p8133
aVThe discriminant of the cubic polynomial
p8134
aVformula_3
p8135
aVis
p8136
aVformula_4
p8137
aVFor higher degrees, the discriminant is always a polynomial function of the coefficients. It becomes significantly longer for the higher degrees. The discriminant of a "general" quartic has 16 terms, that of a quintic has 59 terms, that of a 6th degree polynomial has 246 terms,
p8138
aVand the number of terms increases exponentially with the degree.
p8139
aVA polynomial has a multiple root (i.e. a root with multiplicity greater than one) in the complex numbers if and only if its discriminant is zero.
p8140
aVThe concept also applies if the polynomial has coefficients in a field which is not contained in the complex numbers. In this case, the discriminant vanishes if and only if the polynomial has a multiple root in any algebraically closed field containing the coefficients.
p8141
aVAs the discriminant is a polynomial function of the coefficients, it is defined as soon as the coefficients belong to an integral domain "R" and, in this case, the discriminant is in "R". In particular, the discriminant of a polynomial with integer coefficients is always an integer. This property is widely used in number theory.
p8142
aVThe term "discriminant" was coined in 1851 by the British mathematician James Joseph Sylvester.
p8143
aVDefinition.
p8144
aVIn terms of the roots, the discriminant is given by
p8145
aVformula_5
p8146
aVwhere formula_6 is the leading coefficient and formula_7 are the roots (counting multiplicity) of the polynomial in some splitting field. It is the square of the Vandermonde polynomial times formula_8.
p8147
aVAs the discriminant is a symmetric function in the roots, it can also be expressed in terms of the coefficients of the polynomial, since the coefficients are the elementary symmetric polynomials in the roots; such a formula is given below.
p8148
aVExpressing the discriminant in terms of the roots makes its key property clear, namely that it vanishes if and only if there is a repeated root, but does not allow it to be calculated without factoring a polynomial, after which the information it provides is redundant (if one has the roots, one can tell if there are any duplicates). Hence the formula in terms of the coefficients allows the nature of the roots to be determined without factoring the polynomial.
p8149
aVFormulas for low degrees.
p8150
aVThe quadratic polynomial
p8151
aVformula_9
p8152
aVhas discriminant
p8153
aVformula_10
p8154
aVThe cubic polynomial
p8155
aVformula_11
p8156
aVhas discriminant
p8157
aVformula_12
p8158
aVThe quartic polynomial
p8159
aVformula_13
p8160
aVhas discriminant
p8161
aVformula_14
p8162
aVformula_15
p8163
aVThese are homogeneous polynomials in the coefficients, respectively of degree 2, 4 and 6. They are also homogeneous in term of the roots, of respective degrees 2, 6 and 12.
p8164
aVSimpler polynomials have simpler expressions for their discriminants. For example, the monic quadratic polynomial "x"2 + "bx" + "c" has discriminant \u0394 = "b"2 \u2212 4"c".
p8165
aVThe monic cubic polynomial without quadratic term "x"3 + "px" + "q" has discriminant \u0394 = \u22124"p"3 \u2212 27"q"2.
p8166
aVIn terms of the roots, these discriminants are homogeneous polynomials of respective degree 2 and 6.
p8167
aVHomogeneity.
p8168
aVThe discriminant is a homogeneous polynomial in the coefficients; it is also a homogeneous polynomial in the roots.
p8169
aVIn the coefficients, the discriminant is homogeneous of degree 2"n"\u22122; this can be seen two ways. In terms of the roots-and-leading-term formula, multiplying all the coefficients by \u03bb does not change the roots, but multiplies the leading term by \u03bb. In terms of the formula as a determinant of a (2"n"\u22121) ×(2"n"\u22121) matrix divided by "an", the determinant of the matrix is homogeneous of degree 2"n"\u22121 in the entries, and dividing by "an" makes the degree 2"n"\u22122; explicitly, multiplying the coefficients by \u03bb multiplies all entries of the matrix by \u03bb, hence multiplies the determinant by \u03bb2"n"\u22121.
p8170
aVFor a monic polynomial, the discriminant is a polynomial in the roots alone (as the "an" term is one), and is of degree "n"("n"\u22121) in the roots, as there are formula_16 terms in the product, each squared.
p8171
aVLet us consider the polynomial
p8172
aVformula_17
p8173
aVIt follows from what precedes that its discriminant is homogeneous of degree 2"n"\u22122 in the formula_18 and quasi-homogeneous of weight "n"("n"\u22121) if each formula_19 is given the weight "i". In other words, every monomial formula_20 appearing in the discriminant satisfies the two equations
p8174
aVformula_21
p8175
aVand
p8176
aVformula_22
p8177
aVThese thus correspond to the partitions of "n"("n"\u22121) into at 2"n"\u22122 (non negative) parts of size at most n
p8178
aVThis restricts the possible terms in the discriminant. For the quadratic polynomial formula_23 there are only two possibilities for formula_24, these are the partitions of 6 into 4 parts of size at most 3:
p8179
aVformula_25
p8180
aVAll these five monomials occur effectively in the discriminant.
p8181
aVWhile this approach gives the possible terms, it does not determine the coefficients. Moreover, in general not all possible terms will occur in the discriminant. The first example is for the quartic polynomial formula_26, in which case formula_27 satisfies formula_28 and formula_29, even though the corresponding discriminant does not involve the monomial formula_30.
p8182
aVQuadratic formula.
p8183
aVThe quadratic polynomial formula_31 has discriminant
p8184
aVformula_32
p8185
aVwhich is the quantity under the square root sign in the quadratic formula. For real numbers "a", "b", "c", one has:
p8186
aVformula_33
p8187
aVand its graph crosses the "x"-axis twice.
p8188
aVformula_34
p8189
aVand its graph is tangent to the "x"-axis.
p8190
aVformula_35
p8191
aVAn alternative way to understand the discriminant of a quadratic is to use the characterization as "zero if and only if the polynomial has a repeated root".
p8192
aVIn that case the polynomial is formula_36
p8193
aVThe coefficients then satisfy formula_37 so formula_38
p8194
aVand a monic quadratic has a repeated root if and only if this is the case, in which case the root is formula_39 Putting both terms on one side and including a leading coefficient yields formula_40
p8195
aVDiscriminant of a polynomial.
p8196
aVTo find the formula for the discriminant of a polynomial in terms of its coefficients, it is easiest to introduce the resultant. Just as the discriminant of a single polynomial is the product of the square of the differences between distinct roots, the resultant of two polynomials is the product of the differences between their roots, and just as the discriminant vanishes if and only if the polynomial has a repeated root, the resultant vanishes if and only if the two polynomials share a root.
p8197
aVSince a polynomial formula_41 has a repeated root if and only if it shares a root with its derivative formula_42 the discriminant formula_43 and the resultant formula_44 both have the property that they vanish if and only if "p" has a repeated root, and they have almost the same degree (the degree of the resultant is one greater than the degree of the discriminant) and thus are equal up to a factor of degree one.
p8198
aVThe benefit of the resultant is that it can be computed as a determinant, namely as the determinant of the Sylvester matrix, a (2"n" \u2212 1)×(2"n" \u2212 1) matrix, whose "n" \u2212 1 first rows contain the coefficients of "p" and the "n" last ones the coefficients of its derivative.
p8199
aVThe resultant formula_44 of the general polynomial
p8200
aVformula_46
p8201
aVis, up to a factor, equal to the determinant of the (2"n" \u2212 1)×(2"n" \u2212 1) Sylvester matrix:
p8202
aVformula_47
p8203
aVThe discriminant formula_43 of formula_41 is now given by the formula
p8204
aVformula_50
p8205
aVFor example, in the case "n" = 4, the above determinant is
p8206
aVformula_51
p8207
aVThe discriminant of the degree 4 polynomial is then obtained from this determinant upon dividing by formula_52.
p8208
aVIn terms of the roots, the discriminant is equal to
p8209
aVformula_53
p8210
aVwhere "r"1, ..., "r""n" are the complex roots (counting multiplicity) of the polynomial:
p8211
aVformula_54
p8212
aVThis second expression makes it clear that "p" has a multiple root if and only if the discriminant is zero. (This multiple root can be complex.)
p8213
aVThe discriminant can be defined for polynomials over arbitrary fields, in exactly the same fashion as above. The product formula involving the roots "r""i" remains valid; the roots have to be taken in some splitting field of the polynomial. The discriminant can even be defined for polynomials over any commutative ring. However, if the ring is not an integral domain, above division of the resultant by formula_6 should be replaced by substituting formula_6 by 1 in the first column of the matrix.
p8214
aVNature of the roots.
p8215
aVThe discriminant gives additional information on the nature of the roots beyond simply whether there are any repeated roots: for polynomials with real coefficients, it also gives information on whether the roots are real or complex. This is most transparent and easily stated for quadratic and cubic polynomials; for polynomials of degree 4 or higher this is more difficult to state.
p8216
aVQuadratic.
p8217
aVBecause the quadratic formula expressed the roots of a quadratic polynomial as a rational function in terms of the "square root" of the discriminant, the roots of a quadratic polynomial are in the same field as the coefficients if and only if the discriminant is a square in the field of coefficients: in other words, the polynomial factors over the field of coefficients if and only if the discriminant is a square.
p8218
aVAs a real number has real square roots if and only if it is nonnegative, and these roots are distinct if and only if it is positive (not zero), the sign of the discriminant allows a complete description of the nature of the roots of a quadratic polynomial with real coefficients:
p8219
aVFurther, for a quadratic polynomial with rational coefficients, it factors over the rationals if and only if the discriminant \u2013 which is necessarily a rational number, being a polynomial in the coefficients \u2013 is in fact a square.
p8220
aVCubic.
p8221
aVFor a cubic polynomial with real coefficients, the discriminant reflects the nature of the roots as follows:
p8222
aVIf a cubic polynomial has a triple root, it is a root of its derivative and of its second derivative, which is linear. Thus to decide if a cubic polynomial has a triple root or not, one may compute the root of the second derivative and look if it is a root of the cubic and of its derivative.
p8223
aVHigher degrees.
p8224
aVMore generally, for a polynomial of degree "n" with real coefficients, we have
p8225
aVDiscriminant of a polynomial over a commutative ring.
p8226
aVThe definition of the discriminant of a polynomial in terms of the resultant may easily be extended to polynomials whose coefficients belong to any commutative ring. However, as the division is not always defined in such a ring, instead of dividing the determinant by the leading coefficient, one substitutes the leading coefficient by 1 in the first column of the determinant. This generalized discriminant has the following property which is fundamental in algebraic geometry.
p8227
aVLet "f" be a polynomial with coefficients in a commutative ring "A" and "D" its discriminant. Let \u03c6 be a ring homomorphism of "A" into a field "K" and \u03c6("f") be the polynomial over "K" obtained by replacing the coefficients of "f" by their images by \u03c6. Then \u03c6("D") = 0 if and only if either the difference of the degrees of "f" and \u03c6("f") is at least 2 or \u03c6("f") has a multiple root in an algebraic closure of "K". The first case may be interpreted by saying that \u03c6("f") has a multiple root at infinity.
p8228
aVThe typical situation where this property is applied is when "A" is a (univariate or multivariate) polynomial ring over a field "k" and \u03c6 is the substitution of the indeterminates in "A" by elements of a field extension "K" of "k".
p8229
aVFor example, let "f" be a bivariate polynomial in "X" and "Y" with real coefficients, such that "f" = 0 is the implicit equation of a plane algebraic curve. Viewing "f" as a univariate polynomial in "Y" with coefficients depending on "X", then the discriminant is a polynomial in "X" whose roots are the "X"-coordinates of the singular points, of the points with a tangent parallel to the "Y"-axis and of some of the asymptotes parallel to the "Y"-axis. In other words the computation of the roots of the "Y"-discriminant and the "X"-discriminant allows to compute all remarkable points of the curve, except the inflection points.
p8230
aVGeneralizations.
p8231
aVThe concept of discriminant has been generalized to other algebraic structures besides polynomials of one variable, including conic sections, quadratic forms, and algebraic number fields. Discriminants in algebraic number theory are closely related, and contain information about ramification. In fact, the more geometric types of ramification are also related to more abstract types of discriminant, making this a central algebraic idea in many applications.
p8232
aVDiscriminant of a conic section.
p8233
aVFor a conic section defined in plane geometry by the real polynomial
p8234
aVformula_59
p8235
aVthe discriminant is equal to
p8236
aVformula_60
p8237
aVand determines the shape of the conic section. If the discriminant is less than 0, the equation is of an ellipse or a circle. If the discriminant equals 0, the equation is that of a parabola. If the discriminant is greater than 0, the equation is that of a hyperbola. This formula will not work for degenerate cases (when the polynomial factors).
p8238
aVDiscriminant of a quadratic form.
p8239
aVThere is a substantive generalization to quadratic forms "Q" over any field "K" of characteristic \u2260 2. For characteristic 2, the corresponding invariant is the Arf invariant.
p8240
aVGiven a quadratic form "Q," the discriminant or determinant is the determinant of a symmetric matrix "S" for "Q".
p8241
aVChange of variables by a matrix "A" changes the matrix of the symmetric form by formula_61 which has determinant formula_62 so under change of variables, the discriminant changes by a non-zero square, and thus the class of the discriminant is well-defined in "K"/("K"*)2, i.e., up to non-zero squares. See also quadratic residue.
p8242
aVLess intrinsically, by a theorem of Jacobi, quadratic forms on formula_63 can be expressed, after a linear change of variables, in diagonal form as
p8243
aVformula_64
p8244
aVMore precisely, a quadratic forms on "V" may be expressed as a sum
p8245
aVformula_65
p8246
aVwhere the "L""i" are independent linear forms and "n" is the number of the variables (some of the "a""i" may be zero). Then the discriminant is the product of the "a""i", which is well-defined as a class in "K"/("K"*)2.
p8247
aVFor "K"=R, the real numbers, (R*)2 is the positive real numbers (any positive number is a square of a non-zero number), and thus the quotient R/(R*)2 has three elements: positive, zero, and negative. This is a cruder invariant than signature ("n"0, "n"+, "n"\u2212), where "n"0 is the number 0s and "n"± is the number of ±1s in diagonal form. The discriminant is then zero if the form is degenerate (formula_66), and otherwise it is the parity of the number of negative coefficients, formula_67
p8248
aVFor "K"=C, the complex numbers, (C*)2 is the non-zero complex numbers (any complex number is a square), and thus the quotient C/(C*)2 has two elements: non-zero and zero.
p8249
aVThis definition generalizes the discriminant of a quadratic polynomial, as the polynomial formula_68 homogenizes to the quadratic form formula_69 which has symmetric matrix
p8250
aV formula_70
p8251
aVwhose determinant is formula_71 Up to a factor of \u22124, this is formula_72
p8252
aVThe invariance of the class of the discriminant of a real form (positive, zero, or negative) corresponds to the corresponding conic section being an ellipse, parabola, or hyperbola.
p8253
aVAlternating polynomials.
p8254
aVThe discriminant is a symmetric polynomial in the roots; if one adjoins a square root of it (halves each of the powers: the Vandermonde polynomial) to the ring of symmetric polynomials in "n" variables formula_73, one obtains the ring of alternating polynomials, which is thus a quadratic extension of formula_73.
p8255
asS'Corollary'
p8256
(lp8257
VA corollary ( or ) is a statement that follows readily from a previous statement. 
p8258
aVIn mathematics a corollary typically follows a theorem. The use of the term "corollary", rather than "proposition" or "theorem", is intrinsically subjective. Proposition "B" is a corollary of proposition "A" if "B" can readily be deduced from "A" or is self-evident from its proof, but the meaning of "readily" or "self-evident" varies depending upon the author and context. The importance of the corollary is often considered secondary to that of the initial theorem; "B" is unlikely to be termed a corollary if its mathematical consequences are as significant as those of "A". Sometimes a corollary has a proof that explains the derivation; sometimes the derivation is considered self-evident.
p8259
aVPeirce on corollarial and theorematic reasonings.
p8260
aVCharles Sanders Peirce held that the most important division of kinds of deductive reasoning is that between corollarial and theorematic. He argued that, while finally all deduction depends in one way or another on mental experimentation on schemata or diagrams, still in corollarial deduction "it is only necessary to imagine any case in which the premisses are true in order to perceive immediately that the conclusion holds in that case", whereas theorematic deduction "is deduction in which it is necessary to experiment in the imagination upon the image of the premiss in order from the result of such experiment to make corollarial deductions to the truth of the conclusion." He held that corollarial deduction matches Aristotle's conception of direct demonstration, which Aristotle regarded as the only thoroughly satisfactory demonstration, while theorematic deduction (A) is the kind more prized by mathematicians, (B) is peculiar to mathematics, and (C) involves in its course the introduction of a lemma or at least a definition uncontemplated in the thesis (the proposition that is to be proved); in remarkable cases that definition is of an abstraction that "ought to be supported by a proper postulate."
p8261
asS'Fundamental theorem of algebra'
p8262
(lp8263
VThe fundamental theorem of algebra states that every non-constant single-variable polynomial with complex coefficients has at least one complex root. This includes polynomials with real coefficients, since every real number is a complex number with an imaginary part equal to zero.
p8264
aVEquivalently (by definition), the theorem states that the field of complex numbers is algebraically closed.
p8265
aVThe theorem is also stated as follows: every non-zero, single-variable, degree "n" polynomial with complex coefficients has, counted with multiplicity, exactly "n" roots. The equivalence of the two statements can be proven through the use of successive polynomial division.
p8266
aVIn spite of its name, there is no purely algebraic proof of the theorem, since any proof must use the completeness of the reals (or some other equivalent formulation of completeness), which is not an algebraic concept. Additionally, it is not fundamental for modern algebra; its name was given at a time when the study of algebra was mainly concerned with the solutions of polynomial equations with real or complex coefficients.
p8267
aVHistory.
p8268
aVPeter Rothe, in his book "Arithmetica Philosophica" (published in 1608), wrote that a polynomial equation of degree "n" (with real coefficients) "may" have "n" solutions. Albert Girard, in his book "L'invention nouvelle en l'Algèbre" (published in 1629), asserted that a polynomial equation of degree "n" has "n" solutions, but he did not state that they had to be real numbers. Furthermore, he added that his assertion holds "unless the equation is incomplete", by which he meant that no coefficient is equal to 0. However, when he explains in detail what he means, it is clear that he actually believes that his assertion is always true; for instance, he shows that the equation "x"4 = 4x \u2212 3, although incomplete, has four solutions (counting multiplicities): 1 (twice), \u22121 + "i"\u221a2, and \u22121 \u2212 "i"\u221a2.
p8269
aVAs will be mentioned again below, it follows from the fundamental theorem of algebra that every non-constant polynomial with real coefficients can be written as a product of polynomials with real coefficients whose degree is either 1 or 2. However, in 1702 Leibniz said that no polynomial of the type "x"4 + "a"4 (with "a" real and distinct from 0) can be written in such a way. Later, Nikolaus Bernoulli made the same assertion concerning the polynomial "x"4 \u2212  4"x"3 + 2"x"2 + 4"x" + 4, but he got a letter from Euler in 1742 in which he was told that his polynomial happened to be equal to
p8270
aVformula_1
p8271
aVwhere \u03b1 is the square root of 4 + 2\u221a7. Also, Euler mentioned that
p8272
aVformula_2
p8273
aVA first attempt at proving the theorem was made by d'Alembert in 1746, but his proof was incomplete. Among other problems, it assumed implicitly a theorem (now known as Puiseux's theorem) which would not be proved until more than a century later, and furthermore the proof assumed the fundamental theorem of algebra. Other attempts were made by Euler (1749), de Foncenex (1759), Lagrange (1772), and Laplace (1795). These last four attempts assumed implicitly Girard's assertion; to be more precise, the existence of solutions was assumed and all that remained to be proved was that their form was "a" + "bi" for some real numbers "a" and "b". In modern terms, Euler, de Foncenex, Lagrange, and Laplace were assuming the existence of a splitting field of the polynomial "p"("z").
p8274
aVAt the end of the 18th century, two new proofs were published which did not assume the existence of roots. One of them, due to James Wood and mainly algebraic, was published in 1798 and it was totally ignored. Wood's proof had an algebraic gap. The other one was published by Gauss in 1799 and it was mainly geometric, but it had a topological gap, filled by Alexander Ostrowski in 1920, as discussed in Smale 1981 [http://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.bams/1183547848] (Smale writes, "...I wish to point out what an immense gap Gauss' proof contained. It is a subtle point even today that a real algebraic plane curve cannot enter a disk without leaving. In fact even though Gauss redid this proof 50 years later, the gap remained. It was not until 1920 that Gauss' proof was completed. In the reference Gauss, A. Ostrowski has a paper which does this and gives an excellent discussion of the problem as well..."). A rigorous proof was published by Argand in 1806; it was here that, for the first time, the fundamental theorem of algebra was stated for polynomials with complex coefficients, rather than just real coefficients. Gauss produced two other proofs in 1816 and another version of his original proof in 1849.
p8275
aVThe first textbook containing a proof of the theorem was Cauchy's "Cours d'analyse de l'École Royale Polytechnique" (1821). It contained Argand's proof, although Argand is not credited for it.
p8276
aVNone of the proofs mentioned so far is constructive. It was Weierstrass who raised for the first time, in the middle of the 19th century, the problem of finding a constructive proof of the fundamental theorem of algebra. He presented his solution, that amounts in modern terms to a combination of the Durand\u2013Kerner method with the homotopy continuation principle, in 1891. Another proof of this kind was obtained by Hellmuth Kneser in 1940 and simplified by his son Martin Kneser in 1981.
p8277
aVWithout using countable choice, it is not possible to constructively prove the fundamental theorem of algebra for complex numbers based on the Dedekind real numbers (which are not constructively equivalent to the Cauchy real numbers without countable choice
p8278
aVProofs.
p8279
aVAll proofs below involve some analysis, or at least the topological concept of continuity of real or complex functions. Some also use differentiable or even analytic functions. This fact has led to the remark that the Fundamental Theorem of Algebra is neither fundamental, nor a theorem of algebra.
p8280
aVSome proofs of the theorem only prove that any non-constant polynomial with real coefficients has some complex root. This is enough to establish the theorem in the general case because, given a non-constant polynomial "p"("z") with complex coefficients, the polynomial
p8281
aVformula_3
p8282
aVhas only real coefficients and, if "z" is a zero of "q"("z"), then either "z" or its conjugate is a root of "p"("z").
p8283
aVA large number of non-algebraic proofs of the theorem use the fact (sometimes called "growth lemma") that an "n"-th degree polynomial function "p"("z") whose dominant coefficient is 1 behaves like "zn" when |"z"| is large enough. A more precise statement is: there is some positive real number "R" such that:
p8284
aVformula_4
p8285
aVwhen |"z"| > "R".
p8286
aVComplex-analytic proofs.
p8287
aVFind a closed disk "D" of radius "r" centered at the origin such that |"p"("z")| > |"p"(0)| whenever |"z"| \u2265 "r". The minimum of |"p"("z")| on "D", which must exist since "D" is compact, is therefore achieved at some point "z"0 in the interior of "D", but not at any point of its boundary. The Maximum modulus principle (applied to 1/"p"("z")) implies then that "p"("z"0) = 0. In other words, "z"0 is a zero of "p"("z").
p8288
aVA variation of this proof does not require the use of the maximum modulus principle (in fact, the same argument with minor changes also gives a proof of the maximum modulus principle for holomorphic functions). If we assume by contradiction that "a" := "p"("z"0) \u2260 0, then, expanding "p"("z") in powers of "z" \u2212 "z"0 we can write
p8289
aVformula_5
p8290
aVHere, the "cj" are simply the coefficients of the polynomial "z" \u2192 "p"("z" + "z"0), and we let "k" be the index of the first coefficient following the constant term that is non-zero. But now we see that for "z" sufficiently close to "z"0 this has behavior asymptotically similar to the simpler polynomial formula_6, in the sense that (as is easy to check) the function formula_7 is bounded by some positive constant "M" in some neighborhood of "z"0. Therefore if we define formula_8 and let formula_9, then for any sufficiently small positive number "r" (so that the bound "M" mentioned above holds), using the triangle inequality we see that
p8291
aVformula_10
p8292
aVWhen "r" is sufficiently close to 0 this upper bound for |"p"("z")| is strictly smaller than |"a"|, in contradiction to the definition of "z"0. (Geometrically, we have found an explicit direction \u03b80 such that if one approaches "z"0 from that direction one can obtain values "p"("z") smaller in absolute value than |"p"("z"0)|.)
p8293
aVAnother analytic proof can be obtained along this line of thought observing that, since |"p"("z")| > |"p"(0)| outside "D", the minimum of |"p"("z")| on the whole complex plane is achieved at "z"0. If |"p"("z"0)| > 0, then 1/"p" is a bounded holomorphic function in the entire complex plane since, for each complex number "z", |1/"p"("z")| \u2264 |1/"p"("z"0)|. Applying Liouville's theorem, which states that a bounded entire function must be constant, this would imply that 1/"p" is constant and therefore that "p" is constant. This gives a contradiction, and hence "p"("z"0) = 0.
p8294
aVYet another analytic proof uses the argument principle. Let "R" be a positive real number large enough so that every root of "p"("z") has absolute value smaller than "R"; such a number must exist because every non-constant polynomial function of degree "n" has at most "n" zeros. For each "r" > "R", consider the number
p8295
aVformula_11
p8296
aVwhere "c"("r") is the circle centered at 0 with radius "r" oriented counterclockwise; then the argument principle says that this number is the number "N" of zeros of "p"("z") in the open ball centered at 0 with radius "r", which, since "r" > "R", is the total number of zeros of "p"("z"). On the other hand, the integral of "n"/"z" along "c"("r") divided by 2\u03c0"i" is equal to "n". But the difference between the two numbers is
p8297
aVformula_12
p8298
aVThe numerator of the rational expression being integrated has degree at most "n" \u2212 1 and the degree of the denominator is "n" + 1. Therefore, the number above tends to 0 as "r" \u2192 +\u221e. But the number is also equal to "N" \u2212 "n" and so "N" = "n".
p8299
aVStill another complex-analytic proof can be given by combining linear algebra with the Cauchy theorem. To establish that every complex polynomial of degree "n" > 0 has a zero, it suffices to show that every complex square matrix of size "n" > 0 has a (complex) eigenvalue. The proof of the latter statement is by contradiction.
p8300
aVLet "A" be a complex square matrix of size "n" > 0 and let "In" be the unit matrix of the same size. Assume "A" has no eigenvalues. Consider the resolvent function
p8301
aVformula_13
p8302
aVwhich is a meromorphic function on the complex plane with values in the vector space of matrices. The eigenvalues of "A" are precisely the poles of "R(z)". Since, by assumption, "A" has no eigenvalues, the function "R(z)" is an entire function and Cauchy theorem implies that
p8303
aVformula_14
p8304
aVOn the other hand, "R"("z") expanded as a geometric series gives:
p8305
aVformula_15
p8306
aVThis formula is valid outside the closed disc of radius ||"A"|| (the operator norm of "A"). Let "r" > ||"A"||. Then
p8307
aVformula_16
p8308
aV(in which only the summand "k" = 0 has a nonzero integral). This is a contradiction, and so "A" has an eigenvalue.
p8309
aVFinally, Rouché's theorem gives perhaps the shortest proof of the theorem.
p8310
aVTopological proofs.
p8311
aVLet "z"0 \u2208 C be such that the minimum of |"p"("z")| on the whole complex plane is achieved at "z"0; it was seen at the proof which uses Liouville's theorem that such a number must exist. We can write "p"("z") as a polynomial in "z" \u2212 "z"0: there is some natural number "k" and there are some complex numbers "ck", "c""k" + 1, ..., "cn" such that "ck" \u2260 0 and that
p8312
aVformula_17
p8313
aVIn the case that "p"("z"0) is nonzero, it follows that if "a" is a "k"th root of \u2212"p"("z"0)/"ck" and if "t" is positive and sufficiently small, then |"p"("z"0 + "ta")| < |"p"("z"0)|, which is impossible, since |"p"("z"0)| is the minimum of |"p"| on "D".
p8314
aVFor another topological proof by contradiction, suppose that "p"("z") has no zeros. Choose a large positive number "R" such that, for |"z"| = "R", the leading term "zn" of "p"("z") dominates all other terms combined; in other words, such that |"z"|"n" > |"a""n"\u22121"z""n"\u22121 + ··· + "a"0|. As "z" traverses the circle given by the equation |"z"| = "R" once counter-clockwise, "p"("z"), like "zn", winds "n" times counter-clockwise around 0. At the other extreme, with |"z"| = 0, the "curve" "p"("z") is simply the single (nonzero) point "p"(0), whose winding number is clearly 0. If the loop followed by "z" is continuously deformed between these extremes, the path of "p"("z") also deforms continuously. We can explicitly write such a deformation as "H"("Re""i"\u03b8,"t") = "p"((1 \u2212 "t")"Re""i"\u03b8), where 0 \u2264 "t" \u2264 1. If one views the variable "t" as time, then at time zero the curve is "p"("z") and at time one the curve is "p"(0). Clearly at every point "t", "p"("z") cannot be zero by the original assumption, therefore during the deformation, the curve never crosses zero. Therefore the winding number of the curve around zero should never change. However, given that the winding number started as "n" and ended as 0, this is absurd. Therefore, "p"("z") has at least one zero.
p8315
aVAlgebraic proofs.
p8316
aVThese proofs use two facts about real numbers that require only a small amount of analysis (more precisely, the intermediate value theorem):
p8317
aVThe second fact, together with the quadratic formula, implies the theorem for real quadratic polynomials. In other words, algebraic proofs of the fundamental theorem actually show that if "R" is any real-closed field, then its extension "C" = "R"(\u221a\u22121) is algebraically closed.
p8318
aVAs mentioned above, it suffices to check the statement "every non-constant polynomial "p"("z") with real coefficients has a complex root". This statement can be proved by induction on the greatest non-negative integer "k" such that 2"k" divides the degree "n" of "p"("z"). Let "a" be the coefficient of "zn" in "p"("z") and let "F" be a splitting field of "p"("z") over "C"; in other words, the field "F" contains "C" and there are elements "z"1, "z"2, ..., "zn" in "F" such that
p8319
aVformula_18
p8320
aVIf "k" = 0, then "n" is odd, and therefore "p"("z") has a real root. Now, suppose that "n" = 2"km" (with "m" odd and "k" > 0) and that the theorem is already proved when the degree of the polynomial has the form 2"k" \u2212 1"m"\u2032 with "m"\u2032 odd. For a real number "t", define:
p8321
aVformula_19
p8322
aVThen the coefficients of "qt"("z") are symmetric polynomials in the "zi"'s with real coefficients. Therefore, they can be expressed as polynomials with real coefficients in the elementary symmetric polynomials, that is, in \u2212"a"1, "a"2, ..., (\u22121)"nan". So "qt"("z") has in fact "real" coefficients. Furthermore, the degree of "qt"("z") is "n"("n" \u2212 1)/2 = 2"k"\u22121"m"("n" \u2212 1), and "m"("n" \u2212 1) is an odd number. So, using the induction hypothesis, "qt" has at least one complex root; in other words, "zi" + "zj" + "tzizj" is complex for two distinct elements "i" and "j" from {1, ..., "n"}. Since there are more real numbers than pairs ("i", "j"), one can find distinct real numbers "t" and "s" such that "zi" + "zj" + "tzizj" and "zi" + "zj" + "szizj" are complex (for the same "i" and "j"). So, both "zi" + "zj" and "zizj" are complex numbers. It is easy to check that every complex number has a complex square root, thus every complex polynomial of degree 2 has a complex root by the quadratic formula. It follows that "zi" and "zj" are complex numbers, since they are roots of the quadratic polynomial "z"2 \u2212  ("zi" + "zj")"z" + "zizj".
p8323
aVJ. Shipman showed in 2007 that the assumption that odd degree polynomials have roots is stronger than necessary; any field in which polynomials of prime degree have roots is algebraically closed (so "odd" can be replaced by "odd prime" and furthermore this holds for fields of all characteristics). For axiomatization of algebraically closed fields, this is the best possible, as there are counterexamples if a single prime is excluded. However, these counterexamples rely on \u22121 having a square root. If we take a field where \u22121 has no square root, and every polynomial of degree "n" \u2208 "I" has a root, where "I" is any fixed infinite set of odd numbers, then every polynomial "f"("x") of odd degree has a root (since has a root, where "k" is chosen so that ).
p8324
aVAnother algebraic proof of the fundamental theorem can be given using Galois theory. It suffices to show that C has no proper finite field extension. Let "K"/C be a finite extension. Since the normal closure of "K" over R still has a finite degree over C (or R), we may assume without loss of generality that "K" is a normal extension of R (hence it is a Galois extension, as every algebraic extension of a field of characteristic 0 is separable). Let "G" be the Galois group of this extension, and let "H" be a Sylow 2-subgroup of "G", so that the order of "H" is a power of 2, and the index of "H" in "G" is odd. By the fundamental theorem of Galois theory, there exists a subextension "L" of "K"/R such that Gal("K"/"L") = "H". As ["L":R] = ["G":"H"] is odd, and there are no nonlinear irreducible real polynomials of odd degree, we must have "L" = R, thus ["K":R] and ["K":C] are powers of 2. Assuming by way of contradiction that ["K":C] > 1, we conclude that the 2-group Gal("K"/C) contains a subgroup of index 2, so there exists a subextension "M" of C of degree 2. However, C has no extension of degree 2, because every quadratic complex polynomial has a complex root, as mentioned above. This shows that ["K":C] = 1, and therefore "K" = C, which completes the proof.
p8325
aVGeometric proofs.
p8326
aVThere exists still another way to approach the fundamental theorem of algebra, due to J. M. Almira and A. Romero: by Riemannian Geometric arguments. The main idea here is to prove that the existence of a non-constant polynomial "p"("z") without zeros implies the existence of a flat Riemannian metric over the sphere S2. This leads to a contradiction, since the sphere is not flat.
p8327
aVRecall that a Riemannian surface ("M", "g") is said to be flat if its Gaussian curvature, which we denote by "Kg", is identically null. Now, Gauss\u2013Bonnet theorem, when applied to the sphere S2, claims that
p8328
aVformula_20,
p8329
aVwhich proves that the sphere is not flat.
p8330
aVLet us now assume that "n" > 0 and "p"("z") = "a"0 + "a"1"z" + \u22c5\u22c5\u22c5 + "anzn" \u2260 0 for each complex number "z". Let us define "p*"("z") = "znp"("1/z") = "a"0"zn" + "a"1"z""n"\u22121 + \u22c5\u22c5\u22c5 + "an". Obviously, "p*"("z") \u2260 0 for all "z" in C. Consider the polynomial "f"("z") = "p"("z")"p*"("z"). Then "f"("z") \u2260 0 for each "z" in C. Furthermore,
p8331
aVformula_21.
p8332
aVWe can use this functional equation to prove that "g", given by
p8333
aVformula_22
p8334
aVfor "w" in C, and
p8335
aVformula_23
p8336
aVfor "w" \u2208 S2\u005c{0}, is a well defined Riemannian metric over the sphere S2 (which we identify with the extended complex plane C \u222a {\u221e}).
p8337
aVNow, a simple computation shows that
p8338
aVformula_24,
p8339
aVsince the real part of an analytic function is harmonic. This proves that "Kg" = 0.
p8340
aVCorollaries.
p8341
aVSince the fundamental theorem of algebra can be seen as the statement that the field of complex numbers is algebraically closed, it follows that any theorem concerning algebraically closed fields applies to the field of complex numbers. Here are a few more consequences of the theorem, which are either about the field of real numbers or about the relationship between the field of real numbers and the field of complex numbers:
p8342
aVBounds on the zeros of a polynomial.
p8343
aVWhile the fundamental theorem of algebra states a general existence result, it is of some interest, both from the theoretical and from the practical point of view, to have information on the location of the zeros of a given polynomial. The simpler result in this direction is a bound on the modulus: all zeros \u03b6 of a monic polynomial formula_25 satisfy an inequality |\u03b6| \u2264 "R"\u221e, where
p8344
aVformula_26
p8345
aVNotice that, as stated, this is not yet an existence result but rather an example of what is called an a priori bound: it says that "if there are solutions" then they lie inside the closed disk of center the origin and radius "R"\u221e. However, once coupled with the fundamental theorem of algebra it says that the disk contains in fact at least one solution. More generally, a bound can be given directly in terms of any p-norm of the "n"-vector of coefficients formula_27, that is |\u03b6| \u2264 "Rp", where "Rp" is precisely the "q"-norm of the 2-vector formula_28, "q" being the conjugate exponent of "p", 1/"p" + 1/"q" = 1, for any 1 \u2264 "p" \u2264 \u221e. Thus, the modulus of any solution is also bounded by
p8346
aVformula_29
p8347
aVformula_30
p8348
aVfor 1 < "p" < \u221e, and in particular
p8349
aVformula_31
p8350
aV(where we define "an" to mean 1, which is reasonable since 1 is indeed the "n"-th coefficient of our polynomial). The case of a generic polynomial of degree n, formula_32, is of course reduced to the case of a monic, dividing all coefficients by "an" \u2260 0. Also, in case that 0 is not a root, i.e. "a"0 \u2260 0., bounds from below on the roots \u03b6 follow immediately as bounds from above on formula_33, that is, the roots of formula_34. Finally, the distance formula_35 from the roots \u03b6 to any point formula_36 can be estimated from below and above, seeing formula_37 as zeros of the polynomial formula_38, whose coefficients are the Taylor expansion of "P"("z") at formula_39
p8351
aVWe report here the proof of the above bounds, which is short and elementary. Let \u03b6 be a root of the polynomial formula_25; in order to prove the inequality |\u03b6| \u2264 "Rp" we can assume, of course, |\u03b6| > 1. Writing the equation as formula_41, and using the Hölder's inequality we find formula_42. Now, if "p" = 1, this is formula_43, thus formula_44. In the case 1 < "p" \u2264 \u221e, taking into account the summation formula for a geometric progression, we have
p8352
aVformula_45
p8353
aVthus formula_46 and simplifying, formula_47. Therefore formula_48 holds, for all 1 \u2264 "p" \u2264 \u221e.
p8354
asS'Coprime'
p8355
(lp8356
sS"Bayes' theorem"
p8357
(lp8358
VIn probability theory and statistics, Bayes' theorem (alternatively Bayes' law or Bayes' rule) relates current probability to prior probability. It is important in the mathematical manipulation of conditional probabilities. 
p8359
aVWhen applied, the probabilities involved in Bayes' theorem may have different interpretations. In one of these interpretations, the theorem is used directly as part of a particular approach to statistical inference. In particular, with the Bayesian interpretation of probability, the theorem expresses how a subjective degree of belief should rationally change to account for evidence: this is Bayesian inference, which is fundamental to Bayesian statistics. However, Bayes' theorem has applications in a wide range of calculations involving probabilities, not just in Bayesian inference.
p8360
aVBayes' theorem is named after Rev. Thomas Bayes (; 1701\u20131761), who first showed how to use new evidence to update beliefs. It was further developed by Pierre-Simon Laplace, who first published the modern formulation in his 1812 "Théorie analytique des probabilités". Sir Harold Jeffreys put Bayes' algorithm and Laplace's formulation on an axiomatic basis. Jeffreys wrote that Bayes' theorem "is to the theory of probability what Pythagoras's theorem is to geometry".
p8361
aVStatement of theorem.
p8362
aVBayes' theorem is stated mathematically as the following equation:
p8363
aVformula_1,
p8364
aVwhere "A" and "B" are events.
p8365
aVIntroductory example.
p8366
aVThe entire output of a factory is produced on three machines. The three machines account for 20%, 30%, and 50% of the output, respectively. The fraction of defective items produced is this: for the first machine, 5%; for the second machine, 3%; for the third machine, 1%. If an item is chosen at random from the total output and is found to be defective, what is the probability that it was produced by the third machine?
p8367
aVA solution is as follows. Let "Ai" denote the event that a randomly chosen item was made by the "i"th machine (for "i" = 1,2,3). Let "B" denote the event that a randomly chosen item is defective. Then, we are given the following information:
p8368
aV"P"("A"1) = 0.2,    "P"("A"2) = 0.3,    "P"("A"3) = 0.5.
p8369
aVIf the item was made by machine "A"1, then the probability that it is defective is 0.05; that is, "P"("B"|"A"1) = 0.05. Overall, we have
p8370
aV"P"("B"|"A"1) = 0.05,    "P"("B"|"A"2) = 0.03,    "P"("B"|"A"3) = 0.01.
p8371
aVTo answer the original question, we first find "P"("B"). That can be done in the following way:
p8372
aV"P"("B") = \u03a3"i" "P"("B"|"A""i")\u202f"P"("Ai") = (0.05)(0.2) + (0.03)(0.3) + (0.01)(0.5) = 0.024.
p8373
aVHence 2.4% of the total output of the factory is defective.
p8374
aVWe are given that "B" has occurred, and we want to calculate the conditional
p8375
aVprobability of "A"3. By Bayes' theorem,
p8376
aV"P"("A"3|"B") = "P"("B"|"A"3)\u202f"P"("A"3)/"P"("B") = (0.01)(0.50)/(0.024) = 5/24.
p8377
aVGiven that the item is defective, the probability that it was made by the third
p8378
aVmachine is only 5/24. Although machine 3 produces half of the total output, it
p8379
aVproduces a much smaller fraction of the defective items. Hence the knowledge
p8380
aVthat the item selected was defective enables us to replace the prior probability
p8381
aV"P"("A"3) = 1/2 by the smaller posterior probability "P"("A"3|"B") = 5/24.
p8382
aVInterpretations.
p8383
aVThe interpretation of Bayes' theorem depends on the interpretation of probability ascribed to the terms. The two main interpretations are described below.
p8384
aVBayesian interpretation.
p8385
aVIn the Bayesian (or epistemological) interpretation, probability measures a "degree of belief". Bayes' theorem then links the degree of belief in a proposition before and after accounting for evidence. For example, suppose it is believed with 50% certainty that a coin is twice as likely to land heads than tails. If the coin is flipped a number of times and the outcomes observed, that degree of belief may rise, fall or remain the same depending on the results.
p8386
aVFor proposition "A" and evidence "B",
p8387
aV* "P"("A"), the "prior", is the initial degree of belief in "A".
p8388
aV* "P"("A"|"B"), the "posterior", is the degree of belief having accounted for "B".
p8389
aV* the quotient "P"("B"|"A")/"P"("B") represents the support "B" provides for "A".
p8390
aVFor more on the application of Bayes' theorem under the Bayesian interpretation of probability, see Bayesian inference.
p8391
aVFrequentist interpretation.
p8392
aVIn the frequentist interpretation, probability measures a "proportion of outcomes". For example, suppose an experiment is performed many times. "P"("A") is the proportion of outcomes with property "A", and "P"("B") that with property "B". "P"("B"|"A") is the proportion of outcomes with property "B" "out of" outcomes with property "A", and "P"("A"|"B") the proportion of those with "A" "out of" those with "B".
p8393
aVThe role of Bayes' theorem is best visualized with tree diagrams, as shown to the right. The two diagrams partition the same outcomes by "A" and "B" in opposite orders, to obtain the inverse probabilities. Bayes' theorem serves as the link between these different partitionings.
p8394
aVForms.
p8395
aVEvents.
p8396
aVSimple form.
p8397
aVFor events "A" and "B", provided that "P"("B") \u2260 0,
p8398
aVformula_2
p8399
aVIn many applications, for instance in Bayesian inference, the event "B" is fixed in the discussion, and we wish to consider the impact of its having been observed on our belief in various possible events "A". In such a situation the denominator of the last expression, the probability of the given evidence "B", is fixed; what we want to vary is "A". Bayes' theorem then shows that the posterior probabilities are proportional to the numerator:
p8400
aVformula_3 (proportionality over "A" for given "B").
p8401
aVIn words: posterior is proportional to prior times likelihood.
p8402
aVIf events "A"1, "A"2, ..., are mutually exclusive and exhaustive, i.e., one of them is certain to occur but no two can occur together, and we know their probabilities up to proportionality, then we can determine the proportionality constant by using the fact that their probabilities must add up to one. For instance, for a given event "A", the event "A" itself and its complement ¬"A" are exclusive and exhaustive. Denoting the constant of proportionality by "c" we have
p8403
aVformula_4 and formula_5
p8404
aVAdding these two formulas we deduce that
p8405
aVformula_6
p8406
aVAlternative form.
p8407
aVAnother form of Bayes' Theorem that is generally encountered when looking at two competing statements or hypotheses is:
p8408
aVformula_7
p8409
aVFor an epistemological interpretation:
p8410
aVFor proposition "A" and evidence or background "B",
p8411
aVExtended form.
p8412
aVOften, for some partition {"Aj"} of the event space, the event space is given or conceptualized in terms of "P"("Aj") and "P"("B"|"Aj"). It is then useful to compute "P"("B") using the law of total probability:
p8413
aVformula_8
p8414
aVformula_9
p8415
aVIn the special case where "A" is a binary variable:
p8416
aVformula_7
p8417
aVRandom variables.
p8418
aVConsider a sample space \u03a9 generated by two random variables "X" and "Y". In principle, Bayes' theorem applies to the events "A" = {"X" = "x"} and "B" = {"Y" = "y"}. However, terms become 0 at points where either variable has finite probability density. To remain useful, Bayes' theorem may be formulated in terms of the relevant densities (see Derivation).
p8419
aVSimple form.
p8420
aVIf "X" is continuous and "Y" is discrete,
p8421
aVformula_11
p8422
aVIf "X" is discrete and "Y" is continuous,
p8423
aVformula_12
p8424
aVIf both "X" and "Y" are continuous,
p8425
aVformula_13
p8426
aVExtended form.
p8427
aVA continuous event space is often conceptualized in terms of the numerator terms. It is then useful to eliminate the denominator using the law of total probability. For "fY"("y"), this becomes an integral:
p8428
aVformula_14
p8429
aVBayes' rule.
p8430
aVBayes' rule is Bayes' theorem in odds form.
p8431
aVformula_15
p8432
aVwhere
p8433
aVformula_16
p8434
aVis called the Bayes factor or likelihood ratio and the odds between two events is simply the ratio of the probabilities of the two events. Thus
p8435
aVformula_17,
p8436
aVformula_18,
p8437
aVSo the rule says that the posterior odds are the prior odds times the Bayes factor, or in other words, posterior is proportional to prior times likelihood.
p8438
aVDerivation.
p8439
aVFor events.
p8440
aVBayes' theorem may be derived from the definition of conditional probability:
p8441
aVformula_19
p8442
aVformula_20
p8443
aVformula_21
p8444
aVformula_22
p8445
aVFor random variables.
p8446
aVFor two continuous random variables "X" and "Y", Bayes' theorem may be analogously derived from the definition of conditional density:
p8447
aVformula_23
p8448
aVformula_24
p8449
aVformula_25
p8450
aVExamples.
p8451
aVFrequentist example.
p8452
aVAn entomologist spots what might be a rare subspecies of beetle, due to the pattern on its back. In the rare subspecies, 98% have the pattern, or "P(Pattern|Rare)" = 98%. In the common subspecies, 5% have the pattern. The rare subspecies accounts for only 0.1% of the population. How likely is the beetle having the pattern to be rare, or what is "P(Rare|Pattern)"?
p8453
aVFrom the extended form of Bayes' theorem (since any beetle can be only rare or common),
p8454
aVformula_26
p8455
aVDrug testing.
p8456
aVSuppose a drug test is 99% sensitive and 99% specific. That is, the test will produce 99% true positive results for drug users and 99% true negative results for non-drug users. Suppose that 0.5% of people are users of the drug. If a randomly selected individual tests positive, what is the probability he or she is a user?
p8457
aVformula_27
p8458
aVDespite the apparent accuracy of the test, if an individual tests positive, it is more likely that they do "not" use the drug than that they do.
p8459
aVThis surprising result arises because the number of non-users is very large compared to the number of users; thus the number of false positives (0.995%) outweighs the number of true positives (0.495%). To use concrete numbers, if 1000 individuals are tested, there are expected to be 995 non-users and 5 users. From the 995 non-users, 0.01 × 995 \u2243 10 false positives are expected. From the 5 users, 0.99 × 5 \u2243 5 true positives are expected. Out of 15 positive results, only 5, about 33%, are genuine.
p8460
aVNote: The importance of specificity can be illustrated by showing that even if sensitivity is 100% and specificity is at 99% the probability of the person being a drug user is \u224833% but if the specificity is changed to 99.5% and the sensitivity is dropped down to 99% the probability of the person being a drug user rises to 49.8%.
p8461
aVHistory.
p8462
aVBayes' theorem was named after the Reverend Thomas Bayes (1701\u201361), who studied how to compute a distribution for the probability parameter of a binomial distribution (in modern terminology). Bayes' unpublished manuscript was significantly edited by Richard Price before it was posthumously read at the Royal Society. Price edited Bayes' major work "An Essay towards solving a Problem in the Doctrine of Chances" (1763), which appeared in "Philosophical Transactions", and contains Bayes' Theorem. Price wrote an introduction to the paper which provides some of the philosophical basis of Bayesian statistics. In 1765 he was elected a Fellow of the Royal Society in recognition of his work on the legacy of Bayes. 
p8463
aVThe French mathematician Pierre-Simon Laplace reproduced and extended Bayes' results in 1774, apparently quite unaware of Bayes' work. Stephen Stigler suggested in 1983 that Bayes' theorem was discovered by Nicholas Saunderson some time before Bayes; that interpretation, however, has been disputed.
p8464
aVMartyn Hooper and Sharon McGrayne have argued that Richard Price's contribution was substantial:
p8465
asVHindu\u2013Arabic numeral system
p8466
(lp8467
VThe Hindu\u2013Arabic numeral system or Hindu numeral system is a positional decimal numeral system, nowadays the most common symbolic representation of numbers in the world. It was invented between the 1st and 4th centuries by Hindu mathematicians. The system was adopted, by Persian mathematicians (Al-Khwarizmi's c. 825 book "On the Calculation with Hindu Numerals") and Arab mathematicians (Al-Kindi's c. 830 volumes "On the Use of the Hindu Numerals") by the 9th century. It later spread to the western world by the High Middle Ages.
p8468
aVThe system is based upon ten (originally nine) different glyphs. The symbols (glyphs) used to represent the system are in principle independent of the system itself. The glyphs in actual use are descended from Hindu Brahmi numerals and have split into various typographical variants since the Middle Ages.
p8469
aVThese symbol sets can be divided into three main families: the Hindu numerals used in the Indian subcontinent, the Eastern Arabic numerals used in Egypt and the Middle East and the West Arabic numerals used in the Maghreb and in Europe.
p8470
aVEtymology.
p8471
aVThe Hindu-Arabic numerals were invented by mathematicians in India. They were called "Hindu numerals". They were later called "Arabic" numerals by Europeans, because they were introduced in the West by Arab merchants.
p8472
aVPositional notation.
p8473
aVThe Hindu numeral system is designed for positional notation in a decimal system. In a more developed form, positional notation also uses a decimal marker (at first a mark over the ones digit but now more usually a decimal point or a decimal comma which separates the ones place from the tenths place), and also a symbol for "these digits recur "ad infinitum."" In modern usage, this latter symbol is usually a vinculum (a horizontal line placed over the repeating digits). In this more developed form, the numeral system can symbolize any rational number using only 13 symbols (the ten digits, decimal marker, vinculum, and an optional prepended dash to indicate a negative number).
p8474
aVDespite the numeral system being described as the "Hindu\u2013Arabic numeral system", the system had been developed by Hindu mathematicians and in use extensively throughout India, before being adopted by Persian mathematicians in India and passed on to the Arabs further west. The numeral system was transmitted to Europe in the Middle Ages by Fibonacci. The use of Arabic numerals spread around the world through European trade, books. Today they are the most common symbolic representation of numbers in the world.
p8475
aVAlthough generally found in text written with the Arabic abjad ("alphabet"), numbers written with these numerals also place the most-significant digit to the left, so they read from left to right. The requisite changes in reading direction are found in text that mixes left-to-right writing systems with right-to-left systems.
p8476
aVSymbols.
p8477
aVVarious symbol sets are used to represent numbers in the Hindu\u2013Arabic numeral system, all of which developed from the Brahmi numerals.
p8478
aVThe symbols used to represent the system have split into various typographical variants since the Middle Ages, arranged in three main groups:
p8479
aVAs in many numbering systems, the numbers 1, 2, and 3 represent simple tally marks. 1 being a single line, 2 being two lines (now connected by a diagonal) and 3 being three lines (now connected by two vertical lines). After three, numbers tend to become more complex symbols (examples are the Chinese/Japanese numbers and Roman numerals). Theorists believe that this is because it becomes difficult to instantaneously count objects past three.
p8480
aVHistory.
p8481
aVPredecessors.
p8482
aVThe Brahmi numerals at the basis of the system predate the Common Era. They replaced the earlier Kharosthi numerals used since the 4th century BC. Brahmi and Kharosthi numerals were used alongside one another in the Maurya Empire period, both appearing on the 3rd century BC edicts of Ashoka.
p8483
aVBuddhist inscriptions from around 300 BC use the symbols that became 1, 4 and 6. One century later, their use of the symbols that became 2, 4, 6, 7 and 9 was recorded. These Brahmi numerals are the ancestors of the Hindu\u2013Arabic glyphs 1 to 9, but they were not used as a positional system with a zero, and there were rather separate numerals for each of the tens (10, 20, 30, etc.).
p8484
aVThe actual numeral system, including positional notation and use of zero, is in principle independent of the glyphs used, and significantly younger than the Brahmi numerals.
p8485
aVDevelopment.
p8486
aVThe place-value system is used in the Bakhshali Manuscript. Although date of the composition of the manuscript is uncertain, the language used in the manuscript indicates that it could not have been composed any later than 400. The development of the positional decimal system takes its origins in Hindu mathematics during the Gupta period.
p8487
aVAround 500, the astronomer Aryabhata uses the word "kha" ("emptiness") to mark "zero" in tabular arrangements of digits.
p8488
aVThe 7th century "Brahmasphuta Siddhanta" contains a comparatively advanced understanding of the mathematical role of zero.
p8489
aVThe Sanskrit translation of the lost 5th century Prakrit Jaina cosmological text "Lokavibhaga"
p8490
aVmay preserve an early instance of positional use of zero.
p8491
aVThese Indian developments were taken up in Islamic mathematics in the 8th century, as recorded in al-Qifti's "Chronology of the scholars" (early 13th century).
p8492
aVThe numeral system came to be known to both the Persian Muslim mathematician Khwarizmi, who wrote a book, "On the Calculation with Hindu Numerals" in about 825, and the Arab mathematician Al-Kindi, who wrote four volumes, "On the Use of the Hindu Numerals" ( ["kit\u0101b f\u012b isti'm\u0101l al-'ad\u0101d al-hind\u012b"]) around 830. These earlier texts did not use the Hindu numerals. Kushyar ibn Labban who wrote "Kitab fi usul hisab al-hind (Principles of Hindu Reckoning)" is one of the oldest surviving manuscripts using the Hindu numerals. These books are principally responsible for the diffusion of the Hindu system of numeration throughout the Islamic world and ultimately also to Europe [http://www-gap.dcs.st-and.ac.uk/%7Ehistory/HistTopics/Indian_numerals.html].
p8493
aVThe first dated and undisputed inscription showing the use of a symbol for zero appears on a stone inscription found at the Chaturbhuja Temple at Gwalior in India, dated 876.
p8494
aVIn 10th century Islamic mathematics, the system was extended to include fractions, as recorded in a treatise by Syrian mathematician Abu'l-Hasan al-Uqlidisi in 952\u2013953.
p8495
aVAdoption in Europe.
p8496
aVIn Christian Europe, the first mention and representation of Hindu-Arabic numerals (from one to nine, without zero), is in the Codex Vigilanus, an illuminated compilation of various historical documents from the Visigothic period in Spain, written in the year 976 by three monks of the Riojan monastery of San Martín de Albelda.
p8497
aVBetween 967 and 969, Gerbert of Aurillac discovered and studied Arab science in the Catalan abbeys. Later he obtained from these places the book "De multiplicatione et divisione" ("On multiplication and division"). After becoming pope Sylvester II in the year 999, he introduced a new model of abacus, the so-called Abacus of Gerbert, by adopting tokens representing Hindu-Arab numerals, from one to nine.
p8498
aVLeonardo Fibonacci brought this system to Europe. His book Liber Abaci introduced Arabic numerals, the use of zero, and the decimal place system to the Latin world. The numeral system came to be called "Arabic" by the Europeans. It was used in European mathematics from the 12th century, and entered common use from the 15th century to replace Roman numerals. Robert Chester translated the Latin into English.
p8499
aVThe familiar shape of the Western Arabic glyphs as now used with the Latin alphabet (0, 1, 2, 3, 4, 5, 6, 7, 8, 9) are the product of the late 15th to early 16th century, when they enter early typesetting.
p8500
aVMuslim scientists used the Babylonian numeral system, and merchants used the Abjad numerals, a system similar to the Greek numeral system and the Hebrew numeral system. Similarly, Fibonacci's introduction of the system to Europe was restricted to learned circles.
p8501
aVThe credit for first establishing widespread understanding and usage of the decimal positional notation among the general population goes to Adam Ries, an author of the German Renaissance, whose 1522 "Rechenung auff der linihen und federn" was targeted at the apprentices of businessmen and craftsmen.
p8502
aVAdoption in East Asia.
p8503
aVIn China, Gautama Siddha introduced Hindu numerals with zero in 718, but Chinese mathematicians did not find them useful, as they had already had the decimal positional counting rods.
p8504
aVIn Chinese numerals, a circle (\u3007) is used to write zero in Suzhou numerals. Many historians think it was imported from Indian numerals by Gautama Siddha in 718, but some think it was created from the Chinese text space filler "\u25a1".
p8505
aVChinese and Japanese finally adopted the Hindu\u2013Arabic numerals in the 19th century, abandoning counting rods.
p8506
aVSpread of the Western Arabic variant.
p8507
aVThe "Western Arabic" numerals as they were in common use in Europe since the Baroque period have secondarily found worldwide use together with the Latin alphabet, and even significantly beyond the contemporary spread of the Latin alphabet, intruding into the writing systems in regions where other variants of the Hindu\u2013Arabic numerals had been in use, but also in conjunction with Chinese and Japanese writing (see Chinese numerals, Japanese numerals).
p8508
asS'Euler characteristic'
p8509
(lp8510
VIn mathematics, and more specifically in algebraic topology and polyhedral combinatorics, the Euler characteristic (or Euler\u2013Poincaré characteristic) is a topological invariant, a number that describes a topological space's shape or structure regardless of the way it is bent. It is commonly denoted by formula_1 (Greek lower-case letter chi).
p8511
aVThe Euler characteristic was originally defined for polyhedra and used to prove various theorems about them, including the classification of the Platonic solids. Leonhard Euler, for whom the concept is named, was responsible for much of this early work. In modern mathematics, the Euler characteristic arises from homology and, more abstractly, homological algebra.
p8512
aVPolyhedra.
p8513
aVThe Euler characteristic formula_2 was classically defined for the surfaces of polyhedra, according to the formula
p8514
aVformula_3
p8515
aVwhere "V", "E", and "F" are respectively the numbers of vertices (corners), edges and faces in the given polyhedron. Any convex polyhedron's surface has Euler characteristic
p8516
aVformula_4
p8517
aVThis equation is known as Euler's polyhedron formula. It corresponds to the Euler characteristic of the sphere (i.e. \u03c7 = 2), and applies identically to spherical polyhedra. An illustration of the formula on some polyhedra is given below.
p8518
aVThe surfaces of nonconvex polyhedra can have various Euler characteristics;
p8519
aVFor regular polyhedra, Arthur Cayley derived a modified form of Euler's formula using the density "D", vertex figure density "d""v", and face density formula_5:
p8520
aVformula_6
p8521
aVThis version holds both for convex polyhedra (where the densities are all 1) and the non-convex Kepler-Poinsot polyhedra.
p8522
aVProjective polyhedra all have Euler characteristic 1, like the real projective plane, while the surfaces of toroidal polyhedra all have Euler characteristic 0, like the torus.
p8523
aVPlanar graphs.
p8524
aVThe Euler characteristic can be defined for connected planar graphs by the same formula_7 formula as for polyhedral surfaces, where "F" is the number of faces in the graph, including the exterior face.
p8525
aVThe Euler characteristic of any planar connected graph G is 2. This is easily proved by induction on the number of faces determined by G, starting with a tree as the base case. For trees, E = V-1 and F = 1. If G has C components, the same argument by induction on F shows that formula_8. One of the few graph theory papers of Cauchy also proves this result.
p8526
aVVia stereographic projection the plane maps to the two-dimensional sphere, such that a connected graph maps to a polygonal decomposition of the sphere, which has Euler characteristic 2. This viewpoint is implicit in Cauchy's proof of Euler's formula given below.
p8527
aVProof of Euler's formula.
p8528
aVThere are many proofs of Euler's formula. One was given by Cauchy in 1811, as follows. It applies to any convex polyhedron, and more generally to any polyhedron whose boundary is topologically equivalent to a sphere and whose faces are topologically equivalent to disks.
p8529
aVRemove one face of the polyhedral surface. By pulling the edges of the missing face away from each other, deform all the rest into a planar graph of points and curves, as illustrated by the first of the three graphs for the special case of the cube. (The assumption that the polyhedral surface is homeomorphic to the sphere at the beginning is what makes this possible.) After this deformation, the regular faces are generally not regular anymore. The number of vertices and edges has remained the same, but the number of faces has been reduced by 1. Therefore, proving Euler's formula for the polyhedron reduces to proving "V" \u2212 "E" + "F" =1 for this deformed, planar object.
p8530
aVIf there is a face with more than three sides, draw a diagonal\u2014that is, a curve through the face connecting two vertices that aren't connected yet. This adds one edge and one face and does not change the number of vertices, so it does not change the quantity "V" \u2212 "E" + "F". (The assumption that all faces are disks is needed here, to show via the Jordan curve theorem that this operation increases the number of faces by one.) Continue adding edges in this manner until all of the faces are triangular.
p8531
aVApply repeatedly either of the following two transformations, maintaining the invariant that the exterior boundary is always a simple cycle:
p8532
aVThese transformations eventually reduce the planar graph to a single triangle. (Without the simple-cycle invariant, removing a triangle might disconnect the remaining triangles, invalidating the rest of the argument. A valid removal order is an elementary example of a shelling.)
p8533
aVAt this point the lone triangle has "V" = 3, "E" = 3, and "F" = 1, so that "V" \u2212 "E" + "F" = 1. Since each of the two above transformation steps preserved this quantity, we have shown "V" \u2212 "E" + "F" = 1 for the deformed, planar object thus demonstrating "V" \u2212 "E" + "F" = 2 for the polyhedron. This proves the theorem.
p8534
aVFor additional proofs, see "Twenty Proofs of Euler's Formula" by David Eppstein. Multiple proofs, including their flaws and limitations, are used as examples in "Proofs and Refutations" by Imre Lakatos.
p8535
aVTopological definition.
p8536
aVThe polyhedral surfaces discussed above are, in modern language, two-dimensional finite CW-complexes. (When only triangular faces are used, they are two-dimensional finite simplicial complexes.) In general, for any finite CW-complex, the Euler characteristic can be defined as the alternating sum
p8537
aVformula_9
p8538
aVwhere "k""n" denotes the number of cells of dimension "n" in the complex.
p8539
aVSimilarly, for a simplicial complex, the Euler characteristic equals the alternating sum
p8540
aVformula_9
p8541
aVwhere "k""n" denotes the number of "n"-simplexes in the complex.
p8542
aVMore generally still, for any topological space, we can define the "n"th Betti number "b""n" as the rank of the "n"-th singular homology group. The Euler characteristic can then be defined as the alternating sum
p8543
aVformula_11
p8544
aVThis quantity is well-defined if the Betti numbers are all finite and if they are zero beyond a certain index "n"0. For simplicial complexes, this is not the same definition as in the previous paragraph but a homology computation shows that the two definitions will give the same value for formula_2.
p8545
aVProperties.
p8546
aVThe Euler characteristic behaves well with respect to many basic operations on topological spaces, as follows.
p8547
aVHomotopy invariance.
p8548
aVHomology is a topological invariant, and moreover a homotopy invariant: Two topological spaces that are homotopy equivalent have isomorphic homology groups. It follows that the Euler characteristic is also a homotopy invariant.
p8549
aVFor example, any contractible space (that is, one homotopy equivalent to a point) has trivial homology, meaning that the 0th Betti number is 1 and the others 0. Therefore its Euler characteristic is 1. This case includes Euclidean space formula_13 of any dimension, as well as the solid unit ball in any Euclidean space \u2014 the one-dimensional interval, the two-dimensional disk, the three-dimensional ball, etc.
p8550
aVFor another example, any convex polyhedron is homeomorphic to the three-dimensional ball, so its surface is homeomorphic (hence homotopy equivalent) to the two-dimensional sphere, which has Euler characteristic 2. This explains why convex polyhedra have Euler characteristic 2.
p8551
aVInclusion-exclusion principle.
p8552
aVIf "M" and "N" are any two topological spaces, then the Euler characteristic of their disjoint union is the sum of their Euler characteristics, since homology is additive under disjoint union:
p8553
aVformula_14
p8554
aVMore generally, if "M" and "N" are subspaces of a larger space "X", then so are their union and intersection. In some cases, the Euler characteristic obeys a version of the inclusion-exclusion principle:
p8555
aVformula_15
p8556
aVThis is true in the following cases:
p8557
aVIn general, the inclusion-exclusion principle is false. A counterexample is given by taking "X" to be the real line, "M" a subset consisting of one point and "N" the complement of "M".
p8558
aVProduct property.
p8559
aVAlso, the Euler characteristic of any product space "M" × "N" is
p8560
aVformula_16
p8561
aVThese addition and multiplication properties are also enjoyed by cardinality of sets. In this way, the Euler characteristic can be viewed as a generalisation of cardinality; see [http://math.ucr.edu/home/baez/counting/].
p8562
aVCovering spaces.
p8563
aVSimilarly, for an "k"-sheeted covering space formula_17 one has
p8564
aVformula_18
p8565
aVMore generally, for a ramified covering space, the Euler characteristic of the cover can be computed from the above, with a correction factor for the ramification points, which yields the Riemann\u2013Hurwitz formula.
p8566
aVFibration property.
p8567
aVThe product property holds much more generally, for fibrations with certain conditions.
p8568
aVIf formula_19 is a fibration with fiber "F," with the base "B" path-connected, and the fibration is orientable over a field "K," then the Euler characteristic with coefficients in the field "K" satisfies the product property:
p8569
aVformula_20
p8570
aVThis includes product spaces and covering spaces as special cases,
p8571
aVand can be proven by the Serre spectral sequence on homology of a fibration.
p8572
aVFor fiber bundles, this can also be understood in terms of a transfer map formula_21 \u2013 note that this is a lifting and goes "the wrong way" \u2013 whose composition with the projection map formula_22 is multiplication by the Euler class of the fiber:
p8573
aVformula_23
p8574
aVExamples.
p8575
aVSurfaces.
p8576
aVThe Euler characteristic can be calculated easily for general surfaces by finding a polygonization of the surface (that is, a description as a CW-complex) and using the above definitions.
p8577
aVSoccer ball.
p8578
aVIt is common to construct soccer balls by stitching together pentagonal and hexagonal pieces, with three pieces meeting at each vertex (see for example the Adidas Telstar). If "P" pentagons and "H" hexagons are used, then there are "F" = "P" + "H" faces, "V" = (5 "P" + 6 "H") / 3 vertices, and "E" = (5 "P" + 6 "H") / 2 edges. The Euler characteristic is thus
p8579
aV "V" - "E" + "F" = (5 "P" + 6 "H") / 3 - (5 "P" + 6 "H") / 2 + "P" + "H" = "P" / 6.
p8580
aVBecause the sphere has Euler characteristic 2, it follows that "P" = 12. That is, a soccer ball constructed in this way always has 12 pentagons. In principle, the number of hexagons is unconstrained. This result is also applicable to fullerenes.
p8581
aVArbitrary dimensions.
p8582
aVThe "n"-dimensional sphere has Betti number 1 in dimensions 0 and "n", and all other Betti numbers 0. Hence its Euler characteristic is 1 + (-1)"n" \u2014 that is, either 0 or 2.
p8583
aVThe "n"-dimensional real projective space is the quotient of the "n"-sphere by the antipodal map. It follows that its Euler characteristic is exactly half that of the corresponding sphere \u2014 either 0 or 1.
p8584
aVThe "n"-dimensional torus is the product space of "n" circles. Its Euler characteristic is 0, by the product property. More generally, any parallelizable manifold, including any Lie group, has Euler characteristic 0.
p8585
aVThe Euler characteristic of any closed odd-dimensional manifold is also 0. The case for orientable examples is a corollary of Poincaré duality. This property applies more generally to any compact stratified space all of whose strata have odd dimension. It also applies to closed odd-dimensional non-orientable manifolds, via the two-to-one orientable double cover.
p8586
aVRelations to other invariants.
p8587
aVThe Euler characteristic of a closed orientable surface can be calculated from its genus "g" (the number of tori in a connected sum decomposition of the surface; intuitively, the number of "handles") as
p8588
aVformula_24
p8589
aVThe Euler characteristic of a closed non-orientable surface can be calculated from its non-orientable genus "k" (the number of real projective planes in a connected sum decomposition of the surface) as
p8590
aVformula_25
p8591
aVFor closed smooth manifolds, the Euler characteristic coincides with the Euler number, i.e., the Euler class of its tangent bundle evaluated on the fundamental class of a manifold. The Euler class, in turn, relates to all other characteristic classes of vector bundles.
p8592
aVFor closed Riemannian manifolds, the Euler characteristic can also be found by integrating the curvature; see the Gauss\u2013Bonnet theorem for the two-dimensional case and the generalized Gauss\u2013Bonnet theorem for the general case.
p8593
aVA discrete analog of the Gauss\u2013Bonnet theorem is Descartes' theorem that the "total defect" of a polyhedron, measured in full circles, is the Euler characteristic of the polyhedron; see defect (geometry).
p8594
aVHadwiger's theorem characterizes the Euler characteristic as the "unique" (up to scalar multiplication) translation-invariant, finitely additive, not-necessarily-nonnegative set function defined on finite unions of compact convex sets in R"n" that is "homogeneous of degree 0".
p8595
aVGeneralizations.
p8596
aVFor every combinatorial cell complex, one defines the Euler characteristic as the number of 0-cells, minus the number of 1-cells, plus the number of 2-cells, etc., if this alternating sum is finite. In particular, the Euler characteristic of a finite set is simply its cardinality, and the Euler characteristic of a graph is the number of vertices minus the number of edges.
p8597
aVMore generally, one can define the Euler characteristic of any chain complex to be the alternating sum of the ranks of the homology groups of the chain complex.
p8598
aVA version used in algebraic geometry is as follows. For any sheaf formula_26 on a projective scheme "X", one defines its Euler characteristic
p8599
aVformula_27
p8600
aVwhere formula_28 is the dimension of the "i"-th sheaf cohomology group of formula_26.
p8601
aVAnother generalization of the concept of Euler characteristic on manifolds comes from orbifolds. While every manifold has an integer Euler characteristic, an orbifold can have a fractional Euler characteristic. For example, the teardrop orbifold has Euler characteristic 1 + 1/"p", where "p" is a prime number corresponding to the cone angle 2"\u03c0" / "p".
p8602
aVThe concept of Euler characteristic of a bounded finite poset is another generalization, important in combinatorics. A poset is "bounded" if it has smallest and largest elements; call them 0 and 1. The Euler characteristic of such a poset is defined as the integer \u03bc(0,1), where \u03bc is the Möbius function in that poset's incidence algebra.
p8603
aVThis can be further generalized by defining a Q-valued Euler characteristic for certain finite categories, a notion compatible with the Euler characteristics of graphs, orbifolds and posets mentioned above. In this setting, the Euler characteristic of a finite group or monoid "G" is 1/|"G"|, and the Euler characteristic of a finite groupoid is the sum of 1/|"Gi"|, where we picked one representative group "Gi" for each connected component of the groupoid.
p8604
asS'Topology'
p8605
(lp8606
VTopology (from the Greek \u03c4\u03cc\u03c0\u03bf\u03c2, "place", and \u03bb\u03cc\u03b3\u03bf\u03c2, "study") is the mathematical study of shapes and topological spaces. It is an area of mathematics concerned with the properties of space that are preserved under continuous deformations including stretching and bending, but not tearing or gluing. This includes such properties as connectedness, continuity and boundary.
p8607
aVTopology developed as a field of study out of geometry and set theory, through analysis of such concepts as space, dimension, and transformation. Such ideas go back to Leibniz, who in the 17th century envisioned the "geometria situs" (Greek-Latin for "geometry of place") and "analysis situs" (Greek-Latin for "picking apart of place"). The term "topology" was introduced by Johann Benedict Listing in the 19th century, although it was not until the first decades of the 20th century that the idea of a topological space was developed. By the middle of the 20th century, topology had become a major branch of mathematics.
p8608
aVTopology has many subfields:
p8609
aVSee also: topology glossary for definitions of some of the terms used in topology, and topological space for a more technical treatment of the subject.
p8610
aVHistory.
p8611
aVTopology began with the investigation of certain questions in geometry. Leonhard Euler's 1736 paper on the Seven Bridges of Königsberg is regarded as one of the first academic treatises in modern topology.
p8612
aVThe term "Topologie" was introduced in German in 1847 by Johann Benedict Listing in "Vorstudien zur Topologie", who had used the word for ten years in correspondence before its first appearance in print. The English form topology was first used in 1883 in Listing's obituary in the journal "Nature" to distinguish "qualitative geometry from the ordinary geometry in which quantitative relations chiefly are treated". The term topologist in the sense of a specialist in topology was used in 1905 in the magazine "Spectator". However, none of these uses corresponds exactly to the modern definition of topology.
p8613
aVModern topology depends strongly on the ideas of set theory, developed by Georg Cantor in the later part of the 19th century. In addition to establishing the basic ideas of set theory, Cantor considered point sets in Euclidean space as part of his study of Fourier series.
p8614
aVHenri Poincaré published "Analysis Situs" in 1895, introducing the concepts of homotopy and homology, which are now considered part of algebraic topology.
p8615
aVUnifying the work on function spaces of Georg Cantor, Vito Volterra, Cesare Arzelà, Jacques Hadamard, Giulio Ascoli and others, Maurice Fréchet introduced the metric space in 1906. A metric space is now considered a special case of a general topological space. In 1914, Felix Hausdorff coined the term "topological space" and gave the definition for what is now called a Hausdorff space. Currently, a topological space is a slight generalization of Hausdorff spaces, given in 1922 by Kazimierz Kuratowski.
p8616
aVFor further developments, see point-set topology and algebraic topology.
p8617
aVIntroduction.
p8618
aVTopology can be formally defined as "the study of qualitative properties of certain objects (called topological spaces) that are invariant under a certain kind of transformation (called a continuous map), especially those properties that are invariant under a certain kind of transformation (called homeomorphism)."
p8619
aVTopology is also used to refer to a structure imposed upon a set "X", a structure that essentially 'characterizes' the set "X" as a topological space by taking proper care of properties such as convergence, connectedness and continuity, upon transformation.
p8620
aVTopological spaces show up naturally in almost every branch of mathematics. This has made topology one of the great unifying ideas of mathematics.
p8621
aVThe motivating insight behind topology is that some geometric problems depend not on the exact shape of the objects involved, but rather on the way they are put together. For example, the square and the circle have many properties in common: they are both one dimensional objects (from a topological point of view) and both separate the plane into two parts, the part inside and the part outside.
p8622
aVOne of the first papers in topology was the demonstration, by Leonhard Euler, that it was impossible to find a route through the town of Königsberg (now Kaliningrad) that would cross each of its seven bridges exactly once. This result did not depend on the lengths of the bridges, nor on their distance from one another, but only on connectivity properties: which bridges are connected to which islands or riverbanks. This problem in introductory mathematics called "Seven Bridges of Königsberg" led to the branch of mathematics known as graph theory.
p8623
aVSimilarly, the hairy ball theorem of algebraic topology says that "one cannot comb the hair flat on a hairy ball without creating a cowlick." This fact is immediately convincing to most people, even though they might not recognize the more formal statement of the theorem, that there is no nonvanishing continuous tangent vector field on the sphere. As with the "Bridges of Königsberg", the result does not depend on the shape of the sphere; it applies to any kind of smooth blob, as long as it has no holes.
p8624
aVTo deal with these problems that do not rely on the exact shape of the objects, one must be clear about just what properties these problems "do" rely on. From this need arises the notion of homeomorphism. The impossibility of crossing each bridge just once applies to any arrangement of bridges homeomorphic to those in Königsberg, and the hairy ball theorem applies to any space homeomorphic to a sphere.
p8625
aVIntuitively, two spaces are homeomorphic if one can be deformed into the other without cutting or gluing. A traditional joke is that a topologist cannot distinguish a coffee mug from a doughnut, since a sufficiently pliable doughnut could be reshaped to a coffee cup by creating a dimple and progressively enlarging it, while shrinking the hole into a handle. 
p8626
aVHomeomorphism can be considered the most basic "topological equivalence". Another is homotopy equivalence. This is harder to describe without getting technical, but the essential notion is that two objects are homotopy equivalent if they both result from "squishing" some larger object.
p8627
aVAn introductory exercise is to classify the uppercase letters of the English alphabet according to homeomorphism and homotopy equivalence. The result depends partially on the font used. The figures use the sans-serif Myriad font. Homotopy equivalence is a rougher relationship than homeomorphism; a homotopy equivalence class can contain several homeomorphism classes. The simple case of homotopy equivalence described above can be used here to show two letters are homotopy equivalent. For example, O fits inside P and the tail of the P can be squished to the "hole" part.
p8628
aVHomeomorphism classes are:
p8629
aVHomotopy classes are larger, because the tails can be squished down to a point. They are:
p8630
aVTo be sure that the letters are classified correctly, we need to show that two letters in the same class are equivalent and two letters in different classes are not equivalent. In the case of homeomorphism, this can be done by selecting points and showing their removal disconnects the letters differently. For example, X and Y are not homeomorphic because removing the center point of the X leaves four pieces; whatever point in Y corresponds to this point, its removal can leave at most three pieces. The case of homotopy equivalence is harder and requires a more elaborate argument showing an algebraic invariant, such as the fundamental group, is different on the supposedly differing classes.
p8631
aVLetter topology has practical relevance in stencil typography. For instance, Braggadocio font stencils are made of one connected piece of material.
p8632
aVConcepts.
p8633
aVTopologies on Sets.
p8634
aVThe term topology also refers to a specific mathematical idea which is central to the area of mathematics called topology. Informally, a topology is used to tell how elements of a set are related spatially to each other. The same set can have different topologies. For instance, the real line, the complex plane, and the Cantor set can be thought of as the same set with different topologies.
p8635
aVFormally, let "X" be a set and let "\u03c4" be a family of subsets of "X". Then "\u03c4" is called a "topology on X" if:
p8636
aVIf "\u03c4" is a topology on "X", then the pair ("X", "\u03c4") is called a "topological space". The notation "X\u03c4" may be used to denote a set "X" endowed with the particular topology "\u03c4".
p8637
aVThe members of "\u03c4" are called "open sets" in "X". A subset of "X" is said to be closed if its complement is in "\u03c4" (i.e., its complement is open). A subset of "X" may be open, closed, both (clopen set), or neither. The empty set and "X" itself are always both closed and open. An open set containing a point "x" is called a 'neighborhood' of "x".
p8638
aVA set with a topology is called a topological space.
p8639
aVContinuous functions and homeomorphisms.
p8640
aVA function or map from one topological space to another is called "continuous" if the inverse image of any open set is open. If the function maps the real numbers to the real numbers (both spaces with the Standard Topology), then this definition of continuous is equivalent to the definition of continuous in calculus. If a continuous function is one-to-one and onto, and if the inverse of the function is also continuous, then the function is called a homeomorphism and the domain of the function is said to be homeomorphic to the range. Another way of saying this is that the function has a natural extension to the topology. If two spaces are homeomorphic, they have identical topological properties, and are considered topologically the same. The cube and the sphere are homeomorphic, as are the coffee cup and the doughnut. But the circle is not homeomorphic to the doughnut.
p8641
aVManifolds.
p8642
aVWhile topological spaces can be extremely varied and exotic, many areas of topology focus on the more familiar class of spaces known as manifolds. A manifold is a topological space that resembles Euclidean space near each point. More precisely, each point of an "n"-dimensional manifold has a neighbourhood that is homeomorphic to the Euclidean space of dimension "n". Lines and circles, but not figure eights, are one-dimensional manifolds. Two-dimensional manifolds are also called surfaces. Examples include the plane, the sphere, and the torus, which can all be realized in three dimensions, but also the Klein bottle and real projective plane which cannot.
p8643
aVTopics.
p8644
aVGeneral topology.
p8645
aVGeneral topology is the branch of topology dealing with the basic set-theoretic definitions and constructions used in topology. It is the foundation of most other branches of topology, including differential topology, geometric topology, and algebraic topology. Another name for general topology is point-set topology.
p8646
aVThe fundamental concepts in point-set topology are "continuity", "compactness", and "connectedness". Intuitively, continuous functions take nearby points to nearby points; compact sets are those which can be covered by finitely many sets of arbitrarily small size; and connected sets are sets which cannot be divided into two pieces which are far apart. The words 'nearby', 'arbitrarily small', and 'far apart' can all be made precise by using open sets, as described below. If we change the definition of 'open set', we change what continuous functions, compact sets, and connected sets are. Each choice of definition for 'open set' is called a "topology". A set with a topology is called a "topological space".
p8647
aV"Metric spaces" are an important class of topological spaces where distances can be assigned a number called a "metric". Having a metric simplifies many proofs, and many of the most common topological spaces are metric spaces.
p8648
aVAlgebraic topology.
p8649
aVAlgebraic topology is a branch of mathematics that uses tools from abstract algebra to study topological spaces. The basic goal is to find algebraic invariants that classify topological spaces up to homeomorphism, though usually most classify up to homotopy equivalence.
p8650
aVThe most important of these invariants are homotopy groups, homology, and cohomology.
p8651
aVAlthough algebraic topology primarily uses algebra to study topological problems, using topology to solve algebraic problems is sometimes also possible. Algebraic topology, for example, allows for a convenient proof that any subgroup of a free group is again a free group.
p8652
aVDifferential topology.
p8653
aVDifferential topology is the field dealing with differentiable functions on differentiable manifolds. It is closely related to differential geometry and together they make up the geometric theory of differentiable manifolds.
p8654
aVMore specifically, differential topology considers the properties and structures that require only a smooth structure on a manifold to be defined. Smooth manifolds are 'softer' than manifolds with extra geometric structures, which can act as obstructions to certain types of equivalences and deformations that exist in differential topology. For instance, volume and Riemannian curvature are invariants that can distinguish different geometric structures on the same smooth manifold\u2014that is, one can smoothly "flatten out" certain manifolds, but it might require distorting the space and affecting the curvature or volume.
p8655
aVGeometric topology.
p8656
aVGeometric topology is a branch of topology that primarily focuses on low-dimensional manifolds (i.e. dimensions 2,3 and 4) and their interaction with geometry, but it also includes some higher-dimensional topology.
p8657
aV Some examples of topics in geometric topology are orientability, handle decompositions, local flatness, and the planar and higher-dimensional Schönflies theorem.
p8658
aVIn high-dimensional topology, characteristic classes are a basic invariant, and surgery theory is a key theory.
p8659
aVLow-dimensional topology is strongly geometric, as reflected in the uniformization theorem in 2 dimensions \u2013 every surface admits a constant curvature metric; geometrically, it has one of 3 possible geometries: positive curvature/spherical, zero curvature/flat, negative curvature/hyperbolic \u2013 and the geometrization conjecture (now theorem) in 3 dimensions \u2013 every 3-manifold can be cut into pieces, each of which has one of 8 possible geometries.
p8660
aV2-dimensional topology can be studied as complex geometry in one variable (Riemann surfaces are complex curves) \u2013 by the uniformization theorem every conformal class of metrics is equivalent to a unique complex one, and 4-dimensional topology can be studied from the point of view of complex geometry in two variables (complex surfaces), though not every 4-manifold admits a complex structure.
p8661
aVGeneralizations.
p8662
aVOccasionally, one needs to use the tools of topology but a "set of points" is not available. In pointless topology one considers instead the lattice of open sets as the basic notion of the theory, while Grothendieck topologies are structures defined on arbitrary categories that allow the definition of sheaves on those categories, and with that the definition of general cohomology theories.
p8663
aVApplications.
p8664
aVBiology.
p8665
aVKnot theory, a branch of topology, is used in biology to study the effects of certain enzymes on DNA. These enzymes cut, twist, and reconnect the DNA, causing knotting with observable effects such as slower electrophoresis. Topology is also used in evolutionary biology to represent the relationship between phenotype and genotype. Phenotypic forms which appear quite different can be separated by only a few mutations depending on how genetic changes map to phenotypic changes during development.
p8666
aVComputer science.
p8667
aVTopological data analysis uses techniques from algebraic topology to determine the large scale structure of a set (for instance, determining if a cloud of points is spherical or toroidal). The main method used by topological data analysis is:
p8668
aVPhysics.
p8669
aVIn physics, topology is used in several areas such as quantum field theory and cosmology.
p8670
aVA topological quantum field theory (or topological field theory or TQFT) is a quantum field theory which computes topological invariants.
p8671
aVAlthough TQFTs were invented by physicists, they are also of mathematical interest, being related to, among other things, knot theory and the theory of four-manifolds in algebraic topology, and to the theory of moduli spaces in algebraic geometry. Donaldson, Jones, Witten, and Kontsevich have all won Fields Medals for work related to topological field theory.
p8672
aVIn cosmology, topology can be used to describe the overall shape of the universe. This area is known as spacetime topology.
p8673
aVRobotics.
p8674
aVThe various possible positions of a robot can be described by a manifold called configuration space. In the area of motion planning, one finds paths between two points in configuration space. These paths represent a motion of the robot's joints and other parts into the desired location and pose.
p8675
asS'Closure (mathematics)'
p8676
(lp8677
VA set has closure under an operation if performance of that operation on members of the set always produces a member of the same set; in this case we also say that the set is closed under the operation. For example, the integers are closed under subtraction, but the positive integers are not: 1 and 2 are both positive integers, but the result of subtracting 2 from 1 is not a positive integer. Another example is the set containing only the number zero, which is closed under addition, subtraction and multiplication.
p8678
aVSimilarly, a set is said to be '"closed under a "collection" of operations if it is closed under each of the operations individually.
p8679
aVBasic properties.
p8680
aVA set that is closed under an operation or collection of operations is said to satisfy a closure property. Often a closure property is introduced as an axiom, which is then usually called the axiom of closure"'. Modern set-theoretic definitions usually define operations as maps between sets, so adding closure to a structure as an axiom is superfluous; however in practice operations are often defined initially on a superset of the set in question and a closure proof is required to establish that the operation applied to pairs from that set only produces members of that set. For example, the set of even integers is closed under addition, but the set of odd integers is not.
p8681
aVWhen a set "S" is not closed under some operations, one can usually find the smallest set containing "S" that is closed. This smallest closed set is called the closure of "S" (with respect to these operations). For example, the closure under subtraction of the set of natural numbers, viewed as a subset of the real numbers, is the set of integers. An important example is that of topological closure. The notion of closure is generalized by Galois connection, and further by monads.
p8682
aVThe set "S" must be a subset of a closed set in order for the closure operator to be defined. In the preceding example, it is important that the reals are closed under subtraction; in the domain of the natural numbers subtraction is not always defined.
p8683
aVThe two uses of the word "closure" should not be confused. The former usage refers to the property of being closed, and the latter refers to the smallest closed set containing one that may not be closed. In short, the closure of a set satisfies a closure property.
p8684
aVClosed sets.
p8685
aVA set is closed under an operation if that operation returns a member of the set when evaluated on members of the set. Sometimes the requirement that the operation be valued in a set is explicitly stated, in which case it is known as the axiom of closure. For example, one may define a group as a set with a binary product operator obeying several axioms, including an axiom that the product of any two elements of the group is again an element. However the modern definition of an operation makes this axiom superfluous; an "n"-ary operation on "S" is just a subset of "S""n"+1. By its very definition, an operator on a set cannot have values outside the set.
p8686
aVNevertheless, the closure property of an operator on a set still has some utility. Closure on a set does not necessarily imply closure on all subsets. Thus a subgroup of a group is a subset on which the binary product and the unary operation of inversion satisfy the closure axiom.
p8687
aVAn operation of a different sort is that of finding the limit points of a subset of a topological space (if the space is first-countable, it suffices to restrict consideration to the limits of sequences but in general one must consider at least limits of nets). A set that is closed under this operation is usually just referred to as a closed set in the context of topology. Without any further qualification, the phrase usually means closed in this sense. Closed intervals like [1,2] = {"x" : 1 \u2264 "x" \u2264 2} are closed in this sense.
p8688
aVA partially ordered set is downward closed (and also called a lower set) if for every element of the set all smaller elements are also in it; this applies for example for the real intervals (\u2212\u221e, "p") and (\u2212\u221e, "p"], and for an ordinal number "p" represented as interval [ 0, "p"); every downward closed set of ordinal numbers is itself an ordinal number.
p8689
aVUpward closed and upper set are defined similarly.
p8690
aV"P" closures of binary relations.
p8691
aVThe notion of a closure can be applied for an arbitrary binary relation "R" \u2286 "S"×"S", and an arbitrary property "P" in the following way: the "P" closure of "R" is the least relation "Q" \u2286 "S"×"S" that contains "R" (i.e. "R" \u2286 "Q") and for which property "P" holds (i.e. "P"("Q") is true). For instance, one can define the symmetric closure as the least symmetric relation containing "R". This generalization is often encountered in the theory of rewriting systems, where one often uses more "wordy" notions such as the reflexive transitive closure "R*"\u2014the smallest preorder containing "R", or the reflexive transitive symmetric closure "R"\u2261\u2014the smallest equivalence relation containing "R", and therefore also known as the equivalence closure. When considering a particular term algebra, an equivalence relation that is compatible with all operations of the algebra is called a congruence relation. The congruence closure of "R" is defined as the smallest congruence relation containing "R".
p8692
aVFor arbitrary "P" and "R", the "P" closure of "R" need not exist. In the above examples, these exist because reflexivity, transitivity and symmetry are closed under arbitrary intersections. In such cases, the "P" closure can be directly defined as the intersection of all sets with property "P" containing "R".
p8693
aVSome important particular closures can be constructively obtained as follows:
p8694
aVThe relation "R" is said to have closure under some "cl"xxx, if "R" = "cl"xxx("R"); for example "R" is called symmetric if "R" = "cl"sym("R").
p8695
aVAny of these four closures preserves symmetry, i.e., if "R" is symmetric, so is any "cl"xxx("R"). 
p8696
aVSimilarly, all four preserve reflexivity.
p8697
aVMoreover, "cl"trn preserves closure under "cl"emb,\u03a3 for arbitrary \u03a3.
p8698
aVAs a consequence, the equivalence closure of an arbitrary binary relation "R" can be obtained as "cl"trn("cl"sym("cl"ref("R"))), and the congruence closure with respect to some \u03a3 can be obtained as "cl"trn("cl"emb,\u03a3("cl"sym("cl"ref("R")))). In the latter case, the nesting order does matter; e.g. if "S" is the set of terms over \u03a3 = { "a", "b", "c", "f" } and "R" = { \u27e8"a","b"\u27e9, \u27e8"f"("b"),"c"\u27e9 }, then the pair \u27e8"f"("a"),"c"\u27e9 is contained in the congruence closure "cl"trn("cl"emb,\u03a3("cl"sym("cl"ref("R")))) of "R", but not in the relation "cl"emb,\u03a3("cl"trn("cl"sym("cl"ref("R")))).
p8699
aVClosure operator.
p8700
aVGiven an operation on a set "X", one can define the closure "C"("S") of a subset "S" of "X" to be the smallest subset closed under that operation that contains "S" as a subset, if any such subsets exist. Consequently, "C"("S") is the intersection of all closed sets containing "S". For example, the closure of a subset of a group is the subgroup generated by that set.
p8701
aVThe closure of sets with respect to some operation defines a closure operator on the subsets of "X". The closed sets can be determined from the closure operator; a set is closed if it is equal to its own closure. Typical structural properties of all closure operations are: 
p8702
aVAn object that is its own closure is called closed. By idempotency, an object is closed if and only if it is the closure of some object.
p8703
aVThese three properties define an abstract closure operator. Typically, an abstract closure acts on the class of all subsets of a set.
p8704
aVIf "X" is contained in a set closed under the operation then every subset of "X" has a closure.
p8705
asS'Bayesian network'
p8706
(lp8707
VA Bayesian network, Bayes network, belief network, Bayes(ian) model or probabilistic directed acyclic graphical model is a probabilistic graphical model (a type of statistical model) that represents a set of random variables and their conditional dependencies via a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases.
p8708
aVFormally, Bayesian networks are DAGs whose nodes represent random variables in the Bayesian sense: they may be observable quantities, latent variables, unknown parameters or hypotheses. Edges represent conditional dependencies; nodes that are not connected represent variables that are conditionally independent of each other. Each node is associated with a probability function that takes, as input, a particular set of values for the node's parent variables, and gives (as output) the probability (or probability distribution, if applicable) of the variable represented by the node. For example, if formula_1 parent nodes represent formula_1 Boolean variables then the probability function could be represented by a table of formula_3 entries, one entry for each of the formula_3 possible combinations of its parents being true or false. Similar ideas may be applied to undirected, and possibly cyclic, graphs; such are called Markov networks.
p8709
aVEfficient algorithms exist that perform inference and learning in Bayesian networks. Bayesian networks that model sequences of variables ("e.g." speech signals or protein sequences) are called dynamic Bayesian networks. Generalizations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams.
p8710
aVExample.
p8711
aVSuppose that there are two events which could cause grass to be wet: either the sprinkler is on or it's raining. Also, suppose that the rain has a direct effect on the use of the sprinkler (namely that when it rains, the sprinkler is usually not turned on). Then the situation can be modeled with a Bayesian network (shown). All three variables have two possible values, T (for true) and F (for false).
p8712
aVThe joint probability function is:
p8713
aV formula_5
p8714
aVwhere the names of the variables have been abbreviated to "G = Grass wet (yes/no)", "S = Sprinkler turned on (yes/no)", and "R = Raining (yes/no)".
p8715
aVThe model can answer questions like "What is the probability that it is raining, given the grass is wet?" by using the conditional probability formula and summing over all nuisance variables:
p8716
aVformula_6
p8717
aVUsing the expansion for the joint probability function formula_7 and the conditional probabilities from the conditional probability tables (CPTs) stated in the diagram, one can evaluate each term in the sums in the numerator and denominator. For example,
p8718
aVformula_8
p8719
aVThen the numerical results (subscripted by the associated variable values) are
p8720
aVformula_9
p8721
aVIf, on the other hand, we wish to answer an interventional question: "What is the likelihood that it would rain, given that we wet the grass?" the answer would be governed by the post-intervention joint distribution function formula_10 obtained by removing the factor formula_11 from the pre-intervention distribution. As expected, the likelihood of rain is unaffected by the action: formula_12.
p8722
aVIf, moreover, we wish to predict the impact of turning the sprinkler on, we have
p8723
aV formula_13
p8724
aVwith the term formula_14 removed, showing that the action has an effect on the grass but not on the rain.
p8725
aVThese predictions may not be feasible when some of the variables are unobserved, as in most policy evaluation problems. The effect of the action formula_15 can still be predicted, however, whenever a criterion called "back-door" is satisfied. It states that, if a set "Z" of nodes can be observed that "d"-separates (or blocks) all back-door paths from "X" to "Y" then formula_16. A back-door path is one that ends with an arrow into "X". Sets that satisfy the back-door criterion are called "sufficient" or "admissible." For example, the set "Z" = "R" is admissible for predicting the effect of "S" = "T" on "G", because "R" "d"-separate the (only) back-door path
p8726
aV"S" \u2190 "R" \u2192 "G". However, if "S" is not observed, there is no other set that "d"-separates this path and the effect of turning the sprinkler on ("S" = "T") on the grass ("G") cannot be predicted from passive observations. We then say that "P"("G|do"("S" = "T")) is not "identified." This reflects the fact that, lacking interventional data, we cannot determine if the observed dependence between "S" and "G" is due to a causal connection or is spurious
p8727
aVTo determine whether a causal relation is identified from an arbitrary Bayesian network with unobserved variables, one can use the three rules of ""do"-calculus"
p8728
aVand test whether all "do" terms can be removed from the
p8729
aVexpression of that relation, thus confirming that the desired quantity is estimable from frequency data.
p8730
aVUsing a Bayesian network can save considerable amounts of memory, if the dependencies in the joint distribution are sparse. For example, a naive way of storing the conditional probabilities of 10 two-valued variables as a table requires storage space for formula_17 values. If the local distributions of no variable depends on more than 3 parent variables, the Bayesian network representation only needs to store at most formula_18 values.
p8731
aVOne advantage of Bayesian networks is that it is intuitively easier for a human to understand (a sparse set of) direct dependencies and local distributions than complete joint distributions.
p8732
aVInference and learning.
p8733
aVThere are three main inference tasks for Bayesian networks.
p8734
aVInferring unobserved variables.
p8735
aVBecause a Bayesian network is a complete model for the variables and their relationships, it can be used to answer probabilistic queries about them. For example, the network can be used to find out updated knowledge of the state of a subset of variables when other variables (the "evidence" variables) are observed. This process of computing the "posterior" distribution of variables given evidence is called probabilistic inference. The posterior gives a universal sufficient statistic for detection applications, when one wants to choose values for the variable subset which minimize some expected loss function, for instance the probability of decision error. A Bayesian network can thus be considered a mechanism for automatically applying Bayes' theorem to complex problems.
p8736
aVThe most common exact inference methods are: variable elimination, which eliminates (by integration or summation) the non-observed non-query variables one by one by distributing the sum over the product; clique tree propagation, which caches the computation so that many variables can be queried at one time and new evidence can be propagated quickly; and recursive conditioning and AND/OR search, which allow for a space-time tradeoff and match the efficiency of variable elimination when enough space is used. All of these methods have complexity that is exponential in the network's treewidth. The most common approximate inference algorithms are importance sampling, stochastic MCMC simulation, mini-bucket elimination, loopy belief propagation, generalized belief propagation, and variational methods.
p8737
aVParameter learning.
p8738
aVIn order to fully specify the Bayesian network and thus fully represent the joint probability distribution, it is necessary to specify for each node "X" the probability distribution for "X" conditional upon "X"'s parents. The distribution of "X" conditional upon its parents may have any form. It is common to work with discrete or Gaussian distributions since that simplifies calculations. Sometimes only constraints on a distribution are known; one can then use the principle of maximum entropy to determine a single distribution, the one with the greatest entropy given the constraints. (Analogously, in the specific context of a dynamic Bayesian network, one commonly specifies the conditional distribution for the hidden state's temporal evolution to maximize the entropy rate of the implied stochastic process.)
p8739
aVOften these conditional distributions include parameters which are unknown and must be estimated from data, sometimes using the maximum likelihood approach. Direct maximization of the likelihood (or of the posterior probability) is often complex when there are unobserved variables. A classical approach to this problem is the expectation-maximization algorithm which alternates computing expected values of the unobserved variables conditional on observed data, with maximizing the complete likelihood (or posterior) assuming that previously computed expected values are correct. Under mild regularity conditions this process converges on maximum likelihood (or maximum posterior) values for parameters.
p8740
aVA more fully Bayesian approach to parameters is to treat parameters as additional unobserved variables and to compute a full posterior distribution over all nodes conditional upon observed data, then to integrate out the parameters. This approach can be expensive and lead to large dimension models, so in practice classical parameter-setting approaches are more common.
p8741
aVStructure learning.
p8742
aVIn the simplest case, a Bayesian network is specified by an expert and is then used to perform inference. In other applications the task of defining the network is too complex for humans. In this case the network structure and the parameters of the local distributions must be learned from data.
p8743
aVAutomatically learning the graph structure of a Bayesian network is a challenge pursued within machine learning. The basic idea goes back to a recovery algorithm
p8744
aVdeveloped by Rebane and Pearl (1987) and rests
p8745
aVon the distinction between the three possible types of
p8746
aVadjacent triplets allowed in a directed acyclic graph (DAG):
p8747
aVType 1 and type 2 represent the same dependencies (formula_22 and formula_23 are independent given formula_24) and are, therefore, indistinguishable. Type 3, however, can be uniquely identified, since formula_22 and formula_23 are marginally independent and all other pairs are dependent. Thus, while the "skeletons" (the graphs stripped of arrows) of these three triplets are identical, the directionality of the arrows is partially identifiable. The same distinction applies when formula_22 and formula_23 have common parents, except that one must first condition on those parents. Algorithms have been developed to systematically determine the skeleton of the underlying graph and, then, orient all arrows whose directionality is dictated by the conditional independencies observed.
p8748
aVAn alternative method of structural learning uses optimization based search. It requires a scoring function and a search strategy. A common scoring function is posterior probability of the structure given the training data. The time requirement of an exhaustive search returning a structure that maximizes the score is superexponential in the number of variables. A local search strategy makes incremental changes aimed at improving the score of the structure. A global search algorithm like Markov chain Monte Carlo can avoid getting trapped in local minima. Friedman et al. discuss using mutual information between variables and finding a structure that maximizes this. They do this by restricting the parent candidate set to "k" nodes and exhaustively searching therein.
p8749
aVAnother method consists of focusing on the sub-class of decomposable models, for which the MLE have a closed form. It is then possible to discover a consistent structure for hundreds of variables.
p8750
aVA Bayesian network can be augmented with nodes and edges using rule-based machine learning techniques. Inductive logic programming can be used to mine rules and create new nodes. Statistical relational learning (SRL) approaches use a scoring function based on the Bayes network structure to guide the structural search and augment the network. A common SRL scoring function is the area under the ROC curve.
p8751
aVStatistical introduction.
p8752
aVGiven data formula_29 and parameter formula_30, a simple Bayesian analysis starts with a prior probability ("prior") formula_31 and likelihood formula_32 to compute a posterior probability formula_33.
p8753
aVOften the prior on formula_30 depends in turn on other parameters formula_35 that are not mentioned in the likelihood. So, the prior formula_31 must be replaced by a likelihood formula_37, and a prior formula_38 on the newly introduced parameters formula_35 is required, resulting in a posterior probability
p8754
aVformula_40
p8755
aVThis is the simplest example of a "hierarchical Bayes model".
p8756
aVThe process may be repeated; for example, the parameters formula_35 may depend in turn on additional parameters formula_42, which will require their own prior. Eventually the process must terminate, with priors that do not depend on any other unmentioned parameters.
p8757
aVIntroductory examples.
p8758
aVSuppose we have measured the quantities formula_43each with normally distributed errors of known standard deviation formula_44,
p8759
aVformula_45
p8760
aVSuppose we are interested in estimating the formula_46. An approach would be to estimate the formula_46 using a maximum likelihood approach; since the observations are independent, the likelihood factorizes and the maximum likelihood estimate is simply
p8761
aVformula_48
p8762
aVHowever, if the quantities are related, so that for example we may think that the individual formula_46 have themselves been drawn from an underlying distribution, then this relationship destroys the independence and suggests a more complex model, e.g.,
p8763
aVformula_50
p8764
aVformula_51
p8765
aVwith improper priors formula_52flat, formula_53flatformula_54. When formula_55, this is an identified model (i.e. there exists a unique solution for the model's parameters), and the posterior distributions of the individual formula_46 will tend to move, or "shrink" away from the maximum likelihood estimates towards their common mean. This "shrinkage" is a typical behavior in hierarchical Bayes models.
p8766
aVRestrictions on priors.
p8767
aVSome care is needed when choosing priors in a hierarchical model, particularly on scale variables at higher levels of the hierarchy such as the variable formula_57 in the example. The usual priors such as the Jeffreys prior often do not work, because the posterior distribution will be improper (not normalizable), and estimates made by minimizing the expected loss will be inadmissible.
p8768
aVDefinitions and concepts.
p8769
aVThere are several equivalent definitions of a Bayesian network. For all the following, let "G" = ("V","E") be a directed acyclic graph (or DAG), and let "X" = ("X""v")"v" \u2208 "V" be a set of random variables indexed by "V".
p8770
aVFactorization definition.
p8771
aV"X" is a Bayesian network with respect to "G" if its joint probability density function (with respect to a product measure) can be written as a product of the individual density functions, conditional on their parent variables:
p8772
aVformula_58
p8773
aVwhere pa("v") is the set of parents of "v" (i.e. those vertices pointing directly to "v" via a single edge).
p8774
aVFor any set of random variables, the probability of any member of a joint distribution can be calculated from conditional probabilities using the chain rule (given a topological ordering of "X") as follows:
p8775
aVformula_59
p8776
aVCompare this with the definition above, which can be written as:
p8777
aVformula_60 for each formula_61 which is a parent of formula_62
p8778
aVThe difference between the two expressions is the conditional independence of the variables from any of their non-descendants, given the values of their parent variables.
p8779
aVLocal Markov property.
p8780
aV"X" is a Bayesian network with respect to "G" if it satisfies the "local Markov property": each variable is conditionally independent of its non-descendants given its parent variables:
p8781
aVformula_63
p8782
aVwhere de("v") is the set of descendants and "V" \u005c de("v") is the set of non-descendants of "v".
p8783
aVThis can also be expressed in terms similar to the first definition, as
p8784
aVformula_64 for each formula_65 which is not a descendant of formula_66 for each formula_61 which is a parent of formula_62
p8785
aVNote that the set of parents is a subset of the set of non-descendants because the graph is acyclic.
p8786
aVDeveloping Bayesian networks.
p8787
aVTo develop a Bayesian network, we often first develop a DAG "G" such that we believe "X" satisfies the local Markov property with respect to "G". Sometimes this is done by creating a causal DAG. We then ascertain the conditional probability distributions of each variable given its parents in "G". In many cases, in particular in the case where the variables are discrete, if we define the joint distribution of "X" to be the product of these conditional distributions, then "X" is a Bayesian network with respect to "G".
p8788
aVMarkov blanket.
p8789
aVThe Markov blanket of a node is the set of nodes consisting of its parents, its children, and any other parents of its children. This set renders it independent of the rest of the network; the joint distribution of the variables in the Markov blanket of a node is sufficient knowledge for calculating the distribution of the node. "X" is a Bayesian network with respect to "G" if every node is conditionally independent of all other nodes in the network, given its Markov blanket.
p8790
aV"d"-separation.
p8791
aVThis definition can be made more general by defining the "d"-separation of two nodes, where d stands for directional. Let "P" be a trail (that is, a collection of edges which is like a path, but each of whose edges may have any direction) from node "u" to "v". Then "P" is said to be "d"-separated by a set of nodes "Z" if and only if (at least) one of the following holds:
p8792
aVThus "u" and "v" are said to be "d"-separated by "Z" if all trails between them are "d"-separated. If "u" and "v" are not d-separated, they are called d-connected.
p8793
aV"X" is a Bayesian network with respect to "G" if, for any two nodes "u", "v":
p8794
aVformula_69
p8795
aVwhere "Z" is a set which "d"-separates "u" and "v". (The Markov blanket is the minimal set of nodes which "d"-separates node "v" from all other nodes.)
p8796
aVHierarchical models.
p8797
aVThe term "hierarchical model" is sometimes considered a particular type of Bayesian network, but has no formal definition. Sometimes the term is reserved for models with three or more levels of random variables; other times, it is reserved for models with latent variables. In general, however, any moderately complex Bayesian network is usually termed "hierarchical".
p8798
aVCausal networks.
p8799
aVAlthough Bayesian networks are often used to represent causal relationships, this need not be the case: a directed edge from "u" to "v" does not require that "Xv" is causally dependent on "Xu". This is demonstrated by the fact that Bayesian networks on the graphs:
p8800
aVformula_70
p8801
aVare equivalent: that is they impose exactly the same conditional independence requirements.
p8802
aVA causal network is a Bayesian network with an explicit requirement that the relationships be causal. The additional semantics of the causal networks specify that if a node "X" is actively caused to be in a given state "x" (an action written as "do"("X"="x")), then the probability density function changes to the one of the network obtained by cutting the links from the parents of "X" to "X", and setting "X" to the caused value "x". Using these semantics, one can predict the impact of external interventions from data obtained prior to intervention.
p8803
aVApplications.
p8804
aVBayesian networks are used for modelling knowledge in computational biology and bioinformatics (gene regulatory networks, protein structure, gene expression analysis, learning epistasis from GWAS data sets) medicine, biomonitoring, document classification, information retrieval, semantic search, image processing, data fusion, decision support systems, engineering, sports betting, gaming, law, study design and risk analysis.<ref>
p8805
asS'Projection (mathematics)'
p8806
(lp8807
VIn mathematics, a projection is a mapping of a set (or other mathematical structure) into a subset (or sub-structure), which is equal to its square for mapping composition (or, in other words, which is idempotent). The restriction to a subspace of a projection is also called a "projection", even if the idempotence property is lost.
p8808
aVAn everyday example of a projection is the casting of shadows onto a plane (paper sheet). The projection of a point is its shadow on the paper sheet. The shadow of a point on the paper sheet is this point itself (idempotence). The shadow of a three-dimensional sphere is a circle. Originally, the notion of projection was introduced in Euclidean geometry to denote the projection of the Euclidean space of three dimensions onto a plane in it, like the shadow example. The two main projections of this kind are: 
p8809
aVThe concept of projection in mathematics is a very old one, most likely having its roots in the phenomenon of the shadows cast by real world objects on the ground. This rudimentary idea was refined and abstracted, first in a geometric context and later in other branches of mathematics. Over time differing versions of the concept developed, but today, in a sufficiently abstract setting, we can unify these variations.
p8810
aVIn cartography, a map projection is a map of a part of the surface of the Earth onto a plane, which, in some cases, but not always, is the restriction of a projection in the above meaning. The 3D projections are also at the basis of the theory of perspective. 
p8811
aVThe need for unifying the two kinds of projections and of defining the image by a central projection of any point different of the center of projection are at the origin of projective geometry. However, a projective transformation is a bijection of a projective space, a property "not" shared with the "projections" of this article.
p8812
aVDefinition.
p8813
aVIn an abstract setting we can generally say that a "projection" is a mapping of a set (or of a mathematical structure) which is idempotent, which means that a projection is equal to its composition with itself. A projection may also refer to a mapping which has a left inverse. Both notions are strongly related, as follows. Let "p" be an idempotent map from a set "E" into itself (thus "p"\u2218"p" = "p") and "F" = "p"("E") be the image of "p". If we denote by \u03c0 the map "p" viewed as a map from "E" onto "F" and by "i" the injection of "F" into "E", then we have "i"\u2218\u03c0 = Id"F". Conversely, "i"\u2218\u03c0 = Id"F" implies that \u03c0\u2218"i" is idempotent.
p8814
aVApplications.
p8815
aVThe original notion of projection has been extended or generalized to various mathematical situations, frequently, but not always, related to geometry, for example:
p8816
asS'Identity element'
p8817
(lp8818
VIn mathematics, an identity element (or neutral element) is a special type of element of a set with respect to a binary operation on that set. It leaves other elements unchanged when combined with them. This is used for groups and related concepts.
p8819
aVThe term "identity element" is often shortened to "identity" (as will be done in this article) when there is no possibility of confusion.
p8820
aVLet be a set  with a binary operation \u2217 on it (known as a magma). Then an element  of  is called a left identity if for all  in , and a right identity if for all  in . If is both a left identity and a right identity, then it is called a two-sided identity, or simply an identity.
p8821
aVAn identity with respect to addition is called an additive identity (often denoted as 0) and an identity with respect to multiplication is called a multiplicative identity (often denoted as 1). The distinction is used most often for sets that support both binary operations, such as rings. The multiplicative identity is often called the unit in the latter context, where, though, a unit is often used in a broader sense, to mean an element with a multiplicative inverse.
p8822
aVProperties.
p8823
aVAs the last example (a semigroup) shows, it is possible for to have several left identities. In fact, every element can be a left identity. Similarly, there can be several right identities. But if there is both a right identity and a left identity, then they are equal and there is just a single two-sided identity. To see this, note that if is a left identity and is a right identity then . In particular, there can never be more than one two-sided identity. If there were two, and , then would have to be equal to both and .
p8824
aVIt is also quite possible for to have "no" identity element. A common example of this is the cross product of vectors. The absence of an identity element is related to the fact that the direction of any nonzero cross product is always orthogonal to any element multiplied \u2013 so that it is not possible to obtain a non-zero vector in the same direction as the original. Another example would be the additive semigroup of positive natural numbers.
p8825
aVReferences.
p8826
aV__NOTOC__
p8827
asS'Einstein field equations'
p8828
(lp8829
VThe Einstein field equations (EFE; also known as "Einstein's equations") are the set of ten equations in Albert Einstein's general theory of relativity that describes the fundamental interaction of gravitation as a result of spacetime being curved by matter and energy. First published by Einstein in 1915 as a tensor equation, the EFE equate local spacetime curvature (expressed by the Einstein tensor) with the local energy and momentum within that spacetime (expressed by the stress\u2013energy tensor).
p8830
aVSimilar to the way that electromagnetic fields are determined using charges and currents via Maxwell's equations, the EFE are used to determine the spacetime geometry resulting from the presence of mass\u2013energy and linear momentum, that is, they determine the metric tensor of spacetime for a given arrangement of stress\u2013energy in the spacetime. The relationship between the metric tensor and the Einstein tensor allows the EFE to be written as a set of non-linear partial differential equations when used in this way. The solutions of the EFE are the components of the metric tensor. The inertial trajectories of particles and radiation (geodesics) in the resulting geometry are then calculated using the geodesic equation.
p8831
aVAs well as obeying local energy\u2013momentum conservation, the EFE reduce to Newton's law of gravitation where the gravitational field is weak and velocities are much less than the speed of light.
p8832
aVExact solutions for the EFE can only be found under simplifying assumptions such as symmetry. Special classes of exact solutions are most often studied as they model many gravitational phenomena, such as rotating black holes and the expanding universe. Further simplification is achieved in approximating the actual spacetime as flat spacetime with a small deviation, leading to the linearised EFE. These equations are used to study phenomena such as gravitational waves.
p8833
aVMathematical form.
p8834
aVThe Einstein field equations (EFE) may be written in the form:
p8835
aVwhere formula_1 is the Ricci curvature tensor, formula_2 is the metric tensor, formula_3 is the cosmological constant, formula_4 is Newton's gravitational constant, formula_5 is the speed of light in vacuum, formula_6 is the scalar curvature and formula_7 is the stress\u2013energy tensor.
p8836
aVThe EFE is a tensor equation relating a set of symmetric 4×4 tensors. Each tensor has 10 independent components. The four Bianchi identities reduce the number of independent equations from 10 to 6, leaving the metric with four gauge fixing degrees of freedom, which correspond to the freedom to choose a coordinate system.
p8837
aVAlthough the Einstein field equations were initially formulated in the context of a four-dimensional theory, some theorists have explored their consequences in "n" dimensions. The equations in contexts outside of general relativity are still referred to as the Einstein field equations. The vacuum field equations (obtained when "T" is identically zero) define Einstein manifolds.
p8838
aVDespite the simple appearance of the equations they are actually quite complicated. Given a specified distribution of matter and energy in the form of a stress\u2013energy tensor, the EFE are understood to be equations for the metric tensor formula_8, as both the Ricci tensor and scalar curvature depend on the metric in a complicated nonlinear manner. In fact, when fully written out, the EFE are a system of 10 coupled, nonlinear, hyperbolic-elliptic partial differential equations.
p8839
aVOne can write the EFE in a more compact form by defining the Einstein tensor
p8840
aVformula_9
p8841
aVwhich is a symmetric second-rank tensor that is a function of the metric. The EFE can then be written as
p8842
aVformula_10
p8843
aVUsing geometrized units where "G" = "c" = 1, this can be rewritten as
p8844
aVformula_11
p8845
aVThe expression on the left represents the curvature of spacetime as determined by the metric; the expression on the right represents the matter/energy content of spacetime. The EFE can then be interpreted as a set of equations dictating how matter/energy determines the curvature of spacetime.
p8846
aVThese equations, together with the geodesic equation, which dictates how freely-falling matter moves through space-time, form the core of the mathematical formulation of general relativity.
p8847
aVSign convention.
p8848
aVThe above form of the EFE is the standard established by Misner, Thorne, and Wheeler. The authors analyzed all conventions that exist and classified according to the following three signs (S1, S2, S3):
p8849
aVformula_12
p8850
aVThe third sign above is related to the choice of convention for the Ricci tensor:
p8851
aVformula_13
p8852
aVWith these definitions Misner, Thorne, and Wheeler classify themselves as formula_14, whereas Weinberg (1972) is formula_15, Peebles (1980) and Efstathiou (1990) are formula_16 while Peacock (1994), Rindler (1977), Atwater (1974), Collins Martin & Squires (1989) are formula_17.
p8853
aVAuthors including Einstein have used a different sign in their definition for the Ricci tensor which results in the sign of the constant on the right side being negative
p8854
aVformula_18
p8855
aVThe sign of the (very small) cosmological term would change in both these versions, if the +\u2212\u2212\u2212 metric sign convention is used rather than the MTW \u2212+++ metric sign convention adopted here.
p8856
aVEquivalent formulations.
p8857
aVTaking the trace of both sides of the EFE one gets
p8858
aVformula_19
p8859
aVwhere formula_20 is the spacetime dimension. This expression can be rewritten as
p8860
aVformula_21
p8861
aVIf one adds formula_22 times this to the EFE, one gets the following equivalent "trace-reversed" form
p8862
aVformula_23
p8863
aVFor example, in formula_24 dimensions this reduces to
p8864
aVformula_25
p8865
aVReversing the trace again would restore the original EFE. The trace-reversed form may be more convenient in some cases (for example, when one is interested in weak-field limit and can replace formula_26 in the expression on the right with the Minkowski metric without significant loss of accuracy).
p8866
aVThe cosmological constant.
p8867
aVEinstein modified his original field equations to include a cosmological constant term formula_27 proportional to the metric
p8868
aVformula_28
p8869
aVSince formula_27 is constant, the energy conservation law is unaffected.
p8870
aVThe cosmological constant term was originally introduced by Einstein to allow for a universe that is not expanding or contracting. This effort was unsuccessful because:
p8871
aVSo, Einstein abandoned formula_27, calling it the "biggest blunder ever made".
p8872
aVDespite Einstein's motivation for introducing the cosmological constant term, there is nothing inconsistent with the presence of such a term in the equations. For many years the cosmological constant was almost universally considered to be 0.
p8873
aVHowever, recent improved astronomical techniques have found that a positive value of formula_27 is needed to explain the accelerating universe.
p8874
aVEinstein thought of the cosmological constant as an independent parameter, but its term in the field equation can also be moved algebraically to the other side, written as part of the stress\u2013energy tensor:
p8875
aVformula_32
p8876
aVThe resulting vacuum energy is constant and given by
p8877
aVformula_33
p8878
aVThe existence of a cosmological constant is thus equivalent to the existence of a non-zero vacuum energy. Thus, the terms "cosmological constant" and "vacuum energy" are now used interchangeably in general relativity.
p8879
aVFeatures.
p8880
aVConservation of energy and momentum.
p8881
aVGeneral relativity is consistent with the local conservation of energy and momentum expressed as
p8882
aVformula_34.
p8883
aVwhich expresses the local conservation of stress\u2013energy. This conservation law is a physical requirement. With his field equations Einstein ensured that general relativity is consistent with this conservation condition.
p8884
aVNonlinearity.
p8885
aVThe nonlinearity of the EFE distinguishes general relativity from many other fundamental physical theories. For example, Maxwell's equations of electromagnetism are linear in the electric and magnetic fields, and charge and current distributions (i.e. the sum of two solutions is also a solution); another example is Schrödinger's equation of quantum mechanics which is linear in the wavefunction.
p8886
aVThe correspondence principle.
p8887
aVThe EFE reduce to Newton's law of gravity by using both the weak-field approximation and the slow-motion approximation. In fact, the constant "G" appearing in the EFE is determined by making these two approximations.
p8888
aVVacuum field equations.
p8889
aVIf the energy-momentum tensor formula_35 is zero in the region under consideration, then the field equations are also referred to as the vacuum field equations. By setting formula_36 in the trace-reversed field equations, the vacuum equations can be written as
p8890
aVformula_37
p8891
aVIn the case of nonzero cosmological constant, the equations are
p8892
aVformula_38
p8893
aVThe solutions to the vacuum field equations are called vacuum solutions. Flat Minkowski space is the simplest example of a vacuum solution. Nontrivial examples include the Schwarzschild solution and the Kerr solution.
p8894
aVManifolds with a vanishing Ricci tensor, formula_39, are referred to as Ricci-flat manifolds and manifolds with a Ricci tensor proportional to the metric as Einstein manifolds.
p8895
aVEinstein\u2013Maxwell equations.
p8896
aVIf the energy-momentum tensor formula_35 is that of an electromagnetic field in free space, i.e. if the electromagnetic stress\u2013energy tensor
p8897
aVformula_41
p8898
aVis used, then the Einstein field equations are called the "Einstein\u2013Maxwell equations" (with cosmological constant \u039b, taken to be zero in conventional relativity theory):
p8899
aVformula_42
p8900
aVAdditionally, the covariant Maxwell Equations are also applicable in free space:
p8901
aVformula_43
p8902
aVformula_44
p8903
aVwhere the semicolon represents a covariant derivative, and the brackets denote anti-symmetrization. The first equation asserts that the 4-divergence of the two-form "F" is zero, and the second that its exterior derivative is zero. From the latter, it follows by the Poincaré lemma that in a coordinate chart it is possible to introduce an electromagnetic field potential "A"\u03b1 such that
p8904
aVformula_45
p8905
aVin which the comma denotes a partial derivative. This is often taken as equivalent to the covariant Maxwell equation from which it is derived. However, there are global solutions of the equation which may lack a globally defined potential.
p8906
aVSolutions.
p8907
aVThe solutions of the Einstein field equations are metrics of spacetime. These metrics describe the structure of the spacetime including the inertial motion of objects in the spacetime. As the field equations are non-linear, they cannot always be completely solved (i.e. without making approximations). For example, there is no known complete solution for a spacetime with two massive bodies in it (which is a theoretical model of a binary star system, for example). However, approximations are usually made in these cases. These are commonly referred to as post-Newtonian approximations. Even so, there are numerous cases where the field equations have been solved completely, and those are called exact solutions.
p8908
aVThe study of exact solutions of Einstein's field equations is one of the activities of cosmology. It leads to the prediction of black holes and to different models of evolution of the universe.
p8909
aVOne can also discover new solutions of the Einstein field equations via the method of orthonormal frames as pioneered by Ellis and MacCallum. In this approach, the Einstein field equations are reduced to a set of coupled, nonlinear, ordinary differential equations. As discussed by Hsu and Wainwright, self-similar solutions to the Einstein field equations are fixed points of the resulting dynamical system. New solutions have been discovered using these methods by LeBlanc and Kohli and Haslam.
p8910
aVThe linearised EFE.
p8911
aVThe nonlinearity of the EFE makes finding exact solutions difficult. One way of solving the field equations is to make an approximation, namely, that far from the source(s) of gravitating matter, the gravitational field is very weak and the spacetime approximates that of Minkowski space. The metric is then written as the sum of the Minkowski metric and a term representing the deviation of the true metric from the Minkowski metric, with terms that are quadratic in or higher powers of the deviation being ignored. This linearisation procedure can be used to investigate the phenomena of gravitational radiation.
p8912
aVPolynomial form.
p8913
aVOne might think that EFE are non-polynomial since they contain the inverse of the metric tensor. However, the equations can be arranged so that they contain only the metric tensor and not its inverse. First, the determinant of the metric in 4 dimensions can be written:
p8914
aVformula_46
p8915
aVusing the Levi-Civita symbol; and the inverse of the metric in 4 dimensions can be written as:
p8916
aVformula_47
p8917
aVSubstituting this definition of the inverse of the metric into the equations then multiplying both sides by det("g") until there are none left in the denominator results in polynomial equations in the metric tensor and its first and second derivatives. The action from which the equations are derived can also be written in polynomial form by suitable redefinitions of the fields.
p8918
aVReferences.
p8919
aVSee General relativity resources.
p8920
asS'Whitney embedding theorem'
p8921
(lp8922
VIn mathematics, particularly in differential topology, there are two Whitney embedding theorems, named after Hassler Whitney:
p8923
aVA little about the proof.
p8924
aVThe general outline of the proof is to start with an immersion with transverse self-intersections. These are known to exist from Whitney's earlier work on the weak immersion theorem. Transversality of the double points follows from a general-position argument. The idea is to then somehow remove all the self-intersections. If has boundary, one can remove the self-intersections simply by isotoping into itself (the isotopy being in the domain of ), to a submanifold of that does not contain the double-points. Thus, we are quickly led to the case where has no boundary. Sometimes it is impossible to remove the double-points via an isotopy\u2014consider for example the figure-8 immersion of the circle in the plane. In this case, one needs to introduce a local double point. Once one has two opposite double points, one constructs a closed loop connecting the two, giving a closed path in . Since is simply connected, one can assume this path bounds a disc, and provided one can further assume (by the weak Whitney embedding theorem) that the disc is embedded in such that it intersects the image of only in its boundary. Whitney then uses the disc to create a 1-parameter family of immersions, in effect pushing across the disc, removing the two double points in the process. In the case of the figure-8 immersion with its introduced double-point, the push across move is quite simple (pictured). This process of eliminating opposite sign double-points by pushing the manifold along a disc is called the Whitney Trick.
p8925
aVTo introduce a local double point, Whitney created a family of immersions which are approximately linear outside of the unit ball, but containing a single double point. For such an immersion is defined as
p8926
aVformula_1
p8927
aVNotice that if is considered as a map to i.e.:
p8928
aVformula_2
p8929
aVthen the double point can be resolved to an embedding:
p8930
aVformula_3
p8931
aVNotice and for then as a function of , is an embedding. Define
p8932
aVformula_4
p8933
aVformula_5
p8934
aVwhere
p8935
aVformula_6
p8936
aVThe key properties of is that it is an embedding except for the double-point . Moreover, for large, it is approximately the linear embedding .
p8937
aVEventual consequences of the Whitney trick.
p8938
aVThe Whitney trick was used by Steve Smale to prove the "h"-cobordism theorem; from which follows the Poincaré conjecture in dimensions , and the classification of smooth structures on discs (also in dimensions 5 and up). This provides the foundation for surgery theory, which classifies manifolds in dimension 5 and above.
p8939
aVGiven two oriented submanifolds of complementary dimensions in a simply connected manifold of dimension \u2265 5, one can apply an isotopy to one of the submanifolds so that all the points of intersection have the same sign.
p8940
aVHistory.
p8941
aVThe occasion of the proof by Hassler Whitney of the embedding theorem for smooth manifolds is said (rather surprisingly) to have been the first complete exposition of the "manifold concept" precisely because it brought together and unified the differing concepts of manifolds at the time: no longer was there any confusion as to whether abstract manifolds, intrinsically defined via charts, were any more or less general than manifold extrinsically defined as submanifolds of Euclidean space. See also the history of manifolds and varieties for context.
p8942
aVSharper results.
p8943
aVAlthough every -manifold embeds in , one can frequently do better. Let denote the smallest integer so that all compact connected -manifolds embed in . Whitney's strong embedding theorem states that . For we have , as the circle and the Klein bottle show. More generally, for we have , as the -dimensional real projective space show. Whitney's result can be improved to unless is a power of 2. This is a result of Haefliger\u2013Hirsch () and C.T.C. Wall (); these authors used important preliminary results and particular cases proved by M. Hirsch, W. Massey, S. Novikov and V. Rokhlin. At present the function is not known in closed-form for all integers (compare to the Whitney immersion theorem, where the analogous number is known).
p8944
aVRestrictions on manifolds.
p8945
aVOne can strengthen the results by putting additional restrictions on the manifold. For example, the -sphere always embeds in  \u2013 which is the best possible (closed -manifolds cannot embed in ). Any compact "orientable" surface and any compact surface "with non-empty boundary" embeds in , though any "closed non-orientable" surface needs .
p8946
aVIf is a compact orientable -dimensional manifold, then embeds in (for not a power of 2 the orientability condition is superfluous). For a power of 2 this is a result of A. Haefliger\u2013M. Hirsch () and F. Fang (); these authors used important preliminary results proved by J. Bo'echat-A. Haefliger, S. Donaldson, M. Hirsch and W. Massey. Haefliger proved that if is a compact -dimensional -connected manifold, then embeds in provided .
p8947
aVIsotopy versions.
p8948
aVA relatively 'easy' result is to prove that any two embeddings of a 1-manifold into R4 are isotopic. This is proved using general position, which also allows to show that any two embeddings of an -manifold into are isotopic. This result is an isotopy version of the weak Whitney embedding theorem.
p8949
aVWu proved that for , any two embeddings of an -manifold into are isotopic. This result is an isotopy version of the strong Whitney embedding theorem.
p8950
aVAs an isotopy version of his embedding result, Haefliger proved that if is a compact -dimensional -connected manifold, then any two embeddings of into are isotopic provided . The dimension restriction is sharp: Haefliger went on to give examples of non-trivially embedded 3-spheres in (and, more generally, -spheres in ). See further generalizations.
p8951
asS'Degree (mathematics)'
p8952
(lp8953
sS'0.999...'
p8954
(lp8955
VIn mathematics, the repeating decimal 0.999... (sometimes written with more or fewer 9s before the final ellipsis, for example as 0.9..., or in a variety of other variants such as 0.9, 0.(9), or ) denotes a real number that can be shown to be the number "one". In other words, the symbols "0.999..." and "1" represent the same number. Proofs of this equality have been formulated with varying degrees of mathematical rigor, taking into account preferred development of the real numbers, background assumptions, historical context, and target audience.
p8956
aVEvery nonzero, terminating decimal (with infinitely many trailing 0s) has an equal twin representation with infinitely many trailing 9s (for example, 8.32 and 8.31999...). The terminating decimal representation is usually preferred, contributing to the misconception that it is the only representation. The same phenomenon occurs in all other bases (with a given base's largest digit) or in any similar representation of the real numbers.
p8957
aVThe equality of 0.999... and 1 is closely related to the absence of nonzero infinitesimals in the real number system, the most commonly used system in mathematical analysis. Some alternative number systems, such as the hyperreals, do contain nonzero infinitesimals. In most such number systems, the standard interpretation of the expression 0.999... makes it equal to 1, but in some of these number systems, the symbol "0.999..." admits other interpretations that contain infinitely many 9s while falling infinitesimally short of 1.
p8958
aVThe equality 0.999... = 1 has long been accepted by mathematicians and is part of general mathematical education. Nonetheless, some students find it sufficiently counterintuitive that they question or reject it. Such skepticism is common enough that the difficulty of convincing them of the validity of this identity has been the subject of several studies in mathematics education.
p8959
aVAlgebraic proofs.
p8960
aVAlgebraic proofs showing that 0.999... represents the number 1 use concepts such as fractions, long division, and digit manipulation to build transformations preserving equality from 0.999... to 1. However, these proofs are not entirely rigorous as they don't include a careful analytic definition of 0.999...
p8961
aVFractions and long division.
p8962
aVOne reason that infinite decimals are a necessary extension of finite decimals is to represent fractions. Using long division, a simple division of integers like becomes a recurring decimal, 0.111..., in which the digits repeat without end. This decimal yields a quick proof for . Multiplication of 9 times 1 produces 9 in each digit, so equals 0.999... and equals 1, so :
p8963
aVformula_1
p8964
aVThis result is consistent with other ninth fractions, all of which have repeating decimals, such as 3/9 and 8/9. If 0.999... is to be consistent, it must equal 9/9 = 1.
p8965
aVformula_2
p8966
aVDigit manipulation.
p8967
aVWhen a number in decimal notation is multiplied by 10, the digits do not change but each digit moves one place to the left. Thus 10 × 0.999... equals 9.999..., which is 9 greater than the original number. To see this, consider that in subtracting 0.999... from 9.999..., each of the digits after the decimal separator cancels, i.e. the result is 9 \u2212 9 = 0 for each such digit. The final step uses algebra:
p8968
aVformula_3
p8969
aVDiscussion.
p8970
aVAlthough these proofs demonstrate that 0.999... = 1, the extent to which they "explain" the equation depends on the audience. In introductory arithmetic, such proofs help explain why 0.999... = 1 but 0.333... < 0.34. In introductory algebra, the proofs help explain why the general method of converting between fractions and repeating decimals works. But the proofs shed little light on the fundamental relationship between decimals and the numbers they represent, which underlies the question of how two different decimals can be said to be equal at all.
p8971
aVOnce a representation scheme is defined, it can be used to justify the rules of decimal arithmetic used in the above proofs. Moreover, one can directly demonstrate that the decimals 0.999... and 1.000... both represent the same real number; it is built into the definition. This is done below.
p8972
aVAnalytic proofs.
p8973
aVSince the question of 0.999... does not affect the formal development of mathematics, it can be postponed until one proves the standard theorems of real analysis. One requirement is to characterize real numbers that can be written in decimal notation, consisting of an optional sign, a finite sequence of any number of digits forming an integer part, a decimal separator, and a sequence of digits forming a fractional part. For the purpose of discussing 0.999..., the integer part can be summarized as "b"0 and one can neglect negatives, so a decimal expansion has the form
p8974
aVformula_4
p8975
aVIt should be noted that the fraction part, unlike the integer part, is not limited to a finite number of digits. This is a positional notation, so for example the digit 5 in 500 contributes ten times as much as the 5 in 50, and the 5 in 0.05 contributes one tenth as much as the 5 in 0.5.
p8976
aVInfinite series and sequences.
p8977
aVPerhaps the most common development of decimal expansions is to define them as sums of infinite series. In general:
p8978
aVformula_5
p8979
aVFor 0.999... one can apply the convergence theorem concerning geometric series:
p8980
aVIf formula_6 then formula_7
p8981
aVSince 0.999... is such a sum with a common ratio r = , the theorem makes short work of the question:
p8982
aVformula_8
p8983
aVThis proof (actually, that 10 equals 9.999...) appears as early as 1770 in Leonhard Euler's "Elements of Algebra".
p8984
aVThe sum of a geometric series is itself a result even older than Euler. A typical 18th-century derivation used a term-by-term manipulation similar to the algebraic proof given above, and as late as 1811, Bonnycastle's textbook "An Introduction to Algebra" uses such an argument for geometric series to justify the same maneuver on 0.999... A 19th-century reaction against such liberal summation methods resulted in the definition that still dominates today: the sum of a series is "defined" to be the limit of the sequence of its partial sums. A corresponding proof of the theorem explicitly computes that sequence; it can be found in any proof-based introduction to calculus or analysis.
p8985
aVA sequence ("x"0, "x"1, "x"2, ...) has a limit "x" if the distance |"x" \u2212 "x""n"| becomes arbitrarily small as "n" increases. The statement that 0.999... = 1 can itself be interpreted and proven as a limit:
p8986
aVformula_9
p8987
aVThe last step, that \u2192 0 as "n" \u2192 \u221e, is often justified by the Archimedean property of the real numbers. This limit-based attitude towards 0.999... is often put in more evocative but less precise terms. For example, the 1846 textbook "The University Arithmetic" explains, ".999 +, continued to infinity = 1, because every annexation of a 9 brings the value closer to 1"; the 1895 "Arithmetic for Schools" says, "...when a large number of 9s is taken, the difference between 1 and .99999... becomes inconceivably small". Such heuristics are often interpreted by students as implying that 0.999... itself is less than 1.
p8988
aVNested intervals and least upper bounds.
p8989
aVThe series definition above is a simple way to define the real number named by a decimal expansion. A complementary approach is tailored to the opposite process: for a given real number, define the decimal expansion(s) to name it.
p8990
aVIf a real number "x" is known to lie in the closed interval 10 (i.e., it is greater than or equal to 0 and less than or equal to 10), one can imagine dividing that interval into ten pieces that overlap only at their endpoints: 1, 2, 3, and so on up to 10. The number "x" must belong to one of these; if it belongs to 3 then one records the digit "2" and subdivides that interval into 2.1, 2.2, ..., 2.9, 3. Continuing this process yields an infinite sequence of nested intervals, labeled by an infinite sequence of digits "b"0, "b"1, "b"2, "b"3, ..., and one writes
p8991
aVformula_10
p8992
aVIn this formalism, the identities 1 = 0.999... and 1 = 1.000... reflect, respectively, the fact that 1 lies in both 1 and 2, so one can choose either subinterval when finding its digits. To ensure that this notation does not abuse the "=" sign, one needs a way to reconstruct a unique real number for each decimal. This can be done with limits, but other constructions continue with the ordering theme.
p8993
aVOne straightforward choice is the nested intervals theorem, which guarantees that given a sequence of nested, closed intervals whose lengths become arbitrarily small, the intervals contain exactly one real number in their intersection. So "b"0."b"1"b"2"b"3... is defined to be the unique number contained within all the intervals ["b"0, "b"0 + 1], ["b"0."b"1, "b"0."b"1 + 0.1], and so on. 0.999... is then the unique real number that lies in all of the intervals 1, 1, 1, and 1 for every finite string of 9s. Since 1 is an element of each of these intervals, 0.999... = 1.
p8994
aVThe Nested Intervals Theorem is usually founded upon a more fundamental characteristic of the real numbers: the existence of least upper bounds or "suprema". To directly exploit these objects, one may define "b"0."b"1"b"2"b"3... to be the least upper bound of the set of approximants {"b"0, "b"0."b"1, "b"0."b"1"b"2, ...}. One can then show that this definition (or the nested intervals definition) is consistent with the subdivision procedure, implying 0.999... = 1 again. Tom Apostol concludes,
p8995
aVThe fact that a real number might have two different decimal representations is merely a reflection of the fact that two different sets of real numbers can have the same supremum.
p8996
aVProofs from the construction of the real numbers.
p8997
aVSome approaches explicitly define real numbers to be certain structures built upon the rational numbers, using axiomatic set theory. The natural numbers \u2013 0, 1, 2, 3, and so on \u2013 begin with 0 and continue upwards, so that every number has a successor. One can extend the natural numbers with their negatives to give all the integers, and to further extend to ratios, giving the rational numbers. These number systems are accompanied by the arithmetic of addition, subtraction, multiplication, and division. More subtly, they include ordering, so that one number can be compared to another and found to be less than, greater than, or equal to another number.
p8998
aVThe step from rationals to reals is a major extension. There are at least two popular ways to achieve this step, both published in 1872: Dedekind cuts and Cauchy sequences. Proofs that 0.999... = 1 which directly use these constructions are not found in textbooks on real analysis, where the modern trend for the last few decades has been to use an axiomatic analysis. Even when a construction is offered, it is usually applied towards proving the axioms of the real numbers, which then support the above proofs. However, several authors express the idea that starting with a construction is more logically appropriate, and the resulting proofs are more self-contained.
p8999
aVDedekind cuts.
p9000
aVIn the Dedekind cut approach, each real number "x" is defined as the "'infinite set of all rational numbers less than "x"'". In particular, the real number 1 is the set of all rational numbers that are less than 1. Every positive decimal expansion easily determines a Dedekind cut: the set of rational numbers which are less than some stage of the expansion. So the real number 0.999... is the set of rational numbers "r" such that "r" < 0, or "r" < 0.9, or "r" < 0.99, or "r" is less than some other number of the form
p9001
aVformula_11
p9002
aVEvery element of 0.999... is less than 1, so it is an element of the real number 1. Conversely, an element of 1 is a rational number
p9003
aVformula_12
p9004
aVwhich implies
p9005
aVformula_13
p9006
aVSince 0.999... and 1 contain the same rational numbers, they are the same set: 0.999... = 1.
p9007
aVThe definition of real numbers as Dedekind cuts was first published by Richard Dedekind in 1872.
p9008
aVThe above approach to assigning a real number to each decimal expansion is due to an expository paper titled "Is 0.999 ... = 1?" by Fred Richman in "Mathematics Magazine", which is targeted at teachers of collegiate mathematics, especially at the junior/senior level, and their students. Richman notes that taking Dedekind cuts in any dense subset of the rational numbers yields the same results; in particular, he uses decimal fractions, for which the proof is more immediate. He also notes that typically the definitions allow
p9009
aVCauchy sequences.
p9010
aVAnother approach is to define a real number as the limit of a Cauchy sequence of rational numbers. This construction of the real numbers uses the ordering of rationals less directly. First, the distance between "x" and "y" is defined as the absolute value |"x" \u2212 "y"|, where the absolute value |"z"| is defined as the maximum of "z" and \u2212"z", thus never negative. Then the reals are defined to be the sequences of rationals that have the Cauchy sequence property using this distance. That is, in the sequence ("x"0, "x"1, "x"2, ...), a mapping from natural numbers to rationals, for any positive rational \u03b4 there is an "N" such that |"x""m" \u2212 "x""n"| \u2264 \u03b4 for all "m", "n" > "N". (The distance between terms becomes smaller than any positive rational.)
p9011
aVIf ("x""n") and ("y""n") are two Cauchy sequences, then they are defined to be equal as real numbers if the sequence ("x""n" \u2212 "y""n") has the limit 0. Truncations of the decimal number "b"0."b"1"b"2"b"3... generate a sequence of rationals which is Cauchy; this is taken to define the real value of the number. Thus in this formalism the task is to show that the sequence of rational numbers
p9012
aVformula_14
p9013
aVhas the limit 0. Considering the "n"th term of the sequence, for "n"=0,1,2..., it must therefore be shown that
p9014
aVformula_15
p9015
aVThis limit is plain if one understands the definition of limit. So again 0.999... = 1.
p9016
aVThe definition of real numbers as Cauchy sequences was first published separately by Eduard Heine and Georg Cantor, also in 1872. The above approach to decimal expansions, including the proof that 0.999... = 1, closely follows Griffiths & Hilton's 1970 work "A comprehensive textbook of classical mathematics: A contemporary interpretation". The book is written specifically to offer a second look at familiar concepts in a contemporary light.
p9017
aVInfinite decimal representation.
p9018
aVCommonly in secondary schools' mathematics education, the real numbers are constructed by defining a number using an integer followed by a radix point and an infinite sequence written out as a string to represent the fractional part of any given real number. In this construction, the set of any combination of integers and digits after the decimal point (or radix point in non-base 10 systems) are the set of real numbers. This construction can too be rigorously shown to satisfy all of the real axioms after defining an equivalence relation over the set that defines 1 =eq 0.999... as well as for any other nonzero decimals with only finitely many nonzero terms in the decimal string with its trailing 9s version. With this construction of the reals, all proofs of the statement 1 = .999... can be viewed as implicitly assuming the equality when any operations are performed on the real numbers.
p9019
aVGeneralizations.
p9020
aVThe result that 0.999... = 1 generalizes readily in two ways. First, every nonzero number with a finite decimal notation (equivalently, endless trailing 0s) has a counterpart with trailing 9s. For example, 0.24999... equals 0.25, exactly as in the special case considered. These numbers are exactly the decimal fractions, and they are dense.
p9021
aVSecond, a comparable theorem applies in each radix or base. For example, in base 2 (the binary numeral system) 0.111... equals 1, and in base 3 (the ternary numeral system) 0.222... equals 1. Textbooks of real analysis are likely to skip the example of 0.999... and present one or both of these generalizations from the start.
p9022
aVAlternative representations of 1 also occur in non-integer bases. For example, in the golden ratio base, the two standard representations are 1.000... and 0.101010..., and there are infinitely many more representations that include adjacent 1s. Generally, for almost all "q" between 1 and 2, there are uncountably many base-"q" expansions of 1. On the other hand, there are still uncountably many "q" (including all natural numbers greater than 1) for which there is only one base-"q" expansion of 1, other than the trivial 1.000... This result was first obtained by Paul Erd\u0151s, Miklos Horváth, and István Joó around 1990. In 1998 Vilmos Komornik and Paola Loreti determined the smallest such base, the Komornik\u2013Loreti constant "q" = 1.787231650... In this base, 1 = 0.11010011001011010010110011010011...; the digits are given by the Thue\u2013Morse sequence, which does not repeat.
p9023
aVA more far-reaching generalization addresses the most general positional numeral systems. They too have multiple representations, and in some sense the difficulties are even worse. For example:
p9024
aVImpossibility of unique representation.
p9025
aVThat all these different number systems suffer from multiple representations for some real numbers can be attributed to a fundamental difference between the real numbers as an ordered set and collections of infinite strings of symbols, ordered lexicographically. Indeed the following two properties account for the difficulty:
p9026
aVThe first point follows from basic properties of the real numbers: "L" has a supremum and "R" has an infimum, which are easily seen to be equal; being a real number it either lies in "R" or in "L", but not both since "L" and "R" are supposed to be disjoint. The second point generalizes the 0.999.../1.000... pair obtained for "p"1 = "0", "p"2 = "1". In fact one need not use the same alphabet for all positions (so that for instance mixed radix systems can be included) or consider the full collection of possible strings; the only important points are that at each position a finite set of symbols (which may even depend on the previous symbols) can be chosen from (this is needed to ensure maximal and minimal choices), and that making a valid choice for any position should result in a valid infinite string (so one should not allow "9" in each position while forbidding an infinite succession of "9"s). Under these assumptions, the above argument shows that an order preserving map from the collection of strings to an interval of the real numbers cannot be a bijection: either some numbers do not correspond to any string, or some of them correspond to more than one string.
p9027
aVMarko Petkov\u0161ek has proven that for any positional system that names all the real numbers, the set of reals with multiple representations is always dense. He calls the proof "an instructive exercise in elementary point-set topology"; it involves viewing sets of positional values as Stone spaces and noticing that their real representations are given by continuous functions.
p9028
aVApplications.
p9029
aVOne application of 0.999... as a representation of 1 occurs in elementary number theory. In 1802, H. Goodwin published an observation on the appearance of 9s in the repeating-decimal representations of fractions whose denominators are certain prime numbers. Examples include:
p9030
aVE. Midy proved a general result about such fractions, now called "Midy's theorem", in 1836. The publication was obscure, and it is unclear if his proof directly involved 0.999..., but at least one modern proof by W. G. Leavitt does. If it can be proved that a decimal of the form 0."b"1"b"2"b"3... is a positive integer, then it must be 0.999..., which is then the source of the 9s in the theorem. Investigations in this direction can motivate such concepts as greatest common divisors, modular arithmetic, Fermat primes, order of group elements, and quadratic reciprocity.
p9031
aVReturning to real analysis, the base-3 analogue 0.222... = 1 plays a key role in a characterization of one of the simplest fractals, the middle-thirds Cantor set:
p9032
aVThe "n"th digit of the representation reflects the position of the point in the "n"th stage of the construction. For example, the point 2\u20443 is given the usual representation of 0.2 or 0.2000..., since it lies to the right of the first deletion and to the left of every deletion thereafter. The point 1\u20443 is represented not as 0.1 but as 0.0222..., since it lies to the left of the first deletion and to the right of every deletion thereafter.
p9033
aVRepeating nines also turn up in yet another of Georg Cantor's works. They must be taken into account to construct a valid proof, applying his 1891 diagonal argument to decimal expansions, of the uncountability of the unit interval. Such a proof needs to be able to declare certain pairs of real numbers to be different based on their decimal expansions, so one needs to avoid pairs like 0.2 and 0.1999... A simple method represents all numbers with nonterminating expansions; the opposite method rules out repeating nines. A variant that may be closer to Cantor's original argument actually uses base 2, and by turning base-3 expansions into base-2 expansions, one can prove the uncountability of the Cantor set as well.
p9034
aVSkepticism in education.
p9035
aVStudents of mathematics often reject the equality of 0.999... and 1, for reasons ranging from their disparate appearance to deep misgivings over the limit concept and disagreements over the nature of infinitesimals. There are many common contributing factors to the confusion:
p9036
aVThese ideas are mistaken in the context of the standard real numbers, although some may be valid in other number systems, either invented for their general mathematical utility or as instructive counterexamples to better understand 0.999...
p9037
aVMany of these explanations were found by David Tall, who has studied characteristics of teaching and cognition that lead to some of the misunderstandings he has encountered in his college students. Interviewing his students to determine why the vast majority initially rejected the equality, he found that "students continued to conceive of 0.999... as a sequence of numbers getting closer and closer to 1 and not a fixed value, because 'you haven't specified how many places there are' or 'it is the nearest possible decimal below 1'".
p9038
aVOf the elementary proofs, multiplying 0.333... = 1\u20443 by 3 is apparently a successful strategy for convincing reluctant students that 0.999... = 1. Still, when confronted with the conflict between their belief of the first equation and their disbelief of the second, some students either begin to disbelieve the first equation or simply become frustrated. Nor are more sophisticated methods foolproof: students who are fully capable of applying rigorous definitions may still fall back on intuitive images when they are surprised by a result in advanced mathematics, including 0.999... For example, one real analysis student was able to prove that 0.333... = 1\u20443 using a supremum definition, but then insisted that 0.999... < 1 based on her earlier understanding of long division. Others still are able to prove that 1\u20443 = 0.333..., but, upon being confronted by the fractional proof, insist that "logic" supersedes the mathematical calculations.
p9039
aVJoseph Mazur tells the tale of an otherwise brilliant calculus student of his who "challenged almost everything I said in class but never questioned his calculator," and who had come to believe that nine digits are all one needs to do mathematics, including calculating the square root of 23. The student remained uncomfortable with a limiting argument that 9.99... = 10, calling it a "wildly imagined infinite growing process."
p9040
aVAs part of Ed Dubinsky's APOS theory of mathematical learning, he and his collaborators (2005) propose that students who conceive of 0.999... as a finite, indeterminate string with an infinitely small distance from 1 have "not yet constructed a complete process conception of the infinite decimal". Other students who have a complete process conception of 0.999... may not yet be able to "encapsulate" that process into an "object conception", like the object conception they have of 1, and so they view the process 0.999... and the object 1 as incompatible. Dubinsky "et al." also link this mental ability of encapsulation to viewing 1\u20443 as a number in its own right and to dealing with the set of natural numbers as a whole.
p9041
aVIn popular culture.
p9042
aVWith the rise of the Internet, debates about 0.999... have escaped the classroom and are commonplace on newsgroups and message boards, including many that nominally have little to do with mathematics. In the newsgroup , arguing over 0.999... is described as a "popular sport", and it is one of the questions answered in its FAQ. The FAQ briefly covers 1\u20443, multiplication by 10, and limits, and it alludes to Cauchy sequences as well.
p9043
aVA 2003 edition of the general-interest newspaper column "The Straight Dope" discusses 0.999... via 1\u20443 and limits, saying of misconceptions,
p9044
aVThe lower primate in us still resists, saying: .999~ doesn't really represent a "number", then, but a "process". To find a number we have to halt the process, at which point the .999~ = 1 thing falls apart.
p9045
aVNonsense.
p9046
aV"The Straight Dope" cites a discussion on its own message board that grew out of an unidentified "other message board ... mostly about video games". In the same vein, the question of 0.999... proved such a popular topic in the first seven years of Blizzard Entertainment's Battle.net forums that the company issued a "press release" on April Fools' Day 2004 that it is 1:
p9047
aVWe are very excited to close the book on this subject once and for all. We've witnessed the heartache and concern over whether .999~ does or does not equal 1, and we're proud that the following proof finally and conclusively addresses the issue for our customers.
p9048
aVTwo proofs are then offered, based on limits and multiplication by 10.
p9049
aV0.999... features also in mathematical folklore, specifically in the following joke:
p9050
aVQ: How many mathematicians does it take to screw in a lightbulb?
p9051
aVA: 0.999999...
p9052
aVIn alternative number systems.
p9053
aVAlthough the real numbers form an extremely useful number system, the decision to interpret the notation "0.999..." as naming a real number is ultimately a convention, and Timothy Gowers argues in "Mathematics: A Very Short Introduction" that the resulting identity 0.999... = 1 is a convention as well:
p9054
aVHowever, it is by no means an arbitrary convention, because not adopting it forces one either to invent strange new objects or to abandon some of the familiar rules of arithmetic.
p9055
aVOne can define other number systems using different rules or new objects; in some such number systems, the above proofs would need to be reinterpreted and one might find that, in a given number system, 0.999... and 1 might not be identical. However, many number systems are extensions of \u2014rather than independent alternatives to\u2014 the real number system, so 0.999... = 1 continues to hold. Even in such number systems, though, it is worthwhile to examine alternative number systems, not only for how 0.999... behaves (if, indeed, a number expressed as "0.999..." is both meaningful and unambiguous), but also for the behavior of related phenomena. If such phenomena differ from those in the real number system, then at least one of the assumptions built into the system must break down.
p9056
aVInfinitesimals.
p9057
aVSome proofs that 0.999... = 1 rely on the Archimedean property of the real numbers: that there are no nonzero infinitesimals. Specifically, the difference 1 \u2212 0.999... must be smaller than any positive rational number, so it must be an infinitesimal; but since the reals do not contain nonzero infinitesimals, the difference is therefore zero, and therefore the two values are the same.
p9058
aVHowever, there are mathematically coherent ordered algebraic structures, including various alternatives to the real numbers, which are non-Archimedean. Non-standard analysis provides a number system with a full array of infinitesimals (and their inverses). A. H. Lightstone developed a decimal expansion for hyperreal numbers in (0, 1)\u2217. Lightstone shows how to associate to each number a sequence of digits,
p9059
aVformula_16
p9060
aVindexed by the hypernatural numbers. While he does not directly discuss 0.999..., he shows the real number 1/3 is represented by 0.333...;...333... which is a consequence of the transfer principle. As a consequence the number 0.999...;...999... = 1. With this type of decimal representation, not every expansion represents a number. In particular "0.333...;...000..." and "0.999...;...000..." do not correspond to any number.
p9061
aVThe standard definition of the number 0.999... is the limit of the sequence 0.9, 0.99, 0.999, ... A different definition involves what Terry Tao refers to as "ultralimit", i.e., the equivalence class [(0.9, 0.99, 0.999, ...)] of this sequence in the ultrapower construction, which is a number that falls short of 1 by an infinitesimal amount. More generally, the hyperreal number with last digit 9 at infinite hypernatural rank "H", satisfies a strict inequality Accordingly, an alternative interpretation for "zero followed by infinitely many 9s" could be
p9062
aVformula_17
p9063
aVAll such interpretations of "0.999..." are infinitely close to 1. Ian Stewart characterizes this interpretation as an "entirely reasonable" way to rigorously justify the intuition that "there's a little bit missing" from 1 in 0.999... Along with Katz & Katz, Robert Ely also questions the assumption that students' ideas about are erroneous intuitions about the real numbers, interpreting them rather as "nonstandard" intuitions that could be valuable in the learning of calculus.
p9064
aVJose Benardete in his book "Infinity: An essay in metaphysics" argues that some natural pre-mathematical intuitions cannot be expressed if one is limited to an overly restrictive number system:
p9065
aVThe intelligibility of the continuum has been found\u2014many times over\u2014to require that the domain of real numbers be enlarged to include infinitesimals. This enlarged domain may be styled the domain of continuum numbers. It will now be evident that .9999... does not equal 1 but falls infinitesimally short of it. I think that .9999... should indeed be admitted as a "number" ... though not as a "real" number.
p9066
aVHackenbush.
p9067
aVCombinatorial game theory provides alternative reals as well, with infinite Blue-Red Hackenbush as one particularly relevant example. In 1974, Elwyn Berlekamp described a correspondence between Hackenbush strings and binary expansions of real numbers, motivated by the idea of data compression. For example, the value of the Hackenbush string LRRLRLRL... is 0.0101012... = 1/3. However, the value of LRLLL... (corresponding to 0.111...2) is infinitesimally less than 1. The difference between the two is the surreal number 1/\u03c9, where \u03c9 is the first infinite ordinal; the relevant game is LRRRR... or 0.000...2.
p9068
aVThis is in fact true of the binary expansions of many rational numbers, where the values of the numbers are equal but the corresponding binary tree paths are different. For example, 0.10111...2 = 0.11000...2, which are both equal to , but the first representation corresponds to the binary tree path LRLRLLL... while the second corresponds to the different path LRLLRRR...
p9069
aVRevisiting subtraction.
p9070
aVAnother manner in which the proofs might be undermined is if 1 \u2212 0.999... simply does not exist, because subtraction is not always possible. Mathematical structures with an addition operation but not a subtraction operation include commutative semigroups, commutative monoids and semirings. Richman considers two such systems, designed so that 0.999... < 1.
p9071
aVFirst, Richman defines a nonnegative "decimal number" to be a literal decimal expansion. He defines the lexicographical order and an addition operation, noting that 0.999... < 1 simply because 0 < 1 in the ones place, but for any nonterminating "x", one has 0.999... + "x" = 1 + "x". So one peculiarity of the decimal numbers is that addition cannot always be cancelled; another is that no decimal number corresponds to 1\u20443. After defining multiplication, the decimal numbers form a positive, totally ordered, commutative semiring.
p9072
aVIn the process of defining multiplication, Richman also defines another system he calls "cut "D"", which is the set of Dedekind cuts of decimal fractions. Ordinarily this definition leads to the real numbers, but for a decimal fraction "d" he allows both the cut (\u2212\u221e, "d" ) and the "principal cut" (\u2212\u221e, "d" ). The result is that the real numbers are "living uneasily together with" the decimal fractions. Again 0.999... < 1. There are no positive infinitesimals in cut "D", but there is "a sort of negative infinitesimal," 0\u2212, which has no decimal expansion. He concludes that 0.999... = 1 + 0\u2212, while the equation "0.999... + "x" = 1"
p9073
aVhas no solution.
p9074
aV"p"-adic numbers.
p9075
aVWhen asked about 0.999..., novices often believe there should be a "final 9," believing 1 \u2212 0.999... to be a positive number which they write as "0.000...1". Whether or not that makes sense, the intuitive goal is clear: adding a 1 to the final 9 in 0.999... would carry all the 9s into 0s and leave a 1 in the ones place. Among other reasons, this idea fails because there is no "final 9" in 0.999... However, there is a system that contains an infinite string of 9s including a last 9.
p9076
aVThe "p"-adic numbers are an alternative number system of interest in number theory. Like the real numbers, the "p"-adic numbers can be built from the rational numbers via Cauchy sequences; the construction uses a different metric in which 0 is closer to "p", and much closer to "pn", than it is to 1. The "p"-adic numbers form a field for prime "p" and a ring for other "p", including 10. So arithmetic can be performed in the "p"-adics, and there are no infinitesimals.
p9077
aVIn the 10-adic numbers, the analogues of decimal expansions run to the left. The 10-adic expansion ...999 does have a last 9, and it does not have a first 9. One can add 1 to the ones place, and it leaves behind only 0s after carrying through: 1 + ...999 = ...000 = 0, and so ...999 = \u22121. Another derivation uses a geometric series. The infinite series implied by "...999" does not converge in the real numbers, but it converges in the 10-adics, and so one can re-use the familiar formula:
p9078
aVformula_18
p9079
aV(Compare with the series above.) A third derivation was invented by a seventh-grader who was doubtful over her teacher's limiting argument that 0.999... = 1 but was inspired to take the multiply-by-10 proof above in the opposite direction: if "x" = ...999 then 10"x" =  ...990, so 10"x" = "x" \u2212 9, hence "x" = \u22121 again.
p9080
aVAs a final extension, since 0.999... = 1 (in the reals) and ...999 = \u22121 (in the 10-adics), then by "blind faith and unabashed juggling of symbols" one may add the two equations and arrive at ...999.999... = 0. This equation does not make sense either as a 10-adic expansion or an ordinary decimal expansion, but it turns out to be meaningful and true if one develops a theory of "double-decimals" with eventually repeating left ends to represent a familiar system: the real numbers.
p9081
asS'Rounding'
p9082
(lp9083
VRounding a numerical value means replacing it by another value that is approximately equal but has a shorter, simpler, or more explicit representation; for example, replacing £23.4476 with £23.45, or the fraction 312/937 with 1/3, or the expression \u221a2 with 1.414.
p9084
aVRounding is often done to obtain a value that is easier to report and communicate than the original. Rounding can also be important to avoid misleadingly precise reporting of a computed number, measurement or estimate; for example, a quantity that was computed as 123,456 but is known to be accurate only to within a few hundred units is better stated as "about 123,500."
p9085
aVOn the other hand, rounding of exact numbers will introduce some round-off error in the reported result. Rounding is almost unavoidable when reporting many computations \u2014 especially when dividing two numbers in integer or fixed-point arithmetic; when computing mathematical functions such as square roots, logarithms, and sines; or when using a floating point representation with a fixed number of significant digits. In a sequence of calculations, these rounding errors generally accumulate, and in certain ill-conditioned cases they may make the result meaningless.
p9086
aVAccurate rounding of transcendental mathematical functions is difficult because the number of extra digits that need to be calculated to resolve whether to round up or down cannot be known in advance. This problem is known as "the table-maker's dilemma".
p9087
aVRounding has many similarities to the quantization that occurs when physical quantities must be encoded by numbers or digital signals.
p9088
aVA wavy equals sign (\u2248) is sometimes used to indicate rounding of exact numbers. For example: 9.98 \u2248 10.
p9089
aVTypes of rounding.
p9090
aVTypical rounding problems are:
p9091
aVRounding to a specified increment.
p9092
aVThe most common type of rounding is to round to an integer; or, more generally, to an integer multiple of some increment \u2014 such as rounding to whole tenths of seconds, hundredths of a dollar, to whole multiples of 1/2 or 1/8 inch, to whole dozens or thousands, etc.
p9093
aVIn general, rounding a number "x" to a multiple of some specified increment "m" entails the following steps:
p9094
aV: formula_1
p9095
aVFor example, rounding "x" = 2.1784 dollars to whole cents (i.e., to a multiple of 0.01) entails computing "y" = "x"/"m" = 2.1784/0.01 = 217.84, then rounding "y" to the integer "q" = 218, and finally computing "z" = "q"×"m" = 218×0.01 = 2.18.
p9096
aVWhen rounding to a predetermined number of significant digits, the increment "m" depends on the magnitude of the number to be rounded (or of the rounded result).
p9097
aVThe increment "m" is normally a finite fraction in whatever number system that is used to represent the numbers. For display to humans, that usually means the decimal number system (that is, "m" is an integer times a power of 10, like 1/1000 or 25/100). For intermediate values stored in digital computers, it often means the binary number system ("m" is an integer times a power of 2).
p9098
aVThe abstract single-argument "round()" function that returns an integer from an arbitrary real value has at least a dozen distinct concrete definitions presented in the rounding to integer section. The abstract two-argument "round()" function is formally defined here, but in many cases it is used with the implicit value "m" = 1 for the increment and then reduces to the equivalent abstract single-argument function, with also the same dozen distinct concrete definitions.
p9099
aVRounding to integer.
p9100
aVThe most basic form of rounding is to replace an arbitrary number by an integer. All the following rounding modes are concrete implementations of the abstract single-argument "round()" function presented and used in the previous sections.
p9101
aVThere are many ways of rounding a number "y" to an integer "q". The most common ones are
p9102
aVThe first four methods are called directed rounding, as the displacements from the original number "y" to the rounded value "q" are all directed towards or away from the same limiting value (0, +\u221e, or \u2212\u221e).
p9103
aVIf "y" is positive, round-down is the same as round-towards-zero, and round-up is the same as round-away-from-zero. If "y" is negative, round-down is the same as round-away-from-zero, and round-up is the same as round-towards-zero. In any case, if "y" is integer, "q" is just "y".
p9104
aVWhere many calculations are done in sequence, the choice of rounding method can have a very significant effect on the result. A famous instance involved a new index set up by the Vancouver Stock Exchange in 1982. It was initially set at 1000.000 (three decimal places of accuracy), and after 22 months had fallen to about 520 \u2014 whereas stock prices had generally increased in the period. The problem was caused by the index being recalculated thousands of times daily, and always being rounded down to 3 decimal places, in such a way that the rounding errors accumulated. Recalculating with better rounding gave an index value of 1098.892 at the end of the same period.
p9105
aVTie-breaking.
p9106
aVRounding a number "y" to the nearest integer requires some tie-breaking rule for those cases when "y" is exactly half-way between two integers \u2014 that is, when the fraction part of "y" is exactly 0.5.
p9107
aVRound half down.
p9108
aVOne may also use round half down (or round half towards negative infinity) as opposed to the more common "round half up".
p9109
aVFor example, 23.5 gets rounded to 23, and \u221223.5 gets rounded to \u221224.
p9110
aVThe "round half down" tie-breaking rule is not symmetric, as the fractions that are exactly 0.5 always get rounded down. This asymmetry introduces a negative bias in the roundoff errors. For example, if the fraction of "y" consists of three random decimal digits, then the expected value of "q" will be 0.0005 lower than the expected value of "y". For this reason, round-to-nearest with the "round half down" rule is also (ambiguously) known as asymmetric rounding.
p9111
aVRound half up.
p9112
aVThe following tie-breaking rule, called round half up (or round half towards positive infinity), is widely used in many disciplines. That is, half-way values "y" are always rounded up.
p9113
aVFor example, by this rule the value 23.5 gets rounded to 24, but \u221223.5 gets rounded to \u221223.
p9114
aVHowever, some programming languages (such as Java) define "HALF_UP" as "round half away from zero".
p9115
aVIf it were not for the 0.5 fractions, the round-off errors introduced by the round to nearest method would be symmetric: for every fraction that gets rounded up (such as 0.268), there is a complementary fraction (namely, 0.732) that gets rounded down by the same amount. When rounding a large set of numbers with random fractional parts, these rounding errors would statistically compensate each other, and the expected (average) value of the rounded numbers would be equal to the expected value of the original numbers.
p9116
aVHowever, the "round half up" tie-breaking rule is not symmetric, as the fractions that are exactly 0.5 always get rounded up. This asymmetry introduces a positive bias in the round-off errors. For example, if the fraction of "y" consists of three random decimal digits, then the expected value of "q" will be 0.0005 higher than the expected value of "y". For this reason, round-to-nearest with the "round half up" rule is also (ambiguously) known as asymmetric rounding.
p9117
aVOne reason for rounding up at 0.5 is that for positive decimals, only the first figure after the decimal point needs be examined. For example, when looking at 17.5000\u2026, the "5" alone determines that the number should be rounded up, to 18 in this case. This is not true for negative decimals, such as \u221217.5000\u2026, where all the fractional figures of the value need to be examined to determine if it should round to \u221217, if it were \u221217.5000000, or to \u221218, if it were \u221217.5000001 or smaller.
p9118
aVRound half towards zero.
p9119
aVOne may also round half towards zero (or round half away from infinity) as opposed to the conventional "round half away from zero".
p9120
aVFor example, 23.5 gets rounded to 23, and \u221223.5 gets rounded to \u221223.
p9121
aVThis method also treats positive and negative values symmetrically, and therefore is free of overall bias if the original numbers are positive or negative with equal probability.
p9122
aVRound half away from zero.
p9123
aVThe other tie-breaking method commonly taught and used is the round half away from zero (or round half towards infinity), namely:
p9124
aVFor example, 23.5 gets rounded to 24, and \u221223.5 gets rounded to \u221224.
p9125
aVThis method treats positive and negative values symmetrically, and therefore is free of overall bias if the original numbers are positive or negative with equal probability.
p9126
aVIt is often used for currency conversions and price roundings (when the amount is first converted into the smallest significant subdivision of the currency, such as cents of a euro) as it is easy to explain by just considering the first fractional digit, independently of supplementary precision digits or sign of the amount (for strict equivalence between the paying and recipient of the amount).
p9127
aVRound half to even.
p9128
aVA tie-breaking rule that is less biased is round half to even, namely:
p9129
aVThus, for example, +23.5 becomes +24, as does +24.5; while \u221223.5 becomes \u221224, as does \u221224.5.
p9130
aVThis method treats positive and negative values symmetrically, and is therefore free of sign bias. More importantly, for reasonable distributions of "y" values, the expected (average) value of the rounded numbers is the same as that of the original numbers. However, this rule will introduce a towards-zero bias when is even, and a towards-infinity bias for when it is odd.
p9131
aVThis variant of the round-to-nearest method is also called unbiased rounding, convergent rounding, statistician's rounding, Dutch rounding, Gaussian rounding, odd-even rounding, bankers' rounding, or broken rounding.
p9132
aVThis is the default rounding mode used in IEEE 754 computing functions and operators.
p9133
aVRound half to odd.
p9134
aVA similar tie-breaking rule is round half to odd'":
p9135
aVThus, for example, +23.5 becomes +23, as does +22.5; while \u221223.5 becomes \u221223, as does \u221222.5.
p9136
aVThis method also treats positive and negative values symmetrically, and is therefore free of sign bias. More importantly, for reasonable distributions of "y" values, the expected (average) value of the rounded numbers is the same as that of the original numbers. However, this rule will introduce a towards-zero bias when is odd, and a towards-infinity bias for when it is even.
p9137
aVThis variant is almost never used in computations, except in situations where one wants to avoid rounding 0.5 or \u22120.5 to zero; or to avoid increasing the scale of floating point numbers, which have a limited exponent range. With "round half to even", a non "infinite" number would round to infinity, and a small "denormal" value would round to a normal non-zero value. 
p9138
aVEffectively, this mode prefers preserving the existing scale of tie numbers, avoiding out of range results when possible for even based number systems (such as binary and decimal).
p9139
aVStochastic rounding.
p9140
aVAnother unbiased tie-breaking method is stochastic rounding:
p9141
aVLike round-half-to-even, this rule is essentially free of overall bias; but it is also fair among even and odd "q" values. On the other hand, it introduces a random component into the result; performing the same computation twice on the same data may yield two different results. Also, it is open to nonconscious bias if humans (rather than computers or devices of chance) are "randomly" deciding in which direction to round.
p9142
aVAlternating tie-breaking.
p9143
aVOne method, more obscure than most, is round half alternatingly.
p9144
aVThis suppresses the random component of the result, if occurrences of 0.5 fractional parts can be effectively numbered. But it can still introduce a positive or negative bias according to the direction of rounding assigned to the first occurrence, if the total number of occurrences is odd.
p9145
aVDithering and error diffusion.
p9146
aVWhen digitising continuous signals, for example images or sound, the overall effect of a number of measurements is more important than the accuracy of each individual measurement. In these circumstances dithering, and a related technique, error diffusion, are normally used. A related technique called pulse-width modulation is used to achieve analogue type output from an inertial device by rapidly pulsing the power with a variable duty cycle.
p9147
aVError diffusion tries to ensure the error on average is minimized. When dealing with a gentle slope from one to zero the output would be zero for the first few terms until the sum of the error and the current value becomes greater than 0.5, in which case a 1 is output and the difference subtracted from the error so far. Floyd\u2013Steinberg dithering is a popular error diffusion procedure when digitising images.
p9148
aVRounding to simple fractions.
p9149
aVIn some contexts it is desirable to round a given number "x" to a "neat" fraction \u2014 that is, the nearest fraction "z" = "m"/"n" whose numerator "m" and denominator "n" do not exceed a given maximum. This problem is fairly distinct from that of rounding a value to a fixed number of decimal or binary digits, or to a multiple of a given unit "m". This problem is related to Farey sequences, the Stern\u2013Brocot tree, and continued fractions.
p9150
aVScaled rounding.
p9151
aVThis type of rounding, which is also named rounding to a logarithmic scale, is a variant of Rounding to a specified increment. Rounding on a logarithmic scale is accomplished by taking the log of the amount and doing normal rounding to the nearest value on the log scale.
p9152
aVFor example resistors are supplied with preferred numbers on a logarithmic scale. For example for resistors with 10% accuracy they are supplied with nominal values 100, 121, 147, 178, 215 etc. If a calculation indicates a resistor of 165 ohms is required then log(147)=2.167, log(165)=2.217 and log(178)=2.250. The logarithm of 165 is closer to the logarithm of 178 therefore a 178 ohm resistor would be the first choice if there are no other considerations.
p9153
aVRound to available value.
p9154
aVFinished lumber, writing paper, capacitors, and many other products are usually sold in only a few standard sizes.
p9155
aVMany design procedures describe how to calculate an approximate value, and then "round" to some standard size using phrases such as "round down to nearest standard value", "round up to nearest standard value", or "round to nearest standard value".
p9156
aVWhen a set of preferred values is equally spaced on a logarithmic scale, choosing the closest preferred value to any given value can be seen as a kind of scaled rounding. Such "rounded" values can be directly calculated.
p9157
aVFloating-point rounding.
p9158
aVIn floating-point arithmetic, rounding aims to turn a given value "x" into a value "z" with a specified number of "significant" digits. In other words, "z" should be a multiple of a number "m" that depends on the magnitude of "x". The number "m" is a power of the base (usually 2 or 10) of the floating-point representation.
p9159
aVApart from this detail, all the variants of rounding discussed above apply to the rounding of floating-point numbers as well. The algorithm for such rounding is presented in the Scaled rounding section above, but with a constant scaling factor "s"=1, and an integer base "b">1.
p9160
aVFor results where the rounded result would overflow the result for a directed rounding is either the appropriate signed infinity, or the highest representable positive finite number (or the lowest representable negative finite number if "x" is negative), depending on the direction of rounding. The result of an overflow for the usual case of "round to nearest" is always the appropriate infinity.
p9161
aVDouble rounding.
p9162
aVRounding a number twice in succession to different precisions, with the latter precision being coarser, is not guaranteed to give the same result as rounding once to the final precision except in the case of directed rounding. For instance rounding 9.46 to one decimal gives 9.5, and then 10 when rounding to integer using rounding half to even, but would give 9 when rounded to integer directly.
p9163
aVIn "Martinez v. Allstate" and "Sendejo v. Farmers", litigated between 1995 and 1997, the insurance companies argued that double rounding premiums was permissible and in fact required. The US courts ruled against the insurance companies and ordered them to adopt rules to ensure single rounding.
p9164
aVSome computer languages and the IEEE 754-2008 standard dictate that in straightforward calculations the result should not be rounded twice. This has been a particular problem with Java as it is designed to be run identically on different machines, special programming tricks have had to be used to achieve this with x87 floating point.
p9165
aVThe Java language was changed to allow different results where the difference does not matter and require a strictfp qualifier to be used when the results have to conform accurately.
p9166
aVExact computation with rounded arithmetic.
p9167
aVIt is possible to use rounded arithmetic to evaluate the exact value of a function with a discrete domain and range. For example, if we know that an integer "n" is a perfect square, we can compute its square root by converting "n" to a floating-point value "x", computing the approximate square root "y" of "x" with floating point, and then rounding "y" to the nearest integer "q". If "n" is not too big, the floating-point roundoff error in "y" will be less than 0.5, so the rounded value "q" will be the exact square root of "n". In most modern computers, this method may be much faster than computing the square root of "n" by an all-integer algorithm.
p9168
aVTable-maker's dilemma.
p9169
aVWilliam Kahan coined the term "The Table-Maker's Dilemma" for the unknown cost of rounding transcendental functions:
p9170
aV"Nobody knows how much it would cost to compute y^w correctly rounded for "every" two floating-point arguments at which it does not over/underflow. Instead, reputable math libraries compute elementary transcendental functions mostly within slightly more than half an ulp and almost always well within one ulp. Why can't y^w be rounded within half an ulp like SQRT? Because nobody knows how much computation it would cost... No general way exists to predict how many extra digits will have to be carried to compute a transcendental expression and round it "correctly" to some preassigned number of digits. Even the fact (if true) that a finite number of extra digits will ultimately suffice may be a deep theorem."
p9171
aVThe IEEE floating point standard guarantees that add, subtract, multiply, divide, fused multiply\u2013add, square root, and floating point remainder will give the correctly rounded result of the infinite precision operation. No such guarantee was given in the 1985 standard for more complex functions and they are typically only accurate to within the last bit at best. However, the 2008 standard guarantees that conforming implementations will give correctly rounded results which respect the active rounding mode; implementation of the functions, however, is optional.
p9172
aVUsing the Gelfond\u2013Schneider theorem and Lindemann\u2013Weierstrass theorem many of the standard elementary functions can be proved to return transcendental results when given rational non-zero arguments; therefore it is always possible to correctly round such functions. However, determining a limit for a given precision on how accurate results need to be computed, before a correctly rounded result can be guaranteed, may demand a lot of computation time.
p9173
aVSome packages offer correct rounding. The GNU MPFR package gives correctly rounded arbitrary precision results. Some other libraries implement elementary functions with correct rounding in double precision:
p9174
aVThere exist computable numbers which a rounded value can never be determined no matter how many digits are calculated. Specific instances cannot be given but this follows from the undecidability of the halting problem. For instance, if Goldbach's conjecture is true but unprovable, then the result of rounding the following value up to the next integer cannot be determined: 10\u2212n where n is the first even number greater than 4 which is not the sum of two primes, or 0 if there is no such number. The result is 1 if such a number exists and 0 if no such number exists. The value before rounding can however be approximated to any given precision even if the conjecture is unprovable.
p9175
aVHistory.
p9176
aVThe concept of rounding is very old, perhaps older even than the concept of division. Some ancient clay tablets found in Mesopotamia contain tables with rounded values of reciprocals and square roots in base 60.
p9177
aVRounded approximations to \u03c0, the length of the year, and the length of the month are also ancient\u2014see base 60#Examples.
p9178
aVThe "Round-to-even" method has served as the ASTM (E-29) standard since 1940. The origin of the terms "unbiased rounding" and "statistician's rounding" are fairly self-explanatory. In the 1906 4th edition of "Probability and Theory of Errors" Robert Simpson Woodward called this "the computer's rule" indicating that it was then in common use by human computers who calculated mathematical tables. Churchill Eisenhart indicated the practice was already "well established" in data analysis by the 1940s.
p9179
aVThe origin of the term "bankers' rounding" remains more obscure. If this rounding method was ever a standard in banking, the evidence has proved extremely difficult to find. To the contrary, section 2 of the European Commission report "The Introduction of the Euro and the Rounding of Currency Amounts" suggests that there had previously been no standard approach to rounding in banking; and it specifies that "half-way" amounts should be rounded up.
p9180
aVUntil the 1980s, the rounding method used in floating-point computer arithmetic was usually fixed by the hardware, poorly documented, inconsistent, and different for each brand and model of computer. This situation changed after the IEEE 754 floating point standard was adopted by most computer manufacturers. The standard allows the user to choose among several rounding modes, and in each case specifies precisely how the results should be rounded. These features made numerical computations more predictable and machine-independent, and made possible the efficient and consistent implementation of interval arithmetic.
p9181
aVRounding functions in programming languages.
p9182
aVMost programming languages provide functions or special syntax to round fractional numbers in various ways. The earliest numeric languages, such as FORTRAN and C, would provide only one method, usually truncation (towards zero). This default method could be implied in certain contexts, such as when assigning a fractional number to an integer variable, or using a fractional number as an index of an array. Other kinds of rounding had to be programmed explicitly; for example, rounding a positive number to the nearest integer could be implemented by adding 0.5 and truncating.
p9183
aVIn the last decades, however, the syntax and/or the standard libraries of most languages have commonly provided at least the four basic rounding functions (up, down, to nearest, and towards zero). The tie-breaking method may vary depending the language and version, and/or may be selectable by the programmer. Several languages follow the lead of the IEEE-754 floating-point standard, and define these functions as taking a double precision float argument and returning the result of the same type, which then may be converted to an integer if necessary. This approach may avoid spurious overflows since floating-point types have a larger range than integer types. Some languages, such as PHP, provide functions that round a value to a specified number of decimal digits, e.g. from 4321.5678 to 4321.57 or 4300. In addition, many languages provide a printf or similar string formatting function, which allows one to convert a fractional number to a string, rounded to a user-specified number of decimal places (the "precision"). On the other hand, truncation (round to zero) is still the default rounding method used by many languages, especially for the division of two integer values.
p9184
aVOn the opposite, CSS and SVG do not define any specific maximum precision for numbers and measurements, that are treated and exposed in their DOM and in their IDL interface as strings as if they had infinite precision, and do not discriminate between integers and floating point values; however, the implementations of these languages will typically convert these numbers into IEEE-754 double floating points before exposing the computed digits with a limited precision (notably within standard JavaScript or ECMAScript interface bindings).
p9185
aVOther rounding standards.
p9186
aVSome disciplines or institutions have issued standards or directives for rounding.
p9187
aVU.S. Weather Observations.
p9188
aVIn a guideline issued in mid-1966, the U.S. Office of the Federal Coordinator for Meteorology determined that weather data should be rounded to the nearest round number, with the "round half up" tie-breaking rule. For example, 1.5 rounded to integer should become 2, and \u22121.5 should become \u22121. Prior to that date, the tie-breaking rule was "round half away from zero".
p9189
aVNegative zero in meteorology.
p9190
aVSome meteorologists may write "\u22120" to indicate a temperature between 0.0 and \u22120.5 degrees (exclusive) that was rounded to integer. This notation is used when the negative sign is considered important, no matter how small is the magnitude; for example, when rounding temperatures in the Celsius scale, where below zero indicates freezing.
p9191
asVGödel's incompleteness theorems
p9192
(lp9193
VGödel's incompleteness theorems are two theorems of mathematical logic that establish inherent limitations of all but the most trivial axiomatic systems capable of doing arithmetic. The theorems, proven by Kurt Gödel in 1931, are important both in mathematical logic and in the philosophy of mathematics. The two results are widely, but not universally, interpreted as showing that Hilbert's program to find a complete and consistent set of axioms for all mathematics is impossible, giving a negative answer to Hilbert's second problem.
p9194
aVThe first incompleteness theorem states that no consistent system of axioms whose theorems can be listed by an "effective procedure" (e.g., a computer program, but it could be any sort of algorithm) is capable of proving all truths about the relations of the natural numbers (arithmetic). For any such system, there will always be statements about the natural numbers that are true, but that are unprovable within the system. The second incompleteness theorem, an extension of the first, shows that such a system cannot demonstrate its own consistency.
p9195
aVBackground.
p9196
aVBecause statements of a formal theory are written in symbolic form, it is possible to verify mechanically that a formal proof from a finite set of axioms is valid. This task, known as automatic proof verification, is closely related to automated theorem proving. The difference is that instead of constructing a new proof, the proof verifier simply checks that a provided formal proof (or, in instructions that can be followed to create a formal proof) is correct. This process is not merely hypothetical; systems such as Isabelle and Coq are used today to formalize proofs and then check their validity.
p9197
aVMany theories of interest include an infinite set of axioms, however. To verify a formal proof when the set of axioms is infinite, it must be possible to determine whether a statement that is claimed to be an axiom is actually an axiom. This issue arises in first order theories of arithmetic, such as Peano arithmetic, because the principle of mathematical induction is expressed as an infinite set of axioms (an axiom schema).
p9198
aVA formal theory is said to be "effectively generated" if its set of axioms is a recursively enumerable set. This means that there is a computer program that, in principle, could enumerate all the axioms of the theory without listing any statements that are not axioms. This is equivalent to the existence of a program that enumerates all the theorems of the theory without enumerating any statements that are not theorems. Examples of effectively generated theories with infinite sets of axioms include Peano arithmetic and Zermelo\u2013Fraenkel set theory.
p9199
aVIn choosing a set of axioms, one goal is to be able to prove as many correct results as possible, without proving any incorrect results. A set of axioms is complete if, for any statement in the axioms' language, either that statement or its negation is provable from the axioms. A set of axioms is (simply) consistent if there is no statement such that both the statement and its negation are provable from the axioms. In the standard system of first-order logic, an inconsistent set of axioms will prove every statement in its language (this is sometimes called the principle of explosion), and is thus automatically complete. A set of axioms that is both complete and consistent, however, proves a maximal set of non-contradictory theorems. Gödel's incompleteness theorems show that in certain cases, it is not possible to obtain a theory that is effectively generated and complete and consistent.
p9200
aVFirst incompleteness theorem.
p9201
aVGödel's first incompleteness theorem first appeared as "Theorem VI" in Gödel's 1931 paper "On Formally Undecidable Propositions in Principia Mathematica and Related Systems I."
p9202
aVThe formal theorem is written in highly technical language. It may be stated in English as (the following is not a quote, but rather a précis):
p9203
aV Any effectively generated theory capable of expressing elementary arithmetic cannot be both consistent and complete. In particular, for any consistent, effectively generated formal theory that proves certain basic arithmetic truths, there is an arithmetical statement that is true, but not provable in the theory.
p9204
aVThe true but unprovable statement referred to by the theorem is often referred to as "the Gödel sentence" for the theory. The proof constructs a specific Gödel sentence for each consistent effectively generated theory, but there are infinitely many statements in the language of the theory that share the property of being true but unprovable. For example, the conjunction of the Gödel sentence and any logically valid sentence will have this property.
p9205
aVFor each consistent formal theory "T" having the required small amount of number theory, the corresponding Gödel sentence "G" asserts: ""G" cannot be proved within the theory "T"". This interpretation of "G" leads to the following informal analysis. If "G" were provable under the axioms and rules of inference of "T", then "T" would have a theorem, "G", which effectively contradicts itself, and thus the theory "T" would be inconsistent. This means that if the theory "T" is consistent then "G" cannot be proved within it, and so the theory "T" is incomplete. Moreover, the claim "G" makes about its own unprovability is correct. In this sense "G" is not only unprovable but true, and provability-within-the-theory-"T" is not the same as truth. This informal analysis can be formalized to make a rigorous proof of the incompleteness theorem, as described in the section "Proof sketch for the first theorem" below. The formal proof reveals exactly the hypotheses required for the theory "T" in order for the self-contradictory nature of "G" to lead to a genuine contradiction.
p9206
aVEach effectively generated theory has its own Gödel statement. It is possible to define a larger theory "T\u2019" that contains the whole of "T", plus "G" as an additional axiom. This will not result in a complete theory, because Gödel's theorem will also apply to "T\u2019", and thus "T\u2019" cannot be complete. In this case, "G" is indeed a theorem in "T\u2019", because it is an axiom. Since "G" states only that it is not provable in "T", no contradiction is presented by its provability in "T\u2019". However, because the incompleteness theorem applies to "T\u2019", there will be a new Gödel statement "G\u2019" for "T\u2019", showing that "T\u2019" is also incomplete. "G\u2019" will differ from "G" in that "G\u2019" will refer to "T\u2019", rather than "T".
p9207
aVTo prove the first incompleteness theorem, Gödel represented statements by numbers. Then the theory at hand, which is assumed to prove certain facts about numbers, also proves facts about its own statements, provided that it is effectively generated. Questions about the provability of statements are represented as questions about the properties of numbers, which would be decidable by the theory if it were complete. In these terms, the Gödel sentence states that no natural number exists with a certain, strange property. A number with this property would encode a proof of the inconsistency of the theory. If there were such a number then the theory would be inconsistent, contrary to the consistency hypothesis. So, under the assumption that the theory is consistent, there is no such number.
p9208
aVMeaning of the first incompleteness theorem.
p9209
aVGödel's first incompleteness theorem shows that any consistent effectively generated formal system that includes enough of the theory of the natural numbers is incomplete: there are true statements expressible in its language that are unprovable within the system. Thus no formal system (satisfying the hypotheses of the theorem) that aims to characterize the natural numbers can actually do so, as there will be true number-theoretical statements that that system cannot prove. This fact is sometimes thought to have severe consequences for the program of logicism proposed by Gottlob Frege and Bertrand Russell, which aimed to define the natural numbers in terms of logic (Hellman 1981, p. 451\u2013468). Bob Hale and Crispin Wright argue that it is not a problem for logicism because the incompleteness theorems apply equally to first order logic as they do to arithmetic. They argue that only those who believe that the natural numbers are to be defined in terms of first order logic have this problem.
p9210
aVThe existence of an incomplete formal system is, in itself, not particularly surprising. A system may be incomplete simply because not all the necessary axioms have been discovered. For example, Euclidean geometry without the parallel postulate is incomplete; it is not possible to prove or disprove the parallel postulate from the remaining axioms.
p9211
aVGödel's theorem shows that, in theories that include a small portion of number theory, a complete and consistent finite list of axioms can "never" be created: each time a new statement is added as an axiom, there are other true statements that still cannot be proved, even with the new axiom. If an axiom is ever added that makes the system complete, it does so at the cost of making the system inconsistent. It is not even possible for there to be an infinite list of axioms that is complete, consistent, and can be enumerated by a computer program.
p9212
aVThere "are" complete and consistent lists of axioms for arithmetic that "cannot" be enumerated by a computer program. For example, one might take all true statements about the natural numbers to be axioms (and no false statements), which gives the theory known as "true arithmetic". The difficulty is that there is no mechanical way to decide, given a statement about the natural numbers, whether it is an axiom of this theory, and thus there is no effective way to verify a formal proof in this theory.
p9213
aVMany logicians believe that Gödel's incompleteness theorems struck a fatal blow to David Hilbert's second problem, which asked for a finitary consistency proof for mathematics. The second incompleteness theorem, in particular, is often viewed as making the problem impossible. Not all mathematicians agree with this analysis, however, and the status of Hilbert's second problem is not yet decided (see "Modern viewpoints on the status of the problem").
p9214
aVRelation to the liar paradox.
p9215
aVThe liar paradox is the sentence "This sentence is false." An analysis of the liar sentence shows that it cannot be true (for then, as it asserts, it is false), nor can it be false (for then, it is true). A Gödel sentence "G" for a theory "T" makes a similar assertion to the liar sentence, but with truth replaced by provability: "G" says ""G" is not provable in the theory "T"." The analysis of the truth and provability of "G" is a formalized version of the analysis of the truth of the liar sentence.
p9216
aVIt is not possible to replace "not provable" with "false" in a Gödel sentence because the predicate "Q is the Gödel number of a false formula" cannot be represented as a formula of arithmetic. This result, known as Tarski's undefinability theorem, was discovered independently by Gödel (when he was working on the proof of the incompleteness theorem) and by Alfred Tarski.
p9217
aVExtensions of Gödel's original result.
p9218
aVGödel demonstrated the incompleteness of the theory of "Principia Mathematica", a particular theory of arithmetic, but a parallel demonstration could be given for any effective theory of a certain expressiveness. Gödel commented on this fact in the introduction to his paper, but restricted the proof to one system for concreteness. In modern statements of the theorem, it is common to state the effectiveness and expressiveness conditions as hypotheses for the incompleteness theorem, so that it is not limited to any particular formal theory. The terminology used to state these conditions was not yet developed in 1931 when Gödel published his results.
p9219
aVGödel's original statement and proof of the incompleteness theorem requires the assumption that the theory is not just consistent but "\u03c9-consistent". A theory is \u03c9-consistent if it is not \u03c9-inconsistent, and is \u03c9-inconsistent if there is a predicate "P" such that for every specific natural number "m" the theory proves ~"P"("m"), and yet the theory also proves that there exists a natural number "n" such that "P"("n"). That is, the theory says that a number with property "P" exists while denying that it has any specific value. The \u03c9-consistency of a theory implies its consistency, but consistency does not imply \u03c9-consistency. J. Barkley Rosser (1936) strengthened the incompleteness theorem by finding a variation of the proof (Rosser's trick) that only requires the theory to be consistent, rather than \u03c9-consistent. This is mostly of technical interest, since all true formal theories of arithmetic (theories whose axioms are all true statements about natural numbers) are \u03c9-consistent, and thus Gödel's theorem as originally stated applies to them. The stronger version of the incompleteness theorem that only assumes consistency, rather than \u03c9-consistency, is now commonly known as Gödel's incompleteness theorem and as the Gödel\u2013Rosser theorem.
p9220
aVSecond incompleteness theorem.
p9221
aVGödel's second incompleteness theorem first appeared as "Theorem XI" in Gödel's 1931 paper "On Formally Undecidable Propositions in Principia Mathematica and Related Systems I."
p9222
aVLike with the first incompleteness theorem, Gödel wrote this theorem in highly technical formal mathematics. It may be paraphrased in English as:
p9223
aV For any formal effectively generated theory "T" including basic arithmetical truths and also certain truths about formal provability, if "T" includes a statement of its own consistency then "T" is inconsistent.
p9224
aVThis strengthens the first incompleteness theorem, because the statement constructed in the first incompleteness theorem does not directly express the consistency of the theory. The proof of the second incompleteness theorem is obtained by formalizing the proof of the first incompleteness theorem within the theory itself.
p9225
aVA technical subtlety in the second incompleteness theorem is how to express the consistency of "T" as a formula in the language of "T". There are many ways to do this, and not all of them lead to the same result. In particular, different formalizations of the claim that "T" is consistent may be inequivalent in "T", and some may even be provable. For example, first-order Peano arithmetic (PA) can prove that the largest consistent subset of PA is consistent. But since PA is consistent, the largest consistent subset of PA is just PA, so in this sense PA "proves that it is consistent". What PA does not prove is that the largest consistent subset of PA is, in fact, the whole of PA. (The term "largest consistent subset of PA" is technically ambiguous, but what is meant here is the largest consistent initial segment of the axioms of PA ordered according to specific criteria; i.e., by "Gödel numbers", the numbers encoding the axioms as per the scheme used by Gödel mentioned above).
p9226
aVFor Peano arithmetic, or any familiar explicitly axiomatized theory "T", it is possible to canonically define a formula Con("T") expressing the consistency of "T"; this formula expresses the property that "there does not exist a natural number coding a sequence of formulas, such that each formula is either one of the axioms of "T", a logical axiom, or an immediate consequence of preceding formulas according to the rules of inference of first-order logic, and such that the last formula is a contradiction".
p9227
aVThe formalization of Con("T") depends on two factors: formalizing the notion of a sentence being derivable from a set of sentences and formalizing the notion of being an axiom of "T". Formalizing derivability can be done in canonical fashion: given an arithmetical formula A("x") defining a set of axioms, one can canonically form a predicate ProvA("P"), which expresses that a sentence "P" is provable from the set of axioms defined by A("x").
p9228
aVIn addition, the standard proof of the second incompleteness theorem assumes that ProvA("P") satisfies the Hilbert\u2013Bernays provability conditions. Letting #("P") represent the Gödel number of a formula "P", the derivability conditions say:
p9229
aVImplications for consistency proofs.
p9230
aVGödel's second incompleteness theorem also implies that a theory "T"1 satisfying the technical conditions outlined above cannot prove the consistency of any theory "T"2 that proves the consistency of "T"1. This is because such a theory "T"1 can prove that if "T"2 proves the consistency of "T"1, then "T"1 is in fact consistent. For the claim that "T"1 is consistent has form "for all numbers "n", "n" has the decidable property of not being a code for a proof of contradiction in "T"1". If "T"1 were in fact inconsistent, then "T"2 would prove for some "n" that "n" is the code of a contradiction in "T"1. But if "T"2 also proved that "T"1 is consistent (that is, that there is no such n), then it would itself be inconsistent. This reasoning can be formalized in "T"1 to show that if "T"2 is consistent, then "T"1 is consistent. Since, by second incompleteness theorem, "T"1 does not prove its consistency, it cannot prove the consistency of "T"2 either.
p9231
aVThis corollary of the second incompleteness theorem shows that there is no hope of proving, for example, the consistency of Peano arithmetic using any finitistic means that can be formalized in a theory the consistency of which is provable in Peano arithmetic. For example, the theory of primitive recursive arithmetic (PRA), which is widely accepted as an accurate formalization of finitistic mathematics, is provably consistent in PA. Thus PRA cannot prove the consistency of PA. This fact is generally seen to imply that Hilbert's program, which aimed to justify the use of "ideal" (infinitistic) mathematical principles in the proofs of "real" (finitistic) mathematical statements by giving a finitistic proof that the ideal principles are consistent, cannot be carried out.
p9232
aVThe corollary also indicates the epistemological relevance of the second incompleteness theorem. It would actually provide no interesting information if a theory "T" proved its consistency. This is because inconsistent theories prove everything, including their consistency. Thus a consistency proof of "T" in "T" would give us no clue as to whether "T" really is consistent; no doubts about the consistency of "T" would be resolved by such a consistency proof. The interest in consistency proofs lies in the possibility of proving the consistency of a theory "T" in some theory "T\u2019" that is in some sense less doubtful than "T" itself, for example weaker than "T". For many naturally occurring theories "T" and "T\u2019", such as "T" = Zermelo\u2013Fraenkel set theory and "T\u2019" = primitive recursive arithmetic, the consistency of "T\u2019" is provable in "T", and thus "T\u2019" can't prove the consistency of "T" by the above corollary of the second incompleteness theorem.
p9233
aVThe second incompleteness theorem does not rule out consistency proofs altogether, only consistency proofs that could be formalized in the theory that is proved consistent. For example, Gerhard Gentzen proved the consistency of Peano arithmetic (PA) in a different theory that includes an axiom asserting that the ordinal called \u03b50 is wellfounded; see Gentzen's consistency proof. Gentzen's theorem spurred the development of ordinal analysis in proof theory.
p9234
aVExamples of undecidable statements.
p9235
aVThere are two distinct senses of the word "undecidable" in mathematics and computer science. The first of these is the proof-theoretic sense used in relation to Gödel's theorems, that of a statement being neither provable nor refutable in a specified deductive system. The second sense, which will not be discussed here, is used in relation to computability theory and applies not to statements but to decision problems, which are countably infinite sets of questions each requiring a yes or no answer. Such a problem is said to be undecidable if there is no computable function that correctly answers every question in the problem set (see undecidable problem).
p9236
aVBecause of the two meanings of the word undecidable, the term independent is sometimes used instead of undecidable for the "neither provable nor refutable" sense. The usage of "independent" is also ambiguous, however. Some use it to mean just "not provable", leaving open whether an independent statement might be refuted.
p9237
aVUndecidability of a statement in a particular deductive system does not, in and of itself, address the question of whether the truth value of the statement is well-defined, or whether it can be determined by other means. Undecidability only implies that the particular deductive system being considered does not prove the truth or falsity of the statement. Whether there exist so-called "absolutely undecidable" statements, whose truth value can never be known or is ill-specified, is a controversial point in the philosophy of mathematics.
p9238
aVThe combined work of Gödel and Paul Cohen has given two concrete examples of undecidable statements (in the first sense of the term): The continuum hypothesis can neither be proved nor refuted in ZFC (the standard axiomatization of set theory), and the axiom of choice can neither be proved nor refuted in ZF (which is all the ZFC axioms "except" the axiom of choice). These results do not require the incompleteness theorem. Gödel proved in 1940 that neither of these statements could be disproved in ZF or ZFC set theory. In the 1960s, Cohen proved that neither is provable from ZF, and the continuum hypothesis cannot be proven from ZFC.
p9239
aVIn 1973, the Whitehead problem in group theory was shown to be undecidable, in the first sense of the term, in standard set theory.
p9240
aVGregory Chaitin produced undecidable statements in algorithmic information theory and proved another incompleteness theorem in that setting. Chaitin's incompleteness theorem states that for any theory that can represent enough arithmetic, there is an upper bound "c" such that no specific number can be proven in that theory to have Kolmogorov complexity greater than "c". While Gödel's theorem is related to the liar paradox, Chaitin's result is related to Berry's paradox.
p9241
aVUndecidable statements provable in larger systems.
p9242
aVThese are natural mathematical equivalents of the Gödel "true but undecidable" sentence. They can be proved in a larger system which is generally accepted as a valid form of reasoning, but are undecidable in a more limited system such as Peano Arithmetic.
p9243
aVIn 1977, Paris and Harrington proved that the Paris-Harrington principle, a version of the Ramsey theorem, is undecidable in the first-order axiomatization of arithmetic called Peano arithmetic, but can be proven in the larger system of second-order arithmetic. Kirby and Paris later showed Goodstein's theorem, a statement about sequences of natural numbers somewhat simpler than the Paris-Harrington principle, to be undecidable in Peano arithmetic.
p9244
aVKruskal's tree theorem, which has applications in computer science, is also undecidable from Peano arithmetic but provable in set theory. In fact Kruskal's tree theorem (or its finite form) is undecidable in a much stronger system codifying the principles acceptable based on a philosophy of mathematics called predicativism. The related but more general graph minor theorem (2003) has consequences for computational complexity theory.
p9245
aVLimitations of Gödel's theorems.
p9246
aVThe conclusions of Gödel's theorems are only proven for the formal theories that satisfy the necessary hypotheses. Not all axiom systems satisfy these hypotheses, even when these systems have models that include the natural numbers as a subset. For example, there are first-order axiomatizations of Euclidean geometry, of real closed fields, and of arithmetic in which multiplication is not "provably" total; none of these meet the hypotheses of Gödel's theorems. The key fact is that these axiomatizations are not expressive enough to define the set of natural numbers or develop basic properties of the natural numbers. Regarding the third example, Dan Willard (2001) has studied many weak systems of arithmetic which do not satisfy the hypotheses of the second incompleteness theorem, and which are consistent and capable of proving their own consistency (see self-verifying theories).
p9247
aVGödel's theorems only apply to effectively generated (that is, recursively enumerable) theories. If all true statements about natural numbers are taken as axioms for a theory, then this theory is a consistent, complete extension of Peano arithmetic (called true arithmetic) for which none of Gödel's theorems apply in a meaningful way, because this theory is not recursively enumerable.
p9248
aVThe second incompleteness theorem only shows that the consistency of certain theories cannot be proved from the axioms of those theories themselves. It does not show that the consistency cannot be proved from other (consistent) axioms. For example, the consistency of the Peano arithmetic can be proved in Zermelo\u2013Fraenkel set theory (ZFC), or in theories of arithmetic augmented with transfinite induction, as in Gentzen's consistency proof.
p9249
aVRelationship with computability.
p9250
aVThe incompleteness theorem is closely related to several results about undecidable sets in recursion theory.
p9251
aVStephen Cole Kleene (1943) presented a proof of Gödel's incompleteness theorem using basic results of computability theory. One such result shows that the halting problem is undecidable: there is no computer program that can correctly determine, given any program "P" as input, whether "P" eventually halts when run with a particular given input. Kleene showed that the existence of a complete effective theory of arithmetic with certain consistency properties would force the halting problem to be decidable, a contradiction. This method of proof has also been presented by Shoenfield (1967, p. 132); Charlesworth (1980); and Hopcroft and Ullman (1979).
p9252
aVFranzén (2005, p. 73) explains how Matiyasevich's solution to Hilbert's 10th problem can be used to obtain a proof to Gödel's first incompleteness theorem. Matiyasevich proved that there is no algorithm that, given a multivariate polynomial p(x1, x2...,xk) with integer coefficients, determines whether there is an integer solution to the equation "p" = 0. Because polynomials with integer coefficients, and integers themselves, are directly expressible in the language of arithmetic, if a multivariate integer polynomial equation "p" = 0 does have a solution in the integers then any sufficiently strong theory of arithmetic "T" will prove this. Moreover, if the theory "T" is \u03c9-consistent, then it will never prove that a particular polynomial equation has a solution when in fact there is no solution in the integers. Thus, if "T" were complete and \u03c9-consistent, it would be possible to determine algorithmically whether a polynomial equation has a solution by merely enumerating proofs of "T" until either ""p" has a solution" or ""p" has no solution" is found, in contradiction to Matiyasevich's theorem. Moreover, for each consistent effectively generated theory "T", it is possible to effectively generate a multivariate polynomial "p" over the integers such that the equation "p" = 0 has no solutions over the integers, but the lack of solutions cannot be proved in "T" (Davis 2006:416, Jones 1980).
p9253
aVSmorynski (1977, p. 842) shows how the existence of recursively inseparable sets can be used to prove the first incompleteness theorem. This proof is often extended to show that systems such as Peano arithmetic are essentially undecidable (see Kleene 1967, p. 274).
p9254
aVChaitin's incompleteness theorem gives a different method of producing independent sentences, based on Kolmogorov complexity. Like the proof presented by Kleene that was mentioned above, Chaitin's theorem only applies to theories with the additional property that all their axioms are true in the standard model of the natural numbers. Gödel's incompleteness theorem is distinguished by its applicability to consistent theories that nonetheless include statements that are false in the standard model; these theories are known as \u03c9-inconsistent.
p9255
aVProof sketch for the first theorem.
p9256
aVThe proof by contradiction has three essential parts. To begin, choose a formal system that meets the proposed criteria:
p9257
aVArithmetization of syntax.
p9258
aVThe main problem in fleshing out the proof described above is that it seems at first that to construct a statement "p" that is equivalent to ""p" cannot be proved", "p" would somehow have to contain a reference to "p", which could easily give rise to an infinite regress. Gödel's ingenious technique is to show that statements can be matched with numbers (often called the arithmetization of syntax) in such a way that "proving a statement" can be replaced with "testing whether a number has a given property". This allows a self-referential formula to be constructed in a way that avoids any infinite regress of definitions. The same technique was later used by Alan Turing in his work on the Entscheidungsproblem.
p9259
aVIn simple terms, a method can be devised so that every formula or statement that can be formulated in the system gets a unique number, called its Gödel number, in such a way that it is possible to mechanically convert back and forth between formulas and Gödel numbers. The numbers involved might be very long indeed (in terms of number of digits), but this is not a barrier; all that matters is that such numbers can be constructed. A simple example is the way in which English is stored as a sequence of numbers in computers using ASCII or Unicode:
p9260
aV* The word HELLO is represented by 72-69-76-76-79 using decimal ASCII, ie the number 7269767679.
p9261
aV* The logical statement x=y => y=x is represented by 120-061-121-032-061-062-032-121-061-120 using octal ASCII, ie the number 120061121032061062032121061120.
p9262
aVIn principle, proving a statement true or false can be shown to be equivalent to proving that the number matching the statement does or doesn't have a given property. Because the formal system is strong enough to support reasoning about "numbers in general", it can support reasoning about "numbers which represent formulae and statements" as well. Crucially, because the system can support reasoning about "properties of numbers", the results are equivalent to reasoning about "provability of their equivalent statements".
p9263
aVConstruction of a statement about "provability".
p9264
aVHaving shown that in principle the system can indirectly make statements about provability, by analyzing properties of those numbers representing statements it is now possible to show how to create a statement that actually does this.
p9265
aVA formula "F"("x") that contains exactly one free variable "x" is called a "statement form" or "class-sign". As soon as "x" is replaced by a specific number, the statement form turns into a "bona fide" statement, and it is then either provable in the system, or not. For certain formulas one can show that for every natural number n, F(n) is true if and only if it can be proven (the precise requirement in the original proof is weaker, but for the proof sketch this will suffice). In particular, this is true for every specific arithmetic operation between a finite number of natural numbers, such as "2×3=6".
p9266
aVStatement forms themselves are not statements and therefore cannot be proved or disproved. But every statement form "F"("x") can be assigned a Gödel number denoted by G("F"). The choice of the free variable used in the form "F"("x") is not relevant to the assignment of the Gödel number G("F").
p9267
aVNow comes the trick: The notion of provability itself can also be encoded by Gödel numbers, in the following way. Since a proof is a list of statements which obey certain rules, the Gödel number of a proof can be defined. Now, for every statement "p", one may ask whether a number "x" is the Gödel number of its proof. The relation between the Gödel number of "p" and "x", the potential Gödel number of its proof, is an arithmetical relation between two numbers. Therefore there is a statement form Bew("y") that uses this arithmetical relation to state that a Gödel number of a proof of "y" exists:
p9268
aVBew("y") = \u2203 "x" ( "y" is the Gödel number of a formula and "x" is the Gödel number of a proof of the formula encoded by "y").
p9269
aVThe name Bew is short for "beweisbar", the German word for "provable"; this name was originally used by Gödel to denote the provability formula just described. Note that "Bew("y")" is merely an abbreviation that represents a particular, very long, formula in the original language of "T"; the string "Bew" itself is not claimed to be part of this language.
p9270
aVAn important feature of the formula Bew("y") is that if a statement "p" is provable in the system then Bew(G("p")) is also provable. This is because any proof of "p" would have a corresponding Gödel number, the existence of which causes Bew(G("p")) to be satisfied.
p9271
aVDiagonalization.
p9272
aVThe next step in the proof is to obtain a statement that says it is unprovable. Although Gödel constructed this statement directly, the existence of at least one such statement follows from the diagonal lemma, which says that for any sufficiently strong formal system and any statement form "F" there is a statement "p" such that the system proves
p9273
aV"p" \u2194 "F"(G("p")).
p9274
aVBy letting "F" be the negation of Bew("x"), we obtain the theorem
p9275
aV"p" \u2194 "~Bew"(G("p"))
p9276
aVand the "p" defined by this roughly states that its own Gödel number is the Gödel number of an unprovable formula.
p9277
aVThe statement "p" is not literally equal to ~Bew(G("p")); rather, "p" states that if a certain calculation is performed, the resulting Gödel number will be that of an unprovable statement. But when this calculation is performed, the resulting Gödel number turns out to be the Gödel number of "p" itself. This is similar to the following sentence in English:
p9278
aV", when preceded by itself in quotes, is unprovable.", when preceded by itself in quotes, is unprovable.
p9279
aVThis sentence does not directly refer to itself, but when the stated transformation is made the original sentence is obtained as a result, and thus this sentence asserts its own unprovability. The proof of the diagonal lemma employs a similar method.
p9280
aVNow, assume that the axiomatic system is \u03c9-consistent, and let "p" be the statement obtained in the previous section.
p9281
aVIf "p" were provable, then Bew(G("p")) would be provable, as argued above. But "p" asserts the negation of Bew(G("p")). Thus the system would be inconsistent, proving both a statement and its negation. This contradiction shows that "p" cannot be provable.
p9282
aVIf the negation of "p" were provable, then Bew(G("p")) would be provable (because "p" was constructed to be equivalent to the negation of Bew(G("p"))). However, for each specific number "x", "x" cannot be the Gödel number of the proof of "p", because "p" is not provable (from the previous paragraph). Thus on one hand the system proves there is a number with a certain property (that it is the Gödel number of the proof of "p"), but on the other hand, for every specific number "x", we can prove that it does not have this property. This is impossible in an \u03c9-consistent system. Thus the negation of "p" is not provable.
p9283
aVThus the statement "p" is undecidable in our axiomatic system: it can neither be proved nor disproved within the system.
p9284
aVIn fact, to show that "p" is not provable only requires the assumption that the system is consistent. The stronger assumption of \u03c9-consistency is required to show that the negation of "p" is not provable. Thus, if "p" is constructed for a particular system:
p9285
aVIf one tries to "add the missing axioms" to avoid the incompleteness of the system, then one has to add either "p" or "not "p"" as axioms. But then the definition of "being a Gödel number of a proof" of a statement changes. which means that the formula Bew("x") is now different. Thus when we apply the diagonal lemma to this new Bew, we obtain a new statement "p", different from the previous one, which will be undecidable in the new system if it is \u03c9-consistent.
p9286
aVProof via Berry's paradox.
p9287
aVGeorge Boolos (1989) sketches an alternative proof of the first incompleteness theorem that uses Berry's paradox rather than the liar paradox to construct a true but unprovable formula. A similar proof method was independently discovered by Saul Kripke (Boolos 1998, p. 383). Boolos's proof proceeds by constructing, for any computably enumerable set "S" of true sentences of arithmetic, another sentence which is true but not contained in "S". This gives the first incompleteness theorem as a corollary. According to Boolos, this proof is interesting because it provides a "different sort of reason" for the incompleteness of effective, consistent theories of arithmetic (Boolos 1998, p. 388).
p9288
aVFormalized proofs.
p9289
aVFormalized proofs of versions of the incompleteness theorem have been developed by Natarajan Shankar in 1986 using Nqthm (Shankar 1994) and by Russell O'Connor in 2003 using Coq (O'Connor 2005).
p9290
aVProof sketch for the second theorem.
p9291
aVThe main difficulty in proving the second incompleteness theorem is to show that various facts about provability used in the proof of the first incompleteness theorem can be formalized within the system using a formal predicate for provability. Once this is done, the second incompleteness theorem follows by formalizing the entire proof of the first incompleteness theorem within the system itself.
p9292
aVLet "p" stand for the undecidable sentence constructed above, and assume that the consistency of the system can be proven from within the system itself. The demonstration above shows that if the system is consistent, then "p" is not provable. The proof of this implication can be formalized within the system, and therefore the statement ""p" is not provable", or "not "P"("p")" can be proven in the system.
p9293
aVBut this last statement is equivalent to "p" itself (and this equivalence can be proven in the system), so "p" can be proven in the system. This contradiction shows that the system must be inconsistent.
p9294
aVDiscussion and implications.
p9295
aVThe incompleteness results affect the philosophy of mathematics, particularly versions of formalism, which use a single system of formal logic to define their principles. One can paraphrase the first theorem as saying the following:
p9296
aVAn all-encompassing axiomatic system can never be found that is able to prove "all" mathematical truths, but no falsehoods.
p9297
aVOn the other hand, from a strict formalist perspective this paraphrase would be considered meaningless because it presupposes that mathematical "truth" and "falsehood" are well-defined in an absolute sense, rather than relative to each formal system.
p9298
aVThe following rephrasing of the second theorem is even more unsettling to the foundations of mathematics:
p9299
aVIf an axiomatic system can be proven to be consistent from within itself, then it is inconsistent.
p9300
aVTherefore, to establish the consistency of a system S, one needs to use some other system T, but a proof in T is not completely convincing unless T's consistency has already been established without using S.
p9301
aVTheories such as Peano arithmetic, for which any computably enumerable consistent extension is incomplete, are called essentially undecidable or essentially incomplete.
p9302
aVMinds and machines.
p9303
aVAuthors including the philosopher J. R. Lucas and physicist Roger Penrose have debated what, if anything, Gödel's incompleteness theorems imply about human intelligence. Much of the debate centers on whether the human mind is equivalent to a Turing machine, or by the Church\u2013Turing thesis, any finite machine at all. If it is, and if the machine is consistent, then Gödel's incompleteness theorems would apply to it.
p9304
aVHilary Putnam (1960) suggested that while Gödel's theorems cannot be applied to humans, since they make mistakes and are therefore inconsistent, it may be applied to the human faculty of science or mathematics in general. Assuming that it is consistent, either its consistency cannot be proved or it cannot be represented by a Turing machine.
p9305
aVAvi Wigderson (2010) has proposed that the concept of mathematical "knowability" should be based on computational complexity rather than logical decidability. He writes that "when "knowability" is interpreted by modern standards, namely via computational complexity, the Gödel phenomena are very much with us."
p9306
aVParaconsistent logic.
p9307
aVAlthough Gödel's theorems are usually studied in the context of classical logic, they also have a role in the study of paraconsistent logic and of inherently contradictory statements ("dialetheia"). Graham Priest (1984, 2006) argues that replacing the notion of formal proof in Gödel's theorem with the usual notion of informal proof can be used to show that naive mathematics is inconsistent, and uses this as evidence for dialetheism. The cause of this inconsistency is the inclusion of a truth predicate for a theory within the language of the theory (Priest 2006:47). Stewart Shapiro (2002) gives a more mixed appraisal of the applications of Gödel's theorems to dialetheism.
p9308
aVAppeals to the incompleteness theorems in other fields.
p9309
aVAppeals and analogies are sometimes made to the incompleteness theorems in support of arguments that go beyond mathematics and logic. Several authors have commented negatively on such extensions and interpretations, including Torkel Franzén (2005); Alan Sokal and Jean Bricmont (1999); and Ophelia Benson and Jeremy Stangroom (2006). Bricmont and Stangroom (2006, p. 10), for example, quote from Rebecca Goldstein's comments on the disparity between Gödel's avowed Platonism and the anti-realist uses to which his ideas are sometimes put. Sokal and Bricmont (1999, p. 187) criticize Régis Debray's invocation of the theorem in the context of sociology; Debray has defended this use as metaphorical (ibid.).
p9310
aVRole of self-reference.
p9311
aVTorkel Franzén (2005, p. 46) observes:
p9312
aVGödel's proof of the first incompleteness theorem and Rosser's strengthened version have given many the impression that the theorem can only be proved by constructing self-referential statements [...] or even that only strange self-referential statements are known to be undecidable in elementary arithmetic.
p9313
aVTo counteract such impressions, we need only introduce a different kind of proof of the first incompleteness theorem.
p9314
aVHe then proposes the proofs based on computability, or on information theory, as described earlier in this article, as examples of proofs that should "counteract such impressions".
p9315
aVHistory.
p9316
aVAfter Gödel published his proof of the completeness theorem as his doctoral thesis in 1929, he turned to a second problem for his habilitation. His original goal was to obtain a positive solution to Hilbert's second problem (Dawson 1997, p. 63). At the time, theories of the natural numbers and real numbers similar to second-order arithmetic were known as "analysis", while theories of the natural numbers alone were known as "arithmetic".
p9317
aVGödel was not the only person working on the consistency problem. Ackermann had published a flawed consistency proof for analysis in 1925, in which he attempted to use the method of \u03b5-substitution originally developed by Hilbert. Later that year, von Neumann was able to correct the proof for a theory of arithmetic without any axioms of induction. By 1928, Ackermann had communicated a modified proof to Bernays; this modified proof led Hilbert to announce his belief in 1929 that the consistency of arithmetic had been demonstrated and that a consistency proof of analysis would likely soon follow. After the publication of the incompleteness theorems showed that Ackermann's modified proof must be erroneous, von Neumann produced a concrete example showing that its main technique was unsound (Zach 2006, p. 418, Zach 2003, p. 33).
p9318
aVIn the course of his research, Gödel discovered that although a sentence which asserts its own falsehood leads to paradox, a sentence that asserts its own non-provability does not. In particular, Gödel was aware of the result now called Tarski's indefinability theorem, although he never published it. Gödel announced his first incompleteness theorem to Carnap, Feigel and Waismann on August 26, 1930; all four would attend a key conference in Königsberg the following week.
p9319
aVAnnouncement.
p9320
aVThe 1930 Königsberg conference was a joint meeting of three academic societies, with many of the key logicians of the time in attendance. Carnap, Heyting, and von Neumann delivered one-hour addresses on the mathematical philosophies of logicism, intuitionism, and formalism, respectively (Dawson 1996, p. 69). The conference also included Hilbert's retirement address, as he was leaving his position at the University of Göttingen. Hilbert used the speech to argue his belief that all mathematical problems can be solved. He ended his address by saying,
p9321
aVFor the mathematician there is no "Ignorabimus", and, in my opinion, not at all for natural science either. ... The true reason why one has succeeded in finding an unsolvable problem is, in my opinion, that there is no unsolvable problem. In contrast to the foolish "Ignoramibus", our credo avers: We must know. We shall know!
p9322
aVThis speech quickly became known as a summary of Hilbert's beliefs on mathematics (its final six words, ""Wir müssen wissen. Wir werden wissen!"", were used as Hilbert's epitaph in 1943). Although Gödel was likely in attendance for Hilbert's address, the two never met face to face (Dawson 1996, p. 72).
p9323
aVGödel announced his first incompleteness theorem at a roundtable discussion session on the third day of the conference. The announcement drew little attention apart from that of von Neumann, who pulled Gödel aside for conversation. Later that year, working independently with knowledge of the first incompleteness theorem, von Neumann obtained a proof of the second incompleteness theorem, which he announced to Gödel in a letter dated November 20, 1930 (Dawson 1996, p. 70). Gödel had independently obtained the second incompleteness theorem and included it in his submitted manuscript, which was received by "Monatshefte für Mathematik" on November 17, 1930.
p9324
aVGödel's paper was published in the "Monatshefte" in 1931 under the title "Über formal unentscheidbare Sätze der Principia Mathematica und verwandter Systeme I" (On Formally Undecidable Propositions in Principia Mathematica and Related Systems I). As the title implies, Gödel originally planned to publish a second part of the paper; it was never written.
p9325
aVGeneralization and acceptance.
p9326
aVGödel gave a series of lectures on his theorems at Princeton in 1933\u20131934 to an audience that included Church, Kleene, and Rosser. By this time, Gödel had grasped that the key property his theorems required is that the theory must be effective (at the time, the term "general recursive" was used). Rosser proved in 1936 that the hypothesis of \u03c9-consistency, which was an integral part of Gödel's original proof, could be replaced by simple consistency, if the Gödel sentence was changed in an appropriate way. These developments left the incompleteness theorems in essentially their modern form.
p9327
aVGentzen published his consistency proof for first-order arithmetic in 1936. Hilbert accepted this proof as "finitary" although (as Gödel's theorem had already shown) it cannot be formalized within the system of arithmetic that is being proved consistent.
p9328
aVThe impact of the incompleteness theorems on Hilbert's program was quickly realized. Bernays included a full proof of the incompleteness theorems in the second volume of "Grundlagen der Mathematik" (1939), along with additional results of Ackermann on the \u03b5-substitution method and Gentzen's consistency proof of arithmetic. This was the first full published proof of the second incompleteness theorem.
p9329
aVCriticisms.
p9330
aVFinsler.
p9331
aVPaul Finsler (1926) used a version of Richard's paradox to construct an expression that was false but unprovable in a particular, informal framework he had developed. Gödel was unaware of this paper when he proved the incompleteness theorems (Collected Works Vol. IV., p. 9). Finsler wrote to Gödel in 1931 to inform him about this paper, which Finsler felt had priority for an incompleteness theorem. Finsler's methods did not rely on formalized provability, and had only a superficial resemblance to Gödel's work (van Heijenoort 1967:328). Gödel read the paper but found it deeply flawed, and his response to Finsler laid out concerns about the lack of formalization (Dawson:89). Finsler continued to argue for his philosophy of mathematics, which eschewed formalization, for the remainder of his career.
p9332
aVZermelo.
p9333
aVIn September 1931, Ernst Zermelo wrote Gödel to announce what he described as an "essential gap" in Gödel's argument (Dawson:76). In October, Gödel replied with a 10-page letter (Dawson:76, Grattan-Guinness:512-513). But Zermelo did not relent and published his criticisms in print with "a rather scathing paragraph on his young competitor" (Grattan-Guinness:513). Gödel decided that to pursue the matter further was pointless, and Carnap agreed (Dawson:77). Much of Zermelo's subsequent work was related to logics stronger than first-order logic, with which he hoped to show both the consistency and categoricity of mathematical theories.
p9334
aVWittgenstein.
p9335
aVLudwig Wittgenstein wrote several passages about the incompleteness theorems that were published posthumously in his 1953 "Remarks on the Foundations of Mathematics". Gödel was a member of the Vienna Circle during the period in which Wittgenstein's early ideal language philosophy and Tractatus Logico-Philosophicus dominated the circle's thinking. Writings in Gödel's Nachlass express the belief that Wittgenstein deliberately misread his ideas.
p9336
aVMultiple commentators have read Wittgenstein as misunderstanding Gödel (Rodych 2003), although Juliet Floyd and Hilary Putnam (2000), as well as Graham Priest (2004) have provided textual readings arguing that most commentary misunderstands Wittgenstein. On their release, Bernays, Dummett, and Kreisel wrote separate reviews on Wittgenstein's remarks, all of which were extremely negative (Berto 2009:208). The unanimity of this criticism caused Wittgenstein's remarks on the incompleteness theorems to have little impact on the logic community. In 1972, Gödel, stated: "Has Wittgenstein lost his mind? Does he mean it seriously?" (Wang 1996:197) And wrote to Karl Menger that Wittgenstein's comments demonstrate a willful misunderstanding of the incompleteness theorems writing:
p9337
aV"It is clear from the passages you cite that Wittgenstein did "not" understand first incompleteness theorem (or pretended not to understand it). He interpreted it as a kind of logical paradox, while in fact is just the opposite, namely a mathematical theorem within an absolutely uncontroversial part of mathematics (finitary number theory or combinatorics)." (Wang 1996:197)
p9338
aVSince the publication of Wittgenstein's "Nachlass" in 2000,
p9339
aVa series of papers in philosophy have sought to evaluate whether the original criticism of Wittgenstein's remarks was justified. Floyd and Putnam (2000) argue that Wittgenstein had a more complete understanding of the incompleteness theorem than was previously assumed. They are particularly concerned with the interpretation of a Gödel sentence for an \u03c9-inconsistent theory as actually saying "I am not provable", since the theory has no models in which the provability predicate corresponds to actual provability. Rodych (2003) argues that their interpretation of Wittgenstein is not historically justified, while Bays (2004) argues against Floyd and Putnam's philosophical analysis of the provability predicate. Berto (2009) explores the relationship between Wittgenstein's writing and theories of paraconsistent logic.
p9340
aVReferences.
p9341
aVTranslations, during his lifetime, of Gödel's paper into English.
p9342
aVNone of the following agree in all translated words and in typography. The typography is a serious matter, because Gödel expressly wished to emphasize "those metamathematical notions that had been defined in their usual sense before . . ." (van Heijenoort 1967:595). Three translations exist. Of the first John Dawson states that: "The Meltzer translation was seriously deficient and received a devastating review in the "Journal of Symbolic Logic"; "Gödel also complained about Braithwaite's commentary (Dawson 1997:216). "Fortunately, the Meltzer translation was soon supplanted by a better one prepared by Elliott Mendelson for Martin Davis's anthology "The Undecidable" . . . he found the translation "not quite so good" as he had expected . . . because of time constraints he agreed to its publication" (ibid). (In a footnote Dawson states that "he would regret his compliance, for the published volume was marred throughout by sloppy typography and numerous misprints" (ibid)). Dawson states that "The translation that Gödel favored was that by Jean van Heijenoort" (ibid). For the serious student another version exists as a set of lecture notes recorded by Stephen Kleene and J. B. Rosser "during lectures given by Gödel at to the Institute for Advanced Study during the spring of 1934" (cf commentary by Davis 1965:39 and beginning on p. 41); this version is titled "On Undecidable Propositions of Formal Mathematical Systems". In their order of publication:
p9343
aV*Stephen Hawking editor, 2005. "God Created the Integers: The Mathematical Breakthroughs That Changed History", Running Press, Philadelphia, ISBN 0-7624-1922-9. Gödel's paper appears starting on p. 1097, with Hawking's commentary starting on p. 1089.
p9344
asS'Infinite monkey theorem'
p9345
(lp9346
VThe infinite monkey theorem states that a monkey hitting keys at random on a typewriter keyboard for an infinite amount of time will almost surely type a given text, such as the complete works of William Shakespeare.
p9347
aVIn this context, "almost surely" is a mathematical term with a precise meaning, and the "monkey" is not an actual monkey, but a metaphor for an abstract device that produces an endless random sequence of letters and symbols. One of the earliest instances of the use of the "monkey metaphor" is that of French mathematician Émile Borel in 1913, but the earliest instance may be even earlier. The relevance of the theorem is questionable\u2014the probability of a universe full of monkeys typing a complete work such as Shakespeare's "Hamlet" is so tiny that the chance of it occurring during a period of time hundreds of thousands of orders of magnitude longer than the age of the universe is "extremely" low (but technically not zero).
p9348
aVVariants of the theorem include multiple and even infinitely many typists, and the target text varies between an entire library and a single sentence. The history of these statements can be traced back to Aristotle's "On Generation and Corruption" and Cicero's "De natura deorum" (On the Nature of the Gods), through Blaise Pascal and Jonathan Swift, and finally to modern statements with their iconic simians and typewriters. In the early 20th century, Émile Borel and Arthur Eddington used the theorem to illustrate the timescales implicit in the foundations of statistical mechanics.
p9349
aVSolution.
p9350
aVDirect proof.
p9351
aVThere is a straightforward proof of this theorem. As an introduction, recall that if two events are statistically independent, then the probability of both happening equals the product of the probabilities of each one happening independently. For example, if the chance of rain in Moscow on a particular day in the future is 0.4 and the chance of an earthquake in San Francisco on that same day is 0.00003, then the chance of both happening on that day is , assuming that they are indeed independent.
p9352
aVSuppose the typewriter has 50 keys, and the word to be typed is "banana". If the keys are pressed randomly and independently, it means that each key has an equal chance of being pressed. Then, the chance that the first letter typed is 'b' is 1/50, and the chance that the second letter typed is "a" is also 1/50, and so on. Therefore, the chance of the first six letters spelling "banana" is
p9353
aV(1/50) × (1/50) × (1/50) × (1/50) × (1/50) × (1/50) = (1/50)6 = 1/15 625 000 000 ,
p9354
aVless than one in 15 billion, but not zero, hence a possible outcome.
p9355
aVFrom the above, the chance of "not" typing "banana" in a given block of 6 letters is 1 \u2212 (1/50)6. Because each block is typed independently, the chance "X""n" of not typing "banana" in any of the first "n" blocks of 6 letters is
p9356
aVformula_1
p9357
aVAs "n" grows, "X""n" gets smaller. For an "n" of a million, "X""n" is roughly 0.9999, but for an "n" of 10 billion "X""n" is roughly 0.53 and for an "n" of 100 billion it is roughly 0.0017. As "n" approaches infinity, the probability "X""n" approaches zero; that is, by making "n" large enough, "X""n" can be made as small as is desired, and the chance of typing "banana" approaches 100%.
p9358
aVThe same argument shows why at least one of infinitely many monkeys will produce a text as quickly as it would be produced by a perfectly accurate human typist copying it from the original. In this case "X""n" = (1 \u2212 (1/50)6)"n" where "X""n" represents the probability that none of the first "n" monkeys types "banana" correctly on their first try. When we consider 100 billion monkeys, the probability falls to 0.17%, and as the number of monkeys "n" increases, the value of "X""n" \u2013 the probability of the monkeys failing to reproduce the given text \u2013 approaches zero arbitrarily closely. The limit, for "n" going to infinity, is zero.
p9359
aVInfinite strings.
p9360
aVThis can be stated more generally and compactly in terms of strings, which are sequences of characters chosen from some finite alphabet:
p9361
aVBoth follow easily from the second Borel\u2013Cantelli lemma. For the second theorem, let "E""k" be the event that the "k"th string begins with the given text. Because this has some fixed nonzero probability "p" of occurring, the "E""k" are independent, and the below sum diverges,
p9362
aVformula_2
p9363
aVthe probability that infinitely many of the "E""k" occur is 1. The first theorem is shown similarly; one can divide the random string into nonoverlapping blocks matching the size of the desired text, and make "E""k" the event where the "k"th block equals the desired string.
p9364
aVProbabilities.
p9365
aVHowever, for physically meaningful numbers of monkeys typing for physically meaningful lengths of time the results are reversed. If there were as many monkeys as there are atoms in the observable universe typing extremely fast for trillions of times the life of the universe, the probability of the monkeys replicating even a "single page" of Shakespeare is unfathomably minute.
p9366
aVIgnoring punctuation, spacing, and capitalization, a monkey typing letters uniformly at random has a chance of one in 26 of correctly typing the first letter of "Hamlet." It has a chance of one in 676 (26 × 26) of typing the first two letters. Because the probability shrinks exponentially, at 20 letters it already has only a chance of one in 2620 = 19,928,148,895,209,409,152,340,197,376 (almost 2 × 1028). In the case of the entire text of "Hamlet", the probabilities are so vanishingly small as to be inconceivable. The text of Hamlet contains approximately 130,000 letters. Thus there is a probability of one in 3.4 × 10183,946 to get the text right at the first trial. The average number of letters that needs to be typed until the text appears is also 3.4 × 10183,946, or including punctuation, 4.4 × 10360,783.
p9367
aVEven if every proton in the observable universe were a monkey with a typewriter, typing from the Big Bang until the end of the universe (when protons no longer exist), they would still need a ridiculously longer time - more than three hundred and sixty thousand "orders of magnitude" longer - to have even a 1 in 10500 chance of success. To put it another way, for a one in a trillion chance of success, there would need to be 10360,641 universes made of atomic monkeys. As Kittel and Kroemer put it, "The probability of "Hamlet" is therefore zero in any operational sense of an event...", and the statement that the monkeys must eventually succeed "gives a misleading conclusion about very, very large numbers." This is from their textbook on thermodynamics, the field whose statistical foundations motivated the first known expositions of typing monkeys.
p9368
aVIn fact there is less than a one in a trillion chance of success that such a universe made of monkeys could type any particular document a mere 79 characters long.
p9369
aVAlmost surely.
p9370
aVThe probability that an infinite randomly generated string of text will contain a particular finite substring is 1. However, this does not mean the substring's absence is "impossible", despite the absence having a prior probability of 0. For example, the immortal monkey "could" randomly type G as its first letter, G as its second, and G as every single letter thereafter, producing an infinite string of Gs; at no point must the monkey be "compelled" to type anything else. (To assume otherwise implies the gambler's fallacy.) However long a randomly generated finite string is, there is a small but nonzero chance that it will turn out to consist of the same character repeated throughout; this chance approaches zero as the string's length approaches infinity. There is nothing special about such a monotonous sequence except that it is easy to describe; the same fact applies to any nameable specific sequence, such as "RGRGRG" repeated forever, or "a-b-aa-bb-aaa-bbb-...", or "Three, Six, Nine, Twelve\u2026".
p9371
aVIf the hypothetical monkey has a typewriter with 90 equally likely keys that include numerals and punctuation, then the first typed keys might be "3.14" (the first three digits of pi) with a probability of (1/90)4, which is 1/65,610,000. Equally probable is any other string of four characters allowed by the typewriter, such as "GGGG", "mATh", or "q%8e". The probability that 100 randomly typed keys will consist of the first 99 digits of pi (including the separator key), or any other "particular" sequence of that length, is much lower: (1/90)100. If the monkey's allotted length of text is infinite, the chance of typing only the digits of pi is 0, which is just as "possible" as typing nothing but Gs (also probability 0).
p9372
aVThe same applies to the event of typing a particular version of "Hamlet" followed by endless copies of itself; or "Hamlet" immediately followed by all the digits of pi; these specific strings are equally infinite in length, they are not prohibited by the terms of the thought problem, and they each have a prior probability of 0. In fact, "any" particular infinite sequence the immortal monkey types will have "had" a prior probability of 0, even though the monkey must type something.
p9373
aVThis is an extension of the principle that a finite string of random text has a lower and lower probability of "being" a particular string the longer it is (though all specific strings are equally unlikely). This probability approaches 0 as the string approaches infinity. Thus, the probability of the monkey typing an endlessly long string, such as all of the digits of pi in order, on a 90-key keyboard is (1/90)\u221e which equals (1/\u221e) which is essentially 0. At the same time, the probability that the sequence "contains" a particular subsequence (such as the word MONKEY, or the 12th through 999th digits of pi, or a version of the King James Bible) increases as the total string increases. This probability approaches 1 as the total string approaches infinity, and thus the original theorem is correct.
p9374
aVCorrespondence between strings and numbers.
p9375
aVIn a simplification of the thought experiment, the monkey could have a typewriter with just two keys: 1 and 0. The infinitely long string thusly produced would correspond to the binary digits of a particular real number between 0 and 1. A countably infinite set of possible strings end in infinite repetitions, which means the corresponding real number is rational. Examples include the strings corresponding to one-third (010101\u2026), five-sixths (11010101\u2026) and five-eighths (1100000\u2026). Only a subset of such real number strings (albeit a countably infinite subset) contains the entirety of "Hamlet" (if the text is translated from ASCII to binary).
p9376
aVMeanwhile, there is an "uncountably" infinite set of strings which do not end in such repetition; these correspond to the irrational numbers. These can be sorted into two uncountably infinite subsets: those which contain "Hamlet" and those which do not. However, the "largest" subset of all the real numbers are those which not only contain "Hamlet", but which contain every other possible string of any length, and with equal distribution of such strings. These irrational numbers are called normal. Because almost all numbers are normal, almost all possible strings contain all possible finite substrings. Hence, the probability of the monkey typing a normal number is 1. The same principles apply regardless of the number of keys from which the monkey can choose; a 90-key keyboard can be seen as a generator of numbers written in base 90.
p9377
aVHistory.
p9378
aVStatistical mechanics.
p9379
aVIn one of the forms in which probabilists now know this theorem, with its "dactylographic" typewriting monkeys (; the French word "singe" covers both the monkeys and the apes), appeared in Émile Borel's 1913 article ""Mécanique Statistique et Irréversibilité"" ("Statistical mechanics and irreversibility"), and in his book "Le Hasard" in 1914. His "monkeys" are not actual monkeys; rather, they are a metaphor for an imaginary way to produce a large, random sequence of letters. Borel said that if a million monkeys typed ten hours a day, it was extremely unlikely that their output would exactly equal all the books of the richest libraries of the world; and yet, in comparison, it was even more unlikely that the laws of statistical mechanics would ever be violated, even briefly.
p9380
aVThe physicist Arthur Eddington drew on Borel's image further in "The Nature of the Physical World" (1928), writing:
p9381
aVThese images invite the reader to consider the incredible improbability of a large but finite number of monkeys working for a large but finite amount of time producing a significant work, and compare this with the even greater improbability of certain physical events. Any physical process that is even less likely than such monkeys' success is effectively impossible, and it may safely be said that such a process will never happen.
p9382
aVOrigins and "The Total Library".
p9383
aVIn a 1939 essay entitled "The Total Library", Argentine writer Jorge Luis Borges traced the infinite-monkey concept back to Aristotle's "Metaphysics." Explaining the views of Leucippus, who held that the world arose through the random combination of atoms, Aristotle notes that the atoms themselves are homogeneous and their possible arrangements only differ in shape, position and ordering. In "On Generation and Corruption", the Greek philosopher compares this to the way that a tragedy and a comedy consist of the same "atoms", "i.e.", alphabetic characters. Three centuries later, Cicero's "De natura deorum" ("On the Nature of the Gods") argued against the atomist worldview:
p9384
aVBorges follows the history of this argument through Blaise Pascal and Jonathan Swift, then observes that in his own time, the vocabulary had changed. By 1939, the idiom was "that a half-dozen monkeys provided with typewriters would, in a few eternities, produce all the books in the British Museum." (To which Borges adds, "Strictly speaking, one immortal monkey would suffice.") Borges then imagines the contents of the Total Library which this enterprise would produce if carried to its fullest extreme:
p9385
aVBorges' total library concept was the main theme of his widely read 1941 short story "The Library of Babel", which describes an unimaginably vast library consisting of interlocking hexagonal chambers, together containing every possible volume that could be composed from the letters of the alphabet and some punctuation characters.
p9386
aVReal monkeys.
p9387
aVIn 2003, lecturers and students from the University of Plymouth MediaLab Arts course used a £2,000 grant from the Arts Council to study the literary output of real monkeys. They left a computer keyboard in the enclosure of six Celebes Crested Macaques in Paignton Zoo in Devon in England for a month, with a radio link to broadcast the results on a website.
p9388
aVNot only did the monkeys produce nothing but five total pages largely consisting of the letter S, the lead male began by bashing the keyboard with a stone, and the monkeys continued by urinating and defecating on it. Mike Phillips, director of the university's Institute of Digital Arts and Technology (i-DAT), said that the artist-funded project was primarily performance art, and they had learned "an awful lot" from it. He concluded that monkeys "are not random generators. They're more complex than that. ... They were quite interested in the screen, and they saw that when they typed a letter, something happened. There was a level of intention there."
p9389
aVApplications and criticisms.
p9390
aVEvolution.
p9391
aVIn his 1931 book "The Mysterious Universe", Eddington's rival James Jeans attributed the monkey parable to a "Huxley", presumably meaning Thomas Henry Huxley. This attribution is incorrect. Today, it is sometimes further reported that Huxley applied the example in a now-legendary debate over Charles Darwin's "On the Origin of Species" with the Anglican Bishop of Oxford, Samuel Wilberforce, held at a meeting of the British Association for the Advancement of Science at Oxford on June 30, 1860. This story suffers not only from a lack of evidence, but the fact that in 1860 the typewriter itself had yet to emerge.
p9392
aVDespite the original mix-up, monkey-and-typewriter arguments are now common in arguments over evolution. For example, Doug Powell argues as a Christian apologist that even if a monkey accidentally types the letters of "Hamlet", it has failed to produce "Hamlet" because it lacked the intention to communicate. His parallel implication is that natural laws could not produce the information content in DNA. A more common argument is represented by Reverend John F. MacArthur, who claims that the genetic mutations necessary to produce a tapeworm from an amoeba are as unlikely as a monkey typing Hamlet's soliloquy, and hence the odds against the evolution of all life are impossible to overcome.
p9393
aVEvolutionary biologist Richard Dawkins employs the typing monkey concept in his book "The Blind Watchmaker" to demonstrate the ability of natural selection to produce biological complexity out of random mutations. In a simulation experiment Dawkins has his weasel program produce the Hamlet phrase "METHINKS IT IS LIKE A WEASEL", starting from a randomly typed parent, by "breeding" subsequent generations and always choosing the closest match from progeny that are copies of the parent, with random mutations. The chance of the target phrase appearing in a single step is extremely small, yet Dawkins showed that it could be produced rapidly (in about 40 generations) using cumulative selection of phrases. The random choices furnish raw material, while cumulative selection imparts information. As Dawkins acknowledges, however, the weasel program is an imperfect analogy for evolution, as "offspring" phrases were selected "according to the criterion of resemblance to a "distant ideal" target." In contrast, Dawkins affirms, evolution has no long-term plans and does not progress toward some distant goal (such as humans). The weasel program is instead meant to illustrate the difference between non-random cumulative selection, and random single-step selection. In terms of the typing monkey analogy, this means that "Romeo and Juliet" could be produced relatively quickly if placed under the constraints of a nonrandom, Darwinian-type selection because the fitness function will tend to preserve in place any letters that happen to match the target text, improving each successive generation of typing monkeys.
p9394
aVA different avenue for exploring the analogy between evolution and an unconstrained monkey lies in the problem that the monkey types only one letter at a time, independently of the other letters. Hugh Petrie argues that a more sophisticated setup is required, in his case not for biological evolution but the evolution of ideas:
p9395
aVJames W. Valentine, while admitting that the classic monkey's task is impossible, finds that there is a worthwhile analogy between written English and the metazoan genome in this other sense: both have "combinatorial, hierarchical structures" that greatly constrain the immense number of combinations at the alphabet level.
p9396
aVLiterary theory.
p9397
aVR. G. Collingwood argued in 1938 that art cannot be produced by accident, and wrote as a sarcastic aside to his critics,
p9398
aVNelson Goodman took the contrary position, illustrating his point along with Catherine Elgin by the example of Borges' "Pierre Menard, Author of the Quixote",
p9399
aVIn another writing, Goodman elaborates, "That the monkey may be supposed to have produced his copy randomly makes no difference. It is the same text, and it is open to all the same interpretations..." Gérard Genette dismisses Goodman's argument as begging the question.
p9400
aVFor Jorge J. E. Gracia, the question of the identity of texts leads to a different question, that of author. If a monkey is capable of typing "Hamlet", despite having no intention of meaning and therefore disqualifying itself as an author, then it appears that texts do not require authors. Possible solutions include saying that whoever finds the text and identifies it as "Hamlet" is the author; or that Shakespeare is the author, the monkey his agent, and the finder merely a user of the text. These solutions have their own difficulties, in that the text appears to have a meaning separate from the other agents: what if the monkey operates before Shakespeare is born, or if Shakespeare is never born, or if no one ever finds the monkey's typescript?
p9401
aVRandom document generation.
p9402
aVThe theorem concerns a thought experiment which cannot be fully carried out in practice, since it is predicted to require prohibitive amounts of time and resources. Nonetheless, it has inspired efforts in finite random text generation.
p9403
aVOne computer program run by Dan Oliver of Scottsdale, Arizona, according to an article in "The New Yorker", came up with a result on August 4, 2004: After the group had worked for 42,162,500,000 billion billion monkey-years, one of the "monkeys" typed, "VALENTINE. Cease toIdor:eFLP0FRjWK78aXzVOwm)-\u2018;8.t" The first 19 letters of this sequence can be found in "The Two Gentlemen of Verona". Other teams have reproduced 18 characters from "Timon of Athens", 17 from "Troilus and Cressida", and 16 from "Richard II".
p9404
aVA website entitled "The Monkey Shakespeare Simulator", launched on July 1, 2003, contained a Java applet that simulates a large population of monkeys typing randomly, with the stated intention of seeing how long it takes the virtual monkeys to produce a complete Shakespearean play from beginning to end. For example, it produced this partial line from "Henry IV, Part 2", reporting that it took "2,737,850 million billion billion billion monkey-years" to reach 24 matching characters:
p9405
aVRUMOUR. Open your ears; 9r"5j5&?OWTY Z0d..."
p9406
aVDue to processing power limitations, the program uses a probabilistic model (by using a random number generator or RNG) instead of actually generating random text and comparing it to Shakespeare. When the simulator "detects a match" (that is, the RNG generates a certain value or a value within a certain range), the simulator simulates the match by generating matched text.
p9407
aVMore sophisticated methods are used in practice for natural language generation. If instead of simply generating random characters one restricts the generator to a meaningful vocabulary and conservatively following grammar rules, like using a context-free grammar, then a random document generated this way can even fool some humans (at least on a cursory reading) as shown in the experiments with SCIgen, snarXiv, and the Postmodernism Generator.
p9408
aVTesting of random number generators.
p9409
aVQuestions about the statistics describing how often an ideal monkey is expected to type certain strings translate into practical tests for random number generators; these range from the simple to the "quite sophisticated". Computer science professors George Marsaglia and Arif Zaman report that they used to call one such category of tests "overlapping m-tuple tests" in lecture, since they concern overlapping m-tuples of successive elements in a random sequence. But they found that calling them "monkey tests" helped to motivate the idea with students. They published a report on the class of tests and their results for various RNGs in 1993.
p9410
aVPopular culture.
p9411
aVThe infinite monkey theorem and its associated imagery is considered a popular and proverbial illustration of the mathematics of probability, widely known to the general public because of its transmission through popular culture rather than through formal education.
p9412
aVIn his 1978 radio play, "The Hitchhiker's Guide to the Galaxy", Douglas Adams invoked the theorem to illustrate the power of the \u2018Infinite Improbability Drive\u2019 that powered a spaceship. From Episode 2: "Ford, there\u2019s an infinite number of monkeys outside who want to talk to us about this script for Hamlet they\u2019ve worked out."
p9413
aVA quotation attributed to a 1996 speech by Robert Wilensky stated, "We\u2019ve heard that a million monkeys at a million keyboards could produce the complete works of Shakespeare; now, thanks to the Internet, we know that is not true."
p9414
aVThe enduring, widespread popularity of the theorem was noted in the introduction to a 2001 paper, "Monkeys, Typewriters and Networks: The Internet in the Light of the Theory of Accidental Excellence" (Hoffmann & Hofmann, 2001). In 2002, an article in "The Washington Post" said, "Plenty of people have had fun with the famous notion that an infinite number of monkeys with an infinite number of typewriters and an infinite amount of time could eventually write the works of Shakespeare."
p9415
aV In 2003, the previously mentioned Arts Council funded experiment involving real monkeys and a computer keyboard received widespread press coverage. In 2007, the theorem was listed by "Wired" magazine in a list of eight classic thought experiments.
p9416
aVDuring one episode of "The Ricky Gervais Show", Karl Pilkington successfully "disproved" the Infinite Monkey theorem by reasoning that you can't have an infinite number of monkeys because there isn't an infinite amount of bananas to feed them. He then doubled down by using the acumen that there isn't a big enough wilderness area available to house the monkeys when they had finished their shifts.
p9417
asS'Problem'
p9418
(lp9419
sS'Kepler conjecture'
p9420
(lp9421
VThe Kepler conjecture, named after the 17th-century mathematician and astronomer Johannes Kepler, is a mathematical conjecture about sphere packing in three-dimensional Euclidean space. It says that no arrangement of equally sized spheres filling space has a greater average density than that of the cubic close packing (face-centered cubic) and hexagonal close packing arrangements. The density of these arrangements is slightly greater than 74%.
p9422
aVIn 1998 Thomas Hales, following an approach suggested by , announced that he had a proof of the Kepler conjecture. Hales' proof is a proof by exhaustion involving the checking of many individual cases using complex computer calculations. Referees have said that they are "99% certain" of the correctness of Hales' proof, so the Kepler conjecture is now very close to being accepted as a theorem. In 2014, the Flyspeck project team, headed by Hales, announced the completion of a formal proof of the Kepler conjecture using a combination of the Isabelle and HOL Light proof assistants.
p9423
aVBackground.
p9424
aVImagine filling a large container with small equal-sized spheres. The density of the arrangement is equal to the collective volume of the spheres divided by the volume of the container. To maximize the number of spheres in the container means to create an arrangement with the highest possible density, so that the spheres are packed together as closely as possible.
p9425
aVExperiment shows that dropping the spheres in randomly will achieve a density of around 65%. However, a higher density can be achieved by carefully arranging the spheres as follows. Start with a layer of spheres in a hexagonal lattice, then put the next layer of spheres in the lowest points you can find above the first layer, and so on. At each step there are two choices of where to put the next layer, so this natural method of stacking the spheres creates an uncountably infinite number of equally dense packings, the best known of which are called cubic close packing and hexagonal close packing. Each of these arrangements has an average density of
p9426
aVformula_1
p9427
aVThe Kepler conjecture says that this is the best that can be done\u2014no other arrangement of spheres has a higher average density.
p9428
aVOrigins.
p9429
aVThe conjecture was first stated by in his paper 'On the six-cornered snowflake'. He had started to study arrangements of spheres as a result of his correspondence with the English mathematician and astronomer Thomas Harriot in 1606. Harriot was a friend and assistant of Sir Walter Raleigh, who had set Harriot the problem of determining how best to stack cannonballs on the decks of his ships. Harriot published a study of various stacking patterns in 1591, and went on to develop an early version of atomic theory.
p9430
aVNineteenth century.
p9431
aVKepler did not have a proof of the conjecture, and the next step was taken by , who proved that the Kepler conjecture is true if the spheres have to be arranged in a regular lattice.
p9432
aVThis meant that any packing arrangement that disproved the Kepler conjecture would have to be an irregular one. But eliminating all possible irregular arrangements is very difficult, and this is what made the Kepler conjecture so hard to prove. In fact, there are irregular arrangements that are denser than the cubic close packing arrangement over a small enough volume, but any attempt to extend these arrangements to fill a larger volume always reduces their density.
p9433
aVAfter Gauss, no further progress was made towards proving the Kepler conjecture in the nineteenth century. In 1900 David Hilbert included it in his list of twenty three unsolved problems of mathematics\u2014it forms part of Hilbert's eighteenth problem.
p9434
aVTwentieth century.
p9435
aVThe next step toward a solution was taken by László Fejes Tóth. showed that the problem of determining the maximum density of all arrangements (regular and irregular) could be reduced to a finite (but very large) number of calculations. This meant that a proof by exhaustion was, in principle, possible. As Fejes Tóth realised, a fast enough computer could turn this theoretical result into a practical approach to the problem.
p9436
aVMeanwhile, attempts were made to find an upper bound for the maximum density of any possible arrangement of spheres. English mathematician Claude Ambrose established an upper bound value of about 78%, and subsequent efforts by other mathematicians reduced this value slightly, but this was still much larger than the cubic close packing density of about 74%.
p9437
aVIn 1990, Wu-Yi Hsiang claimed to have proven the Kepler conjecture. The proof was praised by "Encyclopædia Britannica" and "Science" and Hsiang was also honored at joint meetings of AMS-MAA. claimed to prove the Kepler conjecture using geometric methods. However Gábor Fejes Tóth (the son of László Fejes Tóth) stated in his review of the paper "As far as details are concerned, my opinion is that many of the key statements have no acceptable proofs." 
p9438
aVHales' proof.
p9439
aVFollowing the approach suggested by , Thomas Hales, then at the University of Michigan, determined that the maximum density of all arrangements could be found by minimizing a function with 150 variables. In 1992, assisted by his graduate student Samuel Ferguson, he embarked on a research program to systematically apply linear programming methods to find a lower bound on the value of this function for each one of a set of over 5,000 different configurations of spheres. If a lower bound (for the function value) could be found for every one of these configurations that was greater than the value of the function for the cubic close packing arrangement, then the Kepler conjecture would be proved. To find lower bounds for all cases involved solving around 100,000 linear programming problems.
p9440
aVWhen presenting the progress of his project in 1996, Hales said that the end was in sight, but it might take "a year or two" to complete. In August 1998 Hales announced that the proof was complete. At that stage it consisted of 250 pages of notes and 3 gigabytes of computer programs, data and results.
p9441
aVDespite the unusual nature of the proof, the editors of the "Annals of Mathematics" agreed to publish it, provided it was accepted by a panel of twelve referees. In 2003, after four years of work, the head of the referee's panel Gábor Fejes Tóth reported that the panel were "99% certain" of the correctness of the proof, but they could not certify the correctness of all of the computer calculations.
p9442
aVA formal proof.
p9443
aVIn January 2003, Hales announced the start of a collaborative project to produce a complete formal proof of the Kepler conjecture. The aim was to remove any remaining uncertainty about the validity of the proof by creating a formal proof that can be verified by automated proof checking software such as HOL Light and Isabelle (proof assistant). This project is called "Flyspeck" \u2013 the F, P and K standing for "Formal Proof of Kepler". Hales estimated that producing a complete formal proof would take around 20 years of work. The project was announced completed on August 10, 2014. In January 2015 Hales and 21 collaborators published "A formal proof of the Kepler conjecture".
p9444
aVThe 2-dimensional analog of the Kepler conjecture; the proof is elementary. Henk and Ziegler attribute this result to Lagrange, in 1773 (see references, pag. 770).
p9445
aVRelated to Thue's theorem.
p9446
aVA related problem, whose proof uses similar techniques to Hales' proof of the Kepler conjecture. Conjecture by L. Fejes Tóth in the 1950s.
p9447
asS'Clay Mathematics Institute'
p9448
(lp9449
VThe Clay Mathematics Institute (CMI) is a private, non-profit foundation, based in Providence, Rhode Island. CMI's scientific activities are managed from the President's office in Oxford, United Kingdom. The Institute is "dedicated to increasing and disseminating mathematical knowledge." It gives out various awards and sponsorships to promising mathematicians. The institute was founded in 1998 through the sponsorship of Boston businessman Landon T. Clay. Harvard mathematician Arthur Jaffe was the first president of CMI. 
p9450
aVWhile the institute is best known for its Millennium Prize Problems, it carries out a wide range of activities, including a postdoctoral program (five Clay Research Fellows are supported each year) and a bi-annual summer school, the proceedings of which are published jointly with the American Mathematical Society.
p9451
aVGovernance.
p9452
aVThe Institute is run according to a standard structure comprising a scientific advisory committee that decides on grant-awarding and research proposals, and a board of directors that oversees and approves the committee's decisions. , the board is made up of members of the Clay family, whereas the advisory committee is composed of leading authorities in mathematics, namely Sir Andrew Wiles, Yum-Tong Siu, Richard Melrose, Andrei Okounkov, and Simon Donaldson. Nicholas Woodhouse is the current president of CMI.
p9453
aVMillennium Prize Problems.
p9454
aVThe institute is best known for establishing the Millennium Prize Problems on May 24, 2000. These seven problems are considered by CMI to be "important classic questions that have resisted solution over the years". For each problem, the first person to solve it will be awarded $1,000,000 by the CMI. In announcing the prize, CMI drew a parallel to Hilbert's problems, which were proposed in 1900, and had a substantial impact on 20th century mathematics. Of the initial twenty-three Hilbert problems, most of which have been solved, only the Riemann hypothesis (formulated in 1859) is included in the seven Millennium Prize Problems.
p9455
aVFor each problem, the Institute had a professional mathematician write up an official statement of the problem, which will be the main standard by which a given solution will be measured against. The seven problems are:
p9456
aVSome of the mathematicians who were involved in the selection and presentation of the seven problems were Atiyah, Bombieri, Connes, Deligne, Fefferman, Milnor, Mumford, Wiles, and Witten.
p9457
aVOther awards.
p9458
aVThe Clay Research Award.
p9459
aVIn recognition of major breakthroughs in mathematical research, the institute has an annual prize - the Clay Research Award. Its recipients to date are Ian Agol, Manindra Agrawal, Yves Benoist, Manjul Bhargava, Danny Calegari, Alain Connes, Nils Dencker, Alex Eskin, David Gabai, Ben Green, Christopher Hacon, Richard Hamilton, Michael Harris, Jeremy Kahn, Laurent Lafforgue, Gérard Laumon, Vladimir Markovic, James McKernan, Ngô B\u1ea3o Châu, Jonathan Pila, Jean-François Quint, Oded Schramm, Stanislav Smirnov, Terence Tao, Clifford Taubes, Richard Taylor, Claire Voisin, Jean-Loup Waldspurger, Andrew Wiles, and Edward Witten.
p9460
aVOther activities.
p9461
aVBesides the Millennium Prize Problems, the Clay Mathematics Institute also supports mathematics via the awarding of
p9462
aVresearch fellowships (which range from two to five years, and are aimed at younger mathematicians), as well as shorter-term
p9463
aVscholarships for programs, individual research, and book writing. The Institute also has a yearly Clay Research Award, recognizing major breakthroughs in mathematical research. Finally, the Institute also organizes a number of summer schools, conferences, workshops, public lectures, and outreach activities aimed primarily at junior mathematicians (from the high school to postdoctoral level).
p9464
aVCMI publications are available in PDF form at most six months after they appear in print.
p9465
asS'Combination (mathematics)'
p9466
(lp9467
sS'Chinese postman problem'
p9468
(lp9469
sS'Proportions'
p9470
(lp9471
sS'Population genetics'
p9472
(lp9473
VPopulation genetics is the study of the distributions and changes of allele frequency in a population, as the population is subject to the four main evolutionary processes: natural selection, genetic drift, mutation and gene flow. It also takes into account the factors of recombination, population subdivision and population structure. Studies in this branch of biology examine such phenomena as adaptation and speciation.
p9474
aVPopulation genetics was a vital ingredient in the emergence of the modern evolutionary synthesis. Its primary founders were Sewall Wright, J. B. S. Haldane and R. A. Fisher, who also laid the foundations for the related discipline of quantitative genetics.
p9475
aVTraditionally a highly mathematical discipline, modern population genetics encompasses theoretical, lab and field work. Computational approaches, often using coalescent theory, have played a central role since the 1980s.
p9476
aVFundamentals.
p9477
aVPopulation genetics is the study of the frequency and interaction of alleles and genes in populations. A sexual population is a set of organisms in which any pair of members can breed together. This implies that all members belong to the same species and live near each other.
p9478
aVFor example, all of the moths of the same species living in an isolated forest are a population. A gene in this population may have several alternate forms, which account for variations between the phenotypes of the organisms. An example might be a gene for coloration in moths that has two alleles: black and white. A gene pool is the complete set of alleles for a gene in a single population; the allele frequency for an allele is the fraction of the genes in the pool that is composed of that allele (for example, what fraction of moth coloration genes are the black allele). Evolution occurs when there are changes in the frequencies of alleles within a population; for example, the allele for black color in a population of moths becoming more common.
p9479
aVFour processes.
p9480
aVNatural selection.
p9481
aV"Natural selection" is the fact that some traits make it more likely for an organism to survive and reproduce. Population genetics describes natural selection by defining fitness as a propensity or probability of survival and reproduction in a particular environment. The fitness is normally given by the symbol w=1-s where s is the selection coefficient. Natural selection acts on phenotypes, or the observable characteristics of organisms, but the genetically heritable basis of any phenotype which gives a reproductive advantage will become more common in a population (see allele frequency). In this way, natural selection converts differences in fitness into changes in allele frequency in a population over successive generations.
p9482
aVBefore the advent of population genetics, many biologists doubted that small differences in fitness were sufficient to make a large difference to evolution. Population geneticists addressed this concern in part by comparing selection to genetic drift. Selection can overcome genetic drift when s is greater than 1 divided by the effective population size. When this criterion is met, the probability that a new advantageous mutant becomes fixed is approximately equal to 2s. The time until fixation of such an allele depends little on genetic drift, and is approximately proportional to log(sN)/s.
p9483
aVHardy\u2013Weinberg principle.
p9484
aVNatural selection will only cause evolution if there is enough genetic variation in a population. Before the discovery of Mendelian genetics, one common hypothesis was blending inheritance. But with blending inheritance, genetic variance would be rapidly lost, making evolution by natural selection implausible. The "Hardy\u2013Weinberg principle" provides the solution to how variation is maintained in a population with Mendelian inheritance. According to this principle, the frequencies of alleles (variations in a gene) will remain constant in the absence of selection, mutation, migration and genetic drift. The Hardy\u2013Weinberg "equilibrium" refers to this stability of allele frequencies over time.
p9485
aVA second component of the Hardy\u2013Weinberg principle concerns the effects of a single generation of random mating. In this case, the genotype frequencies can be predicted from the allele frequencies. For example, in the simplest case of a single locus with two alleles: the dominant allele is denoted A and the recessive a and their frequencies are denoted by "p" and "q"; freq(A) = "p"; freq(a) = "q"; "p" + "q" = 1. If the genotype frequencies are in Hardy\u2013Weinberg proportions resulting from random mating, then we will have freq(AA) = "p"2 for the AA homozygotes in the population, freq(aa) = "q"2 for the aa homozygotes, and freq(Aa) = 2"pq" for the heterozygotes.
p9486
aVGenetic drift.
p9487
aV"Genetic drift" is a change in allele frequencies caused by random sampling. That is, the alleles in the offspring are a random sample of those in the parents. Genetic drift may cause gene variants to disappear completely, and thereby reduce genetic variability. In contrast to natural selection, which makes gene variants more common or less common depending on their reproductive success, the changes due to genetic drift are not driven by environmental or adaptive pressures, and may be beneficial, neutral, or detrimental to reproductive success.
p9488
aVThe effect of genetic drift is larger for alleles present in few copies than when an allele is present in many copies. Scientists wage vigorous debates over the relative importance of genetic drift compared with natural selection. Ronald Fisher held the view that genetic drift plays at the most a minor role in evolution, and this remained the dominant view for several decades. In 1968 Motoo Kimura rekindled the debate with his neutral theory of molecular evolution which claims that most of the changes in the genetic material are caused by neutral mutations and genetic drift. The role of genetic drift by means of sampling error in evolution has been criticized by John H Gillespie and Will Provine, who argue that selection on linked sites is a more important stochastic force.
p9489
aVThe population genetics of genetic drift are described using either branching processes or a diffusion equation describing changes in allele frequency. These approaches are usually applied to the Wright-Fisher and Moran models of population genetics. Assuming genetic drift is the only evolutionary force acting on an allele, after t generations in many replicated populations, starting with allele frequencies of p and q, the variance in allele frequency across those populations is
p9490
aVformula_1
p9491
aVMutation.
p9492
aVMutation is the ultimate source of genetic variation in the form of new alleles. Mutation can result in several different types of change in DNA sequences; these can either have no effect, alter the product of a gene, or prevent the gene from functioning. Studies in the fly "Drosophila melanogaster" suggest that if a mutation changes a protein produced by a gene, this will probably be harmful, with about 70 percent of these mutations having damaging effects, and the remainder being either neutral or weakly beneficial.
p9493
aVMutations can involve large sections of DNA becoming duplicated, usually through genetic recombination. These duplications are a major source of raw material for evolving new genes, with tens to hundreds of genes duplicated in animal genomes every million years. Most genes belong to larger families of genes of shared ancestry. Novel genes are produced by several methods, commonly through the duplication and mutation of an ancestral gene, or by recombining parts of different genes to form new combinations with new functions. Here, domains act as modules, each with a particular and independent function, that can be mixed together to produce genes encoding new proteins with novel properties. For example, the human eye uses four genes to make structures that sense light: three for color vision and one for night vision; all four arose from a single ancestral gene. Another advantage of duplicating a gene (or even an entire genome) is that this increases redundancy; this allows one gene in the pair to acquire a new function while the other copy performs the original function. Other types of mutation occasionally create new genes from previously noncoding DNA.
p9494
aVIn addition to being a major source of variation, mutation may also function as a mechanism of evolution when there are different probabilities at the molecular level for different mutations to occur, a process known as mutation bias. If two genotypes, for example one with the nucleotide G and another with the nucleotide A in the same position, have the same fitness, but mutation from G to A happens more often than mutation from A to G, then genotypes with A will tend to evolve. Different insertion vs. deletion mutation biases in different taxa can lead to the evolution of different genome sizes. Developmental or mutational biases have also been observed in morphological evolution. For example, according to the phenotype-first theory of evolution, mutations can eventually cause the genetic assimilation of traits that were previously induced by the environment.
p9495
aVMutation bias effects are superimposed on other processes. If selection would favor either one out of two mutations, but there is no extra advantage to having both, then the mutation that occurs the most frequently is the one that is most likely to become fixed in a population. Mutations leading to the loss of function of a gene are much more common than mutations that produce a new, fully functional gene. Most loss of function mutations are selected against. But when selection is weak, mutation bias towards loss of function can affect evolution. For example, pigments are no longer useful when animals live in the darkness of caves, and tend to be lost. This kind of loss of function can occur because of mutation bias, and/or because the function had a cost, and once the benefit of the function disappeared, natural selection leads to the loss. Loss of sporulation ability in a bacterium during laboratory evolution appears to have been caused by mutation bias, rather than natural selection against the cost of maintaining sporulation ability. When there is no selection for loss of function, the speed at which loss evolves depends more on the mutation rate than it does on the effective population size, indicating that it is driven more by mutation bias than by genetic drift.
p9496
aVEvolution of mutation rate.
p9497
aVDue to the damaging effects that mutations can have on cells, organisms have evolved mechanisms such as DNA repair to remove mutations. Therefore, the optimal mutation rate for a species is a trade-off between costs of a high mutation rate, such as deleterious mutations, and the metabolic costs of maintaining systems to reduce the mutation rate, such as DNA repair enzymes. Viruses that use RNA as their genetic material have rapid mutation rates, which can be an advantage since these viruses will evolve constantly and rapidly, and thus evade the defensive responses of e.g. the human immune system.
p9498
aVGene flow and transfer.
p9499
aVGene flow is the exchange of genes between populations, which are usually of the same species. Examples of gene flow within a species include the migration and then breeding of organisms, or the exchange of pollen. Gene transfer between species includes the formation of hybrid organisms and horizontal gene transfer.
p9500
aVMigration into or out of a population can change allele frequencies, as well as introducing genetic variation into a population. Immigration may add new genetic material to the established gene pool of a population. Conversely, emigration may remove genetic material. Population genetic models can be used to reconstruct the history of gene flow between populations.
p9501
aVReproductive isolation.
p9502
aVAs barriers to reproduction between two diverging populations are required for the populations to become new species, gene flow may slow this process by spreading genetic differences between the populations. Gene flow is hindered by mountain ranges, oceans and deserts or even man-made structures such as the Great Wall of China, which has hindered the flow of plant genes.
p9503
aVDepending on how far two species have diverged since their most recent common ancestor, it may still be possible for them to produce offspring, as with horses and donkeys mating to produce mules. Such hybrids are generally infertile, due to the two different sets of chromosomes being unable to pair up during meiosis. In this case, closely related species may regularly interbreed, but hybrids will be selected against and the species will remain distinct. However, viable hybrids are occasionally formed and these new species can either have properties intermediate between their parent species, or possess a totally new phenotype. The importance of hybridization in creating new species of animals is unclear, although cases have been seen in many types of animals, with the gray tree frog being a particularly well-studied example.
p9504
aVHybridization is, however, an important means of speciation in plants, since polyploidy (having more than two copies of each chromosome) is tolerated in plants more readily than in animals. Polyploidy is important in hybrids as it allows reproduction, with the two different sets of chromosomes each being able to pair with an identical partner during meiosis. Polyploids also have more genetic diversity, which allows them to avoid inbreeding depression in small populations.
p9505
aVGenetic structure.
p9506
aVBecause of physical barriers to migration, along with limited tendency for individuals to move or spread (vagility), and tendency to remain or come back to natal place (philopatry), natural populations rarely all interbreed as convenient in theoretical random models (panmixy) (Buston "et al.", 2007). There is usually a geographic range within which individuals are more closely related to one another than those randomly selected from the general population. This is described as the extent to which a population is genetically structured (Repaci "et al.", 2007). Genetic structuring can be caused by migration due to historical climate change, species range expansion or current availability of habitat.
p9507
aVHorizontal Gene Transfer.
p9508
aV"Horizontal gene transfer" is the transfer of genetic material from one organism to another organism that is not its offspring; this is most common among bacteria. In medicine, this contributes to the spread of antibiotic resistance, as when one bacteria acquires resistance genes it can rapidly transfer them to other species. Horizontal transfer of genes from bacteria to eukaryotes such as the yeast "Saccharomyces cerevisiae" and the adzuki bean beetle "Callosobruchus chinensis" may also have occurred. An example of larger-scale transfers are the eukaryotic bdelloid rotifers, which appear to have received a range of genes from bacteria, fungi, and plants. Viruses can also carry DNA between organisms, allowing transfer of genes even across biological domains. Large-scale gene transfer has also occurred between the ancestors of eukaryotic cells and prokaryotes, during the acquisition of chloroplasts and mitochondria.
p9509
aVComplications.
p9510
aVBasic models of population genetics consider only one gene locus at a time. In practice, epistatic and linkage relationships between loci may also be important.
p9511
aVEpistasis.
p9512
aVBecause of epistasis, the phenotypic effect of an allele at one locus may depend on which alleles are present at many other loci. Selection does not act on a single locus, but on a phenotype that arises through development from a complete genotype.
p9513
aVAccording to Lewontin (1974), the theoretical task for population genetics is a process in two spaces: a "genotypic space" and a "phenotypic space". The challenge of a "complete" theory of population genetics is to provide a set of laws that predictably map a population of genotypes ("G"1) to a phenotype space ("P"1), where selection takes place, and another set of laws that map the resulting population ("P"2) back to genotype space ("G"2) where Mendelian genetics can predict the next generation of genotypes, thus completing the cycle. Even leaving aside for the moment the non-Mendelian aspects of molecular genetics, this is clearly a gargantuan task. Visualizing this transformation schematically:
p9514
aVformula_2
p9515
aV(adapted from Lewontin 1974, p. 12). XD
p9516
aV"T"1 represents the genetic and epigenetic laws, the aspects of functional biology, or development, that transform a genotype into phenotype. We will refer to this as the "genotype-phenotype map". "T"2 is the transformation due to natural selection, "T"3 are epigenetic relations that predict genotypes based on the selected phenotypes and finally "T"4 the rules of Mendelian genetics.
p9517
aVIn practice, there are two bodies of evolutionary theory that exist in parallel, traditional population genetics operating in the genotype space and the biometric theory used in plant and animal breeding, operating in phenotype space. The missing part is the mapping between the genotype and phenotype space. This leads to a "sleight of hand" (as Lewontin terms it) whereby variables in the equations of one domain, are considered parameters or "constants", where, in a full-treatment they would be transformed themselves by the evolutionary process and are in reality "functions" of the state variables in the other domain. The "sleight of hand" is assuming that we know this mapping. Proceeding as if we do understand it is enough to analyze many cases of interest. For example, if the phenotype is almost one-to-one with genotype (sickle-cell disease) or the time-scale is sufficiently short, the "constants" can be treated as such; however, there are many situations where it is inaccurate.
p9518
aVLinkage.
p9519
aVIf all genes are in linkage equilibrium, the effect of an allele at one locus can be averaged across the gene pool at other loci. In reality, one allele is frequently found in linkage disequilibrium with genes at other loci, especially with genes located nearby on the same chromosome. Recombination breaks up this linkage disequilibrium too slowly to avoid genetic hitchhiking, where an allele at one locus rises to high frequency because it is linked to an allele under selection at a nearby locus. This is a problem for population genetic models that treat one gene locus at a time. It can, however, be exploited as a method for detecting the action of natural selection via selective sweeps.
p9520
aVIn the extreme case of primarily asexual populations, linkage is complete, and different population genetic equations can be derived and solved, which behave quite differently from the sexual case. Most microbes, such as bacteria, are asexual. The population genetics of microorganisms lays the foundations for tracking the origin and evolution of antibiotic resistance and deadly infectious pathogens. Population genetics of microorganisms is also an essential factor for devising strategies for the conservation and better utilization of beneficial microbes (Xu, 2010).
p9521
aVHistory.
p9522
aV"Population genetics" began as a reconciliation of the Mendelian and biometrician models. A key step was the work of the British biologist and statistician R.A. Fisher. In a series of papers starting in 1918 and culminating in his 1930 book "The Genetical Theory of Natural Selection", Fisher showed that the continuous variation measured by the biometricians could be produced by the combined action of many discrete genes, and that natural selection could change allele frequencies in a population, resulting in evolution. In a series of papers beginning in 1924, another British geneticist, J.B.S. Haldane worked out the mathematics of allele frequency change at a single gene locus under a broad range of conditions. Haldane also applied statistical analysis to real-world examples of natural selection, such as the evolution of industrial melanism in peppered moths, and showed that selection coefficients could be larger than Fisher assumed, leading to more rapid adaptive evolution.
p9523
aVThe American biologist Sewall Wright, who had a background in animal breeding experiments, focused on combinations of interacting genes, and the effects of inbreeding on small, relatively isolated populations that exhibited genetic drift. In 1932, Wright introduced the concept of an adaptive landscape and argued that genetic drift and inbreeding could drive a small, isolated sub-population away from an adaptive peak, allowing natural selection to drive it towards different adaptive peaks.
p9524
aVThe work of Fisher, Haldane and Wright founded the discipline of "population genetics". This integrated natural selection with Mendelian genetics, which was the critical first step in developing a unified theory of how evolution worked. John Maynard Smith was Haldane's pupil, whilst W.D. Hamilton was heavily influenced by the writings of Fisher. The American George R. Price worked with both Hamilton and Maynard Smith. American Richard Lewontin and Japanese Motoo Kimura were heavily influenced by Wright.
p9525
aVModern evolutionary synthesis.
p9526
aVThe mathematics of population genetics were originally developed as the beginning of the modern evolutionary synthesis. According to Beatty (1986), population genetics defines the core of the modern synthesis. In the first few decades of the 20th century, most field naturalists continued to believe that Lamarckian and orthogenic mechanisms of evolution provided the best explanation for the complexity they observed in the living world. However, as the field of genetics continued to develop, those views became less tenable. During the modern evolutionary synthesis, these ideas were purged, and only evolutionary causes that could be expressed in the mathematical framework of population genetics were retained. Consensus was reached as to which evolutionary factors might influence evolution, but not as to the relative importance of the various factors.
p9527
aVTheodosius Dobzhansky, a postdoctoral worker in T. H. Morgan's lab, had been influenced by the work on genetic diversity by Russian geneticists such as Sergei Chetverikov. He helped to bridge the divide between the foundations of microevolution developed by the population geneticists and the patterns of macroevolution observed by field biologists, with his 1937 book "Genetics and the Origin of Species". Dobzhansky examined the genetic diversity of wild populations and showed that, contrary to the assumptions of the population geneticists, these populations had large amounts of genetic diversity, with marked differences between sub-populations. The book also took the highly mathematical work of the population geneticists and put it into a more accessible form. Many more biologists were influenced by population genetics via Dobzhansky than were able to read the highly mathematical works in the original.
p9528
aVSelection vs. genetic drift.
p9529
aVFisher and Wright had some fundamental disagreements and a controversy about the relative roles of selection and drift continued for much of the century between the Americans and the British.
p9530
aVIn Great Britain E.B. Ford, the pioneer of ecological genetics, continued throughout the 1930s and 1940s to demonstrate the power of selection due to ecological factors including the ability to maintain genetic diversity through genetic polymorphisms such as human blood types. Ford's work, in collaboration with Fisher, contributed to a shift in emphasis during the course of the modern synthesis towards natural selection over genetic drift.
p9531
aVRecent studies of eukaryotic transposable elements, and of their impact on speciation, point again to a major role of nonadaptive processes such as mutation and genetic drift. Mutation and genetic drift are also viewed as major factors in the evolution of genome complexity
p9532
asS'Gamma function'
p9533
(lp9534
VIn mathematics, the gamma function (represented by the capital Greek letter \u0393) is an extension of the factorial function, with its argument shifted down by 1, to real and complex numbers. That is, if "n" is a positive integer:
p9535
aVformula_1
p9536
aVThe gamma function is defined for all complex numbers except the non-positive integers. For complex numbers with a positive real part, it is defined via a convergent improper integral:
p9537
aVformula_2
p9538
aVThis integral function is extended by analytic continuation to all complex numbers except the non-positive integers (where the function has simple poles), yielding the meromorphic function we call the gamma function. In fact the gamma function corresponds to the Mellin transform of the negative exponential function:
p9539
aVformula_3
p9540
aVThe gamma function is a component in various probability-distribution functions, and as such it is applicable in the fields of probability and statistics, as well as combinatorics.
p9541
aVMotivation.
p9542
aVThe gamma function can be seen as a solution to the following interpolation problem:
p9543
aV "Find a smooth curve that connects the points ("x", "y") given by "y" = ("x" \u2212 1)! at the positive integer values for "x"."
p9544
aVA plot of the first few factorials makes clear that such a curve can be drawn, but it would be preferable to have a formula that precisely describes the curve, in which the number of operations does not depend on the size of "x". The simple formula for the factorial, "n"! = 1 × 2 × \u2026 × "n", cannot be used directly for fractional values of "x" since it is only valid when "x" is a natural number ("i.e.", a positive integer). There are, relatively speaking, no such simple solutions for factorials; no finite combination of sums, products, powers, exponential functions, or logarithms will suffice to express "x"!. Stirling's approximation is asymptotically equal to the factorial function for large values of "x". It is possible to find a general formula for factorials using tools such as integrals and limits from calculus. A good solution to this is the gamma function.
p9545
aVThere are infinitely many continuous extensions of the factorial to non-integers: infinitely many curves can be drawn through any set of isolated points. The gamma function is the most useful solution in practice, being analytic (except at the non-positive integers), and it can be characterized in several ways. However, it is not the only analytic function which extends the factorial, as adding to it any analytic function which is zero on the positive integers, such as "k" sin "n"\u2009, will give another function with that property.
p9546
aVA more restrictive property than satisfying the above interpolation is to satisfy the recurrence relation defining a translated version of the factorial function,
p9547
aVformula_4
p9548
aVfor "x" equal to any positive real number. The Bohr\u2013Mollerup theorem proves that these properties, together with the assumption that "f" be logarithmically convex (or "superconvex"), uniquely determine "f" for positive, real inputs. From there, the gamma function can be extended to all real and complex values (except the negative integers and zero) by using the unique analytic continuation of "f".
p9549
aVDefinition.
p9550
aVMain definition.
p9551
aVThe notation \u0393("t") is due to Legendre. If the real part of the complex number "t" is positive (Re("t") > 0), then the integral
p9552
aVformula_5
p9553
aVconverges absolutely, and is known as the Euler integral of the second kind (the Euler integral of the first kind defines the Beta function). Using integration by parts, we see that the gamma function satisfies the functional equation:
p9554
aVformula_6
p9555
aVCombining this with \u0393(1) = 1, we get:
p9556
aVformula_7
p9557
aVfor all positive integers "n".
p9558
aVThe identity \u0393("t") = \u0393("t"+1)/"t" can be used (or, yielding the same result, analytic continuation can be used) to extend the integral formulation for \u0393("t") to a meromorphic function defined for all complex numbers "t", except "t" = \u2212"n" for integers "n" \u2265 0, where the function has simple poles with residue (\u22121)"n"/"n"!.
p9559
aVIt is this extended version that is commonly referred to as the gamma function.
p9560
aVAlternative definitions.
p9561
aVThe following infinite product definitions for the gamma function, due to Euler and Weierstrass respectively, are valid for all complex numbers "t", except the non-positive integers:
p9562
aVformula_8
p9563
aVwhere \u03b3 \u2248 0.577216... is the Euler\u2013Mascheroni constant. It is straightforward to show that the Euler definition satisfies the functional equation (1) above.
p9564
aVA somewhat curious parametrization of the gamma function is given in terms of generalized Laguerre polynomials,
p9565
aVformula_9
p9566
aVwhich converges for Re("t") < 1/2.
p9567
aVThe gamma function in the complex plane.
p9568
aVThe behavior of \u0393("t") for an increasing positive variable is simple: it grows quickly \u2014 faster than an exponential function. Asymptotically as "t" \u2192 \u221e, the magnitude of the gamma function is given by Stirling's formula
p9569
aVformula_10
p9570
aVwhere the symbol ~ means that the quotient of both sides converges to 1.
p9571
aVThe behavior for nonpositive "t" is more intricate. Euler's integral does not converge for "t" \u2264 0, but the function it defines in the positive complex half-plane has a unique analytic continuation to the negative half-plane. One way to find that analytic continuation is to use Euler's integral for positive arguments and extend the domain to negative numbers by repeated application of the recurrence formula,
p9572
aVformula_11
p9573
aVchoosing "n" such that "t" + "n" is positive. The product in the denominator is zero when "t" equals any of the integers 0, \u22121, \u22122... . Thus, the gamma function must be undefined at those points; it is a meromorphic function with simple poles at the nonpositive integers. The residues of the function at those points are:
p9574
aVformula_12
p9575
aVThe gamma function is nonzero everywhere along the real line, although it comes arbitrarily close to zero as "t" \u2192 \u2212\u221e. There is in fact no complex number "t" for which \u0393("t") = 0, and hence the "reciprocal gamma function" 1/\u0393 is an entire function, with zeros at "t" = 0, \u22121, \u22122, ... The gamma function has a local minimum at formula_13 where it attains the value formula_14. The gamma function must alternate sign between the poles because the product in the forward recurrence contains an odd number of negative factors if the number of poles between "t" and "t"+"n" is odd, and an even number if the number of poles is even.
p9576
aVProperties.
p9577
aVGeneral.
p9578
aVOther important functional equations for the gamma function are Euler's reflection formula
p9579
aVformula_15
p9580
aVwhich implies
p9581
aVformula_16
p9582
aVand the duplication formula
p9583
aVformula_17
p9584
aVThe duplication formula is a special case of the multiplication theorem
p9585
aVformula_18
p9586
aVA simple but useful property, which can be seen from the limit definition, is:
p9587
aVformula_19
p9588
aVPerhaps the best-known value of the gamma function at a non-integer argument is
p9589
aVformula_20
p9590
aVwhich can be found by setting "z" = 1/2 in the reflection or duplication formulas, by using the relation to the beta function given below with "x" = "y" = 1/2, or simply by making the substitution "u" = \u221a"x" in the integral definition of the gamma function, resulting in a Gaussian integral. In general, for non-negative integer values of "n" we have:
p9591
aVformula_21
p9592
aVwhere "n"!! denotes the double factorial and, when "n" = 0, "n"!! = 1. See Particular values of the gamma function for calculated values.
p9593
aVIt might be tempting to generalize the result that \u0393(1/2) = \u221a\u03c0 by looking for a formula for other individual values \u0393("r") where "r" is rational. However, these numbers are not known to be expressible by themselves in terms of elementary functions. It has been proved that \u0393("n"+"r") is a transcendental number and algebraically independent of \u03c0 for any integer "n" and each of the fractions "r" = 1/6, 1/4, 1/3, 2/3, 3/4, and 5/6. In general, when computing values of the gamma function, we must settle for numerical approximations.
p9594
aVAnother useful limit for asymptotic approximations is:
p9595
aVformula_22
p9596
aVThe derivatives of the gamma function are described in terms of the polygamma function. For example:
p9597
aVformula_23
p9598
aVFor positive integer "m" the derivative of gamma function can be calculated as follows (here \u03b3 is the Euler\u2013Mascheroni constant):
p9599
aVformula_24
p9600
aVFor Re("x") > 0 The "n"-th derivative of the gamma function is:
p9601
aVformula_25
p9602
aVThe gamma function has simple poles at "z" = \u2212"n" = 0, \u22121, \u22122, \u22123, \u2026 The residue there is
p9603
aVformula_12
p9604
aVMoreover, the gamma function has the following Laurent expansion in 1
p9605
aVformula_27
p9606
aVvalid for |"z" \u2212 1| < 1. In particular
p9607
aVformula_28.
p9608
aVThe Bohr\u2013Mollerup theorem states that among all functions extending the factorial functions to the positive real numbers, only the gamma function is log-convex, that is, its natural logarithm is convex on the positive real axis.
p9609
aVIn a certain sense, the log(\u0393)-function is the more natural form; it makes some intrinsic attributes of the function clearer. A striking example is the Taylor series of log(\u0393) in 1:
p9610
aVformula_29
p9611
aVwith \u03b6("k") denoting the Riemann zeta function at "k".
p9612
aVSo, using the following property formula_30, we can find the integral representation for log(\u0393)-function:
p9613
aVformula_31
p9614
aVor, setting z=1 and calculating formula_32:
p9615
aVformula_33
p9616
aVFourier series expansion.
p9617
aVThe logarithm of the gamma function has the following Fourier series expansion
p9618
aVformula_34
p9619
aVwhich has been long-time attributed to Ernst Kummer who derived it in 1847. However, it was comparatively recently that it was discovered by Iaroslav Blagouchine that this series was first derived by Carl Johan Malmsten in 1842.
p9620
aVRaabe's formula.
p9621
aVIn 1840 Raabe proved that
p9622
aVformula_35
p9623
aVIn particular, if formula_36 then
p9624
aVformula_37
p9625
aVPi function.
p9626
aVAn alternative notation which was originally introduced by Gauss and which was sometimes used is the "Pi function", which in terms of the gamma function is
p9627
aVformula_38
p9628
aVso that
p9629
aVformula_39
p9630
aVfor every non-negative integer "n".
p9631
aVUsing the Pi function the reflection formula takes on the form
p9632
aVformula_40
p9633
aVwhere sinc is the normalized sinc function, while the multiplication theorem takes on the form
p9634
aVformula_41
p9635
aVWe also sometimes find
p9636
aVformula_42
p9637
aVwhich is an entire function, defined for every complex number, just like the reciprocal gamma function. That \u03c0("z") is entire entails it has no poles, so \u03a0("z"), like \u0393("z"), has no zeros.
p9638
aVThe Volume of an "n"-ellipsoid with radii formula_43 can be expressed as
p9639
aVformula_44
p9640
aV:formula_45
p9641
aV:formula_46
p9642
aVAnd also in the following elegant formula:
p9643
aV:formula_47 
p9644
aVwhich is valid only for Re("z") > 1.
p9645
aV The logarithm of the gamma function satisfies the following formula due to Lerch:
p9646
aV:formula_48
p9647
aV where \u03b6"H" is the Hurwitz zeta function, \u03b6 is the Riemann zeta function and the prime (') denotes differentiation in the first variable.
p9648
aV: formula_49
p9649
aVParticular values.
p9650
aVSome particular values of the gamma function are:
p9651
aVformula_50
p9652
aVApproximations.
p9653
aVComplex values of the gamma function can be computed numerically with arbitrary precision using Stirling's approximation or the Lanczos approximation.
p9654
aVThe gamma function can be computed to fixed precision for Re("z") \u2208 [1, 2] by applying integration by parts to Euler's integral. For any positive number "x" the gamma function can be written
p9655
aVformula_51
p9656
aVWhen Re("z") \u2208 [1, 2] and "x" \u2265 1, the absolute value of the last integral is smaller than ("x" + 1) "e\u2212x". By choosing a large enough "x", this last expression can be made smaller than 2\u2212"N" for any desired value "N". Thus, the gamma function can be evaluated to "N" bits of precision with the above series.
p9657
aVThe only fast algorithm for calculation of the Euler gamma function for any algebraic argument (including rational) was constructed by E.A. Karatsuba,
p9658
aVFor arguments that are integer multiples of 1/24 the gamma function can also be evaluated quickly using arithmetic-geometric mean iterations (see particular values of the gamma function).
p9659
aVBecause the Gamma and factorial functions grow so rapidly for moderately large arguments, many computing environments include a function that returns the natural logarithm of the gamma function (often given the name "lgamma" or "lngamma" in programming environments or "gammaln" in spreadsheets); this grows much more slowly, and for combinatorial calculations allows adding and subtracting logs instead of multiplying and dividing very large values. The digamma function, which is the derivative of this function, is also commonly seen.
p9660
aVIn the context of technical and physical applications, e.g. with wave propagation, the functional equation
p9661
aVformula_52
p9662
aVis often used since it allows one to determine function values in one strip of width 1 in "z" from the neighbouring strip. In particular, starting with a good approximation for a "z" with large real part one may go step by step down to the desired "z". Following an indication of Carl Friedrich Gauss, Rocktaeschel (1922) proposed for ln(\u0393("z")) an approximation for large Re("z"):
p9663
aVformula_53
p9664
aVThis can be used to accurately approximate ln(\u0393("z")) for "z" with a smaller Re("z") via (P.E.Böhmer, 1939)
p9665
aVformula_54
p9666
aVA more accurate approximation can be obtained by using more terms from the asymptotic expansions of ln(\u0393("z")) and \u0393("z"), which are based on Stirling's approximation.
p9667
aVformula_55
p9668
aVIn a more "natural" presentation:
p9669
aVformula_56
p9670
aVformula_57
p9671
aVThe coefficients of the terms with "k" > 1 of "z"\u2212"k"+1 in the last expansion are simply
p9672
aVformula_58
p9673
aVwhere the "Bk" are the Bernoulli numbers.
p9674
aVApplications.
p9675
aVOpening a random page in an advanced table of formulas, one may be as likely to spot the gamma function as a trigonometric function. One author describes the gamma function as "Arguably, the most common special function, or the least 'special' of them. The other transcendental functions listed below are called 'special' because you could conceivably avoid some of them by staying away from many specialized mathematical topics. On the other hand, the gamma function "y" = \u0393("x") is most difficult to avoid."
p9676
aVIntegration problems.
p9677
aVThe gamma function finds application in such diverse areas as quantum physics, astrophysics and fluid dynamics. The gamma distribution, which is formulated in terms of the gamma function, is used in statistics to model a wide range of processes; for example, the time between occurrences of earthquakes.
p9678
aVThe primary reason for the gamma function's usefulness in such contexts is the prevalence of expressions of the type formula_59 which describe processes that decay exponentially in time or space. Integrals of such expressions can occasionally be solved in terms of the gamma function when no elementary solution exists. For example, if "f" is a power function and "g" is a linear function, a simple change of variables gives the evaluation
p9679
aVformula_60
p9680
aVThe fact that the integration is performed along the entire positive real line might signify that the gamma function describes the cumulation of a time-dependent process that continues indefinitely, or the value might be the total of a distribution in an infinite space.
p9681
aVIt is of course frequently useful to take limits of integration other than 0 and \u221e to describe the cumulation of a finite process, in which case the ordinary gamma function is no longer a solution; the solution is then called an incomplete gamma function. (The ordinary gamma function, obtained by integrating across the entire positive real line, is sometimes called the "complete gamma function" for contrast).
p9682
aVAn important category of exponentially decaying functions is that of Gaussian functions 
p9683
aVformula_61 
p9684
aVand integrals thereof, such as the error function. There are many interrelations between these functions and the gamma function; notably, the square root of \u03c0 we obtained by evaluating \u0393(1/2) is the "same" as that found in the normalizing factor of the error function and the normal distribution.
p9685
aVThe integrals we have discussed so far involve transcendental functions, but the gamma function also arises from integrals of purely algebraic functions. In particular, the arc lengths of ellipses and of the lemniscate, which are curves defined by algebraic equations, are given by elliptic integrals that in special cases can be evaluated in terms of the gamma function. The gamma function can also be used to calculate "volume" and "area" of "n"-dimensional hyperspheres.
p9686
aVAnother important special case is that of the beta function
p9687
aVformula_62
p9688
aVCalculating products.
p9689
aVThe gamma function's ability to generalize factorial products immediately leads to applications in many areas of mathematics; in combinatorics, and by extension in areas such as probability theory and the calculation of power series. Many expressions involving products of successive integers can be written as some combination of factorials, the most important example perhaps being that of the binomial coefficient
p9690
aVformula_63
p9691
aVThe example of binomial coefficients motivates why the properties of the gamma function when extended to negative numbers are natural. A binomial coefficient gives the number of ways to choose "k" elements from a set of "n" elements; if "k" > "n", there are of course no ways. If "k" > "n", ("n"\u2212"k")! is the factorial of a negative integer and hence infinite if we use the gamma function definition of factorials \u2014 dividing by infinity gives the expected value of 0.
p9692
aVWe can replace the factorial by a gamma function to extend any such formula to the complex numbers. Generally, this works for any product wherein each factor is a rational function of the index variable, by factoring the rational function into linear expressions. If "P" and "Q" are monic polynomials of degree "m" and "n" with respective roots formula_64 and formula_65, we have
p9693
aVformula_66
p9694
aVIf we have a way to calculate the gamma function numerically, it is a breeze to calculate numerical values of such products. The number of gamma functions in the right-hand side depends only on the degree of the polynomials, so it does not matter whether "b"\u2212"a" equals 5 or 105. Moreover, due to the poles of the gamma function, the equation also holds (in the sense of taking limits) when the left-hand product contain zeros or poles.
p9695
aVBy taking limits, certain rational products with infinitely many factors can be evaluated in terms of the gamma function as well. Due to the Weierstrass factorization theorem, analytic functions can be written as infinite products, and these can sometimes be represented as finite products or quotients of the gamma function. We have already seen one striking example: the reflection formula essentially represents the sine function as the product of two gamma functions. Starting from this formula, the exponential function as well as all the trigonometric and hyperbolic functions can be expressed in terms of the gamma function.
p9696
aVMore functions yet, including the hypergeometric function and special cases thereof, can be represented by means of complex contour integrals of products and quotients of the gamma function, called Mellin-Barnes integrals.
p9697
aVAnalytic number theory.
p9698
aVAn elegant and deep application of the gamma function is in the study of the Riemann zeta function. A fundamental property of the Riemann zeta function is its functional equation:
p9699
aVformula_67
p9700
aVAmong other things, this provides an explicit form for the analytic continuation of the zeta function to a meromorphic function in the complex plane and leads to an immediate proof that the zeta function has infinitely many so-called "trivial" zeros on the real line. Borwein "et al". call this formula "one of the most beautiful findings in mathematics". Another champion for that title might be
p9701
aVformula_68
p9702
aVBoth formulas were derived by Bernhard Riemann in his seminal 1859 paper "Über die Anzahl der Primzahlen unter einer gegebenen Grösse" ("On the Number of Prime Numbers less than a Given Quantity"), one of the milestones in the development of analytic number theory \u2014 the branch of mathematics that studies prime numbers using the tools of mathematical analysis. Factorial numbers, considered as discrete objects, are an important concept in classical number theory because they contain many prime factors, but Riemann found a use for their continuous extension that arguably turned out to be even more important.
p9703
aVHistory.
p9704
aVThe gamma function has caught the interest of some of the most prominent mathematicians of all time. Its history, notably documented by Philip J. Davis in an article that won him the 1963 Chauvenet Prize, reflects many of the major developments within mathematics since the 18th century. In the words of Davis, "each generation has found something of interest to say about the gamma function. Perhaps the next generation will also."
p9705
aV18th century: Euler and Stirling.
p9706
aVThe problem of extending the factorial to non-integer arguments was apparently first considered by Daniel Bernoulli and Christian Goldbach in the 1720s, and was solved at the end of the same decade by Leonhard Euler. Euler gave two different definitions: the first was not his integral but an infinite product,
p9707
aVformula_69
p9708
aVof which he informed Goldbach in a letter dated October 13, 1729. He wrote to Goldbach again on January 8, 1730, to announce his discovery of the integral representation
p9709
aVformula_70
p9710
aVwhich is valid for "n" > 0. By the change of variables "t" = \u2212ln "s", this becomes the familiar Euler integral. Euler published his results in the paper "De progressionibus transcendentibus seu quarum termini generales algebraice dari nequeunt" ("On transcendental progressions, that is, those whose general terms cannot be given algebraically"), submitted to the St. Petersburg Academy on November 28, 1729. Euler further discovered some of the gamma function's important functional properties, including the reflection formula.
p9711
aVJames Stirling, a contemporary of Euler, also attempted to find a continuous expression for the factorial and came up with what is now known as Stirling's formula. Although Stirling's formula gives a good estimate of "n"!, also for non-integers, it does not provide the exact value. Extensions of his formula that correct the error were given by Stirling himself and by Jacques Philippe Marie Binet.
p9712
aV19th century: Gauss, Weierstrass and Legendre.
p9713
aVCarl Friedrich Gauss rewrote Euler's product as
p9714
aVformula_71
p9715
aVand used this formula to discover new properties of the gamma function. Although Euler was a pioneer in the theory of complex variables, he does not appear to have considered the factorial of a complex number, as instead Gauss first did. Gauss also proved the multiplication theorem of the gamma function and investigated the connection between the gamma function and elliptic integrals.
p9716
aVKarl Weierstrass further established the role of the gamma function in complex analysis, starting from yet another product representation,
p9717
aVformula_72
p9718
aVwhere \u03b3 is the Euler\u2013Mascheroni constant. Weierstrass originally wrote his product as one for 1/\u0393, in which case it is taken over the function's zeros rather than its poles. Inspired by this result, he proved what is known as the Weierstrass factorization theorem\u2014that any entire function can be written as a product over its zeros in the complex plane; a generalization of the fundamental theorem of algebra.
p9719
aVThe name gamma function and the symbol \u0393 were introduced by Adrien-Marie Legendre around 1811; Legendre also rewrote Euler's integral definition in its modern form. Although the symbol is an upper-case Greek gamma, there is no accepted standard for whether the function name should be written "gamma function" or "Gamma function" (some authors simply write "\u0393-function"). The alternative "Pi function" notation \u03a0("z") = "z"! due to Gauss is sometimes encountered in older literature, but Legendre's notation is dominant in modern works.
p9720
aVIt is justified to ask why we distinguish between the "ordinary factorial" and the gamma function by using distinct symbols, and particularly why the gamma function should be normalized to \u0393("n"+1) = "n"! instead of simply using "\u0393("n") = "n"!". Consider that the notation for exponents, "xn", has been generalized from integers to complex numbers "xz" without any change. Legendre's motivation for the normalization does not appear to be known, and has been criticized as cumbersome by some (the 20th-century mathematician Cornelius Lanczos, for example, called it "void of any rationality" and would instead use "z"!). Legendre's normalization does simplify a few formulas, but complicates most others. From a modern point of view, the Legendre normalization of the Gamma function is the integral of the additive character "e\u2212x" against the multiplicative character "xz" with respect to the Haar measure "dx"/"x" on the Lie group R+. Thus this normalization makes it clearer that the Gamma function is a continuous analogue of a Gauss sum.
p9721
aV19th-20th centuries: characterizing the gamma function.
p9722
aVIt is somewhat problematic that a large number of definitions have been given for the gamma function. Although they describe the same function, it is not entirely straightforward to prove the equivalence. Stirling never proved that his extended formula corresponds exactly to Euler's gamma function; a proof was first given by Charles Hermite in 1900. Instead of finding a specialized proof for each formula, it would be desirable to have a general method of identifying the gamma function.
p9723
aVOne way to prove would be to find a differential equation that characterizes the gamma function. Most special functions in applied mathematics arise as solutions to differential equations, whose solutions are unique. However, the gamma function does not appear to satisfy any simple differential equation. Otto Hölder proved in 1887 that the gamma function at least does not satisfy any "algebraic" differential equation by showing that a solution to such an equation could not satisfy the gamma function's recurrence formula. This result is known as Hölder's theorem.
p9724
aVA definite and generally applicable characterization of the gamma function was not given until 1922. Harald Bohr and Johannes Mollerup then proved what is known as the "Bohr\u2013Mollerup theorem": that the gamma function is the unique solution to the factorial recurrence relation that is positive and "logarithmically convex" for positive "z" and whose value at 1 is 1 (a function is logarithmically convex if its logarithm is convex).
p9725
aVThe Bohr\u2013Mollerup theorem is useful because it is relatively easy to prove logarithmic convexity for any of the different formulas used to define the gamma function. Taking things further, instead of defining the gamma function by any particular formula, we can choose the conditions of the Bohr\u2013Mollerup theorem as the definition, and then pick any formula we like that satisfies the conditions as a starting point for studying the gamma function. This approach was used by the Bourbaki group.
p9726
aVReference tables and software.
p9727
aVAlthough the gamma function can be calculated virtually as easily as any mathematically simpler function with a modern computer\u2014even with a programmable pocket calculator\u2014this was of course not always the case. Until the mid-20th century, mathematicians relied on hand-made tables; in the case of the gamma function, notably a table computed by Gauss in 1813 and one computed by Legendre in 1825.
p9728
aVTables of complex values of the gamma function, as well as hand-drawn graphs, were given in "Tables of Higher Functions" by Jahnke and Emde, first published in Germany in 1909. According to Michael Berry, "the publication in J&E of a three-dimensional graph showing the poles of the gamma function in the complex plane acquired an almost iconic status."
p9729
aVThere was in fact little practical need for anything but real values of the gamma function until the 1930s, when applications for the complex gamma function were discovered in theoretical physics. As electronic computers became available for the production of tables in the 1950s, several extensive tables for the complex gamma function were published to meet the demand, including a table accurate to 12 decimal places from the U.S. National Bureau of Standards.
p9730
aV"Abramowitz and Stegun" became the standard reference for this and many other special functions after its publication in 1964.
p9731
aVDouble-precision floating-point implementations of the gamma function and its logarithm are now available in most scientific computing software and special functions libraries, for example TK Solver, Matlab, GNU Octave, and the GNU Scientific Library. The gamma function was also added to the C standard library (math.h). Arbitrary-precision implementations are available in most computer algebra systems, such as Mathematica and Maple. PARI/GP, MPFR and MPFUN contain free arbitrary-precision implementations.
p9732
asS'Decimal separator'
p9733
(lp9734
sS"Zeno's paradoxes"
p9735
(lp9736
VZeno's paradoxes are a set of philosophical problems generally thought to have been devised by Greek philosopher Zeno of Elea (ca. 490\u2013430 BC) to support Parmenides's doctrine that contrary to the evidence of one's senses, the belief in plurality and change is mistaken, and in particular that motion is nothing but an illusion. It is usually assumed, based on Plato's "Parmenides" (128a\u2013d), that Zeno took on the project of creating these paradoxes because other philosophers had created paradoxes against Parmenides's view. Thus Plato has Zeno say the purpose of the paradoxes "is to show that their hypothesis that existences are many, if properly followed up, leads to still more absurd results than the hypothesis that they are one." ("Parmenides" 128d). Plato has Socrates claim that Zeno and Parmenides were essentially arguing exactly the same point ("Parmenides" 128a\u2013b).
p9737
aVSome of Zeno's nine surviving paradoxes (preserved in Aristotle's "Physics"
p9738
aVand Simplicius's commentary thereon) are essentially equivalent to one another. Aristotle offered a refutation of some of them. Three of the strongest and most famous\u2014that of Achilles and the tortoise, the Dichotomy argument, and that of an arrow in flight\u2014are presented in detail below.
p9739
aVZeno's arguments are perhaps the first examples of a method of proof called "reductio ad absurdum" also known as proof by contradiction. They are also credited as a source of the dialectic method used by Socrates.
p9740
aVSome mathematicians and historians, such as Carl Boyer, hold that Zeno's paradoxes are simply mathematical problems, for which modern calculus provides a mathematical solution.
p9741
aVSome philosophers, however, say that Zeno's paradoxes and their variations (see Thomson's lamp) remain relevant metaphysical problems.
p9742
aVThe origins of the paradoxes are somewhat unclear. Diogenes Laertius, a fourth source for information about Zeno and his teachings, citing Favorinus, says that Zeno's teacher Parmenides was the first to introduce the Achilles and the tortoise paradox. But in a later passage, Laertius attributes the origin of the paradox to Zeno, explaining that Favorinus disagrees.
p9743
aVParadoxes of motion.
p9744
aVAchilles and the tortoise.
p9745
aVIn the paradox of Achilles and the Tortoise, Achilles is in a footrace with the tortoise. Achilles allows the tortoise a head start of 100 meters, for example. If we suppose that each racer starts running at some constant speed (one very fast and one very slow), then after some finite time, Achilles will have run 100 meters, bringing him to the tortoise's starting point. During this time, the tortoise has run a much shorter distance, say, 10 meters. It will then take Achilles some further time to run that distance, by which time the tortoise will have advanced farther; and then more time still to reach this third point, while the tortoise moves ahead. Thus, whenever Achilles reaches somewhere the tortoise has been, he still has farther to go. Therefore, because there are an infinite number of points Achilles must reach where the tortoise has already been, he can never overtake the tortoise.
p9746
aVDichotomy paradox.
p9747
aVSuppose Homer wants to catch a stationary bus. Before he can get there, he must get halfway there. Before he can get halfway there, he must get a quarter of the way there. Before traveling a quarter, he must travel one-eighth; before an eighth, one-sixteenth; and so on.
p9748
aVThe resulting sequence can be represented as:
p9749
aVformula_1
p9750
aVThis description requires one to complete an infinite number of tasks, which Zeno maintains is an impossibility.
p9751
aVThis sequence also presents a second problem in that it contains no first distance to run, for any possible (finite) first distance could be divided in half, and hence would not be first after all. Hence, the trip cannot even begin. The paradoxical conclusion then would be that travel over any finite distance can neither be completed nor begun, and so all motion must be an illusion. An alternative conclusion, proposed by Henri Bergson, is that motion (time and distance) is not actually divisible.
p9752
aVThis argument is called the "Dichotomy" because it involves repeatedly splitting a distance into two parts. It contains some of the same elements as the "Achilles and the Tortoise" paradox, but with a more apparent conclusion of motionlessness. It is also known as the Race Course paradox. Some, like Aristotle, regard the Dichotomy as really just another version of "Achilles and the Tortoise".
p9753
aVThere are two versions of the dichotomy paradox. In the other version, before Homer could reach the stationary bus, he must reach half of the distance to it. Before reaching the last half, he must complete the next quarter of the distance. Reaching the next quarter, he must then cover the next eighth of the distance, then the next sixteenth, and so on. There are thus an infinite number of steps that must first be accomplished before he could reach the bus. Expressed this way, the dichotomy paradox is very much analogous to that of "Achilles and the tortoise".
p9754
aVArrow paradox.
p9755
aVIn the arrow paradox (also known as the fletcher's paradox'"), Zeno states that for motion to occur, an object must change the position which it occupies. He gives an example of an arrow in flight. He states that in any one (durationless) instant of time, the arrow is neither moving to where it is, nor to where it is not.
p9756
aVIt cannot move to where it is not, because no time elapses for it to move there; it cannot move to where it is, because it is already there. In other words, at every instant of time there is no motion occurring. If everything is motionless at every instant, and time is entirely composed of instants, then motion is impossible.
p9757
aVWhereas the first two paradoxes divide space, this paradox starts by dividing time\u2014and not into segments, but into points.
p9758
aVThree other paradoxes as given by Aristotle.
p9759
aVParadox of Place.
p9760
aVFrom Aristotle:
p9761
aVParadox of the Grain of Millet.
p9762
aVFrom Aristotle:
p9763
aVDescription of the paradox from the "Routledge Dictionary of Philosophy":
p9764
aVDescription from Nick Huggett:
p9765
aVThe Moving Rows (or Stadium).
p9766
aVFrom Aristotle:
p9767
aVFor an expanded account of Zeno's arguments as presented by Aristotle, see Simplicius' commentary "On Aristotle's Physics".
p9768
aVProposed solutions.
p9769
aVSimplicius of Cilicia.
p9770
aVAccording to Simplicius, Diogenes the Cynic said nothing upon hearing Zeno's arguments, but stood up and walked, in order to demonstrate the falsity of Zeno's conclusions. To fully solve any of the paradoxes, however, one needs to show what is wrong with the argument, not just the conclusions. Through history, several solutions have been proposed, among the earliest recorded being those of Aristotle and Archimedes.
p9771
aVAristotle.
p9772
aVAristotle (384 BC\u2212322 BC) remarked that as the distance decreases, the time needed to cover those distances also decreases, so that the time needed also becomes increasingly small.
p9773
aVAristotle also distinguished "things infinite in respect of divisibility" (such as a unit of space that can be mentally divided into ever smaller units while remaining spatially the same) from things (or distances) that are infinite in extension ("with respect to their extremities").
p9774
aVAristotle's objection to the arrow paradox was that "Time is not composed of indivisible nows any more than any other magnitude is composed of indivisibles."
p9775
aVThomas Aquinas.
p9776
aVThomas Aquinas, commenting on Aristotle's objection, wrote "Instants are not parts of time, for time is not made up of instants any more than a magnitude is made of points, as we have already proved. Hence it does not follow that a thing is not in motion in a given time, just because it is not in motion in any instant of that time."
p9777
aVArchimedes.
p9778
aVBefore 212 BC, Archimedes had developed a method to derive a finite answer for the sum of infinitely many terms that get progressively smaller. (See: Geometric series, 1/4 + 1/16 + 1/64 + 1/256 + · · ·, The Quadrature of the Parabola.) Modern calculus achieves the same result, using more rigorous methods (see convergent series, where the "reciprocals of powers of 2" series, equivalent to the Dichotomy Paradox, is listed as convergent). These methods allow the construction of solutions based on the conditions stipulated by Zeno, i.e. the amount of time taken at each step is geometrically decreasing.
p9779
aVBertrand Russell.
p9780
aVBertrand Russell offered what is known as the "at-at theory of motion". It agrees that there can be no motion "during" a durationless instant, and contends that all that is required for motion is that the arrow be at one point at one time, at another point another time, and at appropriate points between those two points for intervening times. In this view motion is a function of position with respect to time.
p9781
aVNick Huggett.
p9782
aVNick Huggett argues that Zeno is begging the question when he says that objects that occupy the same space as they do at rest must be at rest.
p9783
aVPeter Lynds.
p9784
aVPeter Lynds has argued that all of Zeno's motion paradoxes are resolved by the conclusion that instants in time and instantaneous magnitudes do not physically exist.
p9785
aVLynds argues that an object in relative motion cannot have an instantaneous or determined relative position (for if it did, it could not be in motion), and so cannot have its motion fractionally dissected as if it does, as is assumed by the paradoxes. For more about the inability to know both speed and location, see Heisenberg uncertainty principle.
p9786
aVHermann Weyl.
p9787
aVAnother proposed solution is to question one of the assumptions Zeno used in his paradoxes (particularly the Dichotomy), which is that between any two different points in space (or time), there is always another point. Without this assumption there are only a finite number of distances between two points, hence there is no infinite sequence of movements, and the paradox is resolved. The ideas of Planck length and Planck time in modern physics place a limit on the measurement of time and space, if not on time and space themselves. According to Hermann Weyl, the assumption that space is made of finite and discrete units is subject to a further problem, given by the "tile argument" or "distance function problem".
p9788
aVAccording to this, the length of the hypotenuse of a right angled triangle in discretized space is always equal to the length of one of the two sides, in contradiction to geometry. Jean Paul Van Bendegem has argued that the Tile Argument can be resolved, and that discretization can therefore remove the paradox.
p9789
aVHans Reichenbach.
p9790
aVHans Reichenbach has proposed that the paradox may arise from considering space and time as separate entities. In a theory like general relativity, which presumes a single space-time continuum, the paradox may be blocked.
p9791
aVThe paradoxes in modern times.
p9792
aVInfinite processes remained theoretically troublesome in mathematics until the late 19th century. The epsilon-delta version of Weierstrass and Cauchy developed a rigorous formulation of the logic and calculus involved. These works resolved the mathematics involving infinite processes.
p9793
aVWhile mathematics can calculate where and when the moving Achilles will overtake the Tortoise of Zeno's paradox, philosophers such as Brown and Moorcroft
p9794
aVclaim that mathematics does not address the central point in Zeno's argument, and that solving the mathematical issues does not solve every issue the paradoxes raise.
p9795
aVPopular literature often misrepresents Zeno's arguments. For example, Zeno is often said to have argued that the sum of an infinite number of terms must itself be infinite\u2013with the result that not only the time, but also the distance to be travelled, become infinite. However, none of the original ancient sources has Zeno discussing the sum of any infinite series. Simplicius has Zeno saying "it is impossible to traverse an infinite number of things in a finite time". This presents Zeno's problem not with finding the "sum", but rather with "finishing" a task with an infinite number of steps: how can one ever get from A to B, if an infinite number of (non-instantaneous) events can be identified that need to precede the arrival at B, and one cannot reach even the beginning of a "last event"?
p9796
aVDebate continues on the question of whether or not Zeno's paradoxes have been resolved. In "The History of Mathematics: An Introduction" (2010) Burton writes, "Although Zeno's argument confounded his contemporaries, a satisfactory explanation incorporates a now-familiar idea, the notion of a 'convergent infinite series.'".
p9797
aVBertrand Russell offered a "solution" to the paradoxes based on modern physics, but Brown concludes "Given the history of 'final resolutions', from Aristotle onwards, it's probably foolhardy to think we've reached the end. It may be that Zeno's arguments on motion, because of their simplicity and universality, will always serve as a kind of 'Rorschach image' onto which people can project their most fundamental phenomenological concerns (if they have any)."
p9798
aVPat Corvini offers a solution to the paradox of Achilles and the tortoise by first distinguishing the physical world from the abstract mathematics used to describe it. She claims the paradox arises from a subtle but fatal switch between the physical and abstract. Zeno's syllogism is as follows:
p9799
aVCorvini shows that P1 is a mathematical abstraction which cannot be applied directly to P2 which is a statement regarding the physical world. The physical world requires a resolution amount used to distinguish distance while mathematics can use any resolution.
p9800
aVQuantum Zeno effect.
p9801
aVIn 1977,
p9802
aVphysicists E. C. G. Sudarshan and B. Misra studying quantum mechanics discovered that the dynamical evolution (motion) of a quantum system can be hindered (or even inhibited) through observation of the system.
p9803
aVThis effect is usually called the "quantum Zeno effect" as it is strongly reminiscent of Zeno's arrow paradox. This effect was first theorized in 1958.
p9804
aVZeno behaviour.
p9805
aVIn the field of verification and design of timed and hybrid systems, the system behaviour is called "Zeno" if it includes an infinite number of discrete steps in a finite amount of time.
p9806
aVSome formal verification techniques exclude these behaviours from analysis, if they are not equivalent to non-Zeno behaviour.
p9807
aVIn systems design these behaviours will also often be excluded from system models, since they cannot be implemented with a digital controller.
p9808
aVA simple example of a system showing Zeno behaviour is a bouncing ball coming to rest. The physics of a bouncing ball, ignoring factors other than rebound, can be mathematically analyzed to predict an infinite number of bounces.
p9809
asS'Daubechies wavelet'
p9810
(lp9811
VThe Daubechies wavelets, based on the work of Ingrid Daubechies, are a family of orthogonal wavelets defining a discrete wavelet transform and characterized by a maximal number of vanishing moments for some given support. With each wavelet type of this class, there is a scaling function (called the "father wavelet") which generates an orthogonal multiresolution analysis.
p9812
aVProperties.
p9813
aVIn general the Daubechies wavelets are chosen to have the highest number "A" of vanishing moments, (this does not imply the best smoothness) for given support width "N=2A". There are two naming schemes in use, D"N" using the length or number of taps, and db"A" referring to the number of vanishing moments. So D4 and db2 are the same wavelet transform.
p9814
aVAmong the 2"A"\u22121 possible solutions of the algebraic equations for the moment and orthogonality conditions, the one is chosen whose scaling filter has extremal phase. The wavelet transform is also easy to put into practice using the fast wavelet transform. Daubechies wavelets are widely used in solving a broad range of problems, e.g. self-similarity properties of a signal or fractal problems, signal discontinuities, etc.
p9815
aVThe Daubechies wavelets are not defined in terms of the resulting scaling and wavelet functions; in fact, they are not possible to write down in closed form. The graphs below are generated using the cascade algorithm, a numeric technique consisting of simply inverse-transforming 0 0 0 0 ... an appropriate number of times.
p9816
aVNote that the spectra shown here are not the frequency response of the high and low pass filters, but rather the amplitudes of the continuous Fourier transforms of the scaling (blue) and wavelet (red) functions. 
p9817
aVDaubechies orthogonal wavelets D2-D20 resp. db1-db10 are commonly used. The index number refers to the number "N" of coefficients. Each wavelet has a number of "zero moments" or "vanishing moments" equal to half the number of coefficients. For example, D2 (the Haar wavelet) has one vanishing moment, D4 has two, etc. A vanishing moment limits the wavelets ability to represent polynomial behaviour or information in a signal. For example, D2, with one moment, easily encodes polynomials of one coefficient, or constant signal components. D4 encodes polynomials with two coefficients, i.e. constant and linear signal components; and D6 encodes 3-polynomials, i.e. constant, linear and quadratic signal components. This ability to encode signals is nonetheless subject to the phenomenon of "scale leakage", and the lack of shift-invariance, which raise from the discrete shifting operation (below) during application of the transform. Sub-sequences which represent linear, quadratic (for example) signal components are treated differently by the transform depending on whether the points align with even- or odd-numbered locations in the sequence. The lack of the important property of shift-invariance, has led to the development of several different versions of a shift-invariant (discrete) wavelet transform.
p9818
aVConstruction.
p9819
aVBoth the scaling sequence (Low-Pass Filter) and the wavelet sequence (Band-Pass Filter) (see orthogonal wavelet for details of this construction) will here be normalized to have sum equal 2 and sum of squares equal 2. In some applications, they are normalised to have sum formula_1, so that both sequences and all shifts of them by an even number of coefficients are orthonormal to each other. 
p9820
aVUsing the general representation for a scaling sequence of an orthogonal discrete wavelet transform with approximation order "A", 
p9821
aVformula_2, with "N=2A", "p" having real coefficients, "p(1)=1" and "degree(p)=A-1", 
p9822
aVone can write the orthogonality condition as
p9823
aVformula_3, or equally as formula_4 (*),
p9824
aVwith the Laurent-polynomial formula_5 generating all symmetric sequences and formula_6. Further, "P(X)" stands for the symmetric Laurent-polynomial formula_7. Since formula_8 and formula_9, "P" takes nonnegative values on the segment "[0,2]".
p9825
aVEquation (*) has one minimal solution for each "A", which can be obtained by division in the ring 
p9826
aVof truncated power series in "X",
p9827
aVformula_10.
p9828
aVObviously, this has positive values on "(0,2)"
p9829
aVThe homogeneous equation for (*) is antisymmetric about "X=1" and has thus the general solution formula_11, with "R" some polynomial with real coefficients. That the sum
p9830
aVformula_12
p9831
aVshall be nonnegative on the interval "translates into a set of linear restrictions on the coefficients of "R". The values of "P" on the interval "[0,2" are bounded by some quantity formula_13, maximizing "r" results in a linear program with infinitely many inequality conditions.
p9832
aVTo solve formula_7 for "p" one uses a technique called spectral factorization resp. Fejér-Riesz-algorithm. The polynomial "P(X)" splits into linear factors formula_15, "N=A+1+2deg(R)". Each linear factor represents a Laurent-polynomial formula_16 that can be factored into two linear factors.
p9833
aVOne can assign either one of the two linear factors to "p(Z)", thus one obtains 2N possible solutions. For extremal phase one chooses the one that has all complex roots of "p(Z)" inside or on the unit circle and is thus real.
p9834
aVThe scaling sequences of lowest approximation order.
p9835
aVBelow are the coefficients for the scaling functions for D2-20. The wavelet coefficients are derived by reversing the order of the scaling function coefficients and then reversing the sign of every second one, (i.e., D4 wavelet = {-0.1830127, -0.3169873, 1.1830127, -0.6830127}). Mathematically, this looks like 
p9836
aVformula_17
p9837
aVwhere "k" is the coefficient index, "b" is a coefficient of the wavelet sequence and "a" a coefficient of the scaling sequence. "N" is the wavelet index, i.e., 2 for D2.
p9838
aVParts of the construction are also used to derive the biorthogonal Cohen-Daubechies-Feauveau wavelets (CDFs).
p9839
aVImplementation.
p9840
aVWhile software such as Mathematica supports Daubechies wavelets directly a basic implementation is simple in MATLAB (in this case, Daubechies 4). This implementation uses periodization to handle the problem of finite length signals. Other, more sophisticated methods are available, but often it is not necessary to use these as it only affects the very ends of the transformed signal. The periodization is accomplished in the forward transform directly in MATLAB vector notation, and the inverse transform by using the circshift() function:
p9841
aVTransform, D4.
p9842
aVIt is assumed that S, a column vector with an even number of elements, has been pre-defined as the signal to be analyzed.
p9843
asS'Chaos theory'
p9844
(lp9845
VChaos theory is a field of study in mathematics, with applications in several disciplines including meteorology, sociology, physics, engineering, economics, biology, and philosophy. Chaos theory studies the behavior of dynamical systems that are highly sensitive to initial conditions\u2014a response popularly referred to as the butterfly effect. Small differences in initial conditions (such as those due to rounding errors in numerical computation) yield widely diverging outcomes for such dynamical systems, rendering long-term prediction impossible in general. This happens even though these systems are deterministic, meaning that their future behavior is fully determined by their initial conditions, with no random elements involved. In other words, the deterministic nature of these systems does not make them predictable. This behavior is known as "deterministic chaos", or simply "chaos". The theory was summarized by Edward Lorenz as follows:
p9846
aVChaos: When the present determines the future, but the approximate present does not approximately determine the future.
p9847
aVChaotic behavior can be observed in many natural systems, such as weather and climate. This behavior can be studied through analysis of a chaotic mathematical model, or through analytical techniques such as recurrence plots and Poincaré maps.
p9848
aVIntroduction.
p9849
aVChaos theory concerns deterministic systems whose behavior can in principle be predicted. Chaotic systems are predictable for a while and then "appear" to become random. The amount of time for which the behavior of a chaotic system can be effectively predicted depends on three things: How much uncertainty we are willing to tolerate in the forecast; how accurately we are able to measure its current state; and a time scale depending on the dynamics of the system, called the Lyapunov time. Some examples of Lyapunov times are: chaotic electrical circuits, ~1 millisecond; weather systems, a couple of days (unproven); the solar system, 50 million years. In chaotic systems the uncertainty in a forecast increases exponentially with elapsed time. Hence doubling the forecast time more than squares the proportional uncertainty in the forecast. This means that in practice a meaningful prediction cannot be made over an interval of more than two or three times the Lyapunov time. When meaningful predictions cannot be made, the system appears to be random.
p9850
aVChaotic dynamics.
p9851
aVIn common usage, "chaos" means "a state of disorder". However, in chaos theory, the term is defined more precisely. Although there is no universally accepted mathematical definition of chaos, a commonly used definition says that, for a dynamical system to be classified as chaotic, it must have the following properties:
p9852
aVSensitivity to initial conditions.
p9853
aV"Sensitivity to initial conditions" means that each point in a chaotic system is arbitrarily closely approximated by other points with significantly different future paths, or trajectories. Thus, an arbitrarily small change, or perturbation, of the current trajectory may lead to significantly different future behavior.
p9854
aVIt has been shown that in some cases the last two properties in the above actually imply sensitivity to initial conditions, and if attention is restricted to intervals, the second property implies the other two (an alternative, and in general weaker, definition of chaos uses only the first two properties in the above list). It is interesting that the most practically significant property, that of sensitivity to initial conditions, is redundant in the definition, being implied by two (or for intervals, one) purely topological properties, which are therefore of greater interest to mathematicians.
p9855
aVSensitivity to initial conditions is popularly known as the "butterfly effect", so called because of the title of a paper given by Edward Lorenz in 1972 to the American Association for the Advancement of Science in Washington, D.C., entitled "Predictability: Does the Flap of a Butterfly\u2019s Wings in Brazil set off a Tornado in Texas?". The flapping wing represents a small change in the initial condition of the system, which causes a chain of events leading to large-scale phenomena. Had the butterfly not flapped its wings, the trajectory of the system might have been vastly different.
p9856
aVA consequence of sensitivity to initial conditions is that if we start with only a finite amount of information about the system (as is usually the case in practice), then beyond a certain time the system will no longer be predictable. This is most familiar in the case of weather, which is generally predictable only about a week ahead. Of course this does not mean that we cannot say anything about events far in the future; there are some restrictions on the system. With weather, we know that the temperature will never reach 100 degrees Celsius or fall to -130 degrees Celsius on earth, but we are not able to say exactly what day we will have the hottest temperature of the year.
p9857
aVIn more mathematical terms, the Lyapunov exponent measures the sensitivity to initial conditions. Given two starting trajectories in the phase space that are infinitesimally close, with initial separation formula_1 end up diverging at a rate given by
p9858
aVformula_2
p9859
aVwhere t is the time and \u03bb is the Lyapunov exponent. The rate of separation depends on the orientation of the initial separation vector, so there is a whole spectrum of Lyapunov exponents. The number of Lyapunov exponents is equal to the number of dimensions of the phase space, though it is common to just refer to the largest one. For example, the maximal Lyapunov exponent (MLE) is most often used because it determines the overall predictability of the system. A positive MLE is usually taken as an indication that the system is chaotic.
p9860
aVThere are also other properties that relate to sensitivity of initial conditions, such as measure-theoretical mixing (as discussed in ergodic theory) and properties of a K-system.
p9861
aVTopological mixing.
p9862
aV"Topological mixing" (or "topological transitivity") means that the system will evolve over time so that any given region or open set of its phase space will eventually overlap with any other given region. This mathematical concept of "mixing" corresponds to the standard intuition, and the mixing of colored dyes or fluids is an example of a chaotic system.
p9863
aVTopological mixing is often omitted from popular accounts of chaos, which equate chaos with only sensitivity to initial conditions. However, sensitive dependence on initial conditions alone does not give chaos. For example, consider the simple dynamical system produced by repeatedly doubling an initial value. This system has sensitive dependence on initial conditions everywhere, since any pair of nearby points will eventually become widely separated. However, this example has no topological mixing, and therefore has no chaos. Indeed, it has extremely simple behavior: all points except 0 will tend to positive or negative infinity.
p9864
aVDensity of periodic orbits.
p9865
aVFor a chaotic system to have a "dense periodic orbit" means that every point in the space is approached arbitrarily closely by periodic orbits. The one-dimensional logistic map defined by "x" \u2192 4 "x" (1 \u2013 "x") is one of the simplest systems with density of periodic orbits. For example, formula_3 \u2192 formula_4 \u2192 formula_3 (or approximately 0.3454915 \u2192 0.9045085 \u2192 0.3454915) is an (unstable) orbit of period 2, and similar orbits exist for periods 4, 8, 16, etc. (indeed, for all the periods specified by Sharkovskii's theorem).
p9866
aVSharkovskii's theorem is the basis of the Li and Yorke (1975) proof that any one-dimensional system that exhibits a regular cycle of period three will also display regular cycles of every other length as well as completely chaotic orbits.
p9867
aVStrange attractors.
p9868
aVSome dynamical systems, like the one-dimensional logistic map defined by "x" \u2192 4 "x" (1 \u2013 "x"), are chaotic everywhere, but in many cases chaotic behavior is found only in a subset of phase space. The cases of most interest arise when the chaotic behavior takes place on an attractor, since then a large set of initial conditions will lead to orbits that converge to this chaotic region.
p9869
aVAn easy way to visualize a chaotic attractor is to start with a point in the basin of attraction of the attractor, and then simply plot its subsequent orbit. Because of the topological transitivity condition, this is likely to produce a picture of the entire final attractor, and indeed both orbits shown in the figure on the right give a picture of the general shape of the Lorenz attractor. This attractor results from a simple three-dimensional model of the Lorenz weather system. The Lorenz attractor is perhaps one of the best-known chaotic system diagrams, probably because it was not only one of the first, but it is also one of the most complex and as such gives rise to a very interesting pattern, that with a little imagination, looks like the wings of a butterfly.
p9870
aVUnlike fixed-point attractors and limit cycles, the attractors that arise from chaotic systems, known as "strange attractors", have great detail and complexity. Strange attractors occur in both continuous dynamical systems (such as the Lorenz system) and in some discrete systems (such as the Hénon map). Other discrete dynamical systems have a repelling structure called a Julia set which forms at the boundary between basins of attraction of fixed points \u2013 Julia sets can be thought of as strange "repellers". Both strange attractors and Julia sets typically have a fractal structure, and the fractal dimension can be calculated for them.
p9871
aVMinimum complexity of a chaotic system.
p9872
aVDiscrete chaotic systems, such as the logistic map, can exhibit strange attractors whatever their dimensionality. In contrast, for continuous dynamical systems, the Poincaré\u2013Bendixson theorem shows that a strange attractor can only arise in three or more dimensions. Finite-dimensional linear systems are never chaotic; for a dynamical system to display chaotic behavior, it has to be either nonlinear or infinite-dimensional.
p9873
aVThe Poincaré\u2013Bendixson theorem states that a two-dimensional differential equation has very regular behavior. The Lorenz attractor discussed above is generated by a system of three differential equations such as:
p9874
aV formula_6
p9875
aVwhere formula_7, formula_8, and formula_9 make up the system state, formula_10 is time, and formula_11, formula_12, formula_13 are the system parameters. Five of the terms on the right hand side are linear, while two are quadratic; a total of seven terms. Another well-known chaotic attractor is generated by the Rossler equations which have only one nonlinear term out of seven. Sprott found a three-dimensional system with just five terms, that had only one nonlinear term, which exhibits chaos for certain parameter values. Zhang and Heidel showed that, at least for dissipative and conservative quadratic systems, three-dimensional quadratic systems with only three or four terms on the right-hand side cannot exhibit chaotic behavior. The reason is, simply put, that solutions to such systems are asymptotic to a two-dimensional surface and therefore solutions are well behaved.
p9876
aVWhile the Poincaré\u2013Bendixson theorem shows that a continuous dynamical system on the Euclidean plane cannot be chaotic, two-dimensional continuous systems with non-Euclidean geometry can exhibit chaotic behavior. Perhaps surprisingly, chaos may occur also in linear systems, provided they are infinite dimensional. A theory of linear chaos is being developed in a branch of mathematical analysis known as functional analysis.
p9877
aVJerk systems.
p9878
aVIn physics, jerk is the third derivative of position, and as such, in mathematics differential equations of the form
p9879
aV: formula_14
p9880
aVare sometimes called "Jerk equations". It has been shown, that a jerk equation, which is equivalent to a system of three first order, ordinary, non-linear differential equation is in a certain sense the minimal setting for solutions showing chaotic behaviour. This motivates mathematical interest in "jerk systems". Systems involving a fourth or higher derivative are called accordingly "hyperjerk systems".
p9881
aVA "jerk system" is a system whose behavior is described by a "jerk equation", and for certain jerk equations simple electronic circuits may be designed which model the solutions to this equation. These circuits are known as "jerk circuits".
p9882
aVOne of the most interesting properties of jerk circuits is the possibility of chaotic behavior. In fact, certain well-known chaotic systems, such as the Lorenz attractor and the Rössler map, are conventionally described as a system of three first-order differential equations, but which may be combined into a single (although rather complicated) jerk equation. It has been shown, that non-linear jerk systems are in a sense minimally complex systems to show chaotic behaviour, there is no chaotic system involving only "two" first order, ordinary differential equations (the system resulting in an equation of "second" order only).
p9883
aVAn example of a jerk equation with non-linearity in the magnitude of formula_7, is:
p9884
aVformula_16
p9885
aVHere "A" is an adjustable parameter. This equation has a chaotic solution for A=3/5 and can be implemented with the following jerk circuit; the required non-linearity is brought about by the two diodes:
p9886
aVIn the above circuit, all resistors are of equal value, except formula_17, and all capacitors are of equal size. The dominant frequency will be formula_18. The output of op amp 0 will correspond to the x variable, the output of 1 will correspond to the first derivative of x and the output of 2 will correspond to the second derivative.
p9887
aVSpontaneous order.
p9888
aVUnder the right conditions chaos will spontaneously evolve into a lockstep pattern. In the Kuramoto model, four conditions suffice to produce synchronization in a chaotic system.
p9889
aVExamples include the coupled oscillation of Christiaan Huygens' pendulums, fireflies, neurons, the London Millenium Bridge resonance, and large arrays of Josephson junctions.
p9890
aVHistory.
p9891
aVAn early proponent of chaos theory was Henri Poincaré. In the 1880s, while studying the three-body problem, he found that there can be orbits that are nonperiodic, and yet not forever increasing nor approaching a fixed point. In 1898 Jacques Hadamard published an influential study of the chaotic motion of a free particle gliding frictionlessly on a surface of constant negative curvature, called "Hadamard's billiards". Hadamard was able to show that all trajectories are unstable, in that all particle trajectories diverge exponentially from one another, with a positive Lyapunov exponent.
p9892
aVChaos Theory got its start in the field of ergodic theory. Later studies, also on the topic of nonlinear differential equations, were carried out by George David Birkhoff, , Mary Lucy Cartwright and John Edensor Littlewood, and Stephen Smale. Except for Smale, these studies were all directly inspired by physics: the three-body problem in the case of Birkhoff, turbulence and astronomical problems in the case of Kolmogorov, and radio engineering in the case of Cartwright and Littlewood. Although chaotic planetary motion had not been observed, experimentalists had encountered turbulence in fluid motion and nonperiodic oscillation in radio circuits without the benefit of a theory to explain what they were seeing.
p9893
aVDespite initial insights in the first half of the twentieth century, chaos theory became formalized as such only after mid-century, when it first became evident to some scientists that linear theory, the prevailing system theory at that time, simply could not explain the observed behavior of certain experiments like that of the logistic map. What had been attributed to measure imprecision and simple "noise" was considered by chaos theorists as a full component of the studied systems.
p9894
aVThe main catalyst for the development of chaos theory was the electronic computer. Much of the mathematics of chaos theory involves the repeated iteration of simple mathematical formulas, which would be impractical to do by hand. Electronic computers made these repeated calculations practical, while figures and images made it possible to visualize these systems. As a graduate student in Chihiro Hayashi's laboratory at Kyoto University, Yoshisuke Ueda was experimenting with analog computers and noticed, on Nov. 27, 1961, what he called "randomly transitional phenomena". Yet his advisor did not agree with his conclusions at the time, and did not allow him to report his findings until 1970.
p9895
aVAn early pioneer of the theory was Edward Lorenz whose interest in chaos came about accidentally through his work on weather prediction in 1961. Lorenz was using a simple digital computer, a Royal McBee LGP-30, to run his weather simulation. He wanted to see a sequence of data again and to save time he started the simulation in the middle of its course. He was able to do this by entering a printout of the data corresponding to conditions in the middle of his simulation which he had calculated last time. To his surprise the weather that the machine began to predict was completely different from the weather calculated before. Lorenz tracked this down to the computer printout. The computer worked with 6-digit precision, but the printout rounded variables off to a 3-digit number, so a value like 0.506127 was printed as 0.506. This difference is tiny and the consensus at the time would have been that it should have had practically no effect. However, Lorenz had discovered that small changes in initial conditions produced large changes in the long-term outcome. Lorenz's discovery, which gave its name to Lorenz attractors, showed that even detailed atmospheric modelling cannot, in general, make precise long-term weather predictions.
p9896
aVIn 1963, Benoit Mandelbrot found recurring patterns at every scale in data on cotton prices. Beforehand he had studied information theory and concluded noise was patterned like a Cantor set: on any scale the proportion of noise-containing periods to error-free periods was a constant \u2013 thus errors were inevitable and must be planned for by incorporating redundancy. Mandelbrot described both the "Noah effect" (in which sudden discontinuous changes can occur) and the "Joseph effect" (in which persistence of a value can occur for a while, yet suddenly change afterwards). This challenged the idea that changes in price were normally distributed. In 1967, he published "How long is the coast of Britain? Statistical self-similarity and fractional dimension", showing that a coastline's length varies with the scale of the measuring instrument, resembles itself at all scales, and is infinite in length for an infinitesimally small measuring device. Arguing that a ball of twine appears to be a point when viewed from far away (0-dimensional), a ball when viewed from fairly near (3-dimensional), or a curved strand (1-dimensional), he argued that the dimensions of an object are relative to the observer and may be fractional. An object whose irregularity is constant over different scales ("self-similarity") is a fractal (examples include the Menger sponge, the Sierpi\u0144ski gasket, and the Koch curve or "snowflake", which is infinitely long yet encloses a finite space and has a fractal dimension of circa 1.2619). In 1982 Mandelbrot published "The Fractal Geometry of Nature", which became a classic of chaos theory. Biological systems such as the branching of the circulatory and bronchial systems proved to fit a fractal model.
p9897
aVIn December 1977, the New York Academy of Sciences organized the first symposium on Chaos, attended by David Ruelle, Robert May, James A. Yorke (coiner of the term "chaos" as used in mathematics), Robert Shaw, and the meteorologist Edward Lorenz. The following year, independently Pierre Coullet and Charles Tresser with the article "Iterations d'endomorphismes et groupe de renormalisation" and Mitchell Feigenbaum with the article "Quantitative Universality for a Class of Nonlinear Transformations" described logistic maps. They notably discovered the universality in chaos, permitting the application of chaos theory to many different phenomena.
p9898
aVIn 1979, Albert J. Libchaber, during a symposium organized in Aspen by Pierre Hohenberg, presented his experimental observation of the bifurcation cascade that leads to chaos and turbulence in Rayleigh\u2013Bénard convection systems. He was awarded the Wolf Prize in Physics in 1986 along with Mitchell J. Feigenbaum for their inspiring achievements.
p9899
aVIn 1986, the New York Academy of Sciences co-organized with the National Institute of Mental Health and the Office of Naval Research the first important conference on chaos in biology and medicine. There, Bernardo Huberman presented a mathematical model of the eye tracking disorder among schizophrenics. This led to a renewal of physiology in the 1980s through the application of chaos theory, for example, in the study of pathological cardiac cycles.
p9900
aVIn 1987, Per Bak, Chao Tang and Kurt Wiesenfeld published a paper in "Physical Review Letters" describing for the first time self-organized criticality (SOC), considered to be one of the mechanisms by which complexity arises in nature.
p9901
aVAlongside largely lab-based approaches such as the Bak\u2013Tang\u2013Wiesenfeld sandpile, many other investigations have focused on large-scale natural or social systems that are known (or suspected) to display scale-invariant behavior. Although these approaches were not always welcomed (at least initially) by specialists in the subjects examined, SOC has nevertheless become established as a strong candidate for explaining a number of natural phenomena, including earthquakes (which, long before SOC was discovered, were known as a source of scale-invariant behavior such as the Gutenberg\u2013Richter law describing the statistical distribution of earthquake sizes, and the Omori law describing the frequency of aftershocks), solar flares, fluctuations in economic systems such as financial markets (references to SOC are common in econophysics), landscape formation, forest fires, landslides, epidemics, and biological evolution (where SOC has been invoked, for example, as the dynamical mechanism behind the theory of "punctuated equilibria" put forward by Niles Eldredge and Stephen Jay Gould). Given the implications of a scale-free distribution of event sizes, some researchers have suggested that another phenomenon that should be considered an example of SOC is the occurrence of wars. These investigations of SOC have included both attempts at modelling (either developing new models or adapting existing ones to the specifics of a given natural system), and extensive data analysis to determine the existence and/or characteristics of natural scaling laws.
p9902
aVIn the same year, James Gleick published "", which became a best-seller and introduced the general principles of chaos theory as well as its history to the broad public, though his history under-emphasized important Soviet contributions. Initially the domain of a few, isolated individuals, chaos theory progressively emerged as a transdisciplinary and institutional discipline, mainly under the name of nonlinear systems analysis. Alluding to Thomas Kuhn's concept of a paradigm shift exposed in "The Structure of Scientific Revolutions" (1962), many "chaologists" (as some described themselves) claimed that this new theory was an example of such a shift, a thesis upheld by Gleick.
p9903
aVThe availability of cheaper, more powerful computers broadens the applicability of chaos theory. Currently, chaos theory continues to be a very active area of research, involving many different disciplines (mathematics, topology, physics, social systems, population modeling, biology, meteorology, astrophysics, information theory, computational neuroscience, etc.).
p9904
aVDistinguishing random from chaotic data.
p9905
aVIt can be difficult to tell from data whether a physical or other observed process is random or chaotic, because in practice no time series consists of a pure "signal". There will always be some form of corrupting noise, even if it is present as round-off or truncation error. Thus any real time series, even if mostly deterministic, will contain some (pseudo-)randomness.
p9906
aVAll methods for distinguishing deterministic and stochastic processes rely on the fact that a deterministic system always evolves in the same way from a given starting point. Thus, given a time series to test for determinism, one can
p9907
aVDefine the error as the difference between the time evolution of the test state and the time evolution of the nearby state. A deterministic system will have an error that either remains small (stable, regular solution) or increases exponentially with time (chaos). A stochastic system will have a randomly distributed error.
p9908
aVEssentially, all measures of determinism taken from time series rely upon finding the closest states to a given test state (e.g., correlation dimension, Lyapunov exponents, etc.). To define the state of a system, one typically relies on phase space embedding methods.
p9909
aVTypically one chooses an embedding dimension and investigates the propagation of the error between two nearby states. If the error looks random, one increases the dimension. If the dimension can be increased to obtain a deterministically looking error, then analysis is done. Though it may sound simple, one complication is that as the dimension increases, the search for a nearby state requires a lot more computation time and a lot of data (the amount of data required increases exponentially with embedding dimension) to find a suitably close candidate. If the embedding dimension (number of measures per state) is chosen too small (less than the "true" value), deterministic data can appear to be random, but in theory there is no problem choosing the dimension too large \u2013 the method will work.
p9910
aVWhen a nonlinear deterministic system is attended by external fluctuations, its trajectories present serious and permanent distortions. Furthermore, the noise is amplified due to the inherent nonlinearity and reveals totally new dynamical properties. Statistical tests attempting to separate noise from the deterministic skeleton or inversely isolate the deterministic part risk failure. Things become worse when the deterministic component is a nonlinear feedback system. In presence of interactions between nonlinear deterministic components and noise, the resulting nonlinear series can display dynamics that traditional tests for nonlinearity are sometimes not able to capture.
p9911
aVThe question of how to distinguish deterministic chaotic systems from stochastic systems has also been discussed in philosophy. It has been shown that they might be
p9912
aVobservationally equivalent.
p9913
aVApplications.
p9914
aVChaos theory was born from observing weather patterns, but it has become applicable to a variety of other situations. Some areas benefiting from chaos theory today are geology, mathematics, microbiology, biology, computer science, economics, engineering, finance, algorithmic trading, meteorology, philosophy, physics, politics, population dynamics, psychology, and robotics. A few categories are listed below with examples, but this is by no means a comprehensive list as new applications are appearing every day.
p9915
aVComputer science.
p9916
aVChaos theory is not new to computer science and has been used for many years in cryptography. One type of encryption, secret key or symmetric key, relies on diffusion and confusion, which is modeled well by chaos theory. Another type of computing, DNA computing, when paired with chaos theory, offers a more efficient way to encrypt images and other information. Robotics is another area that has recently benefited from chaos theory. Instead of robots acting in a trial-and-error type of refinement to interact with their environment, chaos theory has been used to build a predictive model.
p9917
aVChaotic dynamics have been exhibited by passive walking biped robots.
p9918
aVBiology.
p9919
aVFor over a hundred years, biologists have been keeping track of populations of different species with population models. Most models are deterministic systems, but recently scientists have been able to implement chaotic models in certain populations. For example, a study on models of Canadian lynx showed there was chaotic behavior in the population growth. Chaos can also be found in ecological systems, such as hydrology. While a chaotic model for hydrology has its shortcomings, there is still much to be learned from looking at the data through the lens of chaos theory. Another biological application is found in cardiotocography. Fetal surveillance is a delicate balance of obtaining accurate information while being as noninvasive as possible. Better models of warning signs of fetal hypoxia can be obtained through chaotic modeling.
p9920
aVOther areas.
p9921
aVIn chemistry, predicting gas solubility is essential to manufacturing polymers, but models using particle swarm optimization (PSO) tend to converge to the wrong points. An improved version of PSO has been created by introducing chaos, which keeps the simulations from getting stuck. In celestial mechanics, especially when observing asteroids, applying chaos theory leads to better predictions about when these objects will come in range of Earth and other planets. In quantum physics and electrical engineering, the study of large arrays of Josephson junctions benefitted greatly from chaos theory. Closer to home, coal mines have always been dangerous places where frequent natural gas leaks cause many deaths. Until recently, there was no reliable way to predict when they would occur. But these gas leaks have chaotic tendencies that, when properly modeled, can be predicted fairly accurately.
p9922
aVChaos theory can be applied outside of the natural sciences. By adapting a model of career counseling to include a chaotic interpretation of the relationship between employees and the job market, better suggestions can be made to people struggling with career decisions. Modern organizations are increasingly seen as open complex adaptive systems, with fundamental natural nonlinear structures, subject to internal and external forces which may be sources of chaos. The chaos metaphor\u2014used in verbal theories\u2014grounded on mathematical models and psychological aspects of human behavior
p9923
aVprovides helpful insights to describing the complexity of small work groups, that go beyond the metaphor itself.
p9924
aVIt is possible that economic models can also be improved through an application of chaos theory, but predicting the health of an economic system and what factors influence it most is an extremely complex task. Economic and financial systems are fundamentally different from those in the physical and natural sciences since the former are inherently stochastic in nature, as they result from the interactions of people, and thus pure deterministic models are unlikely to provide accurate representations of the data. The empirical literature that tests for chaos in economics and finance presents very mixed results, in part due to confusion between specific tests for chaos and more general tests for non-linear relationships.
p9925
aVTraffic forecasting is another area that greatly benefits from applications of chaos theory. Better predictions of when traffic will occur would allow measures to be taken for it to be dispersed before the traffic starts, rather than after. Combining chaos theory principles with a few other methods has led to a more accurate short-term prediction model (see the plot of the BML traffic model at right).
p9926
aVChaos theory also finds applications in psychology. For example, in modeling group behavior in which heterogeneous members may behave as if sharing to different degrees what in Wilfred Bion's theory is a basic assumption, the group dynamics is the result of the individual dynamics of the members: each individual reproduces the group dynamics in a different scale, and the chaotic behavior of the group is reflected in each member.
p9927
asS'Numerical digit'
p9928
(lp9929
VA digit is a type of symbol (a numeral symbol, such as "2" or "5") used in combinations (such as "25") to represent numbers (such as the number 25) in positional numeral systems. The name "digit" comes from the fact that the 10 digits (ancient Latin "digiti" meaning fingers) of the hands correspond to the 10 symbols of the common base 10 number system, i.e. the decimal (ancient Latin adjective "dec." meaning ten) digits.
p9930
aVIn a given number system, if the base is an integer, the number of digits required is always equal to the absolute value of the base. For example, the decimal system (base 10) has ten digits (0 through to 9), whereas binary (base 2) has two digits (0 and 1).
p9931
aVOverview.
p9932
aVIn a basic digital system, a numeral is a sequence of digits, which may be of arbitrary length. Each position in the sequence has a place value, and each digit has a value. The value of the numeral is computed by multiplying each digit in the sequence by its place value, and summing the results.
p9933
aVDigital values.
p9934
aVEach digit in a number system represents an integer. For example, in decimal the digit "1" represents the integer one, and in the hexadecimal system, the letter "A" represents the number ten. A positional number system must have a digit representing the integers from zero up to, but not including, the radix of the number system.
p9935
aVThus in the positional decimal system, the numbers 0 to 9 can be expressed using their respective numerals '0' to '9' in the rightmost 'units' position. The number 12 can be expressed with the numeral '2' in the units position, and with the numeral '1' in in the 'tens' position, to the left of the '2' while the number 312 can be expressed by three numerals: '3' in the 'hundreds' position, '1' in the 'tens' position, and '2' in the 'units' position.
p9936
aVComputation of place values.
p9937
aVThe Hindu\u2013Arabic numeral system (or the Hindu numeral system) uses a decimal separator, commonly a period in the United Kingdom and United States or a comma in Europe, to denote the "ones place" or "units place", which has a place value one. Each successive place to the left of this has a place value equal to the place value of the previous digit times the base. Similarly, each successive place to the right of the separator has a place value equal to the place value of the previous digit divided by the base. For example, in the numeral 10.34 (written in base ten),
p9938
aVthe 0 is immediately to the left of the separator, so it is in the ones or units place, and is called the "units digit" or "ones digit";
p9939
aVthe 1 to the left of the ones place is in the tens place, and is called the "tens digit";
p9940
aVthe 3 is to the right of the ones place, so it is in the tenths place, and is called the "tenths digit";
p9941
aVthe 4 to the right of the tenths place is in the hundredths place, and is called the "hundredths digit".
p9942
aVThe total value of the number is 1 ten, 0 ones, 3 tenths, and 4 hundredths. Note that the zero, which contributes no value to the number, indicates that the 1 is in the tens place rather than the ones place.
p9943
aVThe place value of any given digit in a numeral can be given by a simple calculation, which in itself is a compliment to the logic behind numeral systems. The calculation involves the multiplication of the given digit by the base raised by the exponent "n" \u2212 1, where "n" represents the position of the digit from the separator; the value of "n" is positive (+), but this is only if the digit is to the left of the separator. And to the right, the digit is multiplied by the base raised by a negative (\u2212) n. For example, in the number 10.34 (written in base ten),
p9944
aVthe 1 is second to the left of the separator, so based on calculation, its value is,
p9945
aVn \u2212 1 = 2 \u2212 1 = 1
p9946
aV1 × 10"1" = 10
p9947
aVthe 4 is second to the right of the separator, so based on calculation its value is,
p9948
aVn = \u22122
p9949
aV4 × 10"\u22122" = 
p9950
aVHistory.
p9951
aVThe first true written positional numeral system is considered to be the Hindu\u2013Arabic numeral system. This system was established by the 7th century, but was not yet in its modern form because the use of the digit zero had not yet been widely accepted. Instead of a zero, a space was left in the numeral as a placeholder. The first widely acknowledged use of zero was in 876. Although the original Hindu-Arabic system was very similar to the modern one, even down to the glyphs used to represent digits, the direction of places was reversed, so that place values increased to the right rather than to the left.
p9952
aVBy the 13th century, Hindu-Arabic numerals were accepted in European mathematical circles (Fibonacci used them in his "Liber Abaci"). They began to enter common use in the 15th century. By the end of the 20th century virtually all non-computerized calculations in the world were done with Arabic numerals, which have replaced native numeral systems in most cultures.
p9953
aVOther historical numeral systems using digits.
p9954
aVThe exact age of the Maya numerals is unclear, but it is possible that it is older than the Hindu-Arabic system. The system was vigesimal (base twenty), so it has twenty digits. The Mayas used a shell symbol to represent zero. Numerals were written vertically, with the ones place at the bottom. The Mayas had no equivalent of the modern decimal separator, so their system could not represent fractions.
p9955
aVThe Thai numeral system is identical to the Hindu\u2013Arabic numeral system except for the symbols used to represent digits. The use of these digits is less common in Thailand than it once was, but they are still used alongside Hindu-Arabic numerals.
p9956
aVThe rod numerals, the written forms of counting rods once used by Chinese and Japanese mathematicians, are a decimal positional system able to represent not only zero but also negative numbers. Counting rods themselves predate Hindu-Arabic numeral system. The Suzhou numerals are variants of rod numerals.
p9957
aVModern digital systems.
p9958
aVIn computer science.
p9959
aVThe binary (base 2), octal (base 8), and hexadecimal (base 16) systems, extensively used in computer science, all follow the conventions of the Hindu\u2013Arabic numeral system. The binary system uses only the digits "0" and "1", while the octal system uses the digits from "0" through "7". The hexadecimal system uses all the digits from the decimal system, plus the letters "A" through "F", which represent the numbers 10 to 15 respectively.
p9960
aVUnusual systems.
p9961
aVThe ternary and balanced ternary systems have sometimes been used. They are both base-three systems.
p9962
aVBalanced ternary is unusual in having the digit values 1, 0 and -1. Balanced ternary turns out to have some useful properties and the system has been used in the experimental Russian Setun computers.
p9963
aVSeveral authors in the last 300 years have noted a facility of positional notation that amounts to a "modified" decimal representation.
p9964
aVSome advantages are cited for use of numerical digits that represent negative values. In 1840 Augustin-Louis Cauchy advocated use of signed-digit representation of numbers, and in 1928 Florian Cajori presented his collection of references for negative numerals. The concept of signed-digit representation has also been taken up in computer design.
p9965
aVDigits in mathematics.
p9966
aVDespite the essential role of digits in describing numbers, they are relatively unimportant to modern mathematics. Nevertheless, there are a few important mathematical concepts that make use of the representation of a number as a sequence of digits.
p9967
aVDigital roots.
p9968
aVThe digital root is the single-digit number obtained by summing the digits of a given number, then summing the digits of the result, and so on until a single-digit number is obtained.
p9969
aVCasting out nines.
p9970
aVCasting out nines is a procedure for checking arithmetic done by hand. To describe it, let formula_1 represent the digital root of formula_2, as described above. Casting out nines makes use of the fact that if formula_3, then formula_4. In the process of casting out nines, both sides of the latter equation are computed, and if they are not equal the original addition must have been faulty.
p9971
aVRepunits and repdigits.
p9972
aVRepunits are integers that are represented with only the digit 1. For example, 1111 (one thousand, one hundred eleven) is a repunit. Repdigits are a generalization of repunits; they are integers represented by repeated instances of the same digit. For example, 333 is a repdigit. The primacy of repunits is of interest to mathematicians.
p9973
aVPalindromic numbers and Lychrel numbers.
p9974
aVPalindromic numbers are numbers that read the same when their digits are reversed. A Lychrel number is a positive integer that never yields a palindromic number when subjected to the iterative process of being added to itself with digits reversed. The question of whether there are any Lychrel numbers in base 10 is an open problem in recreational mathematics; the smallest candidate is 196.
p9975
aVHistory of ancient numbers.
p9976
aVCounting aids, especially the use of body parts (counting on fingers), were certainly used in prehistoric times as today. There are many variations. Besides counting 10 fingers, some cultures have counted knuckles, the space between fingers, and toes as well as fingers. The Oksapmin culture of New Guinea uses a system of 27 upper body locations to represent numbers.
p9977
aVTo preserve numerical information, tallies carved in wood, bone, and stone have been used since prehistoric times. Stone age cultures, including ancient indigenous American groups, used tallies for gambling, personal services, and trade-goods.
p9978
aVA method of preserving numeric information in clay was invented by the Sumerians between 8000 and 3500 BCE. This was done with small clay tokens of various shapes that were strung like beads on a string. Beginning about 3500 BCE clay tokens were gradually replaced by number signs impressed with a round stylus at different angles in clay tablets (originally containers for tokens) which were then baked. About 3100 BCE written numbers were dissociated from the things being counted and became abstract numerals.
p9979
aVBetween 2700 BCE and 2000 BCE in Sumer, the round stylus was gradually replaced by a reed stylus that was used to press wedge-shaped cuneiform signs in clay. These cuneiform number signs resembled the round number signs they replaced and retained the additive sign-value notation of the round number signs. These systems gradually converged on a common sexagesimal number system; this was a place-value system consisting of only two impressed marks, the vertical wedge and the chevron, which could also represent fractions. This sexagesimal number system was fully developed at the beginning of the Old Babylonia period (about 1950 BC) and became standard in Babylonia.
p9980
aVSexagesimal numerals were a mixed radix system that retained the alternating base 10 and base 6 in a sequence of cuneiform vertical wedges and chevrons. By 1950 BCE this was a positional notation system. Sexagesimal numerals came to be widely used in commerce, but were also used in astronomical and other calculations. This system was exported from Babylonia and used throughout Mesopotamia, and by every Mediterranean nation that used standard Babylonian units of measure and counting, including the Greeks, Romans and Egyptians. Babylonian-style sexagesimal numeration is still used in modern societies to measure time (minutes per hour) and angles (degrees).
p9981
aVHistory of modern numbers.
p9982
aVIn China, armies and provisions were counted using modular tallies of prime numbers. Unique numbers of troops and measures of rice appear as unique combinations of these tallies. A great convenience of modular arithmetic is that it is easy to multiply, though quite difficult to add. This makes use of modular arithmetic for provisions especially attractive. Conventional tallies are quite difficult to multiply and divide. In modern times modular arithmetic is sometimes used in Digital signal processing.
p9983
aVThe oldest Greek system was the that of the Attic numerals, but in the 4th century BC they began to use a quasidecimal alphabetic system (see Greek numerals). Jews began using a similar system (Hebrew numerals), with the oldest examples known being coins from around 100 BC.
p9984
aVThe Roman empire used tallies written on wax, papyrus and stone, and roughly followed the Greek custom of assigning letters to various numbers. The Roman numerals system remained in common use in Europe until positional notation came into common use in the 16th century.
p9985
aVThe Maya of Central America used a mixed base 18 and base 20 system, possibly inherited from the Olmec, including advanced features such as positional notation and a zero. They used this system to make advanced astronomical calculations, including highly accurate calculations of the length of the solar year and the orbit of Venus.
p9986
aVThe Incan Empire ran a large command economy using quipu, tallies made by knotting colored fibers. Knowledge of the encodings of the knots and colors was suppressed by the Spanish conquistadors in the 16th century, and has not survived although simple quipu-like recording devices are still used in the Andean region.
p9987
aVSome authorities believe that positional arithmetic began with the wide use of counting rods in China. The earliest written positional records seem to be rod calculus results in China around 400. In particular, zero was correctly described by Chinese mathematicians around 932.
p9988
aVThe modern positional Arabic numeral system was developed by mathematicians in India, and passed on to Muslim mathematicians, along with astronomical tables brought to Baghdad by an Indian ambassador around 773.
p9989
aVFrom India, the thriving trade between Islamic sultans and Africa carried the concept to Cairo. Arabic mathematicians extended the system to include decimal fractions, and wrote an important work about it in the 9th century. The modern Arabic numerals were introduced to Europe with the translation of this work in the 12th century in Spain and Leonardo of Pisa's "Liber Abaci" of 1201. In Europe, the complete Indian system with the zero was derived from the Arabs in the 12th century.
p9990
aVThe binary system (base 2), was propagated in the 17th century by Gottfried Leibniz. Leibniz had developed the concept early in his career, and had revisited it when he reviewed a copy of the I ching from China. Binary numbers came into common use in the 20th century because of computer applications.
p9991
asS"Graham's number"
p9992
(lp9993
VGraham's number'", named after Ronald Graham, is a large number that is an upper bound on the solution to a certain problem in Ramsey theory.
p9994
aVThe number gained a degree of popular attention when Martin Gardner described it in the "Mathematical Games" section of "Scientific American" in November 1977, writing that Graham had recently established, in an unpublished proof, "a bound so vast that it holds the record for the largest number ever used in a serious mathematical proof." The 1980 "Guinness Book of World Records" repeated Gardner's claim, adding to the popular interest in this number. According to physicist John Baez, Graham invented the quantity now known as Graham's number in conversation with Gardner himself. While Graham was trying to explain a result in Ramsey theory which he had derived with his collaborator Bruce Lee Rothschild, Graham found that the quantity now known as Graham's number was easier to explain than the actual number appearing in the proof. Because the number which Graham described to Gardner is larger than the number in the paper itself, both are valid upper bounds for the solution to the Ramsey-theory problem studied by Graham and Rothschild.
p9995
aVGraham's number is much larger than many other large numbers such as a googol, googolplex, Skewes' number and Moser's number. Indeed, like the last two of those numbers, the observable universe is far too small to contain an ordinary digital representation of Graham's number, assuming that each digit occupies one Planck volume. Even power towers of the form formula_1 are insufficient for this purpose, although it can be described by recursive formulas using Knuth's up-arrow notation or equivalent, as was done by Graham. The last 12 digits of Graham's number are ...262464195387.
p9996
aVSpecific integers known to be far larger than Graham's number have since appeared in many serious mathematical proofs (e.g., in connection with Harvey Friedman's various finite forms of Kruskal's theorem).
p9997
aVContext.
p9998
aVGraham's number is connected to the following problem in Ramsey theory:
p9999
aVIn 1971, Graham and Rothschild proved that this problem has a solution "N*", giving as a bound 6 \u2264 "N*" \u2264 "N", with "N" being a large but explicitly defined number formula_2, where formula_3 in Knuth's up-arrow notation; the number is between 4 \u2192 2 \u2192 8 \u2192 2 and 2 \u2192 3 \u2192 9 \u2192 2 in Conway chained arrow notation. This was reduced in 2014 via upper bounds on the Hales\u2013Jewett number to formula_4. The lower bound of 6 was later improved to 11 by Geoff Exoo in 2003, and to 13 by Jerome Barkley in 2008. Thus, the best known bounds for "N*" are 13 \u2264 "N*" \u2264 "N"'.
p10000
aVGraham's number, "G", is much larger than "N": formula_5, where formula_6. This weaker upper bound for the problem, attributed to an unpublished work of Graham, was eventually published and named by Martin Gardner in "Scientific American" in November 1977.
p10001
aVDefinition.
p10002
aVUsing Knuth's up-arrow notation, Graham's number "G" (as defined in Gardner's "Scientific American" article) is
p10003
aVformula_7
p10004
aVwhere the number of "arrows" in each layer, starting at the top layer, is specified by the value of the next layer below it; that is,
p10005
aVformula_8
p10006
aVand where a superscript on an up-arrow indicates how many arrows there are. In other words, "G" is calculated in 64 steps: the first step is to calculate "g"1 with four up-arrows between 3s; the second step is to calculate "g"2 with "g"1 up-arrows between 3s; the third step is to calculate "g"3 with "g"2 up-arrows between 3s; and so on, until finally calculating "G" = "g"64 with "g"63 up-arrows between 3s.
p10007
aVEquivalently,
p10008
aVformula_9
p10009
aVand the superscript on "f" indicates an iteration of the function, e.g., formula_10. Expressed in terms of the family of hyperoperations formula_11, the function "f" is the particular sequence formula_12, which is a version of the rapidly growing Ackermann function "A"("n","n"). (In fact, formula_13 for all "n".) The function "f" can also be expressed in Conway chained arrow notation as formula_14, and this notation also provides the following bounds on "G":
p10010
aVformula_15
p10011
aVMagnitude.
p10012
aVTo convey the difficulty of appreciating the enormous size of Graham's number, it may be helpful to express\u2014in terms of exponentiation alone\u2014just the first term ("g"1) of the rapidly growing 64-term sequence. First, in terms of tetration (formula_16) alone:
p10013
aVformula_17
p10014
aVwhere the number of 3s in the expression on the right is
p10015
aVformula_18
p10016
aVNow each tetration (formula_19) operation reduces to a "tower" of exponentiations (formula_20) according to the definition
p10017
aVformula_21
p10018
aVThus,
p10019
aVformula_17
p10020
aVbecomes, solely in terms of repeated "exponentiation towers",
p10021
aVformula_23
p10022
aVand where the number of 3s in each tower, starting from the leftmost tower, is specified by the value of the next tower to the right.
p10023
aVIn other words, "g"1 is computed by first calculating the number of towers, formula_24 (where the number of 3s is formula_25), and then computing the "n"th tower in the following sequence:
p10024
aVwhere the number of 3s in each successive tower is given by the tower just before it. Note that the result of calculating the third tower is the value of "n", the number of towers for "g"1.
p10025
aVThe magnitude of this first term, "g"1, is so large that it is practically incomprehensible, even though the above display is relatively easy to comprehend. Even "n", the mere "number of towers" in this formula for "g"1, is far greater than the number of Planck volumes (roughly 10185 of them) into which one can imagine subdividing the observable universe. And after this first term, still another 63 terms remain in the rapidly growing "g" sequence before Graham's number "G" = "g"64 is reached.
p10026
aVRightmost decimal digits.
p10027
aVGraham's number is a "power tower" of the form 3\u2191\u2191"n" (with a very large value of "n"), so its rightmost decimal digits must satisfy certain properties common to all such towers. One of these properties is that "all such towers of height greater than d (say), have the same sequence of d rightmost decimal digits". This is a special case of a more general property: The "d" rightmost decimal digits of all such towers of height greater than "d"+2, are "independent" of the topmost "3" in the tower; i.e., the topmost "3" can be changed to any other nonnegative integer without affecting the "d" rightmost digits.
p10028
aVThe following table illustrates, for a few values of "d", how this happens. For a given height of tower and number of digits "d", the full range of "d"-digit numbers (10"d" of them) does "not" occur; instead, a certain smaller subset of values repeats itself in a cycle. The length of the cycle and some of the values (in parentheses) are shown in each cell of this table:
p10029
aVThe particular rightmost "d" digits that are ultimately shared by all sufficiently tall towers of 3s are in bold text, and can be seen developing as the tower height increases. For any fixed number of digits "d" (row in the table), the number of values possible for 3formula_263\u2191\u20263\u2191"x" mod 10"d", as "x" ranges over all nonnegative integers, is seen to decrease steadily as the height increases, until eventually reducing the "possibility set" to a single number (colored cells) when the height exceeds "d"+2.
p10030
aVA simple algorithm for computing these digits may be described as follows: let x = 3, then iterate, "d" times, the assignment "x" = 3"x" mod 10"d". Except for omitting any leading 0s, the final value assigned to "x" (as a base-ten numeral) is then composed of the "d" rightmost decimal digits of 3\u2191\u2191"n", for all "n" > "d". (If the final value of "x" has fewer than "d" digits, then the required number of leading 0s must be added.)
p10031
aVLet "k" be the numerousness of these "stable" digits, which satisfy the congruence relation G(mod 10"k")\u2261[GG](mod 10"k").
p10032
aV"k"="t"-1, where G("t"):=3\u2191\u2191"t". It follows that, .
p10033
aVThe algorithm above produces the following 500 rightmost decimal digits of Graham's number (or of any tower of more than 500 3s):
p10034
aVReferences.
p10035
aVNotes
p10036
aVBibliography
p10037
asS'Spiral'
p10038
(lp10039
VIn mathematics, a spiral is a curve which emanates from a central point, getting progressively farther away as it revolves around the point.
p10040
aVSpirals and helices.
p10041
aVTwo major definitions of "spiral" in a respected American dictionary are: 
p10042
aV a. A curve on a plane that winds around a fixed center point at a continuously increasing or decreasing distance from the point.b. A three-dimensional curve that turns around an axis at a constant or continuously varying distance while moving parallel to the axis; a helix.
p10043
aVDefinition a describes a planar curve, that extends in both of the perpendicular directions within its plane; the groove on one side of a record closely approximates a plane spiral (and it is by the finite width and depth of the groove, but "not" by the wider spacing between than within tracks, that it falls short of being a perfect example); note that successive loops "differ" in diameter. In another example, the "center lines" of the arms of a spiral galaxy trace logarithmic spirals.
p10044
aVDefinition b includes two kinds of 3-dimensional relatives of spirals:
p10045
aVIn the side picture, the black curve at the bottom is an Archimedean spiral, while the green curve is a helix. The curve shown in red is a conic helix.
p10046
aVTwo-dimensional spirals.
p10047
aVA two-dimensional spiral may be described most easily using polar coordinates, where the radius "r" is a monotonic continuous function of angle "\u03b8". The circle would be regarded as a degenerate case (the function not being strictly monotonic, but rather constant).
p10048
aVSome of the more important sorts of two-dimensional spirals include:
p10049
aVThree-dimensional spirals.
p10050
aVFor simple 3-d spirals, a third variable, "h" (height), is also a continuous, monotonic function of "\u03b8". For example, a conic helix may be defined as a spiral on a conic surface, with the distance to the apex an exponential function of "\u03b8".
p10051
aVThe helix and vortex can be viewed as a kind of three-dimensional spiral.
p10052
aVFor a helix with thickness, see spring (math).
p10053
aVSpherical spiral.
p10054
aVA "spherical spiral" (rhumb line or loxodrome, left picture) is the curve on a sphere traced by a ship traveling from one pole to the other while keeping a fixed angle (unequal to 0° and to 90°) with respect to the meridians of longitude, i.e. keeping the same bearing. The curve has an infinite number of revolutions, with the distance between them decreasing as the curve approaches either of the poles. The gap between the curves of an Archimedean spiral (right picture) remains constant as the radius changes and hence is not a rhumb line.
p10055
aVIn nature.
p10056
aVThe study of spirals in nature has a long history, Christopher Wren observed that many shells form a logarithmic spiral. Jan Swammerdam observed the common mathematical characteristics of a wide range of shells from "Helix" to "Spirula" and Henry Nottidge Moseley described the mathematics of univalve shells. D\u2019Arcy Wentworth Thompson's "On Growth and Form" gives extensive treatment to these spirals. He describes how shells are formed by rotating a closed curve around a fixed axis, the shape of the curve remains fixed but its size grows in a geometric progression. In some shell such as "Nautilus" and ammonites the generating curve revolves in a plane perpendicular to the axis and the shell will form a planar discoid shape. In others it follows a skew path forming a helico-spiral pattern. Thompson also studied spirals occurring in horns, teeth, claws and plants.
p10057
aVA model for the pattern of florets in the head of a sunflower was proposed by H Vogel. This has the form
p10058
aVformula_6
p10059
aVwhere "n" is the index number of the floret and "c" is a constant scaling factor, and is a form of Fermat's spiral. The angle 137.5° is the golden angle which is related to the golden ratio and gives a close packing of florets.
p10060
aVSpirals in plants and animals are frequently described as whorls. This is also the name given to spiral shaped fingerprints.
p10061
aVAs a symbol.
p10062
aVThe spiral and triple spiral motif is a Neolithic symbol in Europe (Megalithic Temples of Malta). The Celtic symbol the triple spiral is in fact a pre-Celtic symbol. It is carved into the rock of a stone lozenge near the main entrance of the prehistoric Newgrange monument in County Meath, Ireland. Newgrange was built around 3200 BCE predating the Celts and the triple spirals were carved at least 2,500 years before the Celts reached Ireland but has long since been incorporated into Celtic culture. The triskelion symbol, consisting of three interlocked spirals or three bent human legs, appears in many early cultures, including Mycenaean vessels, on coinage in Lycia, on staters of Pamphylia (at Aspendos, 370\u2013333 BC) and Pisidia, as well as on the heraldic emblem on warriors' shields depicted on Greek pottery.
p10063
aVSpirals can be found throughout pre-Columbian art in Latin and Central America. The more than 1,400 petroglyphs (rock engravings) in Las Plazuelas, Guanajuato Mexico, dating 750-1200 AD, predominantly depict spirals, dot figures and scale models. In Colombia monkeys, frog and lizard like figures depicted in petroglyphs or as gold offering figures frequently includes spirals, for example on the palms of hands. In Lower Central America spirals along with circles, wavy lines, crosses and points are universal petroglyphs characters. Spirals can also be found among the Nazca Lines in the coastal desert of Peru, dating from 200 BC to 500 AD. The geoglyphs number in the thousands and depict animals, plants and geometric motifs, including spirals.
p10064
aVWhile scholars are still debating the subject, there is a growing acceptance that the simple spiral, when found in Chinese art, is an early symbol for the sun. Roof tiles dating back to the Tang Dynasty with this symbol have been found west of the ancient city of Chang'an (modern-day Xian).
p10065
aVSpirals are also a symbol of hypnosis, stemming from the cliché of people and cartoon characters being hypnotized by staring into a spinning spiral (one example being Kaa in Disney's "The Jungle Book"). They are also used as a symbol of dizziness, where the eyes of a cartoon character, especially in anime and manga, will turn into spirals to show they are dizzy or dazed. The spiral is also found in structures as small as the double helix of DNA and as large as a galaxy. Because of this frequent natural occurrence, the spiral is the official symbol of the World Pantheist Movement.
p10066
aV The spiral is also a symbol of the process of dialectic.
p10067
aVIn art.
p10068
aVThe spiral has inspired artists throughout the ages. Among the most famous of spiral-inspired art is Robert Smithson's earthwork, "Spiral Jetty", at the Great Salt Lake in Utah. The spiral theme is also present in David Wood's Spiral Resonance Field at the Balloon Museum in Albuquerque, as well as in the critically acclaimed Nine Inch Nails 1994 concept album "The Downward Spiral". The Spiral is also a prominent theme in the anime Gurren Lagann, where it represents a philosophy and way of life. It also central in Mario Merz and Andy Goldsworthy's work.
p10069
asS'Order of magnitude'
p10070
(lp10071
VOrders of magnitude are written in powers of 10. For example, the order of magnitude of 1500 is 3, since 1500 may be written as 1.5 × 103.
p10072
aVDifferences in order of magnitude can be measured on the logarithmic scale in "decades" (i.e., factors of ten). Examples of numbers of different magnitudes can be found at Orders of magnitude (numbers).
p10073
aVUses.
p10074
aVOrders of magnitude are used to make approximate comparisons. If numbers differ by 1 order of magnitude, "x" is "about" ten times different in quantity than "y". If values differ by 2 orders of magnitude, they differ by a factor of about 100. Two numbers of the same order of magnitude have roughly the same scale: the larger value is less than ten times the smaller value.
p10075
aVThe order of magnitude of a number is, intuitively speaking, the number of powers of 10 contained in the number. More precisely, the order of magnitude of a number can be defined in terms of the common logarithm, usually as the integer part of the logarithm, obtained by truncation. For example, the number 4,000,000 has a logarithm (in base 10) of 6.602; its order of magnitude is 6. When truncating, a number of this order of magnitude is between 106 and 107. In a similar example, with the phrase "He had a seven-figure income", the order of magnitude is the number of figures minus one, so it is very easily determined without a calculator to be 6. An order of magnitude is an approximate position on a logarithmic scale.
p10076
aVAn order-of-magnitude estimate of a variable whose precise value is unknown is an estimate rounded to the nearest power of ten. For example, an order-of-magnitude estimate for a variable between about 3 billion and 30 billion (such as the human population of the Earth) is 10 billion. To round a number to its nearest order of magnitude, one rounds its logarithm to the nearest integer. Thus 4,000,000, which has a logarithm (in base 10) of 6.602, has 7 as its nearest order of magnitude, because "nearest" implies rounding rather than truncation. For a number written in scientific notation, this logarithmic rounding scale requires rounding up to the next power of ten when the multiplier is greater than the square root of ten (about 3.162). For example, the nearest order of magnitude for 1.7 × 108 is 8, whereas the nearest order of magnitude for 3.7 × 108 is 9. An order-of-magnitude estimate is sometimes also called a zeroth order approximation.
p10077
aVAn order-of-magnitude difference between two values is a factor of 10. For example, the mass of the planet Saturn is 95 times that of Earth, so Saturn is "two orders of magnitude" more massive than Earth. Order-of-magnitude differences are called decades when measured on a logarithmic scale.
p10078
aVNon-decimal orders of magnitude.
p10079
aVOther orders of magnitude may be calculated using bases other than 10. The ancient Greeks ranked the nighttime brightness of celestial bodies by 6 levels in which each level was the fifth root of one hundred (about 2.512) as bright as the nearest weaker level of brightness, and thus the brightest level being 5 orders of magnitude brighter than the weakest indicates that it is (1001/5)5 or a factor of 100 times brighter.
p10080
aVThe different decimal numeral systems of the world use a larger base to better envision the size of the number, and have created names for the powers of this larger base. The table shows what number the order of magnitude aim at for base 10 and for base 1,000,000. It can be seen that the order of magnitude is included in the number name in this example, because bi- means 2 and tri- means 3 (these make sense in the long scale only), and the suffix -illion tells that the base is 1,000,000. But the number names billion, trillion themselves (here with other meaning than in the first chapter) are not names of the "orders of" magnitudes, they are names of "magnitudes", that is the "numbers" 1,000,000,000,000 etc.
p10081
aVSI units in the table at right are used together with SI prefixes, which were devised with mainly base 1000 magnitudes in mind. The IEC standard prefixes with base 1024 were invented for use in electronic technology.
p10082
aVThe ancient apparent magnitudes for the brightness of stars uses the base formula_1 and is reversed. The modernized version has however turned into a logarithmic scale with non-integer values.
p10083
aVExtremely large numbers.
p10084
aVFor extremely large numbers, a generalized order of magnitude can be based on their double logarithm or super-logarithm. Rounding these downward to an integer gives categories between very "round numbers", rounding them to the nearest integer and applying the inverse function gives the "nearest" round number.
p10085
aVThe double logarithm yields the categories:
p10086
aV ..., 1.0023\u20131.023, 1.023\u20131.26, 1.26\u201310, 10\u20131010, 1010\u201310100, 10100\u2013101000, ...
p10087
aV(the first two mentioned, and the extension to the left, may not be very useful, they merely demonstrate how the sequence mathematically continues to the left).
p10088
aVThe super-logarithm yields the categories:
p10089
aV formula_2, or
p10090
aVnegative numbers, 0\u20131, 1\u201310, 10\u20131e10, 1e10\u2013101e10, 101e10\u2013410, 410\u2013510, etc. (see tetration)
p10091
aVThe "midpoints" which determine which round number is nearer are in the first case:
p10092
aV1.076, 2.071, 1453, 4.20e31, 1.69e316...
p10093
aVand, depending on the interpolation method, in the second case
p10094
aV\u2212.301, .5, 3.162, 1453, 1e1453, formula_3, formula_4... (see notation of extremely large numbers)
p10095
aVFor extremely small numbers (in the sense of close to zero) neither method is suitable directly, but the generalized order of magnitude of the reciprocal can be considered.
p10096
aVSimilar to the logarithmic scale one can have a double logarithmic scale (example provided here) and super-logarithmic scale. The intervals above all have the same length on them, with the "midpoints" actually midway. More generally, a point midway between two points corresponds to the generalised f-mean with "f"("x") the corresponding function log log "x" or slog "x". In the case of log log "x", this mean of two numbers (e.g. 2 and 16 giving 4) does not depend on the base of the logarithm, just like in the case of log "x" (geometric mean, 2 and 8 giving 4), but unlike in the case of log log log "x" (4 and 65536 giving 16 if the base is 2, but, otherwise).
p10097
asS'Limit of a sequence'
p10098
(lp10099
VAs the positive integer "n" becomes larger and larger, the value "n" sin(1/"n") becomes arbitrarily close to 1. We say that "the limit of the sequence "n" sin(1/"n") equals 1."
p10100
aVIn mathematics, the limit of a sequence is the value that the terms of a sequence "tend to". If such a limit exists, the sequence is called convergent. A sequence which does not converge is said to be divergent. The limit of a sequence is said to be the fundamental notion on which the whole of analysis ultimately rests.
p10101
aVLimits can be defined in any metric or topological space, but are usually first encountered in the real numbers.
p10102
aVHistory.
p10103
aVThe Greek philosopher Zeno of Elea is famous for formulating paradoxes that involve limiting processes.
p10104
aVLeucippus, Democritus, Antiphon, Eudoxus and Archimedes developed the method of exhaustion, which uses an infinite sequence of approximations to determine an area or a volume. Archimedes succeeded in summing what is now called a geometric series.
p10105
aVNewton dealt with series in his works on "Analysis with infinite series" (written in 1669, circulated in manuscript, published in 1711), "Method of fluxions and infinite series" (written in 1671, published in English translation in 1736, Latin original published much later) and "Tractatus de Quadratura Curvarum" (written in 1693, published in 1704 as an Appendix to his "Optiks"). In the latter work, Newton considers the binomial expansion of ("x"+"o")"n" which he then linearizes by "taking limits" (letting "o"\u21920).
p10106
aVIn the 18th century, mathematicians like Euler succeeded in summing some "divergent" series by stopping at the right moment; they did not much care whether a limit existed, as long as it could be calculated. At the end of the century, Lagrange in his "Théorie des fonctions analytiques" (1797) opined that the lack of rigour precluded further development in calculus. Gauss in his etude of hypergeometric series (1813) for the first time rigorously investigated under which conditions a series converged to a limit.
p10107
aVThe modern definition of a limit (for any \u03b5 there exists an index "N" so that ...) was given by Bernhard Bolzano ("Der binomische Lehrsatz", Prague 1816, little noticed at the time) and by Karl Weierstrass in the 1870s.
p10108
aVReal numbers.
p10109
aVIn the real numbers, a number formula_1 is the limit of the sequence formula_2 if the numbers in the sequence become closer and closer to formula_1 and not to any other number.
p10110
aVformula_18.
p10111
aVFormal Definition.
p10112
aVWe call formula_20 the limit of the sequence formula_2 if the following condition holds:
p10113
aV*For each real number formula_22, there exists a natural number formula_23 such that, for every natural number formula_24, we have formula_25. 
p10114
aVIn other words, for every measure of closeness formula_26, the sequence's terms are eventually that close to the limit. The sequence formula_2 is said to converge to or tend to the limit formula_20, written formula_29 or formula_30.
p10115
aVIf a sequence converges to some limit, then it is convergent; otherwise it is divergent.
p10116
aVProperties.
p10117
aVLimits of sequences behave well with respect to the usual arithmetic operations. If formula_31 and formula_32, then formula_33, formula_34 and, if neither "b" nor any formula_35 is zero, formula_36.
p10118
aVFor any continuous function "f", if formula_29 then formula_38. In fact, any real-valued function "f" is continuous if and only if it preserves the limits of sequences (though this is not necessarily true when using more general notions of continuity).
p10119
aVSome other important properties of limits of real sequences include the following.
p10120
aVThese properties are extensively used to prove limits without the need to directly use the cumbersome formal definition. Once proven that formula_53 it becomes easy to show that formula_54, (formula_55), using the properties above.
p10121
aVInfinite limits.
p10122
aVA sequence formula_2 is said to tend to infinity, written formula_57 or formula_58 if, for every "K", there is an "N" such that, for every formula_59, formula_60; that is, the sequence terms are eventually larger than any fixed "K". Similarly, formula_61 if, for every "K", there is an "N" such that, for every formula_59, formula_63. If a sequence tends to infinity, or to minus infinity, then it is divergent (however, a divergent sequence need not tend to plus or minus infinity).
p10123
aVMetric spaces.
p10124
aVDefinition.
p10125
aVA point "x" of the metric space ("X", "d") is the limit of the sequence ("xn") if, for all \u03b5 > 0, there is an "N" such that, for every formula_59, formula_65. This coincides with the definition given for real numbers when formula_66 and formula_67.
p10126
aVProperties.
p10127
aVFor any continuous function "f", if formula_29 then formula_38. In fact, a function "f" is continuous if and only if it preserves the limits of sequences.
p10128
aVLimits of sequences are unique when they exist, as distinct points are separated by some positive distance, so for formula_26 less than half this distance, sequence terms cannot be within a distance formula_26 of both points.
p10129
aVTopological spaces.
p10130
aVDefinition.
p10131
aVA point "x" of the topological space ("X", \u03c4) is the limit of the sequence ("xn") if, for every neighbourhood "U" of "x", there is an "N" such that, for every formula_59, formula_73. This coincides with the definition given for metric spaces if ("X","d") is a metric space and formula_74 is the topology generated by "d".
p10132
aVThe limit of a sequence of points formula_75 in a topological space "T" is a special case of the limit of a function: the domain is formula_76 in the space formula_77 with the induced topology of the affinely extended real number system, the range is "T", and the function argument "n" tends to +\u221e, which in this space is a limit point of formula_76.
p10133
aVProperties.
p10134
aVIf "X" is a Hausdorff space then limits of sequences are unique where they exist. Note that this need not be the case in general; in particular, if two points "x" and "y" are topologically indistinguishable, any sequence that converges to "x" must converge to "y" and vice versa.
p10135
aVCauchy sequences.
p10136
aVA Cauchy sequence is a sequence whose terms become arbitrarily close together as n gets very large. The notion of a Cauchy sequence is important in the study of sequences in metric spaces, and, in particular, in real analysis. One particularly important result in real analysis is "Cauchy characterization of convergence for sequences": 
p10137
aVA sequence is convergent if and only if it is Cauchy.
p10138
aVDefinition in hyperreal numbers.
p10139
aVThe definition of the limit using the hyperreal numbers formalizes the intuition that for a "very large" value of the index, the corresponding term is "very close" to the limit. More precisely, a real sequence formula_2 tends to "L" if for every infinite hypernatural "H", the term "x""H" is infinitely close to "L", i.e., the difference "x""H" - "L" is infinitesimal. Equivalently, "L" is the standard part of "x""H"
p10140
aVformula_80.
p10141
aVThus, the limit can be defined by the formula
p10142
aVformula_81
p10143
aVwhere the limit exists if and only if the righthand side is independent of the choice of an infinite "H".
p10144
asS'Norm (mathematics)'
p10145
(lp10146
VIn linear algebra, functional analysis and related areas of mathematics, a norm is a function that assigns a strictly positive "length" or "size" to each vector in a vector space\u2014save possibly for the zero vector, which is assigned a length of zero. A seminorm, on the other hand, is allowed to assign zero length to some non-zero vectors (in addition to the zero vector).
p10147
aVA norm must also satisfy certain properties pertaining to scalability and additivity which are given in the formal definition below.
p10148
aVA simple example is the 2-dimensional Euclidean space R2 equipped with the Euclidean norm. Elements in this vector space (e.g., (3, 7)) are usually drawn as arrows in a 2-dimensional cartesian coordinate system starting at the origin (0, 0). The Euclidean norm assigns to each vector the length of its arrow. Because of this, the Euclidean norm is often known as the magnitude.
p10149
aVA vector space on which a norm is defined is called a normed vector space. Similarly, a vector space with a seminorm is called a seminormed vector space. It is often possible to supply a norm for a given vector space in more than one way.
p10150
aVDefinition.
p10151
aVGiven a vector space "V" over a subfield "F" of the complex numbers, a norm on "V" is a function with the following properties:
p10152
aVFor all "a" \u2208 "F" and all u, v \u2208 "V",
p10153
aVBy the first axiom, absolute homogeneity, we have "p"(0) = 0 and "p"(-v) = "p"(v), so that by the triangle inequality
p10154
aV "p"(v) \u2265 0 ("positivity").
p10155
aVA seminorm on "V" is a function with the properties 1. and 2. above.
p10156
aVEvery vector space "V" with seminorm "p" induces a normed space "V/W", called the quotient space, where "W" is the subspace of "V" consisting of all vectors v in "V" with "p"(v) = 0. The induced norm on "V/W" is clearly well-defined and is given by:
p10157
aV "p"("W" + v) = "p"(v).
p10158
aVTwo norms (or seminorms) "p" and "q" on a vector space "V" are equivalent if there exist two real constants "c" and "C", with such that
p10159
aVfor every vector v in "V", one has that: .
p10160
aVA topological vector space is called normable (seminormable) if the topology of the space can be induced by a norm (seminorm).
p10161
aVNotation.
p10162
aVIf a norm is given on a vector space "V" then the norm of a vector v \u2208 "V" is usually denoted by enclosing it within double vertical lines: \u2016v\u2016 := "p"(v). Such notation is also sometimes used if "p" is only a seminorm.
p10163
aVFor the length of a vector in Euclidean space (which is an example of a norm, as explained below), the notation |v| with single vertical lines is also widespread.
p10164
aVIn Unicode, the codepoint of the "double vertical line" character \u2016 is U+2016. The double vertical line should not be confused with the "parallel to" symbol, Unicode U+2225 ( \u2225 ). This is usually not a problem because the former is used in parenthesis-like fashion, whereas the latter is used as an infix operator. The single vertical line | is called "vertical line" in Unicode and its codepoint is U+007C.
p10165
aVExamples.
p10166
aVAbsolute-value norm.
p10167
aVThe absolute value
p10168
aVformula_1
p10169
aVis a norm on the one-dimensional vector spaces formed by the real or complex numbers.
p10170
aVEuclidean norm.
p10171
aVOn an "n"-dimensional Euclidean space R"n", the intuitive notion of length of the vector x = ("x"1, "x"2, ..., "x""n") is captured by the formula
p10172
aVformula_2
p10173
aVThis gives the ordinary distance from the origin to the point x, a consequence of the Pythagorean theorem.
p10174
aVThe Euclidean norm is by far the most commonly used norm on R"n", but there are other norms on this vector space as will be shown below. However all these norms are equivalent in the sense that they all define the same topology.
p10175
aVOn an "n"-dimensional complex space C"n" the most common norm is
p10176
aVformula_3 then there exists "k"-seminorm "p" on "X" equivalent to "q".
p10177
asS'Gauss-Bonnet theorem'
p10178
(lp10179
sS'Mathematics'
p10180
(lp10181
VMathematics (from Greek \u03bc\u03ac\u03b8\u03b7\u03bc\u03b1 "máth\u0113ma", \u201cknowledge, study, learning\u201d), often shortened to maths or math, is the study of topics such as quantity (numbers), structure, space, and change. There is a range of views among mathematicians and philosophers as to the exact scope and definition of mathematics. 
p10182
aVMathematicians seek out patterns and use them to formulate new conjectures. Mathematicians resolve the truth or falsity of conjectures by mathematical proof. When mathematical structures are good models of real phenomena, then mathematical reasoning can provide insight or predictions about nature. Through the use of abstraction and logic, mathematics developed from counting, calculation, measurement, and the systematic study of the shapes and motions of physical objects. Practical mathematics has been a human activity for as far back as written records exist. The research required to solve mathematical problems can take years or even centuries of sustained inquiry.
p10183
aVRigorous arguments first appeared in Greek mathematics, most notably in Euclid's "Elements". Since the pioneering work of Giuseppe Peano (1858\u20131932), David Hilbert (1862\u20131943), and others on axiomatic systems in the late 19th century, it has become customary to view mathematical research as establishing truth by rigorous deduction from appropriately chosen axioms and definitions. Mathematics developed at a relatively slow pace until the Renaissance, when mathematical innovations interacting with new scientific discoveries led to a rapid increase in the rate of mathematical discovery that has continued to the present day.
p10184
aVGalileo Galilei (1564\u20131642) said, "The universe cannot be read until we have learned the language and become familiar with the characters in which it is written. It is written in mathematical language, and the letters are triangles, circles and other geometrical figures, without which means it is humanly impossible to comprehend a single word. Without these, one is wandering about in a dark labyrinth." Carl Friedrich Gauss (1777\u20131855) referred to mathematics as "the Queen of the Sciences". Benjamin Peirce (1809\u20131880) called mathematics "the science that draws necessary conclusions". David Hilbert said of mathematics: "We are not speaking here of arbitrariness in any sense. Mathematics is not like a game whose tasks are determined by arbitrarily stipulated rules. Rather, it is a conceptual system possessing internal necessity that can only be so and by no means otherwise." Albert Einstein (1879\u20131955) stated that "as far as the laws of mathematics refer to reality, they are not certain; and as far as they are certain, they do not refer to reality." French mathematician Claire Voisin states "There is creative drive in mathematics, it's all about movement trying to express itself." 
p10185
aVMathematics is used throughout the world as an essential tool in many fields, including natural science, engineering, medicine, finance and the social sciences. Applied mathematics, the branch of mathematics concerned with application of mathematical knowledge to other fields, inspires and makes use of new mathematical discoveries, which has led to the development of entirely new mathematical disciplines, such as statistics and game theory. Mathematicians also engage in pure mathematics, or mathematics for its own sake, without having any application in mind. There is no clear line separating pure and applied mathematics, and practical applications for what began as pure mathematics are often discovered.
p10186
aVHistory.
p10187
aVEvolution.
p10188
aVThe evolution of mathematics might be seen as an ever-increasing series of abstractions, or alternatively an expansion of subject matter. The first abstraction, which is shared by many animals, was probably that of numbers: the realization that a collection of two apples and a collection of two oranges (for example) have something in common, namely quantity of their members.
p10189
aVEvidenced by tallies found on bone, in addition to recognizing how to count physical objects, prehistoric peoples may have also recognized how to count abstract quantities, like time \u2013 days, seasons, years.
p10190
aVMore complex mathematics did not appear until around 3000 BC, when the Babylonians and Egyptians began using arithmetic, algebra and geometry for taxation and other financial calculations, for building and construction, and for astronomy. The earliest uses of mathematics were in trading, land measurement, painting and weaving patterns and the recording of time.
p10191
aVIn Babylonian mathematics elementary arithmetic (addition, subtraction, multiplication and division) first appears in the archaeological record. Numeracy pre-dated writing and numeral systems have been many and diverse, with the first known written numerals created by Egyptians in Middle Kingdom texts such as the Rhind Mathematical Papyrus.
p10192
aVBetween 600 and 300 BC the Ancient Greeks began a systematic study of mathematics in its own right with Greek mathematics.
p10193
aVMathematics has since been greatly extended, and there has been a fruitful interaction between mathematics and science, to the benefit of both. Mathematical discoveries continue to be made today. According to Mikhail B. Sevryuk, in the January 2006 issue of the "Bulletin of the American Mathematical Society", "The number of papers and books included in the "Mathematical Reviews" database since 1940 (the first year of operation of MR) is now more than 1.9 million, and more than 75 thousand items are added to the database each year. The overwhelming majority of works in this ocean contain new mathematical theorems and their proofs."
p10194
aVEtymology.
p10195
aVThe word "mathematics" comes from the Greek \u03bc\u03ac\u03b8\u03b7\u03bc\u03b1 ("máth\u0113ma"), which, in the ancient Greek language, means "that which is learnt", "what one gets to know", hence also "study" and "science", and in modern Greek just "lesson". The word "máth\u0113ma" is derived from \u03bc\u03b1\u03bd\u03b8\u03ac\u03bd\u03c9 ("manthano"), while the modern Greek equivalent is \u03bc\u03b1\u03b8\u03b1\u03af\u03bd\u03c9 ("mathaino"), both of which mean "to learn". In Greece, the word for "mathematics" came to have the narrower and more technical meaning "mathematical study" even in Classical times. Its adjective is ("math\u0113matikós"), meaning "related to learning" or "studious", which likewise further came to mean "mathematical". In particular, ("math\u0113matik\u1e17 tékhn\u0113"), , meant "the mathematical art".
p10196
aVIn Latin, and in English until around 1700, the term "mathematics" more commonly meant "astrology" (or sometimes "astronomy") rather than "mathematics"; the meaning gradually changed to its present one from about 1500 to 1800. This has resulted in several mistranslations: a particularly notorious one is Saint Augustine's warning that Christians should beware of "mathematici" meaning astrologers, which is sometimes mistranslated as a condemnation of mathematicians.
p10197
aVThe apparent plural form in English, like the French plural form (and the less commonly used singular derivative ), goes back to the Latin neuter plural (Cicero), based on the Greek plural ("ta math\u0113matiká"), used by Aristotle (384\u2013322 BC), and meaning roughly "all things mathematical"; although it is plausible that English borrowed only the adjective "mathematic(al)" and formed the noun "mathematics" anew, after the pattern of physics and metaphysics, which were inherited from the Greek. In English, the noun "mathematics" takes singular verb forms. It is often shortened to "maths" or, in English-speaking North America, "math".
p10198
aVDefinitions of mathematics.
p10199
aVAristotle defined mathematics as "the science of quantity", and this definition prevailed until the 18th century. Starting in the 19th century, when the study of mathematics increased in rigor and began to address abstract topics such as group theory and projective geometry, which have no clear-cut relation to quantity and measurement, mathematicians and philosophers began to propose a variety of new definitions. Some of these definitions emphasize the deductive character of much of mathematics, some emphasize its abstractness, some emphasize certain topics within mathematics. Today, no consensus on the definition of mathematics prevails, even among professionals. There is not even consensus on whether mathematics is an art or a science. A great many professional mathematicians take no interest in a definition of mathematics, or consider it undefinable. Some just say, "Mathematics is what mathematicians do."
p10200
aVThree leading types of definition of mathematics are called logicist, intuitionist, and formalist, each reflecting a different philosophical school of thought. All have severe problems, none has widespread acceptance, and no reconciliation seems possible.
p10201
aVAn early definition of mathematics in terms of logic was Benjamin Peirce's "the science that draws necessary conclusions" (1870). In the "Principia Mathematica", Bertrand Russell and Alfred North Whitehead advanced the philosophical program known as logicism, and attempted to prove that all mathematical concepts, statements, and principles can be defined and proven entirely in terms of symbolic logic. A logicist definition of mathematics is Russell's "All Mathematics is Symbolic Logic" (1903).
p10202
aVIntuitionist definitions, developing from the philosophy of mathematician L.E.J. Brouwer, identify mathematics with certain mental phenomena. An example of an intuitionist definition is "Mathematics is the mental activity which consists in carrying out constructs one after the other." A peculiarity of intuitionism is that it rejects some mathematical ideas considered valid according to other definitions. In particular, while other philosophies of mathematics allow objects that can be proven to exist even though they cannot be constructed, intuitionism allows only mathematical objects that one can actually construct.
p10203
aVFormalist definitions identify mathematics with its symbols and the rules for operating on them. Haskell Curry defined mathematics simply as "the science of formal systems". A formal system is a set of symbols, or "tokens", and some "rules" telling how the tokens may be combined into "formulas". In formal systems, the word "axiom" has a special meaning, different from the ordinary meaning of "a self-evident truth". In formal systems, an axiom is a combination of tokens that is included in a given formal system without needing to be derived using the rules of the system.
p10204
aVInspiration, pure and applied mathematics, and aesthetics.
p10205
aVMathematics arises from many different kinds of problems. At first these were found in commerce, land measurement, architecture and later astronomy; today, all sciences suggest problems studied by mathematicians, and many problems arise within mathematics itself. For example, the physicist Richard Feynman invented the path integral formulation of quantum mechanics using a combination of mathematical reasoning and physical insight, and today's string theory, a still-developing scientific theory which attempts to unify the four fundamental forces of nature, continues to inspire new mathematics. 
p10206
aVSome mathematics is relevant only in the area that inspired it, and is applied to solve further problems in that area. But often mathematics inspired by one area proves useful in many areas, and joins the general stock of mathematical concepts. A distinction is often made between pure mathematics and applied mathematics. However pure mathematics topics often turn out to have applications, e.g. number theory in cryptography. This remarkable fact that even the "purest" mathematics often turns out to have practical applications is what Eugene Wigner has called "the unreasonable effectiveness of mathematics". As in most areas of study, the explosion of knowledge in the scientific age has led to specialization: there are now hundreds of specialized areas in mathematics and the latest Mathematics Subject Classification runs to 46 pages. Several areas of applied mathematics have merged with related traditions outside of mathematics and become disciplines in their own right, including statistics, operations research, and computer science.
p10207
aVFor those who are mathematically inclined, there is often a definite aesthetic aspect to much of mathematics. Many mathematicians talk about the "elegance" of mathematics, its intrinsic aesthetics and inner beauty. Simplicity and generality are valued. There is beauty in a simple and elegant proof, such as Euclid's proof that there are infinitely many prime numbers, and in an elegant numerical method that speeds calculation, such as the fast Fourier transform. G.H. Hardy in "A Mathematician's Apology" expressed the belief that these aesthetic considerations are, in themselves, sufficient to justify the study of pure mathematics. He identified criteria such as significance, unexpectedness, inevitability, and economy as factors that contribute to a mathematical aesthetic. Mathematicians often strive to find proofs that are particularly elegant, proofs from "The Book" of God according to Paul Erd\u0151s. The popularity of recreational mathematics is another sign of the pleasure many find in solving mathematical questions.
p10208
aVNotation, language, and rigor.
p10209
aVMost of the mathematical notation in use today was not invented until the 16th century. Before that, mathematics was written out in words, a painstaking process that limited mathematical discovery. Euler (1707\u20131783) was responsible for many of the notations in use today. Modern notation makes mathematics much easier for the professional, but beginners often find it daunting. It is extremely compressed: a few symbols contain a great deal of information. Like musical notation, modern mathematical notation has a strict syntax (which to a limited extent varies from author to author and from discipline to discipline) and encodes information that would be difficult to write in any other way.
p10210
aVMathematical language can be difficult to understand for beginners. Words such as "or" and "only" have more precise meanings than in everyday speech. Moreover, words such as "open" and "field" have been given specialized mathematical meanings. Technical terms such as "homeomorphism" and "integrable" have precise meanings in mathematics. Additionally, shorthand phrases such as "iff" for "if and only if" belong to mathematical jargon. There is a reason for special notation and technical vocabulary: mathematics requires more precision than everyday speech. Mathematicians refer to this precision of language and logic as "rigor".
p10211
aVMathematical proof is fundamentally a matter of rigor. Mathematicians want their theorems to follow from axioms by means of systematic reasoning. This is to avoid mistaken "theorems", based on fallible intuitions, of which many instances have occurred in the history of the subject. The level of rigor expected in mathematics has varied over time: the Greeks expected detailed arguments, but at the time of Isaac Newton the methods employed were less rigorous. Problems inherent in the definitions used by Newton would lead to a resurgence of careful analysis and formal proof in the 19th century. Misunderstanding the rigor is a cause for some of the common misconceptions of mathematics. Today, mathematicians continue to argue among themselves about computer-assisted proofs. Since large computations are hard to verify, such proofs may not be sufficiently rigorous.
p10212
aVAxioms in traditional thought were "self-evident truths", but that conception is problematic. At a formal level, an axiom is just a string of symbols, which has an intrinsic meaning only in the context of all derivable formulas of an axiomatic system. It was the goal of Hilbert's program to put all of mathematics on a firm axiomatic basis, but according to Gödel's incompleteness theorem every (sufficiently powerful) axiomatic system has undecidable formulas; and so a final axiomatization of mathematics is impossible. Nonetheless mathematics is often imagined to be (as far as its formal content) nothing but set theory in some axiomatization, in the sense that every mathematical statement or proof could be cast into formulas within set theory.
p10213
aVFields of mathematics.
p10214
aVMathematics can, broadly speaking, be subdivided into the study of quantity, structure, space, and change (i.e. arithmetic, algebra, geometry, and analysis). In addition to these main concerns, there are also subdivisions dedicated to exploring links from the heart of mathematics to other fields: to logic, to set theory (foundations), to the empirical mathematics of the various sciences (applied mathematics), and more recently to the rigorous study of uncertainty.
p10215
aVFoundations and philosophy.
p10216
aVIn order to clarify the foundations of mathematics, the fields of mathematical logic and set theory were developed. Mathematical logic includes the mathematical study of logic and the applications of formal logic to other areas of mathematics; set theory is the branch of mathematics that studies sets or collections of objects. Category theory, which deals in an abstract way with mathematical structures and relationships between them, is still in development. The phrase "crisis of foundations" describes the search for a rigorous foundation for mathematics that took place from approximately 1900 to 1930. Some disagreement about the foundations of mathematics continues to the present day. The crisis of foundations was stimulated by a number of controversies at the time, including the controversy over Cantor's set theory and the Brouwer\u2013Hilbert controversy.
p10217
aVMathematical logic is concerned with setting mathematics within a rigorous axiomatic framework, and studying the implications of such a framework. As such, it is home to Gödel's incompleteness theorems which (informally) imply that any effective formal system that contains basic arithmetic, if "sound" (meaning that all theorems that can be proven are true), is necessarily "incomplete" (meaning that there are true theorems which cannot be proved "in that system"). Whatever finite collection of number-theoretical axioms is taken as a foundation, Gödel showed how to construct a formal statement that is a true number-theoretical fact, but which does not follow from those axioms. Therefore no formal system is a complete axiomatization of full number theory. Modern logic is divided into recursion theory, model theory, and proof theory, and is closely linked to theoretical computer science, as well as to category theory.
p10218
aVTheoretical computer science includes computability theory, computational complexity theory, and information theory. Computability theory examines the limitations of various theoretical models of the computer, including the most well-known model \u2013 the Turing machine. Complexity theory is the study of tractability by computer; some problems, although theoretically solvable by computer, are so expensive in terms of time or space that solving them is likely to remain practically unfeasible, even with the rapid advancement of computer hardware. A famous problem is the "P = NP problem" problem, one of the Millennium Prize Problems. Finally, information theory is concerned with the amount of data that can be stored on a given medium, and hence deals with concepts such as compression and entropy.
p10219
aVPure mathematics.
p10220
aVQuantity.
p10221
aVThe study of quantity starts with numbers, first the familiar natural numbers and integers ("whole numbers") and arithmetical operations on them, which are characterized in arithmetic. The deeper properties of integers are studied in number theory, from which come such popular results as Fermat's Last Theorem. The twin prime conjecture and Goldbach's conjecture are two unsolved problems in number theory.
p10222
aVAs the number system is further developed, the integers are recognized as a subset of the rational numbers ("fractions"). These, in turn, are contained within the real numbers, which are used to represent continuous quantities. Real numbers are generalized to complex numbers. These are the first steps of a hierarchy of numbers that goes on to include quaternions and octonions. Consideration of the natural numbers also leads to the transfinite numbers, which formalize the concept of "infinity". Another area of study is size, which leads to the cardinal numbers and then to another conception of infinity: the aleph numbers, which allow meaningful comparison of the size of infinitely large sets.
p10223
aVStructure.
p10224
aVMany mathematical objects, such as sets of numbers and functions, exhibit internal structure as a consequence of operations or relations that are defined on the set. Mathematics then studies properties of those sets that can be expressed in terms of that structure; for instance number theory studies properties of the set of integers that can be expressed in terms of arithmetic operations. Moreover, it frequently happens that different such structured sets (or structures) exhibit similar properties, which makes it possible, by a further step of abstraction, to state axioms for a class of structures, and then study at once the whole class of structures satisfying these axioms. Thus one can study groups, rings, fields and other abstract systems; together such studies (for structures defined by algebraic operations) constitute the domain of abstract algebra. 
p10225
aVBy its great generality, abstract algebra can often be applied to seemingly unrelated problems; for instance a number of ancient problems concerning compass and straightedge constructions were finally solved using Galois theory, which involves field theory and group theory. Another example of an algebraic theory is linear algebra, which is the general study of vector spaces, whose elements called vectors have both quantity and direction, and can be used to model (relations between) points in space. This is one example of the phenomenon that the originally unrelated areas of geometry and algebra have very strong interactions in modern mathematics. Combinatorics studies ways of enumerating the number of objects that fit a given structure.
p10226
aVSpace.
p10227
aVThe study of space originates with geometry \u2013 in particular, Euclidean geometry. Trigonometry is the branch of mathematics that deals with relationships between the sides and the angles of triangles and with the trigonometric functions; it combines space and numbers, and encompasses the well-known Pythagorean theorem. The modern study of space generalizes these ideas to include higher-dimensional geometry, non-Euclidean geometries (which play a central role in general relativity) and topology. Quantity and space both play a role in analytic geometry, differential geometry, and algebraic geometry. Convex and discrete geometry were developed to solve problems in number theory and functional analysis but now are pursued with an eye on applications in optimization and computer science. Within differential geometry are the concepts of fiber bundles and calculus on manifolds, in particular, vector and tensor calculus. Within algebraic geometry is the description of geometric objects as solution sets of polynomial equations, combining the concepts of quantity and space, and also the study of topological groups, which combine structure and space. Lie groups are used to study space, structure, and change. Topology in all its many ramifications may have been the greatest growth area in 20th-century mathematics; it includes point-set topology, set-theoretic topology, algebraic topology and differential topology. In particular, instances of modern day topology are metrizability theory, axiomatic set theory, homotopy theory, and Morse theory. Topology also includes the now solved Poincaré conjecture, and the still unsolved areas of the Hodge conjecture. Other results in geometry and topology, including the four color theorem and Kepler conjecture, have been proved only with the help of computers.
p10228
aVChange.
p10229
aVUnderstanding and describing change is a common theme in the natural sciences, and calculus was developed as a powerful tool to investigate it. Functions arise here, as a central concept describing a changing quantity. The rigorous study of real numbers and functions of a real variable is known as real analysis, with complex analysis the equivalent field for the complex numbers. Functional analysis focuses attention on (typically infinite-dimensional) spaces of functions. One of many applications of functional analysis is quantum mechanics. Many problems lead naturally to relationships between a quantity and its rate of change, and these are studied as differential equations. Many phenomena in nature can be described by dynamical systems; chaos theory makes precise the ways in which many of these systems exhibit unpredictable yet still deterministic behavior.
p10230
aVApplied mathematics.
p10231
aVApplied mathematics concerns itself with mathematical methods that are typically used in science, engineering, business, and industry. Thus, "applied mathematics" is a mathematical science with specialized knowledge. The term "applied mathematics" also describes the professional specialty in which mathematicians work on practical problems; as a profession focused on practical problems, "applied mathematics" focuses on the "formulation, study, and use of mathematical models" in science, engineering, and other areas of mathematical practice.
p10232
aVIn the past, practical applications have motivated the development of mathematical theories, which then became the subject of study in pure mathematics, where mathematics is developed primarily for its own sake. Thus, the activity of applied mathematics is vitally connected with research in pure mathematics.
p10233
aVStatistics and other decision sciences.
p10234
aVApplied mathematics has significant overlap with the discipline of statistics, whose theory is formulated mathematically, especially with probability theory. Statisticians (working as part of a research project) "create data that makes sense" with random sampling and with randomized experiments; the design of a statistical sample or experiment specifies the analysis of the data (before the data be available). When reconsidering data from experiments and samples or when analyzing data from observational studies, statisticians "make sense of the data" using the art of modelling and the theory of inference \u2013 with model selection and estimation; the estimated models and consequential predictions should be tested on new data.
p10235
aVStatistical theory studies decision problems such as minimizing the risk (expected loss) of a statistical action, such as using a procedure in, for example, parameter estimation, hypothesis testing, and selecting the best. In these traditional areas of mathematical statistics, a statistical-decision problem is formulated by minimizing an objective function, like expected loss or cost, under specific constraints: For example, designing a survey often involves minimizing the cost of estimating a population mean with a given level of confidence. Because of its use of optimization, the mathematical theory of statistics shares concerns with other decision sciences, such as operations research, control theory, and mathematical economics.
p10236
aVComputational mathematics.
p10237
aVComputational mathematics proposes and studies methods for solving mathematical problems that are typically too large for human numerical capacity. Numerical analysis studies methods for problems in analysis using functional analysis and approximation theory; numerical analysis includes the study of approximation and discretization broadly with special concern for rounding errors. Numerical analysis and, more broadly, scientific computing also study non-analytic topics of mathematical science, especially algorithmic matrix and graph theory. Other areas of computational mathematics include computer algebra and symbolic computation.
p10238
aVMathematical awards.
p10239
aVArguably the most prestigious award in mathematics is the Fields Medal, established in 1936 and now awarded every four years. The Fields Medal is often considered a mathematical equivalent to the Nobel Prize. 
p10240
aVThe Wolf Prize in Mathematics, instituted in 1978, recognizes lifetime achievement, and another major international award, the Abel Prize, was introduced in 2003. The Chern Medal was introduced in 2010 to recognize lifetime achievement. These accolades are awarded in recognition of a particular body of work, which may be innovational, or provide a solution to an outstanding problem in an established field.
p10241
aVA famous list of 23 open problems, called "Hilbert's problems", was compiled in 1900 by German mathematician David Hilbert. This list achieved great celebrity among mathematicians, and at least nine of the problems have now been solved. A new list of seven important problems, titled the "Millennium Prize Problems", was published in 2000. A solution to each of these problems carries a $1 million reward, and only one (the Riemann hypothesis) is duplicated in Hilbert's problems.
p10242
aVMathematics as science.
p10243
aVGauss referred to mathematics as "the Queen of the Sciences". In the original Latin "Regina Scientiarum", as well as in German "Königin der Wissenschaften", the word corresponding to "science" means a "field of knowledge", and this was the original meaning of "science" in English, also; mathematics is in this sense a field of knowledge. The specialization restricting the meaning of "science" to "natural science" follows the rise of Baconian science, which contrasted "natural science" to scholasticism, the Aristotelean method of inquiring from first principles. The role of empirical experimentation and observation is negligible in mathematics, compared to natural sciences such as psychology, biology, or physics. Albert Einstein stated that "as far as the laws of mathematics refer to reality, they are not certain; and as far as they are certain, they do not refer to reality." More recently, Marcus du Sautoy has called mathematics "the Queen of Science ... the main driving force behind scientific discovery".
p10244
aVMany philosophers believe that mathematics is not experimentally falsifiable, and thus not a science according to the definition of Karl Popper. However, in the 1930s Gödel's incompleteness theorems convinced many mathematicians that mathematics cannot be reduced to logic alone, and Karl Popper concluded that "most mathematical theories are, like those of physics and biology, hypothetico-deductive: pure mathematics therefore turns out to be much closer to the natural sciences whose hypotheses are conjectures, than it seemed even recently." Other thinkers, notably Imre Lakatos, have applied a version of falsificationism to mathematics itself.
p10245
aVAn alternative view is that certain scientific fields (such as theoretical physics) are mathematics with axioms that are intended to correspond to reality. The theoretical physicist J.M. Ziman proposed that science is "public knowledge", and thus includes mathematics. Mathematics shares much in common with many fields in the physical sciences, notably the exploration of the logical consequences of assumptions. Intuition and experimentation also play a role in the formulation of conjectures in both mathematics and the (other) sciences. Experimental mathematics continues to grow in importance within mathematics, and computation and simulation are playing an increasing role in both the sciences and mathematics.
p10246
aVThe opinions of mathematicians on this matter are varied. Many mathematicians feel that to call their area a science is to downplay the importance of its aesthetic side, and its history in the traditional seven liberal arts; others feel that to ignore its connection to the sciences is to turn a blind eye to the fact that the interface between mathematics and its applications in science and engineering has driven much development in mathematics. One way this difference of viewpoint plays out is in the philosophical debate as to whether mathematics is "created" (as in art) or "discovered" (as in science). It is common to see universities divided into sections that include a division of "Science and Mathematics", indicating that the fields are seen as being allied but that they do not coincide. In practice, mathematicians are typically grouped with scientists at the gross level but separated at finer levels. This is one of many issues considered in the philosophy of mathematics.
p10247
asS'Pythagorean triple'
p10248
(lp10249
VA Pythagorean triple consists of three positive integers "a", "b", and "c", such that . Such a triple is commonly written , and a well-known example is . If is a Pythagorean triple, then so is ("ka", "kb", "kc") for any positive integer "k". A primitive Pythagorean triple is one in which "a", "b" and "c" are coprime. A right triangle whose sides form a Pythagorean triple is called a Pythagorean triangle.
p10250
aVThe name is derived from the Pythagorean theorem, stating that every right triangle has side lengths satisfying the formula ; thus, Pythagorean triples describe the three integer side lengths of a right triangle. However, right triangles with non-integer sides do not form Pythagorean triples. For instance, the triangle with sides and "c" = \u221a2 is right, but (1, 1, \u221a2) is not a Pythagorean triple because \u221a2 is not an integer. Moreover, 1 and \u221a2 do not have an integer common multiple because \u221a2 is irrational.
p10251
aVExamples.
p10252
aVThere are 16 primitive Pythagorean triples with :
p10253
aVNote, for example, that (6, 8, 10) is "not" a primitive Pythagorean triple, as it is a multiple of (3, 4, 5). Each one of these low-c points forms one of the more easily recognizable radiating lines in the scatter plot.
p10254
aVAdditionally these are all the primitive Pythagorean triples with :
p10255
aVGenerating a triple.
p10256
aVEuclid's formula'" is a fundamental formula for generating Pythagorean triples given an arbitrary pair of positive integers "m" and "n" with . The formula states that the integers
p10257
aVformula_1
p10258
aVform a Pythagorean triple. The triple generated by Euclid's formula is primitive if and only if "m" and "n" are coprime and is odd. If both "m" and "n" are odd, then "a", "b", and "c" will be even, and so the triple will not be primitive; however, dividing "a", "b", and "c" by 2 will yield a primitive triple if "m" and "n" are coprime.
p10259
aV"Every" primitive triple arises from a "unique pair" of coprime numbers "m", "n", one of which is even. It follows that there are infinitely many primitive Pythagorean triples. This relationship of "a", "b" and "c" to "m" and "n" from Euclid's formula is referenced throughout the rest of this article.
p10260
aVDespite generating all primitive triples, Euclid's formula does not produce all triples\u2014for example, (9, 12, 15) cannot be generated using integer "m" and "n". This can be remedied by inserting an additional parameter "k" to the formula. The following will generate all Pythagorean triples uniquely:
p10261
aVformula_2
p10262
aVwhere "m", "n", and "k" are positive integers with , odd, and with "m" and "n" coprime.
p10263
aVThat these formulas generate Pythagorean triples can be verified by expanding using elementary algebra and verifying that the result coincides with "c"2. Since every Pythagorean triple can be divided through by some integer "k" to obtain a primitive triple, every triple can be generated uniquely by using the formula with "m" and "n" to generate its primitive counterpart and then multiplying through by "k" as in the last equation.
p10264
aVMany formulas for generating triples with particular properties have been developed since the time of Euclid.
p10265
aVProof of Euclid's formula.
p10266
aVThat satisfaction of Euclid's formula by "a, b, c" is sufficient for the triangle to be Pythagorean is apparent from the fact that for positive integers "m" and "n", "m" > "n", the "a, b," and "c" given by the formula are all positive integers, and from the fact that
p10267
aVformula_3
p10268
aVA simple proof of the "necessity" that "a, b, c" be expressed by Euclid's formula for any primitive Pythagorean triple is as follows. All such triples can be written as ("a", "b", "c") where and "a", "b", "c" are coprime, and where "b" and "c" have opposite parities (one is even and one is odd). (If "c" had the same parity as both legs, then if all were even the parameters would not be coprime, and if all were odd then would equate an even to an odd.) From formula_4 we obtain formula_5 and hence formula_6. Then formula_7. Since formula_8 is rational, we set it equal to formula_9 in lowest terms. We also observe that formula_10 equals the reciprocal of formula_11 and hence equals the reciprocal of formula_8, and thus equals formula_13. Then solving
p10269
aVformula_14
p10270
aVfor formula_15 and formula_16 gives
p10271
aVformula_17
p10272
aVSince formula_15 and formula_16 are fully reduced by assumption, the numerators can be equated and the denominators can be equated if and only if the right side of each equation is fully reduced; given the previous specification that formula_9 is fully reduced, implying that "m" and "n" are coprime, the right sides are fully reduced if and only if "m" and "n" have opposite parity (one is even and one is odd) so that the numerators are not divisible by 2. (And "m" and "n" "must" have opposite parity: if both were odd then dividing through formula_21 by 2 would give the ratio of two odd numbers; equating this ratio to formula_15, which is a ratio of two numbers with opposite parities, would give different 2-adic orders for numbers supposedly equal.) So, equating numerators and equating denominators, we have Euclid's formula formula_23 with "m" and "n" coprime and of opposite parities.
p10273
aVA longer but more commonplace proof is given in Maor (2007) and Sierpi\u0144ski (2003).
p10274
aVInterpretation of parameters in Euclid's formula.
p10275
aVSuppose the sides of a Pythagorean triangle are formula_24, and formula_25, and suppose the angle between the leg formula_26 and the hypotenuse formula_25 is denoted as formula_28. Then formula_29 and formula_30.
p10276
aVElementary properties of primitive Pythagorean triples.
p10277
aVGeneral properties.
p10278
aVThe properties of a primitive Pythagorean triple ("a", "b", "c") with "a" < "b" < "c" (without specifying which of "a" or "b" is even and which is odd) include:
p10279
aVformula_32
p10280
aVSpecial cases.
p10281
aVIn addition, special Pythagorean triples with certain additional properties can be guaranteed to exist:
p10282
aVGeometry of Euclid's formula.
p10283
aVEuclid's formulae for a Pythagorean triple
p10284
aVformula_33
p10285
aVcan be understood in terms of the geometry of rational number points on the unit circle . To motivate this, consider a right triangle with legs "a" and "b", and hypotenuse "c", where "a", "b", and "c" are positive integers. By the Pythagorean theorem, or, dividing both sides by "c"2,
p10286
aVformula_34
p10287
aVGeometrically, the point in the Cartesian plane with coordinates
p10288
aVformula_35
p10289
aVis on the unit circle . In this equation, the coordinates "x" and "y" are given by rational numbers. Conversely, any point on the unit circle whose coordinates "x", "y" are rational numbers gives rise to a primitive Pythagorean triple. Indeed, write "x" and "y" as fractions in lowest terms:
p10290
aVformula_35
p10291
aVwhere the greatest common divisor of "a", "b", and "c" is 1. Then, since "x" and "y" are on the unit circle,
p10292
aVformula_37
p10293
aVas claimed.
p10294
aVThere is therefore a correspondence between points on the unit circle with rational coordinates and primitive Pythagorean triples. At this point, Euclid's formulae can be derived either by methods of trigonometry or equivalently by using the stereographic projection.
p10295
aVFor the stereographic approach, suppose that "P"\u2032 is a point on the "x"-axis with rational coordinates
p10296
aVformula_38
p10297
aVThen, it can be shown by basic algebra that the point "P" has coordinates
p10298
aVformula_39
p10299
aVThis establishes that each rational point of the "x"-axis goes over to a rational point of the unit circle. The converse, that every rational point of the unit circle comes from such a point of the "x"-axis, follows by applying the inverse stereographic projection. Suppose that "P"("x", "y") is a point of the unit circle with "x" and "y" rational numbers. Then the point "P"\u2032 obtained by stereographic projection onto the "x"-axis has coordinates
p10300
aVformula_40
p10301
aVwhich is rational.
p10302
aVIn terms of algebraic geometry, the algebraic variety of rational points on the unit circle is birational to the affine line over the rational numbers. The unit circle is thus called a rational curve, and it is this fact which enables an explicit parameterization of the (rational number) points on it by means of rational functions.
p10303
aVPythagorean triangles in a 2D lattice.
p10304
aVA 2D lattice is a regular array of isolated points where if any one point is chosen as the Cartesian origin (0, 0), then all the other points are at ("x", "y") where "x" and "y" range over all positive and negative integers. Any Pythagorean triangle with triple ("a", "b", "c") can be drawn within a 2D lattice with vertices at coordinates (0, 0), ("a", 0) and (0, "b"). The count of lattice points lying strictly within the bounds of the triangle is given by   formula_41 for primitive Pythagorean triples this interior lattice count is  formula_42 The area (by Pick's theorem equal to one less than the interior lattice count plus half the boundary lattice count) equals  formula_43 .
p10305
aVThe first occurrence of two primitive Pythagorean triples sharing the same area occurs with triangles with sides (20, 21, 29), (12, 35, 37) and common area 210 . The first occurrence of two primitive Pythagorean triples sharing the same interior lattice count occurs with (18108, 252685, 253333), (28077, 162964, 165365) and interior lattice count 2287674594 . Three primitive Pythagorean triples have been found sharing the same area: (4485,  5852,  7373), (3059, 8580, 9109), (1380, 19019, 19069) with area 13123110. As yet, no set of three primitive Pythagorean triples have been found sharing the same interior lattice count.
p10306
aVSpinors and the modular group.
p10307
aVPythagorean triples can likewise be encoded into a matrix of the form
p10308
aVformula_44
p10309
aVA matrix of this form is symmetric. Furthermore, the determinant of "X" is
p10310
aVformula_45
p10311
aVwhich is zero precisely when ("a","b","c") is a Pythagorean triple. If "X" corresponds to a Pythagorean triple, then as a matrix it must have rank 1.
p10312
aVSince "X" is symmetric, it follows from a result in linear algebra that there is a column vector such that the outer product
p10313
aVholds, where the "T" denotes the matrix transpose. The vector \u03be is called a spinor (for the Lorentz group SO(1, 2)). In abstract terms, the Euclid formula means that each primitive Pythagorean triple can be written as the outer product with itself of a spinor with integer entries, as in ().
p10314
aVThe modular group \u0393 is the set of 2×2 matrices with integer entries
p10315
aVformula_46
p10316
aVwith determinant equal to one: . This set forms a group, since the inverse of a matrix in \u0393 is again in \u0393, as is the product of two matrices in \u0393. The modular group acts on the collection of all integer spinors. Furthermore, the group is transitive on the collection of integer spinors with relatively prime entries. For if ["m" "n"]T has relatively prime entries, then
p10317
aVformula_47
p10318
aVwhere "u" and "v" are selected (by the Euclidean algorithm) so that .
p10319
aVBy acting on the spinor \u03be in (), the action of \u0393 goes over to an action on Pythagorean triples, provided one allows for triples with possibly negative components. Thus if "A" is a matrix in \u0393, then
p10320
aVgives rise to an action on the matrix "X" in (). This does not give a well-defined action on primitive triples, since it may take a primitive triple to an imprimitive one. It is convenient at this point (per ) to call a triple ("a","b","c") standard if and either ("a","b","c") are relatively prime or ("a"/2,"b"/2,"c"/2) are relatively prime with "a"/2 odd. If the spinor ["m" "n"]T has relatively prime entries, then the associated triple ("a","b","c") determined by () is a standard triple. It follows that the action of the modular group is transitive on the set of standard triples.
p10321
aVAlternatively, restrict attention to those values of "m" and "n" for which "m" is odd and "n" is even. Let the subgroup \u0393(2) of \u0393 be the kernel of the group homomorphism
p10322
aVformula_48
p10323
aVwhere SL(2,Z2) is the special linear group over the finite field Z2 of integers modulo 2. Then \u0393(2) is the group of unimodular transformations which preserve the parity of each entry. Thus if the first entry of \u03be is odd and the second entry is even, then the same is true of "A"\u03be for all . In fact, under the action (), the group \u0393(2) acts transitively on the collection of primitive Pythagorean triples .
p10324
aVThe group \u0393(2) is the free group whose generators are the matrices
p10325
aVformula_49
p10326
aVConsequently, every primitive Pythagorean triple can be obtained in a unique way as a product of copies of the matrices "U" and "L".
p10327
aVParent/child relationships.
p10328
aVBy a result of , all primitive Pythagorean triples can be generated from the (3, 4, 5) triangle by using the three linear transformations T1, T2, T3 below, where "a", "b", "c" are sides of a triple:
p10329
aVIf one begins with 3, 4, 5 then all other primitive triples will eventually be produced. In other words, every primitive triple will be a \u201cparent\u201d to 3 additional primitive triples.
p10330
aVStarting from the initial node with "a" = 3, "b" = 4, and "c" = 5, the next generation of triples is
p10331
aVThe linear transformations T1, T2, and T3 have a geometric interpretation in the language of quadratic forms. They are closely related to (but are not equal to) reflections generating the orthogonal group of "x"2 + "y"2 \u2212 "z"2 over the integers. A different set of three linear transformations is discussed in Pythagorean triples by use of matrices and linear transformations. For further discussion of parent-child relationships in triples, see: Pythagorean triple (Wolfram) and
p10332
aVRelation to Gaussian integers.
p10333
aVAlternatively, Euclid's formulae can be analyzed and proven using the Gaussian integers. Gaussian integers are complex numbers of the form , where "u" and "v" are ordinary integers and "i" is the square root of negative one. The units of Gaussian integers are ±1 and ±i. The ordinary integers are called the rational integers and denoted as Z. The Gaussian integers are denoted as Z["i"].. The right-hand side of the Pythagorean theorem may be factored in Gaussian integers:
p10334
aVformula_50
p10335
aVA primitive Pythagorean triple is one in which "a" and "b" are coprime, i.e., they share no prime factors in the integers. For such a triple, either "a" or "b" is even, and the other is odd; from this, it follows that "c" is also odd.
p10336
aVThe two factors and of a primitive Pythagorean triple each equal the square of a Gaussian integer. This can be proved using the property that every Gaussian integer can be factored uniquely into Gaussian primes up to units. (This unique factorization follows from the fact that, roughly speaking, a version of the Euclidean algorithm can be defined on them.) The proof has three steps. First, if "a" and "b" share no prime factors in the integers, then they also share no prime factors in the Gaussian integers. (Assume "a" = "gu" and "b" = "gv" with Gaussian integers "g", "u" and "v" and "g" not a unit. Then "u" and "v" lie on the same line through the origin. All Gaussian integers on such a line are integer multiples of some Gaussian integer "h". But then the integer "gh" \u2260 ±1 divides both "a" and "b".) Second, it follows that "z" and "z*" likewise share no prime factors in the Gaussian integers. For if they did, then their common divisor \u03b4 would also divide "z" + "z*" = 2"a" and "z" \u2212 "z*" = 2"ib". Since "a" and "b" are coprime, that implies that \u03b4 divides 2 = (1 + i)(1 \u2212 i) = i(1 \u2212 i)2. From the formula "c"2 = "zz*", that in turn would imply that "c" is even, contrary to the hypothesis of a primitive Pythagorean triple. Third, since "c"2 is a square, every Gaussian prime in its factorization is doubled, i.e., appears an even number of times. Since "z" and "z*" share no prime factors, this doubling is also true for them. Hence, "z" and "z*" are squares.
p10337
aVThus, the first factor can be written
p10338
aVformula_51
p10339
aVThe real and imaginary parts of this equation give the two formulas:
p10340
aVformula_52
p10341
aVFor any primitive Pythagorean triple, there must be integers "m" and "n" such that these two equations are satisfied. Hence, every Pythagorean triple can be generated from some choice of these integers.
p10342
aVAs perfect square Gaussian integers.
p10343
aVIf we consider the square of a Gaussian integer we get the following direct interpretation of Euclid's formulae as representing a perfect square Gaussian integers.
p10344
aVformula_53
p10345
aVUsing the facts that the Gaussian integers are a Euclidean domain and that for a Gaussian integer p formula_54 is always a square it is possible to show that a Pythagorean triples correspond to the square of a prime Gaussian integer if the hypotenuse is prime.
p10346
aVIf the Gaussian integer is not prime then it is the product of two Gaussian integers p and q with formula_54 and formula_56 integers. Since magnitudes multiply in the Gaussian integers, the product must be formula_57, which when squared to find a Pythagorean triple must be composite. The contrapositive completes the proof.
p10347
aVDistribution of triples.
p10348
aVThere are a number of results on the distribution of Pythagorean triples. In the scatter plot, a number of obvious patterns are already apparent. Whenever the legs ("a","b") of a primitive triple appear in the plot, all integer multiples of ("a","b") must also appear in the plot, and this property produces the appearance of lines radiating from the origin in the diagram.
p10349
aVWithin the scatter, there are sets of parabolic patterns with a high density of points and all their foci at the origin, opening up in all four directions. Different parabolas intersect at the axes and appear to reflect off the axis with an incidence angle of 45 degrees, with a third parabola entering in a perpendicular fashion. Within this quadrant, each arc centered around the origin shows that section of the parabola that lies between its tip and its intersection with its semi-latus rectum.
p10350
aVThese patterns can be explained as follows. If formula_58 is an integer, then ("a", formula_59, formula_60) is a Pythagorean triple. (In fact every Pythagorean triple ("a", "b", "c") can be written in this way with integer "n", possibly after exchanging "a" and "b", since formula_61 and "a" and "b" cannot both be odd.) The Pythagorean triples thus lie on curves given by formula_62, that is, parabolas reflected at the "a"-axis, and the corresponding curves with "a" and "b" interchanged. If "a" is varied for a given "n" (i.e. on a given parabola), integer values of "b" occur relatively frequently if "n" is a square or a small multiple of a square. If several such values happen to lie close together, the corresponding parabolas approximately coincide, and the triples cluster in a narrow parabolic strip. For instance, 382 = 1444, 2 × 272 = 1458,
p10351
aV3 × 222 = 1452, 5 × 172 = 1445 and 10 × 122 = 1440; the corresponding parabolic strip around "n" \u2248 1450 is clearly visible in the scatter plot.
p10352
aVThe angular properties described above follow immediately from the functional form of the parabolas. The parabolas are reflected at the "a"-axis at "a" = 2"n", and the derivative of "b" with respect to "a" at this point is \u20131; hence the incidence angle is 45°. Since the clusters, like all triples, are repeated at integer multiples, the value 2"n" also corresponds to a cluster. The corresponding parabola intersects the "b"-axis at right angles at "b" = 2"n", and hence its reflection upon interchange of "a" and "b" intersects the "a"-axis at right angles at "a" = 2"n", precisely where the parabola for "n" is reflected at the "a"-axis. (The same is of course true for "a" and "b" interchanged.)
p10353
aVAlbert Fässler and others provide insights into the significance of these parabolas in the context of conformal mappings.
p10354
aVSpecial cases.
p10355
aVThe Platonic sequence.
p10356
aVThe case "n" = 1 of the more general construction of Pythagorean triples has been known for a long time. Proclus, in his commentary to the 47th Proposition of the first book of Euclid's Elements, describes it as follows:
p10357
aVCertain methods for the discovery of triangles of this kind are handed down, one which they refer to Plato, and another to Pythagoras. (The latter) starts from odd numbers. For it makes the odd number the smaller of the sides about the right angle; then it takes the square of it, subtracts unity and makes half the difference the greater of the sides about the right angle; lastly it adds unity to this and so forms the remaining side, the hypotenuse.
p10358
aV...For the method of Plato argues from even numbers. It takes the given even number and makes it one of the sides about the right angle; then, bisecting this number and squaring the half, it adds unity to the square to form the hypotenuse, and subtracts unity from the square to form the other side about the right angle. ... Thus it has formed the same triangle that which was obtained by the other method.
p10359
aVIn equation form, this becomes:
p10360
aV"a" is odd (Pythagoras, c. 540 BC):
p10361
aVformula_63
p10362
aV"a" is even (Plato, c. 380 BC):
p10363
aVformula_64
p10364
aVIt can be shown that all Pythagorean triples can be obtained, with appropriate rescaling, from the basic Platonic sequence ("a", and ) by allowing "a" to take non-integer rational values. If "a" is replaced with the fraction "m"/"n" in the sequence, the result is equal to the 'standard' triple generator (2"mn", ,) after rescaling. It follows that every triple has a corresponding rational "a" value which can be used to generate a similar triangle (one with the same three angles and with sides in the same proportions as the original). For example, the Platonic equivalent of (56, 33, 65) is generated by "a" = "m"/"n" = 7/4 as ("a", ("a"2 \u20131)/2, ("a"2+1)/2) = (56/32, 33/32, 65/32). The Platonic sequence itself can be derived by following the steps for 'splitting the square' described in Diophantus II.VIII.
p10365
aVThe Jacobi-Madden equation.
p10366
aVThe equation,
p10367
aVformula_65
p10368
aVis equivalent to the special Pythagorean triple,
p10369
aVformula_66
p10370
aVThere is an infinite number of solutions to this equation as solving for the variables involves an elliptic curve. Small ones are,
p10371
aVformula_67
p10372
aVformula_68
p10373
aVEqual sums of two squares.
p10374
aVOne way to generate solutions to formula_69 is to parametrize "a, b, c, d" in terms of integers "m, n, p, q" as follows:
p10375
aVformula_70
p10376
aVEqual sums of two fourth powers.
p10377
aVGiven two sets of Pythagorean triples,
p10378
aVformula_71
p10379
aVformula_72
p10380
aVthe problem of finding equal products of a non-hypotenuse side and the hypotenuse,
p10381
aVformula_73
p10382
aVis easily seen to be equivalent to the equation,
p10383
aVformula_74
p10384
aVand was first solved by Euler as formula_75. Since he showed this is a rational point in an elliptic curve, then there is an infinite number of solutions. In fact, he also found a 7th degree polynomial parameterization.
p10385
aVDescartes' Circle Theorem.
p10386
aVFor the case of Descartes' circle theorem where all variables are squares,
p10387
aVformula_76
p10388
aVEuler showed this is equivalent to three simultaneous Pythagorean triples,
p10389
aVformula_77
p10390
aVformula_78
p10391
aVformula_79
p10392
aVThere is also an infinite number of solutions, and for the special case when formula_80, then the equation simplifies to,
p10393
aVformula_81
p10394
aVwith small solutions as formula_82 and can be solved as binary quadratic forms.
p10395
aVAlmost-isosceles Pythagorean triples.
p10396
aVThese are right-angled triangles with integral sides for which the lengths of the non-hypotenuse edges differ by one, such as,
p10397
aVformula_83
p10398
aVformula_84
p10399
aVand an infinite number of others. They can be completely parameterized as,
p10400
aVformula_85
p10401
aVwhere {"x, y"} are the solutions to the Pell equation formula_86.
p10402
aVWhen it is the longer non-hypotenuse leg and hypotenuse that differ by one, such as in
p10403
aVformula_87
p10404
aVformula_88
p10405
aVthen the complete solution is
p10406
aVformula_89
p10407
aVwhich also shows that all odd numbers (greater than 1) appear in a primitive Pythagorean triple.
p10408
aVGeneralizations.
p10409
aVThere are several ways to generalize the concept of Pythagorean triples.
p10410
aVPythagorean quadruple.
p10411
aVA set of four positive integers "a", "b", "c" and "d" such that is called a Pythagorean quadruple. The simplest example is (1, 2, 2, 3), since 12 + 22 + 22 = 32. The next simplest (primitive) example is (2, 3, 6, 7), since 22 + 32 + 62 = 72.
p10412
aVAll quadruples are given by the formula
p10413
aVformula_90
p10414
aVPythagorean "n"-tuple.
p10415
aVUsing the simple algebraic identity,
p10416
aVformula_91
p10417
aVfor arbitrary "x"0, "x"1, it is easy to prove that the square of the sum of "n" squares is itself the sum of "n" squares by letting "x"0 = "x"22 + "x"32 + ... + "x""n"2 and then distributing terms. One can see how Pythagorean triples and quadruples are just the particular cases "x"0 = "x"22 and "x"0 = "x"22 + "x"32, respectively, and so on for other "n", with quintuples given by
p10418
aVformula_92
p10419
aVSince the sum "F"("k","m") of "k" consecutive squares beginning with "m"2 is given by the formula,
p10420
aVformula_93
p10421
aVone may find values ("k", "m") so that "F"("k","m") is a square, such as one by Hirschhorn where the number of terms is itself a square,
p10422
aVformula_94
p10423
aVand "v" \u2265 5 is any integer not divisible by 2 or 3. For the smallest case "v" = 5, hence "k" = 25, this yields the well-known cannonball-stacking problem of Lucas,
p10424
aVformula_95
p10425
aVa fact which is connected to the Leech lattice.
p10426
aVIn addition, if in a Pythagorean "n"-tuple ("n" \u2265 4) all addends are consecutive except one, one can use the equation,
p10427
aVformula_96
p10428
aVSince the second power of "p" cancels out, this is only linear and easily solved for as formula_97 though "k", "m" should be chosen so that "p" is an integer, with a small example being "k" = 5, "m" = 1 yielding,
p10429
aVformula_98
p10430
aVThus, one way of generating Pythagorean "n"-tuples is by using, for various "x",
p10431
aVformula_99
p10432
aVwhere "q = n"\u20132 and where
p10433
aVformula_100
p10434
aVFermat's Last Theorem.
p10435
aVA generalization of the concept of Pythagorean triples is the search for triples of positive integers "a", "b", and "c", such that , for some "n" strictly greater than 2. Pierre de Fermat in 1637 claimed that no such triple exists, a claim that came to be known as Fermat's Last Theorem because it took longer than any other conjecture by Fermat to be proven or disproven. The first proof was given by Andrew Wiles in 1994.
p10436
aV"n" \u2212 1 or "n" "n"th powers summing to an "n"th power.
p10437
aVAnother generalization is searching for sequences of "n" + 1 positive integers for which the "n"th power of the last is the sum of the "n"th powers of the previous terms. The smallest sequences for known values of "n" are:
p10438
aVFor the "n"=3 case, in which formula_101 called the Fermat cubic, a general formula exists giving all solutions.
p10439
aVA slightly different generalization allows the sum of ("k" + 1) "n"th powers to equal the sum of ("n" \u2212 "k") "n"th powers. For example:
p10440
aVThere can also exist "n" \u2212 1 positive integers whose "n"th powers sum to an "n"th power (though, by Fermat's last theorem, not for "n" = 3); these are counterexamples to Euler's sum of powers conjecture. The smallest known counterexamples are
p10441
aVHeronian triangle triples.
p10442
aVA Heronian triangle is commonly defined as one with integer sides whose area is also an integer, and we shall consider Heronian triangles with "distinct" integer sides. The lengths of the sides of such a triangle form a Heronian triple ("a, b, c") provided "a" < "b" < "c".
p10443
aVClearly, any Pythagorean triple is a Heronian triple, since in a Pythagorean triple at least one of the legs "a", "b" must be even, so that the area "ab"/2 is an integer. Not every Heronian triple is a Pythagorean triple, however, as the example (4, 13, 15) with area 24 shows.
p10444
aVIf ("a", "b", "c") is a Heronian triple, so is ("ma", "mb", "mc") where "m" is any positive integer greater than one.
p10445
aVThe Heronian triple ("a", "b", "c") is primitive provided "a", "b", "c" are pairwise relatively prime (as with a Pythagorean triple). Here are a few of the simplest primitive Heronian triples that are not Pythagorean triples:
p10446
aV (4, 13, 15) with area 24
p10447
aV (3, 25, 26) with area 36
p10448
aV (7, 15, 20) with area 42
p10449
aV (6, 25, 29) with area 60
p10450
aV (11, 13, 20) with area 66
p10451
aV (13, 14, 15) with area 84
p10452
aV (13, 20, 21) with area 126
p10453
aVBy Heron's formula, the extra condition for a triple of positive integers ("a", "b", "c") with "a" < "b" < "c" to be Heronian is that
p10454
aV: ("a"2 + "b"2 + "c"2)2 \u2212 2("a"4 + "b"4 + "c"4)
p10455
aVor equivalently
p10456
aV: 2("a"2"b"2 + "a"2"c"2 + "b"2"c"2) \u2212 ("a"4 + "b"4 + "c"4)
p10457
aVbe a nonzero perfect square divisible by 16.
p10458
aVApplication to cryptography.
p10459
aVPrimitive Pythagorean triples have been used in cryptography as random sequences and for the generation of keys.
p10460
asS'Fields Medal'
p10461
(lp10462
VThe Fields Medal is a prize awarded to two, three, or four mathematicians under 40 years of age at the International Congress of the International Mathematical Union (IMU), a meeting that takes place every four years. The Fields Medal is sometimes viewed as the highest honour a mathematician can receive. The Fields Medal and the Abel Prize have often been described as the "mathematician's Nobel Prize" (but different at least for the age restriction).
p10463
aVThe prize comes with a monetary award, which since 2006 has been C$15,000 (in Canadian dollars). The colloquial name is in honour of Canadian mathematician John Charles Fields. Fields was instrumental in establishing the award, designing the medal itself, and funding the monetary component.
p10464
aVThe medal was first awarded in 1936 to Finnish mathematician Lars Ahlfors and American mathematician Jesse Douglas, and it has been awarded every four years since 1950. Its purpose is to give recognition and support to younger mathematical researchers who have made major contributions.
p10465
aVIn 2014 Maryam Mirzakhani became the first woman as well as the first Iranian, and Artur Avila became the first mathematician from Latin America to be awarded a Fields Medal.
p10466
aVConditions of the award.
p10467
aVThe Fields Medal is often described as the "Nobel Prize of Mathematics" and for a long time was regarded as the most prestigious award in the field of mathematics. However, in contrast to the Nobel Prize, the Fields Medal is awarded only every four years. The Fields Medal also has an age limit: a recipient must be under age 40 until 1 January of the year in which the medal is awarded (similar to the Clark Medal in economics). The under 40 rule is based on Fields' desire that "while it was in recognition of work already done, it was at the same time intended to be an encouragement for further achievement on the part of the recipients and a stimulus to renewed effort on the part of others."
p10468
aVThe monetary award is much lower than the 8,000,000 Swedish kronor (roughly 1,400,000 Canadian dollars) given with each Nobel prize as of 2014. Other major awards in mathematics, such as the Abel Prize and the Chern Medal, have larger monetary prizes, comparable to the Nobel.
p10469
aVLandmarks.
p10470
aVIn 1954, Jean-Pierre Serre became the youngest winner of the Fields Medal, at 27. He still retains this distinction.
p10471
aVIn 1966, Alexander Grothendieck boycotted the ICM, held in Moscow, to protest Soviet military actions taking place in Eastern Europe. Léon Motchane, founder and director of the Institut des Hautes Études Scientifiques attended and accepted Grothendieck's Fields Medal on his behalf.
p10472
aVIn 1970, Sergei Novikov, because of restrictions placed on him by the Soviet government, was unable to travel to the congress in Nice to receive his medal.
p10473
aVIn 1978, Grigory Margulis, because of restrictions placed on him by the Soviet government, was unable to travel to the congress in Helsinki to receive his medal. The award was accepted on his behalf by Jacques Tits, who said in his address: "I cannot but express my deep disappointment \u2014 no doubt shared by many people here \u2014 in the absence of Margulis from this ceremony. In view of the symbolic meaning of this city of Helsinki, I had indeed grounds to hope that I would have a chance at last to meet a mathematician whom I know only through his work and for whom I have the greatest respect and admiration."
p10474
aVIn 1982, the congress was due to be held in Warsaw but had to be rescheduled to the next year, because of martial law introduced in Poland 13 Dec 1981. The awards were announced at the ninth General Assembly of the IMU earlier in the year and awarded at the 1983 Warsaw congress.
p10475
aVIn 1990, Edward Witten became the first and so far only physicist to win this award.
p10476
aVIn 1998, at the ICM, Andrew Wiles was presented by the chair of the Fields Medal Committee, Yuri I. Manin, with the first-ever IMU silver plaque in recognition of his proof of Fermat's Last Theorem. Don Zagier referred to the plaque as a "quantized Fields Medal". Accounts of this award frequently make reference that at the time of the award Wiles was over the age limit for the Fields medal. Although Wiles was slightly over the age limit in 1994, he was thought to be a favorite to win the medal; however, a gap (later resolved by Taylor and Wiles) in the proof was found in 1993.
p10477
aVIn 2006, Grigori Perelman, who proved the Poincaré conjecture, refused his Fields Medal and did not attend the congress.
p10478
aVIn 2014, Maryam Mirzakhani became the first woman and Artur Avila the first South American to win the Fields Medal, .
p10479
aVFields Medals by affiliation.
p10480
aVUpon appointment, the Fields medalists were working in the following institutions:
p10481
aVThe medal.
p10482
aVThe medal was designed by Canadian sculptor R. Tait McKenzie.
p10483
aV 
aV 
aVTranslation: "Mathematicians gathered from the entire world have awarded 'this prize' for outstanding writings."
p10484
aVIn the background, there is the representation of Archimedes' tomb, with the carving illustrating his theorem on the sphere and the cylinder, behind a branch. (This is the mathematical result of which Archimedes was reportedly most proud: Given a sphere and a circumscribed cylinder of the same height and diameter, the ratio between their volumes is equal to \u2154.)
p10485
aVThe rim bears the name of the prizewinner.
p10486
asS'Signed number representations'
p10487
(lp10488
VIn computing, signed number representations are required to encode negative numbers in binary number systems.
p10489
aVIn mathematics, negative numbers in any base are represented by prefixing them with a minus ("\u2212") sign. However, in computer hardware, numbers are represented only as sequences of bits, without extra symbols. The four best-known methods of extending the binary numeral system to represent signed numbers are: sign-and-magnitude, ones' complement, two's complement, and excess-"K". Some of the alternative methods use implicit instead of explicit signs, such as negative binary, using the base \u22122. Corresponding methods can be devised for other bases, whether positive, negative, fractional, or other elaborations on such themes.
p10490
aVThere is no definitive criterion by which any of the representations is universally superior. The representation used in most current computing devices is two's complement, although the CDC 3000 and 6000 series, and the Unisys ClearPath Dorado series mainframes, use ones' complement.
p10491
aVHistory.
p10492
aVThe early days of digital computing were marked by a lot of competing ideas about both hardware technology and mathematics technology (numbering systems). One of the great debates was the format of negative numbers, with some of the era's most expert people having very strong and different opinions. One camp supported two's complement, the system that is dominant today. Another camp supported ones' complement, where any positive value is made into its negative equivalent by inverting all of the bits in a word. A third group supported "sign & magnitude" (sign-magnitude), where a value is changed from positive to negative simply by toggling the word's sign (high-order) bit.
p10493
aVThere were arguments for and against each of the systems. Sign & magnitude allowed for easier tracing of memory dumps (a common process 40 years ago) as numeric values tended to use fewer 1 bits. Internally, these systems did ones' complement math so numbers would have to be converted to ones' complement values when they were transmitted from a register to the math unit and then converted back to sign-magnitude when the result was transmitted back to the register. The electronics required more gates than the other systems \u2013 a key concern when the cost and packaging of discrete transistors was critical. IBM was one of the early supporters of sign-magnitude, with their 7090 (709x series) computers perhaps the best known architecture to use it.
p10494
aVOnes' complement allowed for somewhat simpler hardware designs as there was no need to convert values when passed to and from the math unit. But it also shared an undesirable characteristic with sign-magnitude \u2013 the ability to represent negative zero (\u22120). Negative zero behaves exactly like positive zero; when used as an operand in any calculation, the result will be the same whether an operand is positive or negative zero. The disadvantage, however, is that the existence of two forms of the same value necessitates two rather than a single comparison when checking for equality with zero. Ones' complement subtraction can also result in an end-around borrow (described below). It can be argued that this makes the addition/subtraction logic more complicated or that it makes it simpler as a subtraction requires simply inverting the bits of the second operand as it is passed to the adder. The PDP-1, CDC 160 series, CDC 6000 series, UNIVAC 1100 series, and the LINC computer used ones' complement representation.
p10495
aVTwo's complement is the easiest to implement in hardware, which may be the ultimate reason for its widespread popularity. Processors on the early mainframes often consisted of thousands of transistors \u2013 eliminating a significant number of transistors was a significant cost savings. Mainframes such as the IBM System/360, the GE-600 series, and the PDP-6 and PDP-10 used two's complement, as did minicomputers such as the PDP-5 and PDP-8 and the PDP-11 and VAX. The architects of the early integrated circuit-based CPUs (Intel 8080, etc.) chose to use two's complement math. As IC technology advanced, virtually all adopted two's complement technology. x86, m68k, Power Architecture, MIPS, SPARC, ARM, Itanium, PA-RISC, and DEC Alpha processors are all two's complement.
p10496
aVSigned magnitude representation.
p10497
aV(Also called "sign-magnitude" or "sign and magnitude" representation.) In the first approach, the problem of representing a number's sign can be to allocate one sign bit to represent the sign: set that bit (often the most significant bit) to 0 for a positive number, and set to 1 for a negative number. The remaining bits in the number indicate the magnitude (or absolute value). Hence in a byte with only 7 bits (apart from the sign bit), the magnitude can range from 0000000 (0) to 1111111 (127). Thus you can represent numbers from \u221212710 to +12710 once you add the sign bit (the eighth bit). A consequence of this representation is that there are two ways to represent zero, 00000000 (0) and 10000000 (\u22120). This way, \u22124310 encoded in an eight-bit byte is 10101011.
p10498
aVThis approach is directly comparable to the common way of showing a sign (placing a "+" or "\u2212" next to the number's magnitude). Some early binary computers (e.g., IBM 7090) used this representation, perhaps because of its natural relation to common usage. Signed magnitude is the most common way of representing the significand in floating point values.
p10499
aVOnes' complement.
p10500
aVAlternatively, a system known as ones' complement can be used to represent negative numbers. The ones' complement form of a negative binary number is the bitwise NOT applied to it \u2014 the "complement" of its positive counterpart. Like sign-and-magnitude representation, ones' complement has two representations of 0: 00000000 (+0) and 11111111 (\u22120).
p10501
aVAs an example, the ones' complement form of 00101011 (4310) becomes 11010100 (\u22124310). The range of signed numbers using ones' complement is represented by \u2212(2N\u22121\u22121) to (2N\u22121\u22121) and ±0. A conventional eight-bit byte is \u221212710 to +12710 with zero being either 00000000 (+0) or 11111111 (\u22120).
p10502
aVTo add two numbers represented in this system, one does a conventional binary addition, but it is then necessary to do an "end-around carry": that is, add any resulting carry back into the resulting sum. To see why this is necessary, consider the following example showing the case of the addition of \u22121 (11111110) to +2 (00000010).
p10503
aVIn the previous example, the binary addition alone gives 00000000, which is incorrect. Only when the carry is added back in does the correct result (00000001) appear.
p10504
aVThis numeric representation system was common in older computers; the PDP-1, CDC 160 series, and UNIVAC 1100/2200 series, among many others, used ones'-complement arithmetic.
p10505
aVA remark on terminology: The system is referred to as "ones' complement" because the negation of a positive value x (represented as the bitwise NOT of x) can also be formed by subtracting x from the ones' complement representation of zero that is a long sequence of ones (\u22120). Two's complement arithmetic, on the other hand, forms the negation of x by subtracting x from a single large power of two that is congruent to +0. Therefore, ones' complement and two's complement representations of the same negative value will differ by one.
p10506
aVNote that the ones' complement representation of a negative number can be obtained from the sign-magnitude representation merely by bitwise complementing the magnitude.
p10507
aVTwo's complement.
p10508
aVThe problems of multiple representations of 0 and the need for the end-around carry are circumvented by a system called two's complement. In two's complement, negative numbers are represented by the bit pattern which is one greater (in an unsigned sense) than the ones' complement of the positive value.
p10509
aVIn two's-complement, there is only one zero, represented as 00000000. Negating a number (whether negative or positive) is done by inverting all the bits and then adding 1 to that result. This actually reflects the ring structure on all integers modulo 2N: formula_1. Addition of a pair of two's-complement integers is the same as addition of a pair of unsigned numbers (except for detection of overflow, if that is done); the same is true for subtraction and even for N lowest significant bits of a product (value of multiplication). For instance, a two's-complement addition of 127 and \u2212128 gives the same binary bit pattern as an unsigned addition of 127 and 128, as can be seen from the 8 bit two's complement table.
p10510
aVAn easier method to get the negation of a number in two's complement is as follows:
p10511
aVMethod two:
p10512
aVExample: for +1 which is 00000001 in binary: 
p10513
aVExcess-K.
p10514
aVExcess-K, also called offset binary or biased representation, uses a pre-specified number K as a biasing value. A value is represented by the unsigned number which is K greater than the intended value. Thus 0 is represented by K, and \u2212K is represented by the all-zeros bit pattern. This can be seen as a slight modification and generalization of the aforementioned one's-complement, which is virtually the excess-(2N\u22121-1) representation with negated most significant bit.
p10515
aVBiased representations are now primarily used for the exponent of floating-point numbers. The IEEE floating-point standard defines the exponent field of a single-precision (32-bit) number as an 8-bit excess-127 field. The double-precision (64-bit) exponent field is an 11-bit excess-1023 field; see exponent bias. It also had use for binary coded decimal numbers as excess-3.
p10516
aVBase \u22122.
p10517
aVIn conventional binary number systems, the base, or radix, is 2; thus the rightmost bit represents 20, the next bit represents 21, the next bit 22, and so on. However, a binary number system with base \u22122 is also possible.
p10518
aVThe rightmost bit represents , the next bit represents , the next bit and so on, with alternating sign. The numbers that can be represented with four bits are shown in the comparison table below.
p10519
aVThe range of numbers that can be represented is asymmetric. If the word has an even number of bits, the magnitude of the largest negative number that can be represented is twice as large as the largest positive number that can be represented, and vice versa if the word has an odd number of bits.
p10520
aVComparison table.
p10521
aVThe following table shows the positive and negative integers that can be represented using 4 bits.
p10522
aVSame table, as viewed from "given these binary bits, what is the number as interpreted by the representation system":
p10523
aVOther systems.
p10524
aVGoogle's Protocol Buffers "zig-zag encoding" is a system similar to sign-and-magnitude, but uses the least significant bit to represent the sign and has a single representation of zero. This has the advantage to make variable-length quantity encoding efficient with signed integers.
p10525
aVAnother approach is to give each digit a sign, yielding the signed-digit representation. For instance, in 1726, John Colson advocated reducing expressions to "small numbers", numerals 1, 2, 3, 4, and 5. In 1840, Augustin Cauchy also expressed preference for such modified decimal numbers to reduce errors in computation.
p10526
asS'Periodic function'
p10527
(lp10528
VIn mathematics, a periodic function is a function that repeats its values in regular intervals or periods. The most important examples are the trigonometric functions, which repeat over intervals of 2"\u03c0" radians. Periodic functions are used throughout science to describe oscillations, waves, and other phenomena that exhibit periodicity. Any function which is not periodic is called aperiodic.
p10529
aVDefinition.
p10530
aVA function "f" is said to be periodic with period "P" ("P" being a nonzero constant) if we have
p10531
aVformula_1
p10532
aVfor all values of "x" in the domain. If there exists a least positive
p10533
aVconstant "P" with this property, it is called the fundamental period (also primitive period, basic period, or prime period.) A function with period "P" will repeat on intervals of length "P", and these intervals
p10534
aVare referred to as periods.
p10535
aVGeometrically, a periodic function can be defined as a function whose graph exhibits translational symmetry. Specifically, a function "f" is periodic with period "P" if the graph of "f" is invariant under translation in the "x"-direction by a distance of "P". This definition of periodic can be extended to other geometric shapes and patterns, such as periodic tessellations of the plane.
p10536
aVA function that is not periodic is called aperiodic.
p10537
aVExamples.
p10538
aVFor example, the sine function is periodic with period 2"\u03c0", since
p10539
aVformula_2
p10540
aVfor all values of "x". This function repeats on intervals of length 2"\u03c0" (see the graph to the right).
p10541
aVEveryday examples are seen when the variable is "time"; for instance the hands of a clock or the phases of the moon show periodic behaviour. Periodic motion is motion in which the position(s) of the system are expressible as periodic functions, all with the "same" period.
p10542
aVFor a function on the real numbers or on the integers, that means that the entire graph can be formed from copies of one particular portion, repeated at regular intervals.
p10543
aVA simple example of a periodic function is the function "f" that gives the "fractional part" of its argument. Its period is 1. In particular,
p10544
aV "f"( 0.5 ) = "f"( 1.5 ) = "f"( 2.5 ) = ... = 0.5.
p10545
aVThe graph of the function "f" is the sawtooth wave.
p10546
aVThe trigonometric functions sine and cosine are common periodic functions, with period 2\u03c0 (see the figure on the right). The subject of Fourier series investigates the idea that an 'arbitrary' periodic function is a sum of trigonometric functions with matching periods.
p10547
aVAccording to the definition above, some exotic functions, for example the Dirichlet function, are also periodic; in the case of Dirichlet function, any nonzero rational number is a period.
p10548
aVProperties.
p10549
aVIf a function "f" is periodic with period "P", then for all "x" in the domain of "f" and all integers "n",
p10550
aV "f"("x" + "nP") = "f"("x").
p10551
aVIf "f"("x") is a function with period "P", then "f"("ax+b"), where "a" is a positive constant, is periodic with period "P/|a|". For example, "f"("x")=sin"x" has period 2\u03c0, therefore sin(5"x") will have period 2\u03c0/5.
p10552
aVDouble-periodic functions.
p10553
aVA function whose domain is the complex numbers can have two incommensurate periods without being constant. The elliptic functions are such functions.
p10554
aVComplex example.
p10555
aVUsing complex variables we have the common period function:
p10556
aVformula_3
p10557
aVAs you can see, since the cosine and sine functions are periodic, and the complex exponential above is made up of cosine/sine waves, then the above (actually Euler's formula) has the following property. If "L" is the period of the function then:
p10558
aVformula_4
p10559
aVGeneralizations.
p10560
aVAntiperiodic functions.
p10561
aVOne common generalization of periodic functions is that of antiperiodic functions. This is a function "f" such that "f"("x" + "P") = \u2212"f"("x") for all "x". (Thus, a "P"-antiperiodic function is a 2"P"-periodic function.) For example, the sine or cosine function is \u03c0-antiperiodic and 2\u03c0-periodic
p10562
aVBloch-periodic functions.
p10563
aVA further generalization appears in the context of Bloch waves and Floquet theory, which govern the solution of various periodic differential equations. In this context, the solution (in one dimension) is typically a function of the form:
p10564
aVformula_5
p10565
aVwhere "k" is a real or complex number (the "Bloch wavevector" or "Floquet exponent"). Functions of this form are sometimes called Bloch-periodic in this context. A periodic function is the special case "k" = 0, and an antiperiodic function is the special case "k" = \u03c0/"P".
p10566
aVQuotient spaces as domain.
p10567
aVIn signal processing you encounter the problem, that Fourier series represent periodic functions
p10568
aVand that Fourier series satisfy convolution theorems
p10569
aV(i.e. convolution of Fourier series corresponds to multiplication of represented periodic function and vice versa),
p10570
aVbut periodic functions cannot be convolved with the usual definition,
p10571
aVsince the involved integrals diverge.
p10572
aVA possible way out is to define a periodic function on a bounded but periodic domain.
p10573
aVTo this end you can use the notion of a quotient space:
p10574
aVformula_6 is an equivalence class
p10575
aVof real numbers that share the same fractional part.
p10576
aVThus a function like formula_7
p10577
aVis a representation of a 1-periodic function.
p10578
asS'Binary adder'
p10579
(lp10580
sS'Power of two'
p10581
(lp10582
VIn mathematics, a power of two means a number of the form where is an integer, i.e. the result of exponentiation with number two as the base and integer  as the exponent.
p10583
aVIn a context where only integers are considered, is restricted to non-negative values, so we have 1, 2, and 2 multiplied by itself a certain number of times.
p10584
aVBecause two is the base of the binary numeral system, powers of two are common in computer science. Written in binary, a power of two always has the form 100\u2026000 or 0.00\u2026001, just like a power of ten in the decimal system.
p10585
aVExpressions and notations.
p10586
aVVerbal expressions, mathematical notations, and computer programming expressions using a power operator or function include:
p10587
aV 2 to the "n"
p10588
aV 2 to the power of "n"
p10589
aV 2 power "n"
p10590
aV power(2, "n")
p10591
aV pow(2, "n")
p10592
aV 2"n"
p10593
aV 1 Â« "n"
p10594
aV 2 ^ "n"
p10595
aV 2 ** "n"
p10596
aV 2 "n"
p10597
aV 2 \u2191 "n"
p10598
aV "A"("n" - 3, 3) + 3
p10599
aV formula_1
p10600
aV formula_2
p10601
aV formula_3
p10602
aVComputer science.
p10603
aVTwo to the power of , written as , is the number of ways the bits in a binary word of length can be arranged. As an unsigned integers these ways represent numbers from 0 (000\u2026000) to  (111\u2026111) inclusively. Corresponding signed integer are positive, negative numbers, and zero; see signed number representations. Either way, one less than a power of two is often the upper bound of an integer in binary computers. As a consequence, numbers of this form show up frequently in computer software. As an example, a video game running on an 8-bit system might limit the score or the number of items the player can hold to 255\u2014the result of using a byte, which is 8 bits long, to store the number, giving a maximum value of . For example, in the original "Legend of Zelda" the main character was limited to carrying 255 rupees (the currency of the game) at any given time, and the video game Pac-Man famously shuts down at level 255.
p10604
aVPowers of two are often used to measure computer memory. A byte is now considered to be eight bits (an octet, resulting in the possibility of 256 values (28). (The term "byte" has been, and in some case continues to be, used to be a collection of bits, typically of 5 to 32 bits, rather than only an 8-bit unit.) The prefix "kilo", in conjunction with "byte", may be, and has traditionally been, used, to mean 1,024 (210). However, in general, the term "kilo" has been used in the International System of Units to mean 1,000 (103). Binary prefixes have been standardized, such as "kibi" (Ki) meaning 1,024. Nearly all processor registers have sizes that are powers of two, 32 or 64 being most common.
p10605
aVPowers of two occur in a range of other places as well. For many disk drives, at least one of the sector size, number of sectors per track, and number of tracks per surface is a power of two. The logical block size is almost always a power of two.
p10606
aVNumbers which are not powers of two occur in a number of situations such as video resolutions, but they are often the sum or product of only two or three powers of two, or powers of two minus one. For example, , and . Put another way, they have fairly regular bit patterns.
p10607
aVMersenne primes.
p10608
aVA prime number that is one less than a power of two is called a Mersenne prime. For example, the prime number 31 is a Mersenne prime because it is 1 less than 32 (25). Similarly, a prime number (like 257) that is one more than a positive power of two is called a Fermat prime; the exponent will itself be a power of two. A fraction that has a power of two as its denominator is called a dyadic rational. The numbers that can be represented as sums of consecutive positive integers are called polite numbers; they are exactly the numbers that are not powers of two.
p10609
aVEuclid's "Elements", Book IX.
p10610
aVThe geometric progression 1, 2, 4, 8, 16, 32, \u2026 (or, in the binary numeral system, 1, 10, 100, 1000, 10000, 100000, \u2026 ) is important in number theory. Book IX, Proposition 36 of "Elements" proves that if the sum of the first terms of this progression is a prime number (means, a Mersenne prime mentioned above), then this sum times the th term is a perfect number. For example, the sum of the first 5 terms of the series 1 + 2 + 4 + 8 + 16 = 31, which is a prime number. The sum 31 multiplied by 16 (the 5th term in the series) equals 496, which is a perfect number.
p10611
aVBook IX, Proposition 35, proves that in a geometric series if the first term is subtracted from the second and last term in the sequence then as the excess of the second is to the first, so will the excess of the last be to all of those before it. (This is a restatement of our formula for geometric series from above.) Applying this to the geometric progression 31, 62, 124, 248, 496 (which results from 1, 2, 4, 8, 16 by multiplying all terms by 31), we see that 62 minus 31 is to 31 as 496 minus 31 is to the sum of 31, 62, 124, 248. Therefore the numbers 1, 2, 4, 8, 16, 31, 62, 124 and 248 add up to 496 and further these are all the numbers which divide 496. For suppose that divides 496 and it is not amongst these numbers. Assume is equal to , or 31 is to as is to 16. Now cannot divide 16 or it would be amongst the numbers 1, 2, 4, 8 or 16.
p10612
aVTherefore 31 cannot divide . And since 31 does not divide and measures 496, the fundamental theorem of arithmetic implies that must divide 16 and be amongst the numbers 1, 2, 4, 8 or 16. Let be 4, then must be 124, which is impossible since by hypothesis is not amongst the numbers 1, 2, 4, 8, 16, 31, 62, 124 or 248.
p10613
aVThe first 96 powers of two.
p10614
aVOne can see that starting with 2 the last digit is periodic with period 4, with the cycle 2\u20134\u20138\u20136\u2013, and starting with 4 the last two digits are periodic with period 20. These patterns are generally true of any power, with respect to any base. The pattern continues, of course, where each pattern has starting point , and the period is the multiplicative order of 2 modulo , which is  = 4 ×  (see Multiplicative group of integers modulo n).
p10615
aVPowers of 1024.
p10616
aVThe first few powers of 210 are a little more than those of 1000:
p10617
aVSee also IEEE 1541-2002.
p10618
aVPowers of two whose exponents are powers of two.
p10619
aVBecause data (specifically integers) and the addresses of data are stored using the same hardware, and the data is stored in one or more octets (), double exponentials of two are common. For example,
p10620
aV 21 = 2
p10621
aV 22 = 4
p10622
aV 24 = 16
p10623
aV 28 = 256
p10624
aV 216 = 65,536
p10625
aV 232 = 4,294,967,296
p10626
aV 264 = 18,446,744,073,709,551,616 (20 digits)
p10627
aV 2128 = 340,282,366,920,938,463,463,374,607,431,768,211,456 (39 digits)
p10628
aV 2256 = <br>115,792,089,237,316,195,423,570,985,008,687,907,853,269,984,665,640,564,039,457,584,007,913,129,<br>639,936 (78 digits)
p10629
aV 2512 = <br>13,407,807,929,942,597,099,574,024,998,205,846,127,479,365,820,592,393,377,723,561,443,721,764,<br>030,073,546,976,801,874,298,166,903,427,690,031,858,186,486,050,853,753,882,811,946,569,946,433,<br>649,006,084,096 (155 digits)
p10630
aV 21,024 = 179,769,313,486,231,590,772,931...,304,835,356,329,624,224,137,216 (309 digits)
p10631
aV 22,048 = 323,170,060,713,110,073,007,148...,193,555,853,611,059,596,230,656 (617 digits)
p10632
aV 24,096 = 104,438,888,141,315,250,669,175...,243,804,708,340,403,154,190,336 (1,234 digits)
p10633
aV 28,192 = 109,074,813,561,941,592,946,298...,997,186,505,665,475,715,792,896 (2,467 digits)
p10634
aV 216,384 = 118,973,149,535,723,176,508,576...,460,447,027,290,669,964,066,816 (4,933 digits)
p10635
aV 232,768 = 141,546,103,104,495,478,900,155...,541,122,668,104,633,712,377,856 (9,865 digits)
p10636
aV 265,536 = 200,352,993,040,684,646,497,907...,339,445,587,895,905,719,156,736 (19,729 digits)
p10637
aVSeveral of these numbers represent the number of values representable using common computer data types. For example, a 32-bit word consisting of 4 bytes can represent distinct values, which can either be regarded as mere bit-patterns, or are more commonly interpreted as the unsigned numbers from 0 to , or as the range of signed numbers between and . Also see tetration and lower hyperoperations. For more about representing signed numbers see two's complement.
p10638
aVIn a connection with nimbers these numbers are often called "Fermat 2-powers".
p10639
aVThe numbers formula_4 form an irrationality sequence: for every sequence of positive integers, the series
p10640
aVformula_5
p10641
aVconverges to an irrational number. Despite the rapid growth of this sequence, it is the slowest-growing irrationality sequence known.
p10642
aVThe number of values represented by the 8 bits in a byte, more specifically termed as an octet. (The term byte is often defined as a collection of bits rather than the strict definition of an 8-bit quantity, as demonstrated by the term kilobyte.)
p10643
aV The binary approximation of the kilo-, or 1,000 multiplier, which causes a change of prefix. For example: 1,024 bytes = 1 kilobyte (or kibibyte).
p10644
aV This number has no special significance to computers, but is important to humans because we make use of powers of ten.
p10645
aV The hardware page size of Intel x86 processor.
p10646
aV The number of distinct values representable in a single word on a 16-bit processor, such as the original x86 processors.
p10647
aV The maximum range of a short integer variable in the C#, and Java programming languages. The maximum range of a Word or Smallint variable in the Pascal programming language.
p10648
aV The binary approximation of the mega-, or 1,000,000 multiplier, which causes a change of prefix. For example: 1,048,576 bytes = 1 megabyte (or mibibyte).
p10649
aV This number has no special significance to computers, but is important to humans because we make use of powers of ten.
p10650
aV The number of unique colors that can be displayed in truecolor, which is used by common computer monitors.
p10651
aV This number is the result of using the three-channel RGB system, with 8 bits for each channel, or 24 bits in total.
p10652
aV The binary approximation of the giga-, or 1,000,000,000 multiplier, which causes a change of prefix. For example, 1,073,741,824 bytes = 1 gigabyte (or gibibyte).
p10653
aV This number has no special significance to computers, but is important to humans because we make use of powers of ten.
p10654
aV The number of non-negative values for a "signed" 32-bit integer. Since Unix time is measured in seconds since January 1, 1970, it will run out at 2,147,483,647 seconds or 03:14:07 UTC on Tuesday, 19 January 2038 on 32-bit computers running Unix, a problem known as the year 2038 problem.
p10655
aV The number of distinct values representable in a single word on a 32-bit processor. Or, the number of values representable in a doubleword on a 16-bit processor, such as the original x86 processors.
p10656
aV The range of an codice_1 variable in the Java and C# programming languages.
p10657
aV The range of a codice_2 or codice_3 variable in the Pascal programming language.
p10658
aV The minimum range of a long integer variable in the C and C++ programming languages.
p10659
aV The total number of IP addresses under IPv4. Although this is a seemingly large number, IPv4 address exhaustion is imminent.
p10660
aV The binary approximation of the tera-, or 1,000,000,000,000 multiplier, which causes a change of prefix. For example, 1,099,511,627,776 bytes = 1 terabyte (or tebibyte).
p10661
aV This number has no special significance to computers, but is important to humans because we make use of powers of ten.
p10662
aV The binary approximation of the peta-, or 1,000,000,000,000,000 multiplier. 1,125,899,906,842,624 bytes = 1 petabyte (or pebibyte).
p10663
aV The binary approximation of the exa-, or 1,000,000,000,000,000,000 multiplier. 1,152,921,504,606,846,976 bytes = 1 exabyte (or exbibyte).
p10664
aV The number of distinct values representable in a single word on a 64-bit processor. Or, the number of values representable in a doubleword on a 32-bit processor. Or, the number of values representable in a quadword on a 16-bit processor, such as the original x86 processors.
p10665
aV The range of a long variable in the Java and C# programming languages.
p10666
aV The range of a Int64 or QWord variable in the Pascal programming language.
p10667
aV The total number of IPv6 addresses generally given to a single LAN or subnet.
p10668
aV One more than the number of grains of rice on a chessboard, according to the old story, where the first square contains one grain of rice and each succeeding square twice as many as the previous square. For this reason the number 264 \u2013 1 is known as the "chess number".
p10669
aV The binary approximation of yotta-, or 1,000,000,000,000,000,000,000 multiplier, which causes a change of prefix. For example, 1,180,591,620,717,411,303,424 bytes = 1 Yottabyte (or yobibyte).
p10670
aV 286 is conjectured to be the largest power of two not containing a zero.
p10671
aV The total number of IPv6 addresses generally given to a local Internet registry. In CIDR notation, ISPs are given a /32, which means that 128-32=96 bits are available for addresses (as opposed to network designation). Thus, 296 addresses.
p10672
aV The total number of IP addresses available under IPv6. Also the number of distinct universally unique identifiers (UUIDs).
p10673
aV The smallest power of 2 which is greater than a googol (10100).
p10674
aV The maximum number that can fit in an IEEE double-precision floating-point format, and hence the maximum number that can be represented by many programs, for example Microsoft Excel.
p10675
aV One more than the largest known prime number . It has more than 17 million digits.
p10676
aVFast algorithm to check if a positive number is a power of two.
p10677
aVThe binary representation of integers makes it possible to apply a very fast test to determine whether a given positive integer  is a power of two:
p10678
aVpositive is a power of two \u21d4 is equal to zero.
p10679
aVwhere "&" is a bitwise logical "AND" operator. Note that if is 0, this incorrectly indicates that 0 is a power of two, so this check only works if .
p10680
aVExamples:
p10681
aVProof of Concept:<br>
p10682
aVProof uses the technique of contrapositive.<br>
p10683
aVStatement, S: If x&(x-1) = 0 and x is an integer greater than zero then x = 2k (where k is an integer such that k>=0).
p10684
aVConcept of Contrapositive:<br>
p10685
aVS1: P -> Q is same as S2: ~Q -> ~P<br>
p10686
aVIn above statement S1 and S2 both are contrapositive of each other.<br>
p10687
aVSo statement S can be re-stated as below<br>
p10688
aVS': If x is a positive integer and x \u2260 2k (k is some non negative integer)then x&(x-1) \u2260 0<br>
p10689
aVProof:<br>
p10690
aVIf x \u2260 2k then at least two bits of x are set.(Let's assume m bits are set.)<br>
p10691
aVNow, bit pattern of x - 1 can be obtained by inverting all the bits of x up to first set bit of x (starting from LSB and moving towards MSB, this set bit inclusive).<br>
p10692
aVNow, we observe that expression x & (x-1) has all the bits zero up to the first set bit of x and since x & (x-1) has remaining bits same as x and x has at least two set bits hence predicate x & (x-1) \u2260 0 is true.
p10693
aVFast algorithm to find a number modulo a power of two.
p10694
aVAs a generalization of the above, the binary representation of integers makes it possible to calculate the modulos of a non-negative integer () with a power of two () very quickly:
p10695
aVwhere "&" is a bitwise logical "AND" operator. This bypasses the need to perform an expensive division. This is useful if the modulo operation is a significant part of the performance critical path as this can be much faster than the regular modulo operator.
p10696
aVAlgorithm to convert any number into nearest power of two number.
p10697
aVThe following formula finds the nearest power of two, on a logarithmic scale, of a given value :
p10698
aVformula_6
p10699
aVThis should be distinguished from the nearest power of two on a linear scale. For example, 23 is nearer to 16 than it is to 32, but the previous formula rounds it to 32, corresponding to the fact that 23/16 = 1.4375, larger than 32/23 = 1.3913.
p10700
aVIf is an integer value, following steps can be taken to find the nearest value (with respect to actual value rather than the binary logarithm) in a computer program:
p10701
aVAlgorithm to round up to power of two.
p10702
aVSometimes it is desired to find the least power of two that is not less than a particular integer, "n". The pseudocode for an algorithm to compute the next-higher power of two is as follows. If the input is a power of two it is returned unchanged.
p10703
aVWhere "|" is a binary or operator, "Â»" is the binary right-shift operator, and bitspace is the size (in bits) of the integer space represented by n. For most computer architectures, this value is either 8, 16, 32, or 64. This operator works by setting all bits on the right-hand side of the most significant flagged bit to "1", and then incrementing the entire value at the end so it "rolls over" to the nearest power of two. An example of each step of this algorithm for the number 2689 is as follows:
p10704
aVAs demonstrated above, the algorithm yields the correct value of 4,096. The nearest power to 2,689 happens to be 2,048; however, this algorithm is designed only to give the "next highest" power of two to a given number, not the nearest.
p10705
aVAnother way of obtaining the 'next highest' power of two to a given number independent of the length of the bitspace is as follows.
p10706
aVFast algorithms to round any integer to a multiple of a given power of two.
p10707
aVFor any integer, "x" and integral power of two, "y", if "z" = "y" - 1,
p10708
aV"x" to a multiple of "y".
p10709
aVOther properties.
p10710
aVThe sum of all -choose binomial coefficients is equal to . Consider the set of all -digit binary integers. Its cardinality will be . It will also be the sums of the cardinalities of certain subsets: the subset of integers with no 1s (consisting of a single number, written as 0s), the subset with a single 1, the subset with two 1s, and so on up to the subset with 1s (consisting of the number written as 1s). Each of these is in turn equal to the binomial coefficient indexed by and the number of 1s being considered (e.g., there are 10-choose-3 binary numbers with ten digits that include exactly three 1s).
p10711
aVThe number of vertices of an -dimensional hypercube is . Similarly, the number of -faces of an -dimensional cross-polytope is also and the formula for the number of -faces an -dimensional cross-polytope has is formula_7.
p10712
aVThe sum of the reciprocals of the powers of two is 2. The sum of the reciprocals of the squared powers of two is 1\u2153.
p10713
asS'Chain rule'
p10714
(lp10715
VIn calculus, the chain rule is a formula for computing the derivative of the composition of two or more functions. That is, if "f" and "g" are functions, then the chain rule expresses the derivative of their composition "f" \u2218 "g" (the function which maps "x" to "f"("g"("x"))) in terms of the derivatives of "f" and "g" and the product of functions as follows:
p10716
aVformula_1
p10717
aVThe chain rule can also be written with a different notation for function composition (though still in Lagrange's notation for differentiation). The meaning is identical.
p10718
aVformula_2
p10719
aVThe chain rule may be written, in Leibniz's notation, in the following way. We consider "z" to be a function of the variable "y", which is itself a function of "x" (see dependent variable), and so, "z" becomes a function of "x" as well:
p10720
aVformula_3
p10721
aVIn integration, the counterpart to the chain rule is the substitution rule.
p10722
aVHistory.
p10723
aVThe chain rule seems to have first been used by Leibniz. He used it to calculate the derivative of formula_4 as the composite of the square root function and the function formula_5. He first mentioned it in a 1676 memoir (with a sign error in the calculation). The common notation of chain rule is due to Leibniz. L'Hôpital uses the chain rule implicitly in his "Analyse des infiniment petits". The chain rule does not appear in any of Leonhard Euler's analysis books, even though they were written over a hundred years after Leibniz's discovery.
p10724
aVOne dimension.
p10725
aVFirst example.
p10726
aVSuppose that a skydiver jumps from an aircraft. Assume that "t" seconds after his jump, his height above sea level in meters is given by . One model for the atmospheric pressure at a height "h" is . These two equations can be differentiated and combined in various ways to produce the following data:
p10727
aVThe chain rule gives a method for computing in terms of and . While it is always possible to directly apply the definition of the derivative to compute the derivative of a composite function, this is usually very difficult. The utility of the chain rule is that it turns a complicated derivative into several easy derivatives.
p10728
aVThe chain rule states that, under appropriate conditions,
p10729
aVformula_6
p10730
aVIn this example, this equals
p10731
aVformula_7
p10732
aVIn the statement of the chain rule, "f" and "g" play slightly different roles because "f"\u2032 is evaluated at "g"("t") whereas "g"\u2032 is evaluated at "t". This is necessary to make the units work out correctly. For example, suppose that we want to compute the rate of change in atmospheric pressure ten seconds after the skydiver jumps. This is and has units of Pascals per second. The factor "g"\u2032(10) in the chain rule is the velocity of the skydiver ten seconds after his jump, and it is expressed in meters per second. "f"\u2032("g"(10)) is the change in pressure with respect to height at the height "g"(10) and is expressed in Pascals per meter. The product of "f"\u2032("g"(10)) and "g"\u2032(10) therefore has the correct units of Pascals per second. It is not possible to evaluate "f" anywhere else. For instance, because the 10 in the problem represents ten seconds, the expression "f"\u2032(10) represents the change in pressure at a height of ten seconds, which is nonsense. Similarly, because meters per second, the expression "f"\u2032("g"\u2032(10)) represents the change in pressure at a height of \u221298 meters per second, which is also nonsense. However, "g"(10) is 3020 meters above sea level, the height of the skydiver ten seconds after his jump. This has the correct units for an input to "f".
p10733
aVStatement.
p10734
aVThe simplest form of the chain rule is for real-valued functions of one real variable. It says that if "g" is a function that is differentiable at a point "c" (i.e. the derivative "g"\u2032("c") exists) and "f" is a function that is differentiable at "g"("c"), then the composite function "f" \u2218 "g" is differentiable at "c", and the derivative is
p10735
aVformula_8
p10736
aVThe rule is sometimes abbreviated as
p10737
aVformula_9
p10738
aVIf and , then this abbreviated form is written in Leibniz notation as:
p10739
aVformula_10
p10740
aVThe points where the derivatives are evaluated may also be stated explicitly:
p10741
aVformula_11
p10742
aVFurther examples.
p10743
aVAbsence of formulas.
p10744
aVIt may be possible to apply the chain rule even when there are no formulas for the functions which are being differentiated. This can happen when the derivatives are measured directly. Suppose that a car is driving up a tall mountain. The car's speedometer measures its speed directly. If the grade is known, then the rate of ascent can be calculated using trigonometry. Suppose that the car is ascending at 2.5 km/h. Standard models for the Earth's atmosphere imply that the temperature drops about 6.5 °C per kilometer ascended (see lapse rate). To find the temperature drop per hour, we apply the chain rule. Let the function "g"("t") be the altitude of the car at time "t", and let the function "f"("h") be the temperature "h" kilometers above sea level. "f" and "g" are not known exactly: For example, the altitude where the car starts is not known and the temperature on the mountain is not known. However, their derivatives are known: "f"\u2032 is \u22126.5 °C/km, and "g"\u2032 is 2.5 km/h. The chain rule says that the derivative of the composite function is the product of the derivative of "f" and the derivative of "g". This is .
p10745
aVOne of the reasons why this computation is possible is because "f"\u2032 is a constant function. This is because the above model is very simple. A more accurate description of how the temperature near the car varies over time would require an accurate model of how the temperature varies at different altitudes. This model may not have a constant derivative. To compute the temperature change in such a model, it would be necessary to know "g" and not just "g"\u2032, because without knowing "g" it is not possible to know where to evaluate "f"\u2032.
p10746
aVComposites of more than two functions.
p10747
aVThe chain rule can be applied to composites of more than two functions. To take the derivative of a composite of more than two functions, notice that the composite of "f", "g", and "h" (in that order) is the composite of "f" with . The chain rule says that to compute the derivative of , it is sufficient to compute the derivative of "f" and the derivative of . The derivative of "f" can be calculated directly, and the derivative of can be calculated by applying the chain rule again.
p10748
aVFor concreteness, consider the function
p10749
aVformula_12
p10750
aVThis can be decomposed as the composite of three functions:
p10751
aVformula_13
p10752
aVTheir derivatives are:
p10753
aVformula_14
p10754
aVThe chain rule says that the derivative of their composite at the point is:
p10755
aVformula_15
p10756
aVIn Leibniz notation, this is:
p10757
aVformula_16
p10758
aVor for short,
p10759
aVformula_17
p10760
aVThe derivative function is therefore:
p10761
aVformula_18
p10762
aVAnother way of computing this derivative is to view the composite function as the composite of and "h". Applying the chain rule to this situation gives:
p10763
aVformula_19
p10764
aVThis is the same as what was computed above. This should be expected because .
p10765
aVSometimes it is necessary to differentiate an arbitrarily long composition of the form formula_20. In this case, define
p10766
aVformula_21
p10767
aVwhere formula_22 and formula_23 when formula_24. Then the chain rule takes the form
p10768
aVformula_25
p10769
aVor, in the Lagrange notation,
p10770
aVformula_26
p10771
aVQuotient rule.
p10772
aVThe chain rule can be used to derive some well-known differentiation rules. For example, the quotient rule is a consequence of the chain rule and the product rule. To see this, write the function "f"("x")/"g"("x") as the product . First apply the product rule:
p10773
aVformula_27
p10774
aVTo compute the derivative of 1/"g"("x"), notice that it is the composite of "g" with the reciprocal function, that is, the function that sends "x" to 1/"x". The derivative of the reciprocal function is \u22121/"x"2. By applying the chain rule, the last expression becomes:
p10775
aVformula_28
p10776
aVwhich is the usual formula for the quotient rule.
p10777
aVDerivatives of inverse functions.
p10778
aVSuppose that has an inverse function. Call its inverse function "f" so that we have . There is a formula for the derivative of "f" in terms of the derivative of "g". To see this, note that "f" and "g" satisfy the formula
p10779
aVformula_29
p10780
aVBecause the functions "f"("g"("x")) and "x" are equal, their derivatives must be equal. The derivative of "x" is the constant function with value 1, and the derivative of "f"("g"("x")) is determined by the chain rule. Therefore we have:
p10781
aVformula_30
p10782
aVTo express "f"\u2032 as a function of an independent variable "y", we substitute "f"("y") for "x" wherever it appears. Then we can solve for "f"\u2032.
p10783
aVformula_31
p10784
aVFor example, consider the function . It has an inverse . Because , the above formula says that
p10785
aVformula_32
p10786
aVThis formula is true whenever "g" is differentiable and its inverse "f" is also differentiable. This formula can fail when one of these conditions is not true. For example, consider . Its inverse is , which is not differentiable at zero. If we attempt to use the above formula to compute the derivative of "f" at zero, then we must evaluate 1/"g"\u2032("f"(0)). and , so we must evaluate 1/0, which is undefined. Therefore the formula fails in this case. This is not surprising because "f" is not differentiable at zero.
p10787
aVHigher derivatives.
p10788
aVFaà di Bruno's formula generalizes the chain rule to higher derivatives. Assuming that and , then the first few derivatives are:
p10789
aVformula_33
p10790
aVformula_34
p10791
aVformula_35
p10792
aVformula_36
p10793
aVProofs.
p10794
aVFirst proof.
p10795
aVOne proof of the chain rule begins with the definition of the derivative:
p10796
aVformula_37
p10797
aVAssume for the moment that "g"("x") does not equal "g"("a") for any "x" near "a". Then the previous expression is equal to the product of two factors:
p10798
aVformula_38
p10799
aVWhen "g" oscillates near "a", then it might happen that no matter how close one gets to "a", there is always an even closer "x" such that "g"("x") equals "g"("a"). For example, this happens for near the point . Whenever this happens, the above expression is undefined because it involves division by zero. To work around this, introduce a function "Q" as follows:
p10800
aVformula_39
p10801
aVWe will show that the difference quotient for is always equal to:
p10802
aVformula_40
p10803
aVWhenever "g"("x") is not equal to "g"("a"), this is clear because the factors of cancel. When "g"("x") equals "g"("a"), then the difference quotient for is zero because "f"("g"("x")) equals "f"("g"("a")), and the above product is zero because it equals "f"\u2032("g"("a")) times zero. So the above product is always equal to the difference quotient, and to show that the derivative of at "a" exists and to determine its value, we need only show that the limit as "x" goes to "a" of the above product exists and determine its value.
p10804
aVTo do this, recall that the limit of a product exists if the limits of its factors exist. When this happens, the limit of the product of these two factors will equal the product of the limits of the factors. The two factors are "Q"("g"("x")) and . The latter is the difference quotient for "g" at "a", and because "g" is differentiable at "a" by assumption, its limit as "x" tends to "a" exists and equals "g"\u2032("a").
p10805
aVIt remains to study "Q"("g"("x")). "Q" is defined wherever "f" is. Furthermore, because "f" is differentiable at "g"("a") by assumption, "Q" is continuous at "g"("a"). "g" is continuous at "a" because it is differentiable at "a", and therefore is continuous at "a". So its limit as "x" goes to "a" exists and equals "Q"("g"("a")), which is "f"\u2032("g"("a")).
p10806
aVThis shows that the limits of both factors exist and that they equal "f"\u2032("g"("a")) and "g"\u2032("a"), respectively. Therefore the derivative of at "a" exists and equals "f"\u2032("g"("a"))"g"\u2032("a").
p10807
aVSecond proof.
p10808
aVAnother way of proving the chain rule is to measure the error in the linear approximation determined by the derivative. This proof has the advantage that it generalizes to several variables. It relies on the following equivalent definition of differentiability at a point: A function "g" is differentiable at "a" if there exists a real number "g"\u2032("a") and a function "\u03b5"("h") that tends to zero as "h" tends to zero, and furthermore
p10809
aVformula_41
p10810
aVHere the left-hand side represents the true difference between the value of "g" at "a" and at , whereas the right-hand side represents the approximation determined by the derivative plus an error term.
p10811
aVIn the situation of the chain rule, such a function "\u03b5" exists because "g" is assumed to be differentiable at "a". Again by assumption, a similar function also exists for "f" at "g"("a"). Calling this function "\u03b7", we have
p10812
aVformula_42
p10813
aVThe above definition imposes no constraints on "\u03b7"(0), even though it is assumed that "\u03b7"("k") tends to zero as "k" tends to zero. If we set , then "\u03b7" is continuous at 0.
p10814
aVProving the theorem requires studying the difference as "h" tends to zero. The first step is to substitute for using the definition of differentiability of "g" at "a":
p10815
aVformula_43
p10816
aVThe next step is to use the definition of differentiability of "f" at "g"("a"). This requires a term of the form for some "k". In the above equation, the correct "k" varies with "h". Set and the right hand side becomes . Applying the definition of the derivative gives:
p10817
aVformula_44
p10818
aVTo study the behavior of this expression as "h" tends to zero, expand "k""h". After regrouping the terms, the right-hand side becomes:
p10819
aVformula_45
p10820
aVBecause "\u03b5"("h") and "\u03b7"("k""h") tend to zero as "h" tends to zero, the first two bracketed terms tend to zero as "h" tends to zero. Applying the same theorem on products of limits as in the first proof, the third bracketed term also tends zero. Because the above expression is equal to the difference , by the definition of the derivative is differentiable at "a" and its derivative is 
p10821
aVThe role of "Q" in the first proof is played by "\u03b7" in this proof. They are related by the equation:
p10822
aVformula_46
p10823
aVThe need to define "Q" at "g"("a") is analogous to the need to define "\u03b7" at zero.
p10824
aVHigher dimensions.
p10825
aVThe simplest generalization of the chain rule to higher dimensions uses the total derivative. The total derivative is a linear transformation that captures how the function changes in all directions. Fix differentiable functions and and a point a in R"n". Let "D"a"g" denote the total derivative of "g" at a and "D""g"(a)"f" denote the total derivative of "f" at "g"(a). These two derivatives are linear transformations and , respectively, so they can be composed. The chain rule for total derivatives says that their composite is the total derivative of at a:
p10826
aVformula_47
p10827
aVor for short,
p10828
aVformula_48
p10829
aVThe higher-dimensional chain rule can be proved using a technique similar to the second proof given above.
p10830
aVBecause the total derivative is a linear transformation, the functions appearing in the formula can be rewritten as matrices. The matrix corresponding to a total derivative is called a Jacobian matrix, and the composite of two derivatives corresponds to the product of their Jacobian matrices. From this perspective the chain rule therefore says:
p10831
aVformula_49
p10832
aVThat is, the Jacobian of the composite function is the product of the Jacobians of the composed functions.
p10833
aVThe higher-dimensional chain rule is a generalization of the one-dimensional chain rule. If "k", "m", and "n" are 1, so that and , then the Jacobian matrices of "f" and "g" are . Specifically, they are:
p10834
aVformula_50
p10835
aVThe Jacobian of "f" \u2218 "g" is the product of these matrices, so it is , as expected from the one-dimensional chain rule. In the language of linear transformations, "D""a"("g") is the function which scales a vector by a factor of "g"\u2032("a") and "D""g"("a")("f") is the function which scales a vector by a factor of "f"\u2032("g"("a")). The chain rule says that the composite of these two linear transformations is the linear transformation , and therefore it is the function that scales a vector by "f"\u2032("g"("a"))\u22c5"g"\u2032("a").
p10836
aVAnother way of writing the chain rule is used when "f" and "g" are expressed in terms of their components as and . In this case, the above rule for Jacobian matrices is usually written as:
p10837
aVformula_51
p10838
aVThe chain rule for total derivatives implies a chain rule for partial derivatives. Recall that when the total derivative exists, the partial derivative in the "i"th coordinate direction is found by multiplying the Jacobian matrix by the "i"th basis vector. By doing this to the formula above, we find:
p10839
aVformula_52
p10840
aVSince the entries of the Jacobian matrix are partial derivatives, we may simplify the above formula to get:
p10841
aVformula_53
p10842
aVMore conceptually, this rule expresses the fact that a change in the "x""i" direction may change all of "g"1 through "g""k", and any of these changes may affect "f".
p10843
aVIn the special case where , so that "f" is a real-valued function, then this formula simplifies even further:
p10844
aVformula_54
p10845
aVThis can be rewritten as a dot product. Recalling that , the partial derivative is also a vector, and the chain rule says that:
p10846
aVformula_55
p10847
aVExample.
p10848
aVGiven where and , determine the value of and using the chain rule.
p10849
aVformula_56
p10850
aVand
p10851
aVformula_57
p10852
aVHigher derivatives of multivariable functions.
p10853
aVFaà di Bruno's formula for higher-order derivatives of single-variable functions generalizes to the multivariable case. If is a function of as above, then the second derivative of is:
p10854
aVformula_58
p10855
aVFurther generalizations.
p10856
aVAll extensions of calculus have a chain rule. In most of these, the formula remains the same, though the meaning of that formula may be vastly different.
p10857
aVOne generalization is to manifolds. In this situation, the chain rule represents the fact that the derivative of is the composite of the derivative of "f" and the derivative of "g". This theorem is an immediate consequence of the higher dimensional chain rule given above, and it has exactly the same formula.
p10858
aVThe chain rule is also valid for Fréchet derivatives in Banach spaces. The same formula holds as before. This case and the previous one admit a simultaneous generalization to Banach manifolds.
p10859
aVIn abstract algebra, the derivative is interpreted as a morphism of modules of Kähler differentials. A ring homomorphism of commutative rings determines a morphism of Kähler differentials which sends an element "dr" to "d"("f"("r")), the exterior differential of "f"("r"). The formula holds in this context as well.
p10860
aVThe common feature of these examples is that they are expressions of the idea that the derivative is part of a functor. A functor is an operation on spaces and functions between them. It associates to each space a new space and to each function between two spaces a new function between the corresponding new spaces. In each of the above cases, the functor sends each space to its tangent bundle and it sends each function to its derivative. For example, in the manifold case, the derivative sends a "C""r"-manifold to a "C""r"\u22121-manifold (its tangent bundle) and a "C""r"-function to its total derivative. There is one requirement for this to be a functor, namely that the derivative of a composite must be the composite of the derivatives. This is exactly the formula .
p10861
aVThere are also chain rules in stochastic calculus. One of these, It\u014d's lemma, expresses the composite of an It\u014d process (or more generally a semimartingale) "dX""t" with a twice-differentiable function "f". In It\u014d's lemma, the derivative of the composite function depends not only on "dX""t" and the derivative of "f" but also on the second derivative of "f". The dependence on the second derivative is a consequence of the non-zero quadratic variation of the stochastic process, which broadly speaking means that the process can move up and down in a very rough way. This variant of the chain rule is not an example of a functor because the two functions being composed are of different types.
p10862
asS'Fraction (mathematics)'
p10863
(lp10864
VA fraction (from , "broken") represents a part of a whole or, more generally, any number of equal parts. When spoken in everyday English, a fraction describes how many parts of a certain size there are, for example, one-half, eight-fifths, three-quarters.
p10865
aVA "common", "vulgar", or "simple" fraction (examples: formula_1 and 17/3) consists of an integer numerator, displayed above a line (or before a slash), and a non-zero integer denominator, displayed below (or after) that line.
p10866
aVNumerators and denominators are also used in fractions that are not "common", including compound fractions, complex fractions, and mixed numerals.
p10867
aVThe numerator represents a number of equal parts, and the denominator, which cannot be zero, indicates how many of those parts make up a unit or a whole. For example, in the fraction 3/4, the numerator, 3, tells us that the fraction represents 3 equal parts, and the denominator, 4, tells us that 4 parts make up a whole. The picture to the right illustrates formula_2 or 3/4 of a cake.
p10868
aVFractional numbers can also be written without using explicit numerators or denominators, by using decimals, percent signs, or negative exponents (as in 0.01, 1%, and 10\u22122 respectively, all of which are equivalent to 1/100). An integer such as the number 7 can be thought of as having an implicit denominator of one: 7 equals 7/1.
p10869
aVOther uses for fractions are to represent ratios and to represent division.
p10870
aVThus the fraction 3/4 is also used to represent the ratio 3:4 (the ratio of the part to the whole) and the division 3 ÷ 4 (three divided by four).
p10871
aVIn mathematics the set of all numbers which can be expressed in the form a/b, where a and b are integers and b is not zero, is called the set of rational numbers and is represented by the symbol Q, which stands for quotient. The test for a number being a rational number is that it can be written in that form (i.e., as a common fraction). However, the word "fraction" is also used to describe mathematical expressions that are not rational numbers, for example algebraic fractions (quotients of algebraic expressions), and expressions that contain irrational numbers, such as \u221a2/2 (see square root of 2) and \u03c0/4 (see proof that \u03c0 is irrational).
p10872
aVVocabulary.
p10873
aVWhen reading fractions it is customary in English to pronounce the denominator using the corresponding ordinal number, in plural if the numerator is not one, as in "fifths" for fractions with a 5 in the denominator. Thus, 3/5 is rendered as "three fifths" and 5/32 as "five thirty-seconds". This generally applies to whole number denominators greater than 2, though large denominators that are not powers of ten are often rendered using the cardinal number. Thus, 5/123 might be rendered as "five one-hundred-twenty-thirds", but is often "five "over" one hundred twenty-three". In contrast, because one million is a power of ten, 6/1,000,000 is usually expressed as "six millionths" or "six one-millionths", rather than as "six "over" one million".
p10874
aVThe denominators 1, 2, and 4 are special cases. The fraction 3/1 may be spoken of as "three wholes". The denominator 2 is expressed as "half" (plural "halves"); "\u2212" is "minus three-halves" or "negative three-halves". The fraction 3/4 may be either "three fourths" or "three quarters". Furthermore, since most fractions in prose function as adjectives, the fractional modifier is hyphenated. This is evident in standard prose in which one might write about "every two-tenths of a mile", "the quarter-mile run", or the Three-Fifths Compromise. When the fraction's numerator is 1, then the word "one" may be omitted, such as "every tenth of a second" or "during the final quarter of the year".
p10875
aVIn the examples 2/5 and 7/3, the slanting line is called a solidus or forward slash. In the examples formula_3 and formula_4, the horizontal line is called a "fraction bar". When the solidus is encountered in a fraction, a speaker will sometimes parse it by pronouncing it "over" as in the examples above.
p10876
aVForms of fractions.
p10877
aVSimple, common, or vulgar fractions.
p10878
aVA simple fraction (also known as a common fraction or vulgar fraction) is a rational number written as "a"/"b" or formula_5, where "a" and "b" are both integers.
p10879
aVAs with other fractions, the denominator ("b") cannot be zero. Examples include formula_1, formula_7, formula_8, formula_9, and 3/17.
p10880
aV"Simple fractions" can be positive or negative, proper, or improper (see below). Compound fractions, complex fractions, mixed numerals, and decimals (see below) are not "simple fractions", though, unless irrational, they can be evaluated to a simple fraction.
p10881
aVProper and improper fractions.
p10882
aVCommon fractions can be classified as either proper or improper. When the numerator and the denominator are both positive, the fraction is called proper if the numerator is less than the denominator, and improper otherwise. In general, a common fraction is said to be a proper fraction if the absolute value of the fraction is strictly less than one\u2014that is, if the fraction is greater than \u22121 and less than 1.
p10883
aVIt is said to be an improper fraction, or sometimes top-heavy fraction, if the absolute value of the fraction is greater than or equal to 1. Examples of proper fractions are 2/3, -3/4, and 4/9; examples of improper fractions are 9/4, -4/3, and 3/3.
p10884
aVMixed numbers.
p10885
aVA mixed numeral (often called a "mixed number", also called a "mixed fraction") is the sum of a non-zero integer and a proper fraction. This sum is implied without the use of any visible operator such as "+". For example, in referring to two entire cakes and three quarters of another cake, the whole and fractional parts of the number are written next to each other: formula_10.
p10886
aVThis is not to be confused with the algebra rule of implied multiplication. When two algebraic expressions are written next to each other, the operation of multiplication is said to be "understood". In algebra, formula_11 for example is not a mixed number. Instead, multiplication is understood where formula_12.
p10887
aVTo avoid confusion, the multiplication is often explicitly expressed. So formula_13 may be written as
p10888
aVformula_14,
p10889
aVformula_15, or
p10890
aVformula_16.
p10891
aVAn improper fraction is another way to write a whole plus a part. A mixed number can be converted to an improper fraction as follows:
p10892
aVSimilarly, an improper fraction can be converted to a mixed number as follows:
p10893
aVMixed numbers can also be negative, as in formula_23, which equals formula_24.
p10894
aVRatios.
p10895
aVA ratio is a relationship between two or more numbers that can be sometimes expressed as a fraction. Typically, a number of items are grouped and compared in a ratio, specifying numerically the relationship between each group. Ratios are expressed as "group 1 to group 2 ... to group "n"". For example, if a car lot had 12 vehicles, of which
p10896
aVthen the ratio of red to white to yellow cars is 6 to 2 to 4. The ratio of yellow cars to white cars is 4 to 2 and may be expressed as 4:2 or 2:1.
p10897
aVA ratio is often converted to a fraction when it is expressed as a ratio to the whole. In the above example, the ratio of yellow cars to all the cars on the lot is 4:12 or 1:3. We can convert these ratios to a fraction and say that 4/12 of the cars or 1/3 of the cars in the lot are yellow. Therefore, if a person randomly chose one car on the lot, then there is a one in three chance or probability that it would be yellow.
p10898
aVReciprocals and the "invisible denominator".
p10899
aVThe reciprocal of a fraction is another fraction with the numerator and denominator exchanged. The reciprocal of formula_25, for instance, is formula_4. The product of a fraction and its reciprocal is 1, hence the reciprocal is the multiplicative inverse of a fraction. Any integer can be written as a fraction with the number one as denominator. For example, 17 can be written as formula_27, where 1 is sometimes referred to as the "invisible denominator". Therefore, every fraction or integer except for zero has a reciprocal. The reciprocal of 17 is formula_28.
p10900
aV"Not to be confused with fractions involving Complex numbers
p10901
aVComplex fractions.
p10902
aVIn a complex fraction, either the numerator, or the denominator, or both, is a fraction or a mixed number, corresponding to division of fractions. For example, formula_29 and formula_30 are complex fractions. To reduce a complex fraction to a simple fraction, treat the longest fraction line as representing division. For example:
p10903
aVformula_31
p10904
aVformula_32
p10905
aVformula_33
p10906
aVformula_34.
p10907
aVIf, in a complex fraction, there is no clear way to tell which fraction lines takes precedence, then the expression is improperly formed, and ambiguous. Thus 5/10/20/40 is a poorly constructed mathematical expression, with multiple possible values.
p10908
aVCompound fractions.
p10909
aVA compound fraction is a fraction of a fraction, or any number of fractions connected with the word "of", corresponding to multiplication of fractions. To reduce a compound fraction to a simple fraction, just carry out the multiplication (see the section on multiplication). For example, formula_2 of formula_36 is a compound fraction, corresponding to formula_37. The terms compound fraction and complex fraction are closely related and sometimes one is used as a synonym for the other.
p10910
aVDecimal fractions and percentages.
p10911
aVA decimal fraction is a fraction whose denominator is not given explicitly, but is understood to be an integer power of ten. Decimal fractions are commonly expressed using decimal notation in which the implied denominator is determined by the number of digits to the right of a decimal separator, the appearance of which (e.g., a period, a raised period (\u2022), a comma) depends on the locale (for examples, see decimal separator). Thus for 0.75 the numerator is 75 and the implied denominator is 10 to the second power, "viz." 100, because there are two digits to the right of the decimal separator. In decimal numbers greater than 1 (such as 3.75), the fractional part of the number is expressed by the digits to the right of the decimal (with a value of 0.75 in this case). 3.75 can be written either as an improper fraction, 375/100, or as a mixed number, formula_38.
p10912
aVDecimal fractions can also be expressed using scientific notation with negative exponents, such as , which represents 0.0000006023. The represents a denominator of . Dividing by moves the decimal point 7 places to the left.
p10913
aVDecimal fractions with infinitely many digits to the right of the decimal separator represent an infinite series. For example, 1/3 = 0.333... represents the infinite series 3/10 + 3/100 + 3/1000 + ... .
p10914
aVAnother kind of fraction is the percentage (Latin "per centum" meaning "per hundred", represented by the symbol %), in which the implied denominator is always 100. Thus, 51% means 51/100. Percentages greater than 100 or less than zero are treated in the same way, e.g. 311% equals 311/100, and \u221227% equals \u221227/100.
p10915
aVThe related concept of "permille" or "parts per thousand" has an implied denominator of 1000, while the more general parts-per notation, as in 75 parts per million, means that the proportion is 75/1,000,000.
p10916
aVWhether common fractions or decimal fractions are used is often a matter of taste and context. Common fractions are used most often when the denominator is relatively small. By mental calculation, it is easier to multiply 16 by 3/16 than to do the same calculation using the fraction's decimal equivalent (0.1875). And it is more accurate to multiply 15 by 1/3, for example, than it is to multiply 15 by any decimal approximation of one third. Monetary values are commonly expressed as decimal fractions, for example $3.75. However, as noted above, in pre-decimal British currency, shillings and pence were often given the form (but not the meaning) of a fraction, as, for example 3/6 (read "three and six") meaning 3 shillings and 6 pence, and having no relationship to the fraction 3/6.
p10917
aVArithmetic with fractions.
p10918
aVLike whole numbers, fractions obey the commutative, associative, and distributive laws, and the rule against division by zero.
p10919
aVEquivalent fractions.
p10920
aVMultiplying the numerator and denominator of a fraction by the same (non-zero) number results in a fraction that is equivalent to the original fraction. This is true because for any non-zero number formula_50, the fraction formula_51. Therefore, multiplying by formula_52 is equivalent to multiplying by one, and any number multiplied by one has the same value as the original number. By way of an example, start with the fraction formula_1. When the numerator and denominator are both multiplied by 2, the result is formula_54, which has the same value (0.5) as formula_1. To picture this visually, imagine cutting a cake into four pieces; two of the pieces together (formula_54) make up half the cake (formula_1).
p10921
aVDividing the numerator and denominator of a fraction by the same non-zero number will also yield an equivalent fraction. This is called reducing or simplifying the fraction. A simple fraction in which the numerator and denominator are coprime (that is, the only positive integer that goes into both the numerator and denominator evenly is 1) is said to be irreducible, in lowest terms, or in simplest terms. For example, formula_58 is not in lowest terms because both 3 and 9 can be exactly divided by 3. In contrast, formula_59 "is" in lowest terms\u2014the only positive integer that goes into both 3 and 8 evenly is 1.
p10922
aVUsing these rules, we can show that formula_60 = formula_1 = formula_62 = formula_63.
p10923
aVA common fraction can be reduced to lowest terms by dividing both the numerator and denominator by their greatest common divisor. For example, as the greatest common divisor of 63 and 462 is 21, the fraction formula_64 can be reduced to lowest terms by dividing the numerator and denominator by 21:
p10924
aVformula_65
p10925
aVThe Euclidean algorithm gives a method for finding the greatest common divisor of any two positive integers.
p10926
aVComparing fractions.
p10927
aVComparing fractions with the same denominator only requires comparing the numerators.
p10928
aVformula_66 because 3>2.
p10929
aVIf two positive fractions have the same numerator, then the fraction with the smaller denominator is the larger number. When a whole is divided into equal pieces, if fewer equal pieces are needed to make up the whole, then each piece must be larger. When two positive fractions have the same numerator, they represent the same number of parts, but in the fraction with the smaller denominator, the parts are larger.
p10930
aVOne way to compare fractions with different numerators and denominators is to find a common denominator. To compare formula_5 and formula_68, these are converted to formula_69 and formula_70. Then "bd" is a common denominator and the numerators "ad" and "bc" can be compared.
p10931
aVformula_42 ? formula_1 gives formula_73
p10932
aVIt is not necessary to determine the value of the common denominator to compare fractions. This short cut is known as "cross multiplying" \u2013 you can just compare "ad" and "bc", without computing the denominator.
p10933
aVformula_74 ? formula_75
p10934
aVMultiply top and bottom of each fraction by the denominator of the other fraction, to get a common denominator:
p10935
aVformula_76 ? formula_77
p10936
aVThe denominators are now the same, but it is not necessary to calculate their value \u2013 only the numerators need to be compared. Since 5×17 (= 85) is greater than 4×18 (= 72), formula_78.
p10937
aVAlso note that every negative number, including negative fractions, is less than zero, and every positive number, including positive fractions, is greater than zero, so every negative fraction is less than any positive fraction.
p10938
aVAddition.
p10939
aVThe first rule of addition is that only like quantities can be added; for example, various quantities of quarters. Unlike quantities, such as adding thirds to quarters, must first be converted to like quantities as described below:
p10940
aVImagine a pocket containing two quarters, and another pocket containing three quarters; in total, there are five quarters. Since four quarters is equivalent to one (dollar), this can be represented as follows:
p10941
aVformula_79.
p10942
aVAdding unlike quantities.
p10943
aVTo add fractions containing unlike quantities (e.g. quarters and thirds), it is necessary to convert all amounts to like quantities. It is easy to work out the chosen type of fraction to convert to; simply multiply together the two denominators (bottom number) of each fraction.
p10944
aVFor adding quarters to thirds, both types of fraction are converted to twelfths, thus: formula_80.
p10945
aVConsider adding the following two quantities:
p10946
aVformula_81
p10947
aVFirst, convert formula_82 into fifteenths by multiplying both the numerator and denominator by three: formula_83. Since formula_84 equals 1, multiplication by formula_84 does not change the value of the fraction.
p10948
aVSecond, convert formula_86 into fifteenths by multiplying both the numerator and denominator by five: formula_87.
p10949
aVNow it can be seen that:
p10950
aVformula_81
p10951
aVis equivalent to:
p10952
aVformula_89
p10953
aVThis method can be expressed algebraically:
p10954
aVformula_90
p10955
aVAnd for expressions consisting of the addition of three fractions:
p10956
aVformula_91
p10957
aVThis method always works, but sometimes there is a smaller denominator that can be used (a least common denominator). For example, to add formula_2 and formula_93 the denominator 48 can be used (the product of 4 and 12), but the smaller denominator 12 may also be used, being the least common multiple of 4 and 12.
p10958
aVformula_94
p10959
aVSubtraction.
p10960
aVThe process for subtracting fractions is, in essence, the same as that of adding them: find a common denominator, and change each fraction to an equivalent fraction with the chosen common denominator. The resulting fraction will have that denominator, and its numerator will be the result of subtracting the numerators of the original fractions. For instance,
p10961
aVformula_95
p10962
aVMultiplication.
p10963
aVMultiplying a fraction by another fraction.
p10964
aVTo multiply fractions, multiply the numerators and multiply the denominators. Thus:
p10965
aVformula_96
p10966
aVTo explain the process, consider one third of one quarter. Using the example of a cake, if three small slices of equal size make up a quarter, and four quarters make up a whole, twelve of these small, equal slices make up a whole. Therefore a third of a quarter is a twelfth. Now consider the numerators. The first fraction, two thirds, is twice as large as one third. Since one third of a quarter is one twelfth, two thirds of a quarter is two twelfth. The second fraction, three quarters, is three times as large as one quarter, so two thirds of three quarters is three times as large as two thirds of one quarter. Thus two thirds times three quarters is six twelfths.
p10967
aVA short cut for multiplying fractions is called "cancellation". Effectively the answer is reduced to lowest terms during multiplication. For example:
p10968
aVformula_97
p10969
aVA two is a common factor in both the numerator of the left fraction and the denominator of the right and is divided out of both. Three is a common factor of the left denominator and right numerator and is divided out of both.
p10970
aVMultiplying a fraction by a whole number.
p10971
aVSince a whole number can be rewritten as itself divided by 1, normal fraction multiplication rules can still apply.
p10972
aVformula_98
p10973
aVThis method works because the fraction 6/1 means six equal parts, each one of which is a whole.
p10974
aVMultiplying mixed numbers.
p10975
aVWhen multiplying mixed numbers, it is considered preferable to convert the mixed number into an improper fraction. For example:
p10976
aVformula_99
p10977
aVIn other words, formula_17 is the same as formula_101, making 11 quarters in total (because 2 cakes, each split into quarters makes 8 quarters total) and 33 quarters is formula_102, since 8 cakes, each made of quarters, is 32 quarters in total.
p10978
aVDivision.
p10979
aVTo divide a fraction by a whole number, you may either divide the numerator by the number, if it goes evenly into the numerator, or multiply the denominator by the number. For example, formula_103 equals formula_42 and also equals formula_105, which reduces to formula_42. To divide a number by a fraction, multiply that number by the reciprocal of that fraction. Thus, formula_107.
p10980
aVConverting between decimals and fractions.
p10981
aVTo change a common fraction to a decimal, divide the denominator into the numerator. Round the answer to the desired accuracy. For example, to change 1/4 to a decimal, divide 4 into 1.00, to obtain 0.25. To change 1/3 to a decimal, divide 3 into 1.0000..., and stop when the desired accuracy is obtained. Note that 1/4 can be written exactly with two decimal digits, while 1/3 cannot be written exactly with any finite number of decimal digits.
p10982
aVTo change a decimal to a fraction, write in the denominator a 1 followed by as many zeroes as there are digits to the right of the decimal point, and write in the numerator all the digits in the original decimal, omitting the decimal point. Thus 12.3456 = 123456/10000.
p10983
aVConverting repeating decimals to fractions.
p10984
aVDecimal numbers, while arguably more useful to work with when performing calculations, sometimes lack the precision that common fractions have. Sometimes an infinite repeating decimal is required to reach the same precision. Thus, it is often useful to convert repeating decimals into fractions.
p10985
aVThe preferred way to indicate a repeating decimal is to place a bar over the digits that repeat, for example 0. = 0.789789789\u2026 For repeating patterns where the repeating pattern begins immediately after the decimal point, a simple division of the pattern by the same number of nines as numbers it has will suffice. For example:
p10986
aV0. = 5/9
p10987
aV0. = 62/99
p10988
aV0. = 264/999
p10989
aV0. = 6291/9999
p10990
aVIn case leading zeros precede the pattern, the nines are suffixed by the same number of trailing zeros:
p10991
aV0.0 = 5/90
p10992
aV0.000 = 392/999000
p10993
aV0.00 = 12/9900
p10994
aVIn case a non-repeating set of decimals precede the pattern (such as 0.1523), we can write it as the sum of the non-repeating and repeating parts, respectively:
p10995
aV0.1523 + 0.0000
p10996
aVThen, convert both parts to fractions, and add them using the methods described above:
p10997
aV1523/10000 + 987/9990000 = 1522464/9990000
p10998
aVAlternatively, algebra can be used, such as below:
p10999
aVFractions in abstract mathematics.
p11000
aVIn addition to being of great practical importance, fractions are also studied by mathematicians, who check that the rules for fractions given above are consistent and reliable. Mathematicians define a fraction as an ordered pair ("a", "b") of integers "a" and "b" \u2260 0, for which the operations addition, subtraction, multiplication, and division are defined as follows:
p11001
aVformula_108
p11002
aVformula_109
p11003
aVformula_110
p11004
aVformula_111     (when c \u2260 0)
p11005
aVIn addition, an equivalence relation is specified as follows: formula_112 ~ formula_113 if and only if formula_114.
p11006
aVThese definitions agree in every case with the definitions given above; only the notation is different.
p11007
aVMore generally, "a" and "b" may be elements of any integral domain "R", in which case a fraction is an element of the field of fractions of "R". For example, when "a" and "b" are polynomials in one indeterminate, the field of fractions is the field of rational fractions (also known as the field of rational functions). When "a" and "b" are integers, the field of fractions is the field of rational numbers.
p11008
aVAlgebraic fractions.
p11009
aVAn algebraic fraction is the indicated quotient of two algebraic expressions. Two examples of algebraic fractions are formula_115 and formula_116. Algebraic fractions are subject to the same laws as arithmetic fractions.
p11010
aVIf the numerator and the denominator are polynomials, as in formula_115, the algebraic fraction is called a rational fraction (or rational expression). An irrational fraction is one that contains the variable under a fractional exponent or root, as in formula_116.
p11011
aVThe terminology used to describe algebraic fractions is similar to that used for ordinary fractions. For example, an algebraic fraction is in lowest terms if the only factors common to the numerator and the denominator are 1 and \u22121. An algebraic fraction whose numerator or denominator, or both, contain a fraction, such as formula_119, is called a complex fraction.
p11012
aVRational numbers are the quotient field of integers. Rational expressions are the quotient field of the polynomials (over some integral domain). Since a coefficient is a polynomial of degree zero, a radical expression such as \u221a2/2 is a rational fraction. Another example (over the reals) is formula_120, the radian measure of a right angle.
p11013
aVThe term partial fraction is used when decomposing rational expressions into sums. The goal is to write the rational expression as the sum of other rational expressions with denominators of lesser degree. For example, the rational expression formula_121 can be rewritten as the sum of two fractions: formula_122 + formula_123. This is useful in many areas such as integral calculus and differential equations.
p11014
aVRadical expressions.
p11015
aVA fraction may also contain radicals in the numerator and/or the denominator. If the denominator contains radicals, it can be helpful to rationalize it (compare Simplified form of a radical expression), especially if further operations, such as adding or comparing that fraction to another, are to be carried out. It is also more convenient if division is to be done manually. When the denominator is a monomial square root, it can be rationalized by multiplying both the top and the bottom of the fraction by the denominator:
p11016
aV formula_124
p11017
aVThe process of rationalization of binomial denominators involves multiplying the top and the bottom of a fraction by the conjugate of the denominator so that the denominator becomes a rational number. For example:
p11018
aVformula_125
p11019
aVformula_126
p11020
aVEven if this process results in the numerator being irrational, like in the examples above, the process may still facilitate subsequent manipulations by reducing the number of irrationals one has to work with in the denominator.
p11021
aVTypographical variations.
p11022
aVIn computer displays and typography, simple fractions are sometimes printed as a single character, e.g. ½ (one half). See the article on Number Forms for information on doing this in Unicode.
p11023
aVScientific publishing distinguishes four ways to set fractions, together with guidelines on use:
p11024
aVHistory.
p11025
aVThe earliest fractions were reciprocals of integers: ancient symbols representing one part of two, one part of three, one part of four, and so on. The Egyptians used Egyptian fractions ca. 1000 BC. About 4,000 years ago Egyptians divided with fractions using slightly different methods. They used least common multiples with unit fractions. Their methods gave the same answer as modern methods. The Egyptians also had a different notation for dyadic fractions in the Akhmim Wooden Tablet and several Rhind Mathematical Papyrus problems.
p11026
aVThe Greeks used unit fractions and later continued fractions and followers of the Greek philosopher Pythagoras, ca. 530 BC, discovered that the square root of two cannot be expressed as a fraction. In 150 BC Jain mathematicians in India wrote the "Sthananga Sutra", which contains work on the theory of numbers, arithmetical operations, operations with fractions.
p11027
aVThe method of putting one number below the other and computing fractions first appeared in Aryabhatta's work around AD 499.
p11028
aVIn Sanskrit literature, fractions, or rational numbers were always expressed by an integer followed by a fraction. When the integer is written on a line, the fraction is placed below it and is itself written on two lines, the numerator called "amsa" part on the first line, the denominator called "cheda" \u201cdivisor\u201d on the second below. If the fraction is written without any particular additional sign, one understands that it is added to the integer above it. If it is marked by a small circle or a cross (the shape of the \u201cplus\u201d sign in the West) placed on its right, one understands that it is subtracted from the integer. For example (to be read vertically),
p11029
aVBhaskara I writes
p11030
aV \u0967        \u0967        \u0967\u0966
p11031
aVThat is,
p11032
aV 6        1        2
p11033
aV 1        1        1\u0966
p11034
aV 4        5        9
p11035
aVto denote 6+1/4, 1+1/5, and 2\u20131/9.
p11036
aVAl-Hass\u0101r, a Muslim mathematician from Fez, Morocco specializing in Islamic inheritance jurisprudence during the 12th century, first mentions the use of a fractional bar, where numerators and denominators are separated by a horizontal bar. In his discussion he writes, "... for example, if you are told to write three-fifths and a third of a fifth, write thus, formula_129."
p11037
aVThis same fractional notation appears soon after in the work of Leonardo Fibonacci in the 13th century.
p11038
aVIn discussing the origins of decimal fractions, Dirk Jan Struik states:
p11039
aV"The introduction of decimal fractions as a common computational practice can be dated back to the Flemish pamphlet "De Thiende", published at Leyden in 1585, together with a French translation, "La Disme", by the Flemish mathematician Simon Stevin (1548\u20131620), then settled in the Northern Netherlands. It is true that decimal fractions were used by the Chinese many centuries before Stevin and that the Persian astronomer Al-K\u0101sh\u012b used both decimal and sexagesimal fractions with great ease in his "Key to arithmetic" (Samarkand, early fifteenth century)."
p11040
aVWhile the Persian mathematician Jamsh\u012bd al-K\u0101sh\u012b claimed to have discovered decimal fractions himself in the 15th century, J. Lennart Berggren notes that he was mistaken, as decimal fractions were first used five centuries before him by the Baghdadi mathematician Abu'l-Hasan al-Uqlidisi as early as the 10th century.
p11041
aVIn formal education.
p11042
aVPedagogical tools.
p11043
aVIn primary schools, fractions have been demonstrated through Cuisenaire rods, Fraction Bars, fraction strips, fraction circles, paper (for folding or cutting), pattern blocks, pie-shaped pieces, plastic rectangles, grid paper, dot paper, geoboards, counters and computer software.
p11044
aVDocuments for teachers.
p11045
aVSeveral states in the United States have adopted learning trajectories from the Common Core State Standards Initiative's guidelines for mathematics education. Aside from sequencing the learning of fractions and operations with fractions, the document provides the following definition of a fraction: "A number expressible in the form formula_5 where formula_131 is a whole number and formula_132 is a positive whole number. (The word "fraction" in the standards always refers to a non-negative number.)"
p11046
aVThe document itself also refers to negative fractions.
p11047
asS'Cellular automaton'
p11048
(lp11049
VA cellular automaton (pl. cellular automata, abbrev. CA) is a discrete model studied in computability theory, mathematics, physics, complexity science, theoretical biology and microstructure modeling. Cellular automata are also called cellular spaces, tessellation automata, homogeneous structures, cellular structures, tessellation structures, and iterative arrays.
p11050
aVA cellular automaton consists of a regular grid of "cells", each in one of a finite number of "states", such as "on" and "off" (in contrast to a coupled map lattice). The grid can be in any finite number of dimensions. For each cell, a set of cells called its "neighborhood" is defined relative to the specified cell. An initial state (time "t" = 0) is selected by assigning a state for each cell. A new "generation" is created (advancing "t" by 1), according to some fixed "rule" (generally, a mathematical function) that determines the new state of each cell in terms of the current state of the cell and the states of the cells in its neighborhood. Typically, the rule for updating the state of cells is the same for each cell and does not change over time, and is applied to the whole grid simultaneously, though exceptions are known, such as the stochastic cellular automaton and asynchronous cellular automaton.
p11051
aVThe concept was originally discovered in the 1940s by Stanislaw Ulam and John von Neumann while they were contemporaries at Los Alamos National Laboratory. While studied by some throughout the 1950s and 1960s, it was not until the 1970s and Conway's Game of Life, a two-dimensional cellular automaton, that interest in the subject expanded beyond academia. In the 1980s, Stephen Wolfram engaged in a systematic study of one-dimensional cellular automata, or what he calls elementary cellular automata; his research assistant Matthew Cook showed that one of these rules is Turing-complete. Wolfram published "A New Kind of Science" in 2002, claiming that cellular automata have applications in many fields of science. These include computer processors and cryptography.
p11052
aVThe primary classifications of cellular automata, as outlined by Wolfram, are numbered one to four. They are, in order, automata in which patterns generally stabilize into homogeneity, automata in which patterns evolve into mostly stable or oscillating structures, automata in which patterns evolve in a seemingly chaotic fashion, and automata in which patterns become extremely complex and may last for a long time, with stable local structures. This last class are thought to be computationally universal, or capable of simulating a Turing machine. Special types of cellular automata are "reversible", where only a single configuration leads directly to a subsequent one, and "totalistic", in which the future value of individual cells depend on the total value of a group of neighboring cells. Cellular automata can simulate a variety of real-world systems, including biological and chemical ones.
p11053
aVOverview.
p11054
aVOne way to simulate a two-dimensional cellular automaton is with an infinite sheet of graph paper along with a set of rules for the cells to follow. Each square is called a "cell" and each cell has two possible states, black and white. The "neighborhood" of a cell is the nearby, usually adjacent, cells. The two most common types of neighborhoods are the "von Neumann neighborhood" and the "Moore neighborhood". The former, named after the founding cellular automaton theorist, consists of the four orthogonally adjacent cells. The latter includes the von Neumann neighborhood as well as the four remaining cells surrounding the cell whose state is to be calculated. For such a cell and its Moore neighborhood, there are 512 (= 29) possible patterns. For each of the 512 possible patterns, the rule table would state whether the center cell will be black or white on the next time interval. Conway's Game of Life is a popular version of this model. Another common neighborhood type is the "extended von Neumann neighborhood", which includes the two closest cells in each orthogonal direction, for a total of eight. The general equation for such a system of rules is "k""k""s", where "k" is the number of possible states for a cell, and "s" is the number of neighboring cells (including the cell to be calculated itself) used to determine the cell's next state. Thus, in the two dimensional system with a Moore neighborhood, the total number of automata possible would be 229, or .
p11055
aVIt is usually assumed that every cell in the universe starts in the same state, except for a finite number of cells in other states; the assignment of state values is called a "configuration". More generally, it is sometimes assumed that the universe starts out covered with a periodic pattern, and only a finite number of cells violate that pattern. The latter assumption is common in one-dimensional cellular automata.
p11056
aVCellular automata are often simulated on a finite grid rather than an infinite one. In two dimensions, the universe would be a rectangle instead of an infinite plane. The obvious problem with finite grids is how to handle the cells on the edges. How they are handled will affect the values of all the cells in the grid. One possible method is to allow the values in those cells to remain constant. Another method is to define neighborhoods differently for these cells. One could say that they have fewer neighbors, but then one would also have to define new rules for the cells located on the edges. These cells are usually handled with a "toroidal" arrangement: when one goes off the top, one comes in at the corresponding position on the bottom, and when one goes off the left, one comes in on the right. (This essentially simulates an infinite periodic tiling, and in the field of partial differential equations is sometimes referred to as "periodic" boundary conditions.) This can be visualized as taping the left and right edges of the rectangle to form a tube, then taping the top and bottom edges of the tube to form a torus (doughnut shape). Universes of other dimensions are handled similarly. This solves boundary problems with neighborhoods, but another advantage is that it is easily programmable using modular arithmetic functions. For example, in a 1-dimensional cellular automaton like the examples below, the neighborhood of a cell "xit" is {"x""i"\u22121"t"\u22121, "x""i""t"\u22121, "x""i"+1"t"\u22121}, where "t" is the time step (vertical), and "i" is the index (horizontal) in one generation.
p11057
aVHistory.
p11058
aVStanislaw Ulam, while working at the Los Alamos National Laboratory in the 1940s, studied the growth of crystals, using a simple lattice network as his model. At the same time, John von Neumann, Ulam's colleague at Los Alamos, was working on the problem of self-replicating systems. Von Neumann's initial design was founded upon the notion of one robot building another robot. This design is known as the kinematic model. As he developed this design, von Neumann came to realize the great difficulty of building a self-replicating robot, and of the great cost in providing the robot with a "sea of parts" from which to build its replicant. Neumann read a paper entitled "The general and logical theory of automata" at the Hixon Symposium in 1948. Ulam was the one who suggested using a "discrete" system for creating a reductionist model of self-replication. Nils Aall Barricelli performed many of the earliest explorations of these models of artificial life.
p11059
aVUlam and von Neumann created a method for calculating liquid motion in the late 1950s. The driving concept of the method was to consider a liquid as a group of discrete units and calculate the motion of each based on its neighbors' behaviors. Thus was born the first system of cellular automata. Like Ulam's lattice network, von Neumann's cellular automata are two-dimensional, with his self-replicator implemented algorithmically. The result was a universal copier and constructor working within a cellular automaton with a small neighborhood (only those cells that touch are neighbors; for von Neumann's cellular automata, only orthogonal cells), and with 29 states per cell. Von Neumann gave an existence proof that a particular pattern would make endless copies of itself within the given cellular universe by designing a 200,000 cell configuration that could do so. This design is known as the tessellation model, and is called a von Neumann universal constructor.
p11060
aVAlso in the 1940s, Norbert Wiener and Arturo Rosenblueth developed a model of excitable media with some of the characteristics of a cellular automaton. Their specific motivation was the mathematical description of impulse conduction in cardiac systems. However their model is not a cellular automaton because the medium in which signals propagate is continuous, and wave fronts are curves. A true cellular automaton model of excitable media was developed and studied by J. M. Greenberg and S. P. Hastings in 1978; see Greenberg-Hastings cellular automaton. The original work of Wiener and Rosenblueth contains many insights and continues to be cited in modern research publications on cardiac arrhythmia and excitable systems.
p11061
aVIn the 1960s, cellular automata were studied as a particular type of dynamical system and the connection with the mathematical field of symbolic dynamics was established for the first time. In 1969, Gustav A. Hedlund compiled many results following this point of view in what is still considered as a seminal paper for the mathematical study of cellular automata. The most fundamental result is the characterization in the Curtis\u2013Hedlund\u2013Lyndon theorem of the set of global rules of cellular automata as the set of continuous endomorphisms of shift spaces.
p11062
aVIn 1969, German computer pioneer Konrad Zuse published his book "Calculating Space", proposing that the physical laws of the universe are discrete by nature, and that the entire universe is the output of a deterministic computation on a single cellular automaton; "Zuse's Theory" became the foundation of the field of study called "digital physics".
p11063
aVIn the 1970s a two-state, two-dimensional cellular automaton named Game of Life became widely known, particularly among the early computing community. Invented by John Conway and popularized by Martin Gardner in a "Scientific American" article, its rules are as follows: If a cell has two black neighbors, it stays the same. If it has three black neighbors, it becomes black. In all other situations it becomes white. Despite its simplicity, the system achieves an impressive diversity of behavior, fluctuating between apparent randomness and order. One of the most apparent features of the Game of Life is the frequent occurrence of "gliders", arrangements of cells that essentially move themselves across the grid. It is possible to arrange the automaton so that the gliders interact to perform computations, and after much effort it has been shown that the Game of Life can emulate a universal Turing machine. It was viewed as a largely recreational topic, and little follow-up work was done outside of investigating the particularities of the Game of Life and a few related rules in the early 1970s.
p11064
aVStephen Wolfram independently began working on cellular automata in mid 1981 after considering how complex patterns seemed formed in nature in violation of the Second Law of Thermodynamics. His investigations were initially spurred by an interest in modelling systems such as neural networks. He published his first paper in "Reviews of Modern Physics" investigating "elementary cellular automata" (Rule 30 in particular) in June 1983. The unexpected complexity of the behavior of these simple rules led Wolfram to suspect that complexity in nature may be due to similar mechanisms. His investigations, however, led him to realize that cellular automata were poor at modelling neural networks. Additionally, during this period Wolfram formulated the concepts of intrinsic randomness and computational irreducibility, and suggested that rule 110 may be universal\u2014a fact proved later by Wolfram's research assistant Matthew Cook in the 1990s.
p11065
aVIn 2002 Wolfram published a 1280-page text "A New Kind of Science", which extensively argues that the discoveries about cellular automata are not isolated facts but are robust and have significance for all disciplines of science. Despite confusion in the press, the book did not argue for a fundamental theory of physics based on cellular automata, and although it did describe a few specific physical models based on cellular automata, it also provided models based on qualitatively different abstract systems.
p11066
aVClassification.
p11067
aVWolfram, in "A New Kind of Science" and several papers dating from the mid-1980s, defined four classes into which cellular automata and several other simple computational models can be divided depending on their behavior. While earlier studies in cellular automata tended to try to identify type of patterns for specific rules, Wolfram's classification was the first attempt to classify the rules themselves. In order of complexity the classes are:
p11068
aVThese definitions are qualitative in nature and there is some room for interpretation. According to Wolfram,
p11069
aV"...with almost any general classification scheme there are inevitably cases which get assigned to one class by one definition and another class by another definition. And so it is with cellular automata: there are occasionally rules...that show some features of one class and some of another." Wolfram's classification has been empirically matched to a clustering of the compressed lengths of the outputs of cellular automata.
p11070
aVThere have been several attempts to classify cellular automata in formally rigorous classes, inspired by the Wolfram's classification. For instance, Culik and Yu proposed three well-defined classes (and a fourth one for the automata not matching any of these), which are sometimes called Culik-Yu classes; membership in these proved undecidable.
p11071
aVWolfram's class 2 can be partitioned into two subgroups of stable (fixed-point) and oscillating (periodic) rules.
p11072
aVReversible.
p11073
aVA cellular automaton is "reversible" if, for every current configuration of the cellular automaton, there is exactly one past configuration (preimage). If one thinks of a cellular automaton as a function mapping configurations to configurations, reversibility implies that this function is bijective. If a cellular automaton is reversible, its time-reversed behavior can also be described as a cellular automaton; this fact is a consequence of the Curtis\u2013Hedlund\u2013Lyndon theorem, a topological characterization of cellular automata. For cellular automata in which not every configuration has a preimage, the configurations without preimages are called "Garden of Eden" patterns.
p11074
aVFor one-dimensional cellular automata there are known algorithms for deciding whether a rule is reversible or irreversible. However, for cellular automata of two or more dimensions reversibility is undecidable; that is, there is no algorithm that takes as input an automaton rule and is guaranteed to determine correctly whether the automaton is reversible. The proof by Jarkko Kari is related to the tiling problem by Wang tiles.
p11075
aVReversible cellular automata are often used to simulate such physical phenomena as gas and fluid dynamics, since they obey the laws of thermodynamics. Such cellular automata have rules specially constructed to be reversible. Such systems have been studied by Tommaso Toffoli, Norman Margolus and others. Several techniques can be used to explicitly construct reversible cellular automata with known inverses. Two common ones are the second order cellular automaton and the block cellular automaton, both of which involve modifying the definition of a cellular automaton in some way. Although such automata do not strictly satisfy the definition given above, it can be shown that they can be emulated by conventional cellular automata with sufficiently large neighborhoods and numbers of states, and can therefore be considered a subset of conventional cellular automata. Conversely, it has been shown that every reversible cellular automaton can be emulated by a block cellular automaton.
p11076
aVTotalistic.
p11077
aVA special class of cellular automata are "totalistic" cellular automata. The state of each cell in a totalistic cellular automaton is represented by a number (usually an integer value drawn from a finite set), and the value of a cell at time "t" depends only on the "sum" of the values of the cells in its neighborhood (possibly including the cell itself) at time "t" \u2212 1. If the state of the cell at time "t" does depend on its own state at time "t" \u2212 1 then the cellular automaton is properly called "outer totalistic". Conway's Game of Life is an example of an outer totalistic cellular automaton with cell values 0 and 1; outer totalistic cellular automata with the same Moore neighborhood structure as Life are sometimes called cellular automata.
p11078
aVRelated automata.
p11079
aVThere are many possible generalizations of the cellular automaton concept.
p11080
aVOne way is by using something other than a rectangular (cubic, "etc.") grid. For example, if a plane is tiled with regular hexagons, those hexagons could be used as cells. In many cases the resulting cellular automata are equivalent to those with rectangular grids with specially designed neighborhoods and rules. Another variation would be to make the grid itself irregular, such as with Penrose tiles.
p11081
aVAlso, rules can be probabilistic rather than deterministic. Such cellular automata are called probabilistic cellular automata. A probabilistic rule gives, for each pattern at time "t", the probabilities that the central cell will transition to each possible state at time "t" + 1. Sometimes a simpler rule is used; for example: "The rule is the Game of Life, but on each time step there is a 0.001% probability that each cell will transition to the opposite color."
p11082
aVThe neighborhood or rules could change over time or space. For example, initially the new state of a cell could be determined by the horizontally adjacent cells, but for the next generation the vertical cells would be used.
p11083
aVIn cellular automata, the new state of a cell is not affected by the new state of other cells. This could be changed so that, for instance, a 2 by 2 block of cells can be determined by itself and the cells adjacent to itself.
p11084
aVThere are "continuous automata". These are like totalistic cellular automata, but instead of the rule and states being discrete ("e.g." a table, using states {0,1,2}), continuous functions are used, and the states become continuous (usually values in ]). The state of a location is a finite number of real numbers. Certain cellular automata can yield diffusion in liquid patterns in this way.
p11085
aVContinuous spatial automata have a continuum of locations. The state of a location is a finite number of real numbers. Time is also continuous, and the state evolves according to differential equations. One important example is reaction-diffusion textures, differential equations proposed by Alan Turing to explain how chemical reactions could create the stripes on zebras and spots on leopards. When these are approximated by cellular automata, they often yield similar patterns. MacLennan [http://www.cs.utk.edu/~mclennan/contin-comp.html] considers continuous spatial automata as a model of computation.
p11086
aVThere are known examples of continuous spatial automata, which exhibit propagating phenomena analogous to gliders in the Game of Life.
p11087
aVElementary cellular automata.
p11088
aVThe simplest nontrivial cellular automaton would be one-dimensional, with two possible states per cell, and a cell's neighbors defined as the adjacent cells on either side of it. A cell and its two neighbors form a neighborhood of 3 cells, so there are 23 = 8 possible patterns for a neighborhood. A rule consists of deciding, for each pattern, whether the cell will be a 1 or a 0 in the next generation. There are then 28 = 256 possible rules. These 256 cellular automata are generally referred to by their Wolfram code, a standard naming convention invented by Wolfram that gives each rule a number from 0 to 255. A number of papers have analyzed and compared these 256 cellular automata. The rule 30 and rule 110 cellular automata are particularly interesting. The images below show the history of each when the starting configuration consists of a 1 (at the top of each image) surrounded by 0s. Each row of pixels represents a generation in the history of the automaton, with "t"=0 being the top row. Each pixel is colored white for 0 and black for 1.
p11089
aV<br>
p11090
aVRule 30 cellular automaton
p11091
aV<br>
p11092
aVRule 110 cellular automaton
p11093
aVRule 30 exhibits "class 3" behavior, meaning even simple input patterns such as that shown lead to chaotic, seemingly random histories.
p11094
aVRule 110, like the Game of Life, exhibits what Wolfram calls "class 4" behavior, which is neither completely random nor completely repetitive. Localized structures appear and interact in various complicated-looking ways. In the course of the development of "A New Kind of Science", as a research assistant to Wolfram in 1994, Matthew Cook proved that some of these structures were rich enough to support universality. This result is interesting because rule 110 is an extremely simple one-dimensional system, and difficult to engineer to perform specific behavior. This result therefore provides significant support for Wolfram's view that class 4 systems are inherently likely to be universal. Cook presented his proof at a Santa Fe Institute conference on Cellular Automata in 1998, but Wolfram blocked the proof from being included in the conference proceedings, as Wolfram did not want the proof announced before the publication of "A New Kind of Science". In 2004, Cook's proof was finally published in Wolfram's journal "Complex Systems" (Vol. 15, No. 1), over ten years after Cook came up with it. Rule 110 has been the basis for some of the smallest universal Turing machines.
p11095
aVRule space.
p11096
aVAn elementary cellular automaton rule is specified by 8 bits, and all elementary cellular automaton rules can be considered to sit on the vertices of the 8-dimensional unit hypercube. This unit hypercube is the cellular automaton rule space. For next-nearest-neighbor cellular automata, a rule is specified by 25 = 32 bits, and the cellular automaton rule space is a 32-dimensional unit hypercube. A distance between two rules can be defined by the number of steps required to move from one vertex, which represents the first rule, and another vertex, representing another rule, along the edge of the hypercube. This rule-to-rule distance is also called the
p11097
aVHamming distance.
p11098
aVCellular automaton rule space allows us to ask the question concerning whether rules with similar dynamical behavior are "close" to each. Graphically drawing a high dimensional hypercube on the 2-dimensional plane remains a difficult task, and one crude locator of a rule in the hypercube is the number of bit-1 in the 8-bit string for elementary rules (or 32-bit string for the next-nearest-neighbor rules). Drawing the rules in different Wolfram classes in these slices of the rule space show that class 1 rules tend to have lower number of bit-1's, thus located in one region of the space, whereas class 3 rules tend to have higher proportion (50%) of bit-1's.
p11099
aVFor larger cellular automaton rule space, it is shown that class 4 rules are located between the class 1 and class 3 rules. This observation is the foundation for the phrase edge of chaos, and is reminiscent of the phase transition in thermodynamics.
p11100
aVBiology.
p11101
aVSome biological processes occur\u2014or can be simulated\u2014by cellular automata.
p11102
aVPatterns of some seashells, like the ones in "Conus" and "Cymbiola" genus, are generated by natural cellular automata. The pigment cells reside in a narrow band along the shell's lip. Each cell secretes pigments according to the activating and inhibiting activity of its neighbor pigment cells, obeying a natural version of a mathematical rule. The cell band leaves the colored pattern on the shell as it grows slowly. For example, the widespread species "Conus textile" bears a pattern resembling Wolfram's rule 30 cellular automaton.
p11103
aVPlants regulate their intake and loss of gases via a cellular automaton mechanism. Each stoma on the leaf acts as a cell.
p11104
aVMoving wave patterns on the skin of cephalopods can be simulated with a two-state, two-dimensional cellular automata, each state corresponding to either an expanded or retracted chromatophore.
p11105
aVThreshold automata have been invented to simulate neurons, and complex behaviors such as recognition and learning can be simulated.
p11106
aVFibroblasts bear similarities to cellular automata, as each fibroblast only interacts with its neighbors.
p11107
aVChemical types.
p11108
aVThe Belousov\u2013Zhabotinsky reaction is a spatio-temporal chemical oscillator that can be simulated by means of a cellular automaton. In the 1950s A. M. Zhabotinsky (extending the work of B. P. Belousov) discovered that when a thin, homogenous layer of a mixture of malonic acid, acidified bromate, and a ceric salt were mixed together and left undisturbed, fascinating geometric patterns such as concentric circles and spirals propagate across the medium. In the "Computer Recreations" section of the August 1988 issue of "Scientific American", A. K. Dewdney discussed a cellular automaton developed by Martin Gerhardt and Heike Schuster of the University of Bielefeld (West Germany). This automaton produces wave patterns that resemble those in the Belousov-Zhabotinsky reaction.
p11109
aVApplications.
p11110
aVComputer processors.
p11111
aVCellular automaton processors are physical implementations of CA concepts, which can process information computationally. Processing elements are arranged in a regular grid of identical cells. The grid is usually a square tiling, or tessellation, of two or three dimensions; other tilings are possible, but not yet used. Cell states are determined only by interactions with adjacent neighbor cells. No means exists to communicate directly with cells farther away. One such cellular automaton processor array configuration is the systolic array. Cell interaction can be via electric charge, magnetism, vibration (phonons at quantum scales), or any other physically useful means. This can be done in several ways so no wires are needed between any elements. This is very unlike processors used in most computers today, von Neumann designs, which are divided into sections with elements that can communicate with distant elements over wires.
p11112
aVCryptography.
p11113
aVRule 30 was originally suggested as a possible Block cipher for use in cryptography. Two dimensional cellular automata are used for random number generation.
p11114
aVCellular automata have been proposed for public key cryptography. The one-way function is the evolution of a finite CA whose inverse is believed to be hard to find. Given the rule, anyone can easily calculate future states, but it appears to be very difficult to calculate previous states. 
p11115
aVError correction coding.
p11116
aVCA have been applied to design error correction codes in the paper "Design of CAECC \u2013 Cellular Automata Based Error Correcting Code", by
p11117
aVD. Roy Chowdhury, S. Basu, I. Sen Gupta, P. Pal Chaudhuri. The paper defines a new scheme of building SEC-DED codes using CA, and
p11118
aValso reports a fast hardware decoder for the code.
p11119
aVModeling physical reality.
p11120
aVAs Andrew Ilachinski points out in his "Cellular Automata", many scholars have raised the question of whether the universe is a cellular automaton. Ilachinski argues that the importance of this question may be better appreciated with a simple observation, which can be stated as follows. Consider the evolution of rule 110: if it were some kind of "alien physics", what would be a reasonable description of the observed patterns? If an observer did not know how the images were generated, that observer might end up conjecturing about the movement of some particle-like objects. Indeed, physicist James Crutchfield has constructed a rigorous mathematical theory out of this idea, proving the statistical emergence of "particles" from cellular automata. Then, as the argument goes, one might wonder if "our" world, which is currently well described by physics with particle-like objects, could be a CA at its most fundamental level.
p11121
aVWhile a complete theory along this line has not been developed, entertaining and developing this hypothesis led scholars to interesting speculation and fruitful intuitions on how can we make sense of our world within a discrete framework. Marvin Minsky, the AI pioneer, investigated how to understand particle interaction with a four-dimensional CA lattice; Konrad Zuse\u2014the inventor of the first working computer, the Z3\u2014developed an irregularly organized lattice to address the question of the information content of particles. More recently, Edward Fredkin exposed what he terms the "finite nature hypothesis", i.e., the idea that "ultimately every quantity of physics, including space and time, will turn out to be discrete and finite." Fredkin and Wolfram are strong proponents of a CA-based physics.
p11122
aVIn recent years, other suggestions along these lines have emerged from literature in non-standard computation. Wolfram's "A New Kind of Science" considers CA the key to understanding a variety of subjects, physics included. The "Mathematics of the Models of Reference"\u2014created by iLabs founder Gabriele Rossi and developed with Francesco Berto and Jacopo Tagliabue\u2014features an original 2D/3D universe based on a new "rhombic dodecahedron-based" lattice and a unique rule. This model satisfies universality (it is equivalent to a Turing Machine) and perfect reversibility (a "desideratum" if one wants to conserve various quantities easily and never lose information), and it comes embedded in a first-order theory, allowing computable, qualitative statements on the universe evolution.
p11123
asS'Numerical analysis'
p11124
(lp11125
V[clay tablet YBC 7289 (c. 1800\u20131600 BC) with annotations. The approximation of the square root of 2 is four sexagesimal figures, which is about six decimal figures. 1 + 24/60 + 51/602 + 10/603 = 1.41421296...]]
p11126
aVNumerical analysis is the study of algorithms that use numerical approximation (as opposed to general symbolic manipulations) for the problems of mathematical analysis (as distinguished from discrete mathematics).
p11127
aVOne of the earliest mathematical writings is a Babylonian tablet from the Yale Babylonian Collection (YBC 7289), which gives a sexagesimal numerical approximation of formula_1, the length of the diagonal in a unit square. Being able to compute the sides of a triangle (and hence, being able to compute square roots) is extremely important, for instance, in astronomy, carpentry and construction.
p11128
aVNumerical analysis continues this long tradition of practical mathematical calculations. Much like the Babylonian approximation of formula_1, modern numerical analysis does not seek exact answers, because exact answers are often impossible to obtain in practice. Instead, much of numerical analysis is concerned with obtaining approximate solutions while maintaining reasonable bounds on errors.
p11129
aVNumerical analysis naturally finds applications in all fields of engineering and the physical sciences, but in the 21st century also the life sciences and even the arts have adopted elements of scientific computations. Ordinary differential equations appear in celestial mechanics (planets, stars and galaxies); numerical linear algebra is important for data analysis; stochastic differential equations and Markov chains are essential in simulating living cells for medicine and biology.
p11130
aVBefore the advent of modern computers numerical methods often depended on hand interpolation in large printed tables. Since the mid 20th century, computers calculate the required functions instead. These same interpolation formulas nevertheless continue to be used as part of the software algorithms for solving differential equations.
p11131
aVGeneral introduction.
p11132
aVThe overall goal of the field of numerical analysis is the design and analysis of techniques to give approximate but accurate solutions to hard problems, the variety of which is suggested by the following:
p11133
aVThe rest of this section outlines several important themes of numerical analysis.
p11134
aVHistory.
p11135
aVThe field of numerical analysis predates the invention of modern computers by many centuries. Linear interpolation was already in use more than 2000 years ago. Many great mathematicians of the past were preoccupied by numerical analysis, as is obvious from the names of important algorithms like Newton's method, Lagrange interpolation polynomial, Gaussian elimination, or Euler's method.
p11136
aVTo facilitate computations by hand, large books were produced with formulas and tables of data such as interpolation points and function coefficients. Using these tables, often calculated out to 16 decimal places or more for some functions, one could look up values to plug into the formulas given and achieve very good numerical estimates of some functions. The canonical work in the field is the NIST publication edited by Abramowitz and Stegun, a 1000-plus page book of a very large number of commonly used formulas and functions and their values at many points. The function values are no longer very useful when a computer is available, but the large listing of formulas can still be very handy.
p11137
aVThe mechanical calculator was also developed as a tool for hand computation. These calculators evolved into electronic computers in the 1940s, and it was then found that these computers were also useful for administrative purposes. But the invention of the computer also influenced the field of numerical analysis, since now longer and more complicated calculations could be done.
p11138
aVDirect and iterative methods.
p11139
aVDirect methods compute the solution to a problem in a finite number of steps. These methods would give the precise answer if they were performed in infinite precision arithmetic. Examples include Gaussian elimination, the QR factorization method for solving systems
p11140
aVof linear equations, and the simplex method of linear programming. In practice, finite precision is used and the result is an approximation of the true solution (assuming stability).
p11141
aVIn contrast to direct methods, iterative methods are not expected to terminate in a finite number of steps. Starting from an initial guess, iterative methods form successive approximations that converge to the exact solution only in the limit. A convergence test, often involving the residual, is specified in order to decide when a sufficiently accurate solution has (hopefully) been found. Even using infinite precision arithmetic these methods would not reach the solution within a finite number of steps (in general). Examples include Newton's method, the bisection method, and Jacobi iteration. In computational matrix algebra, iterative methods are generally needed for large problems.
p11142
aVIterative methods are more common than direct methods in numerical analysis. Some methods are direct in principle but are usually used as though they were not, e.g. GMRES and the conjugate gradient method. For these methods the number of steps needed to obtain the exact solution is so large that an approximation is accepted in the same manner as for an iterative method.
p11143
aVDiscretization.
p11144
aVFurthermore, continuous problems must sometimes be replaced by a discrete problem whose solution is known to approximate that of the continuous problem; this process is called "discretization". For example, the solution of a differential equation is a function. This function must be represented by a finite amount of data, for instance by its value at a finite number of points at its domain, even though this domain is a continuum.
p11145
aVGeneration and propagation of errors.
p11146
aVThe study of errors forms an important part of numerical analysis. There are several ways in which error can be introduced in the solution of the problem.
p11147
aVRound-off.
p11148
aVRound-off errors arise because it is impossible to represent all real numbers exactly on a machine with finite memory (which is what all practical digital computers are).
p11149
aVTruncation and discretization error.
p11150
aVTruncation errors are committed when an iterative method is terminated or a mathematical procedure is approximated, and the approximate solution differs from the exact solution. Similarly, discretization induces a discretization error because the solution of the discrete problem does not coincide with the solution of the continuous problem. For instance, in the iteration in the sidebar to compute the solution of formula_3, after 10 or so iterations, we conclude that the root is roughly 1.99 (for example). We therefore have a truncation error of 0.01.
p11151
aVOnce an error is generated, it will generally propagate through the calculation. For instance, we have already noted that the operation + on a calculator (or a computer) is inexact. It follows that a calculation of the type a+b+c+d+e is even more inexact.
p11152
aVWhat does it mean when we say that the truncation error is created when we approximate a mathematical procedure? We know that to integrate a function exactly requires one to find the sum of infinite trapezoids. But numerically one can find the sum of only finite trapezoids, and hence the approximation of the mathematical procedure. Similarly, to differentiate a function, the differential element approaches to zero but numerically we can only choose a finite value of the differential element.
p11153
aVNumerical stability and well-posed problems.
p11154
aVNumerical stability is an important notion in numerical analysis. An algorithm is called "numerically stable" if an error, whatever its cause, does not grow to be much larger during the calculation. This happens if the problem is "well-conditioned", meaning that the solution changes by only a small amount if the problem data are changed by a small amount. To the contrary, if a problem is "ill-conditioned", then any small error in the data will grow to be a large error.
p11155
aVBoth the original problem and the algorithm used to solve that problem can be "well-conditioned" and/or "ill-conditioned", and any combination is possible.
p11156
aVSo an algorithm that solves a well-conditioned problem may be either numerically stable or numerically unstable. An art of numerical analysis is to find a stable algorithm for solving a well-posed mathematical problem. For instance, computing the square root of 2 (which is roughly 1.41421) is a well-posed problem. Many algorithms solve this problem by starting with an initial approximation "x"1 to formula_1, for instance "x"1=1.4, and then computing improved guesses "x"2, "x"3, etc.. One such method is the famous Babylonian method, which is given by "x""k"+1 = "xk"/2 + 1/"xk". Another iteration, which we will call Method X, is given by "x""k" + 1 = ("x""k"2\u22122)2 + "x""k". We have calculated a few iterations of each scheme in table form below, with initial guesses "x"1 = 1.4 and "x"1 = 1.42.
p11157
aVObserve that the Babylonian method converges fast regardless of the initial guess, whereas Method X converges extremely slowly with initial guess 1.4 and diverges for initial guess 1.42. Hence, the Babylonian method is numerically stable, while Method X is numerically unstable.
p11158
aVNumerical stability is affected by the number of the significant digits the machine keeps on, if we use a machine that keeps on the first four floating-point digits, a good example on loss of significance is given by these two equivalent functions
p11159
aVformula_5
p11160
aVIf we compare the results of
p11161
aV: formula_6
p11162
aVand
p11163
aVformula_7
p11164
aV by looking to the two results above, we realize that loss of significance which is also called Subtractive Cancelation has a huge effect on the results, even though both functions are equivalent; to show that they are equivalent simply we need to start by f(x) and end with g(x), and so
p11165
aV: formula_8
p11166
aVThe true value for the result is 11.174755..., which is exactly "g"(500) = 11.1748 after rounding the result to 4 decimal digits.
p11167
aVNow imagine that lots of terms like these functions are used in the program; the error will increase as one proceeds in the program, unless one uses the suitable formula of the two functions each time one evaluates either "f"("x"), or "g"("x"); the choice is dependent on the parity of "x".
p11168
aVAreas of study.
p11169
aVThe field of numerical analysis includes many sub-disciplines. Some of the major ones are:
p11170
aVComputing values of functions.
p11171
aVOne of the simplest problems is the evaluation of a function at a given point. The most straightforward approach, of just plugging in the number in the formula is sometimes not very efficient. For polynomials, a better approach is using the Horner scheme, since it reduces the necessary number of multiplications and additions. Generally, it is important to estimate and control round-off errors arising from the use of floating point arithmetic.
p11172
aVInterpolation, extrapolation, and regression.
p11173
aVInterpolation solves the following problem: given the value of some unknown function at a number of points, what value does that function have at some other point between the given points?
p11174
aVExtrapolation is very similar to interpolation, except that now we want to find the value of the unknown function at a point which is outside the given points.
p11175
aVRegression is also similar, but it takes into account that the data is imprecise. Given some points, and a measurement of the value of some function at these points (with an error), we want to determine the unknown function. The least squares-method is one popular way to achieve this.
p11176
aVSolving equations and systems of equations.
p11177
aVAnother fundamental problem is computing the solution of some given equation. Two cases are commonly distinguished, depending on whether the equation is linear or not. For instance, the equation formula_9 is linear while formula_10 is not.
p11178
aVMuch effort has been put in the development of methods for solving systems of linear equations. Standard direct methods, i.e., methods that use some matrix decomposition are Gaussian elimination, LU decomposition, Cholesky decomposition for symmetric (or hermitian) and positive-definite matrix, and QR decomposition for non-square matrices. Iterative methods such as the Jacobi method, Gauss\u2013Seidel method, successive over-relaxation and conjugate gradient method are usually preferred for large systems. General iterative methods can be developed using a matrix splitting.
p11179
aVRoot-finding algorithms are used to solve nonlinear equations (they are so named since a root of a function is an argument for which the function yields zero). If the function is differentiable and the derivative is known, then Newton's method is a popular choice. Linearization is another technique for solving nonlinear equations.
p11180
aVSolving eigenvalue or singular value problems.
p11181
aVSeveral important problems can be phrased in terms of eigenvalue decompositions or singular value decompositions. For instance, the spectral image compression algorithm is based on the singular value decomposition. The corresponding tool in statistics is called principal component analysis.
p11182
aVOptimization.
p11183
aVOptimization problems ask for the point at which a given function is maximized (or minimized). Often, the point also has to satisfy some constraints.
p11184
aVThe field of optimization is further split in several subfields, depending on the form of the objective function and the constraint. For instance, linear programming deals with the case that both the objective function and the constraints are linear. A famous method in linear programming is the simplex method.
p11185
aVThe method of Lagrange multipliers can be used to reduce optimization problems with constraints to unconstrained optimization problems.
p11186
aVEvaluating integrals.
p11187
aVNumerical integration, in some instances also known as numerical quadrature, asks for the value of a definite integral. Popular methods use one of the Newton\u2013Cotes formulas (like the midpoint rule or Simpson's rule) or Gaussian quadrature. These methods rely on a "divide and conquer" strategy, whereby an integral on a relatively large set is broken down into integrals on smaller sets. In higher dimensions, where these methods become prohibitively expensive in terms of computational effort, one may use Monte Carlo or quasi-Monte Carlo methods (see Monte Carlo integration), or, in modestly large dimensions, the method of sparse grids.
p11188
aVDifferential equations.
p11189
aVNumerical analysis is also concerned with computing (in an approximate way) the solution of differential equations, both ordinary differential equations and partial differential equations.
p11190
aVPartial differential equations are solved by first discretizing the equation, bringing it into a finite-dimensional subspace. This can be done by a finite element method, a finite difference method, or (particularly in engineering) a finite volume method. The theoretical justification of these methods often involves theorems from functional analysis. This reduces the problem to the solution of an algebraic equation.
p11191
aVSoftware.
p11192
aVSince the late twentieth century, most algorithms are implemented in a variety of programming languages. The Netlib repository contains various collections of software routines for numerical problems, mostly in Fortran and C. Commercial products implementing many different numerical algorithms include the IMSL and NAG libraries; a free alternative is the GNU Scientific Library.
p11193
aVThere are several popular numerical computing applications such as MATLAB, TK Solver, S-PLUS, LabVIEW, and IDL as well as free and open source alternatives such as FreeMat, Scilab, GNU Octave (similar to Matlab), IT++ (a C++ library), R (similar to S-PLUS) and certain variants of Python. Performance varies widely: while vector and matrix operations are usually fast, scalar loops may vary in speed by more than an order of magnitude.
p11194
aVMany computer algebra systems such as Mathematica also benefit from the availability of arbitrary precision arithmetic which can provide more accurate results.
p11195
aVAlso, any spreadsheet software can be used to solve simple problems relating to numerical analysis.
p11196
aVExternal links.
p11197
aVJournals
p11198
aVOnline texts
p11199
aVOnline course material
p11200
asS'Abacus'
p11201
(lp11202
VThe abacus ("plural" abaci or abacuses), also called a counting frame, is a calculating tool that was in use centuries before the adoption of the written modern numeral system and is still widely used by merchants, traders and clerks in Asia, Africa, and elsewhere. Today, abaci are often constructed as a bamboo frame with beads sliding on wires, but originally they were beans or stones moved in grooves in sand or on tablets of wood, stone, or metal. The user of an abacus is called an "abacist".
p11203
aVEtymology.
p11204
aVThe use of the word "abacus" dates before 1387 AD, when a Middle English work borrowed the word from Latin to describe a sandboard abacus. The Latin word came from Greek \u1f04\u03b2\u03b1\u03be "abax" which means something without base, and improperly, any piece of rectangular board or plank. 
p11205
aVAlternatively, without reference to ancient texts on etymology, it has been suggested that it means "a square tablet strewn with dust", or "drawing-board covered with dust (for the use of mathematics)" (the exact shape of the Latin perhaps reflects the genitive form of the Greek word, \u1f04\u03b2\u03b1\u03bao\u03c2 "abakos"). Whereas the table strewn with dust definition is popular, there are those that do not place credence in this at all and in fact state that it is not proven. Greek \u1f04\u03b2\u03b1\u03be itself is probably a borrowing of a Northwest Semitic, perhaps Phoenician, word akin to Hebrew "\u02be\u0101b\u0101q" (\u05d0\u05d1\u05e7), "dust" (or in post-Biblical sense meaning "sand used as a writing surface"). The preferred plural of "abacus" is a subject of disagreement, with both "abacuses" and "abaci" in use.
p11206
aVHistory.
p11207
aVMesopotamian.
p11208
aVThe period 2700\u20132300 BC saw the first appearance of the Sumerian abacus, a table of successive columns which delimited the successive orders of magnitude of their sexagesimal number system.
p11209
aVSome scholars point to a character from the Babylonian cuneiform which may have been derived from a representation of the abacus. It is the belief of Old Babylonian scholars such as Carruccio that Old Babylonians "may have used the abacus for the operations of addition and subtraction; however, this primitive device proved difficult to use for more complex calculations".
p11210
aVEgyptian.
p11211
aVThe use of the abacus in Ancient Egypt is mentioned by the Greek historian Herodotus, who writes that the Egyptians manipulated the pebbles from right to left, opposite in direction to the Greek left-to-right method. Archaeologists have found ancient disks of various sizes that are thought to have been used as counters. However, wall depictions of this instrument have not been discovered.
p11212
aVPersian.
p11213
aVDuring the Achaemenid Persian Empire, around 600 BC the Persians first began to use the abacus. Under the Parthian, Sassanian and Iranian empires, scholars concentrated on exchanging knowledge and inventions with the countries around them \u2013 India, China, and the Roman Empire, when it is thought to have been exported to other countries.
p11214
aVGreek.
p11215
aVThe earliest archaeological evidence for the use of the Greek abacus dates to the 5th century BC. Also Demosthenes (384 BC\u2013322 BC) talked of the need to use pebbles for calculations too difficult for your head. A play by Alexis from the 4th century BC mentions an abacus and pebbles for accounting, and both Diogenes and Polybius mention men that sometimes stood for more and sometimes for less, like the pebbles on an abacus. The Greek abacus was a table of wood or marble, pre-set with small counters in wood or metal for mathematical calculations. This Greek abacus saw use in Achaemenid Persia, the Etruscan civilization, Ancient Rome and, until the French Revolution, the Western Christian world.
p11216
aVA tablet found on the Greek island Salamis in 1846 AD (the Salamis Tablet), dates back to 300 BC, making it the oldest counting board discovered so far. It is a slab of white marble long, wide, and thick, on which are 5 groups of markings. In the center of the tablet is a set of 5 parallel lines equally divided by a vertical line, capped with a semicircle at the intersection of the bottom-most horizontal line and the single vertical line. Below these lines is a wide space with a horizontal crack dividing it. Below this crack is another group of eleven parallel lines, again divided into two sections by a line perpendicular to them, but with the semicircle at the top of the intersection; the third, sixth and ninth of these lines are marked with a cross where they intersect with the vertical line. Also from this time frame the "Darius Vase" was unearthed in 1851. It was covered with pictures including a "treasurer" holding a wax tablet in one hand while manipulating counters on a table with the other.
p11217
aVChinese.
p11218
aVThe earliest known written documentation of the Chinese abacus dates to the 2nd century BC.
p11219
aVThe Chinese abacus, known as the "suànpán" (\u7b97\u76e4, lit. "Counting tray"), is typically tall and comes in various widths depending on the operator. It usually has more than seven rods. There are two beads on each rod in the upper deck and five beads each in the bottom for both decimal and hexadecimal computation. The beads are usually rounded and made of a hardwood. The beads are counted by moving them up or down towards the beam. If you move them toward the beam, you count their value. If you move away, you don't count their value. The suanpan can be reset to the starting position instantly by a quick movement along the horizontal axis to spin all the beads away from the horizontal beam at the center.
p11220
aVSuanpans can be used for functions other than counting. Unlike the simple counting board used in elementary schools, very efficient suanpan techniques have been developed to do multiplication, division, addition, subtraction, square root and cube root operations at high speed. There are currently schools teaching students how to use it.
p11221
aVIn the long scroll "Along the River During the Qingming Festival" painted by Zhang Zeduan (1085\u20131145 AD) during the Song Dynasty (960\u20131297 AD), a suanpan is clearly seen lying beside an account book and doctor's prescriptions on the counter of an apothecary's (Feibao).
p11222
aVThe similarity of the Roman abacus to the Chinese one suggests that one could have inspired the other, as there is some evidence of a trade relationship between the Roman Empire and China. However, no direct connection can be demonstrated, and the similarity of the abaci may be coincidental, both ultimately arising from counting with five fingers per hand. Where the Roman model (like most modern Korean and Japanese) has 4 plus 1 bead per decimal place, the standard suanpan has 5 plus 2. (Incidentally, this allows use with a hexadecimal numeral system.) Instead of running on wires as in the Chinese, Korean, and Japanese models, the beads of Roman model run in grooves, presumably making arithmetic calculations much slower.
p11223
aVAnother possible source of the suanpan is Chinese counting rods, which operated with a decimal system but lacked the concept of zero as a place holder. The zero was probably introduced to the Chinese in the Tang Dynasty (618-907 AD) when travel in the Indian Ocean and the Middle East would have provided direct contact with India, allowing them to acquire the concept of zero and the decimal point from Indian merchants and mathematicians.
p11224
aVRoman.
p11225
aVThe normal method of calculation in ancient Rome, as in Greece, was by moving counters on a smooth table. Originally pebbles ("calculi") were used. Later, and in medieval Europe, jetons were manufactured. Marked lines indicated units, fives, tens etc. as in the Roman numeral system. This system of 'counter casting' continued into the late Roman empire and in medieval Europe, and persisted in limited use into the nineteenth century. Due to Pope Sylvester II's reintroduction of the abacus with very useful modifications, it became widely used in Europe once again during the 11th century This abacus used beads on wires, unlike the traditional Roman counting boards, which meant the abacus could be used much faster.
p11226
aVWriting in the 1st century BC, Horace refers to the wax abacus, a board covered with a thin layer of black wax on which columns and figures were inscribed using a stylus.
p11227
aVOne example of archaeological evidence of the Roman abacus, shown here in reconstruction, dates to the 1st century AD. It has eight long grooves containing up to five beads in each and eight shorter grooves having either one or no beads in each. The groove marked I indicates units, X tens, and so on up to millions. The beads in the shorter grooves denote fives \u2013five units, five tens etc., essentially in a bi-quinary coded decimal system, obviously related to the Roman numerals. The short grooves on the right may have been used for marking Roman "ounces" (i.e. fractions).
p11228
aVIndian.
p11229
aVThe "Abhidharmako\u015babh\u0101\u1e63ya" of Vasubandhu (316-396), a Sanskrit work on Buddhist philosophy, says that the second-century CE philosopher Vasumitra said that, "placing a wick (Sanskrit "vartik\u0101") on the number one ("ek\u0101\u1e45ka") means it is a one, while placing the wick on the number hundred means it is called a hundred, and on the number one thousand means it is called a thousand". It is unclear exactly what this arrangement may have been, but it could refer to tokens being cast into counting-pits, or placed on numbered squares. Perhaps it was a type of abacus.
p11230
aVAround the 5th century, Indian clerks were already finding new ways of recording the contents of the Abacus. Hindu texts used the term "\u015b\u016bnya" (zero) to indicate the empty column on the abacus.
p11231
aVJapanese.
p11232
aVIn Japanese, the abacus is called "soroban" (, lit. "Counting tray"), imported from China in the 14th century. It was probably in use by the working class a century or more before the ruling class started, as the class structure did not allow for devices used by the lower class to be adopted or used by the ruling class. The 1/4 abacus, which is suited to decimal calculation, appeared circa 1930, and became widespread as the Japanese abandoned hexadecimal weight calculation which was still common in China. The abacus is still manufactured in Japan today even with the proliferation, practicality, and affordability of pocket electronic calculators. The use of the soroban is still taught in Japanese primary schools as part of mathematics, primarily as an aid to faster mental calculation. Using visual imagery of a soroban, one can arrive at the answer in the same time as, or even faster than, is possible with a physical instrument.
p11233
aVKorean.
p11234
aVThe Chinese abacus migrated from China to Korea around 1400 AD. Koreans call it "jupan" (\uc8fc\ud310), "supan" (\uc218\ud310) or "jusan-means calculating with an abacus-" (\uc8fc\uc0b0).
p11235
aVNative American.
p11236
aVSome sources mention the use of an abacus called a "nepohualtzintzin" in ancient Aztec culture. This Mesoamerican abacus used a 5-digit base-20 system.
p11237
aVThe word Nep\u014dhualtzintzin comes from Nahuatl and it is formed by the roots; "Ne" - personal -; "p\u014dhual" or "p\u014dhualli" - the account -; and "tzintzin" - small similar elements. Its complete meaning was taken as: counting with small similar elements by somebody. Its use was taught in the Calmecac to the "temalpouhqueh" , who were students dedicated to take the accounts of skies, from childhood.
p11238
aVThe Nep\u014dhualtzintzin was divided in two main parts separated by a bar or intermediate cord. In the left part there were four beads, which in the first row have unitary values (1, 2, 3, and 4), and in the right side there are three beads with values of 5, 10, and 15 respectively. In order to know the value of the respective beads of the upper rows, it is enough to multiply by 20 (by each row), the value of the corresponding account in the first row.
p11239
aVAltogether, there were 13 rows with 7 beads in each one, which made up 91 beads in each Nep\u014dhualtzintzin. This was a basic number to understand, 7 times 13, a close relation conceived between natural phenomena, the underworld and the cycles of the heavens. One Nep\u014dhualtzintzin (91) represented the number of days that a season of the year lasts, two Nep\u014dhualtzitzin (182) is the number of days of the corn's cycle, from its sowing to its harvest, three Nep\u014dhualtzintzin (273) is the number of days of a baby's gestation, and four Nep\u014dhualtzintzin (364) completed a cycle and approximate a year (1 days short). When translated into modern computer arithmetic, the Nep\u014dhualtzintzin amounted to the rank from 10 to the 18 in floating point, which calculated stellar as well as infinitesimal amounts with absolute precision, meant that no round off was allowed.
p11240
aVThe rediscovery of the Nep\u014dhualtzintzin was due to the Mexican engineer David Esparza Hidalgo, who in his wanderings throughout Mexico found diverse engravings and paintings of this instrument and reconstructed several of them made in gold, jade, encrustations of shell, etc. There have also been found very old Nep\u014dhualtzintzin attributed to the Olmec culture, and even some bracelets of Mayan origin, as well as a diversity of forms and materials in other cultures.
p11241
aVGeorge I. Sanchez, "Arithmetic in Maya", Austin-Texas, 1961 found another base 5, base 4 abacus in the Yucatán peninsula that also computed calendar data. This was a finger abacus, on one hand 0, 1, 2, 3, and 4 were used; and on the other hand 0, 1, 2 and 3 were used. Note the use of zero at the beginning and end of the two cycles. Sanchez worked with Sylvanus Morley, a noted Mayanist.
p11242
aVThe quipu of the Incas was a system of colored knotted cords used to record numerical data, like advanced tally sticks \u2013 but not used to perform calculations. Calculations were carried out using a yupana (Quechua for "counting tool"; see figure) which was still in use after the conquest of Peru. The working principle of a yupana is unknown, but in 2001 an explanation of the mathematical basis of these instruments was proposed by Italian mathematician Nicolino De Pasquale. By comparing the form of several yupanas, researchers found that calculations were based using the Fibonacci sequence 1, 1, 2, 3, 5 and powers of 10, 20 and 40 as place values for the different fields in the instrument. Using the Fibonacci sequence would keep the number of grains within any one field at a minimum.
p11243
aVRussian.
p11244
aVThe Russian abacus, the "schoty" (\u0441\u0447\u0451\u0442\u044b), usually has a single slanted deck, with ten beads on each wire (except one wire, usually positioned near the user, with four beads for quarter-ruble fractions). Older models have another 4-bead wire for quarter-kopeks, which were minted until 1916. The Russian abacus is often used vertically, with wires from left to right in the manner of a book. The wires are usually bowed to bulge upward in the center, to keep the beads pinned to either of the two sides. It is cleared when all the beads are moved to the right. During manipulation, beads are moved to the left. For easy viewing, the middle 2 beads on each wire (the 5th and 6th bead) usually are of a different colour from the other eight beads. Likewise, the left bead of the thousands wire (and the million wire, if present) may have a different color.
p11245
aVAs a simple, cheap and reliable device, the Russian abacus was in use in all shops and markets throughout the former Soviet Union, and the usage of it was taught in most schools until the 1990s. Even the 1874 invention of mechanical calculator, Odhner arithmometer, had not replaced them in Russia and likewise the mass production of Felix arithmometers since 1924 did not significantly reduce their use in the Soviet Union. Russian abacus began to lose popularity only after the mass production of microcalculators had started in the Soviet Union in 1974. Today it is regarded as an archaism and replaced by the handheld calculator.
p11246
aVThe Russian abacus was brought to France around 1820 by the mathematician Jean-Victor Poncelet, who served in Napoleon's army and had been a prisoner of war in Russia. The abacus had fallen out of use in western Europe in the 16th century with the rise of decimal notation and algorismic methods. To Poncelet's French contemporaries, it was something new. Poncelet used it, not for any applied purpose, but as a teaching and demonstration aid. The Turks and the Armenian people also used abaci similar to the Russian schoty. It was named a "coulba" by the Turks and a "choreb" by the Armenians.
p11247
aVSchool abacus.
p11248
aVAround the world, abaci have been used in pre-schools and elementary schools as an aid in teaching the numeral system and arithmetic.
p11249
aVIn Western countries, a bead frame similar to the Russian abacus but with straight wires and a vertical frame has been common (see image). It is still often seen as a plastic or wooden toy.
p11250
aVThis type of abacus uses a row of 10 beads to represent arithmetical columns; thus the top row represents units, the second, tens, the third, hundreds, and so on. Most of these abaci consist of 10 rows, thus count up to 11,111,111,110.
p11251
aVThe red-and-white abacus is used in contemporary primary schools for a wide range of number-related lessons. The twenty bead version, referred to by its Dutch name "rekenrek", is often used, sometimes on a string of beads, sometimes on a rigid framework.
p11252
aVUses by the blind.
p11253
aVAn adapted abacus, invented by Tim Cranmer, called a Cranmer abacus is still commonly used by individuals who are blind. A piece of soft fabric or rubber is placed behind the beads so that they do not move inadvertently. This keeps the beads in place while the users feel or manipulate them. They use an abacus to perform the mathematical functions multiplication, division, addition, subtraction, square root and cubic root.
p11254
aVAlthough blind students have benefited from talking calculators, the abacus is still very often taught to these students in early grades, both in public schools and state schools for the blind. The abacus teaches mathematical skills that can never be replaced with talking calculators and is an important learning tool for blind students. Blind students also complete mathematical assignments using a braille-writer and Nemeth code (a type of braille code for mathematics) but large multiplication and long division problems can be long and difficult. The abacus gives blind and visually impaired students a tool to compute mathematical problems that equals the speed and mathematical knowledge required by their sighted peers using pencil and paper. Many blind people find this number machine a very useful tool throughout life.
p11255
aVBinary abacus.
p11256
aVThe binary abacus is used to explain how computers manipulate numbers. The abacus shows how numbers, letters, and signs can be stored in a binary system on a computer, or via ASCII. The device consists of a series of beads on parallel wires arranged in three separate rows. The beads represent a switch on the computer in either an 'on' or 'off' position. Thus, each row may be used to represent an octal digit. Below is an octal algorithm that is usable not only on this abacus, but also on others if the requisite adjustments for using a different base are made.
p11257
aVcodice_1
p11258
asS"Euler's identity"
p11259
(lp11260
VIn mathematics, Euler's identity (also known as Euler's equation) is the equality
p11261
aVformula_1
p11262
aVwhere
p11263
aV is Euler's number, the base of natural logarithms,
p11264
aV' is the imaginary unit, which satisfies 2 = \u22121, and
p11265
aV' is pi, the ratio of the circumference of a circle to its diameter. 
p11266
aVEuler's identity is named after the Swiss mathematician Leonhard Euler. It is considered an example of mathematical beauty.
p11267
aVExplanation.
p11268
aVEuler's identity is a special case of Euler's formula from complex analysis, which states that for any real number ,
p11269
aV formula_2
p11270
aVwhere the values of the trigonometric functions "sine" and "cosine" are given in "radians".
p11271
aVIn particular, when  = "", or one half-turn (180°) around a circle:
p11272
aV formula_3
p11273
aVSince
p11274
aVformula_4
p11275
aVand
p11276
aVformula_5
p11277
aVit follows that
p11278
aV formula_6
p11279
aVwhich yields Euler's identity:
p11280
aV formula_7
p11281
aVMathematical beauty.
p11282
aVEuler's identity is often cited as an example of deep mathematical beauty. Three of the basic arithmetic operations occur exactly once each: addition, multiplication, and exponentiation. The identity also links five fundamental mathematical constants:
p11283
aVFurthermore, the equation is given in the form of an expression set equal to zero, which is common practice in several areas of mathematics.
p11284
aVStanford University mathematics professor Keith Devlin has said, "Like a Shakespearean sonnet that captures the very essence of love, or a painting that brings out the beauty of the human form that is far more than just skin deep, Euler's equation reaches down into the very depths of existence." And Paul Nahin, a professor emeritus at the University of New Hampshire, who has written a book dedicated to Euler's formula and its applications in Fourier analysis, describes Euler's identity as being "of exquisite beauty".
p11285
aVThe mathematics writer Constance Reid has opined that Euler's identity is "the most famous formula in all mathematics". And Benjamin Peirce, a noted American 19th-century philosopher, mathematician, and professor at Harvard University, after proving Euler's identity during a lecture, stated that the identity "is absolutely paradoxical; we cannot understand it, and we don't know what it means, but we have proved it, and therefore we know it must be the truth." 
p11286
aVA poll of readers conducted by "The Mathematical Intelligencer" in 1990 named Euler's identity as the "most beautiful theorem in mathematics". In another poll of readers that was conducted by "Physics World" in 2004, Euler's identity tied with Maxwell's equations (of electromagnetism) as the "greatest equation ever".
p11287
aVGeneralizations.
p11288
aVEuler's identity is also a special case of the more general identity that the "n"th roots of unity, for "n" > 1, add up to 0:
p11289
aVformula_8
p11290
aVEuler's identity is the case where "" = 2.
p11291
aVIn another field of mathematics, by using quaternion exponentiation, one can show that a similar identity also applies to quaternions. Let {"i", "j", "k"} be the basis elements, then,
p11292
aVformula_9
p11293
aVIn general, given real "a"1, "a"2, and "a"3 such that formula_10, then,
p11294
aVformula_11
p11295
aVFor octonions, with real "a"n such that formula_12 and the octonion basis elements {"i"1, "i"2..., "i"7}, then,
p11296
aVformula_13
p11297
aVHistory.
p11298
aVIt has been claimed that Euler's identity appears in his monumental work of mathematical analysis published in 1748, "Introductio in analysin infinitorum". However, it is questionable whether this particular concept can be attributed to Euler himself, as he may never have expressed it. (Moreover, while Euler did write in the "Introductio" about what we today call "Euler's formula", which relates with "cosine" and "sine" terms in the field of complex numbers, the English mathematician Roger Cotes also knew of this formula and Euler may have acquired the knowledge through his Swiss compatriot Johann Bernoulli.)
p11299
aVNotes and references.
p11300
aVNotes
p11301
aVReferences
p11302
asS'Distance'
p11303
(lp11304
V"This article is about the measurement of distance. For the 2001 film, see Proximity (film)."
p11305
aVDistance is a numerical description of how far apart objects are. In physics or everyday usage, distance may refer to a physical length, or an estimation based on other criteria (e.g. "two counties over"). In mathematics, a distance function or metric is a generalization of the concept of physical distance. A metric is a function that behaves according to a specific set of rules, and is a concrete way of describing what it means for elements of some space to be "close to" or "far away from" each other.
p11306
aVIn most cases, "distance from A to B" is interchangeable with "distance between B and A".
p11307
aVMathematics.
p11308
aVGeometry.
p11309
aVIn analytic geometry, the distance between two points of the xy-plane can be found using the distance formula. The distance between ("x"1, "y"1) and ("x"2, "y"2) is given by:
p11310
aVformula_1
p11311
aVSimilarly, given points ("x"1, "y"1, "z"1) and ("x"2, "y"2, "z"2) in three-space, the distance between them is:
p11312
aVformula_2
p11313
aVThese formula are easily derived by constructing a right triangle with a leg on the hypotenuse of another (with the other leg orthogonal to the plane that contains the 1st triangle) and applying the Pythagorean theorem.
p11314
aVIn the study of complicated geometries,we call this (most common) type of distance Euclidean distance,as it is derived from the Pythagorean theorem,which does not hold in Non-Euclidean geometries.This distance formula can also be expanded into the arc-length formula.
p11315
aVDistance in Euclidean space.
p11316
aVIn the Euclidean space Rn, the distance between two points is usually given by the Euclidean distance (2-norm distance). Other distances, based on other norms, are sometimes used instead.
p11317
aVFor a point ("x"1, "x"2, ...,"x""n") and a point ("y"1, "y"2, ...,"y""n"), the Minkowski distance of order p (p-norm distance) is defined as:
p11318
aV"p" need not be an integer, but it cannot be less than 1, because otherwise the triangle inequality does not hold.
p11319
aVThe 2-norm distance is the Euclidean distance, a generalization of the Pythagorean theorem to more than two coordinates. It is what would be obtained if the distance between two points were measured with a ruler: the "intuitive" idea of distance.
p11320
aVThe 1-norm distance is more colourfully called the "taxicab norm" or "Manhattan distance", because it is the distance a car would drive in a city laid out in square blocks (if there are no one-way streets).
p11321
aVThe infinity norm distance is also called Chebyshev distance. In 2D, it is the minimum number of moves kings require to travel between two squares on a chessboard.
p11322
aVThe "p"-norm is rarely used for values of "p" other than 1, 2, and infinity, but see super ellipse.
p11323
aVIn physical space the Euclidean distance is in a way the most natural one, because in this case the length of a rigid body does not change with rotation.
p11324
aVVariational formulation of distance.
p11325
aVThe Euclidean distance between two points in space (formula_3 and formula_4) may be written in a variational form where the distance is the minimum value of an integral:
p11326
aV formula_5
p11327
aVHere formula_6 is the trajectory (path) between the two points. The value of the integral (D) represents the length of this trajectory. The distance is the minimal value of this integral and is obtained when formula_7 where formula_8 is the optimal trajectory. In the familiar Euclidean case (the above integral) this optimal trajectory is simply a straight line. It is well known that the shortest path between two points is a straight line. Straight lines can formally be obtained by solving the Euler\u2013Lagrange equations for the above functional. In non-Euclidean manifolds (curved spaces) where the nature of the space is represented by a metric formula_9 the integrand has be to modified to formula_10, where Einstein summation convention has been used.
p11328
aVGeneralization to higher-dimensional objects.
p11329
aVThe Euclidean distance between two objects may also be generalized to the case where the objects are no longer points but are higher-dimensional manifolds, such as space curves, so in addition to talking about distance between two points one can discuss concepts of distance between two strings. Since the new objects that are dealt with are extended objects (not points anymore) additional concepts such as non-extensibility, curvature constraints, and non-local interactions that enforce non-crossing become central to the notion of distance. The distance between the two manifolds is the scalar quantity that results from minimizing the generalized distance functional, which represents a transformation between the two manifolds:
p11330
aV formula_11
p11331
aVThe above double integral is the generalized distance functional between two plymer conformation. formula_12 is a spatial parameter and formula_13 is pseudo-time. This means that formula_14 is the polymer/string conformation at time formula_15 and is parameterized along the string length by formula_16. Similarly formula_17 is the trajectory of an infinitesimal segment of the string during transformation of the entire string from conformation formula_18 to conformation formula_19. The term with cofactor formula_20 is a Lagrange multiplier and its role is to ensure that the length of the polymer remains the same during the transformation. If two discrete polymers are inextensible, then the minimal-distance transformation between them no longer involves purely straight-line motion, even on a Euclidean metric. There is a potential application of such generalized distance to the problem of protein folding
p11332
aVThis generalized distance is analogous to the Nambu-Goto action in string theory, however there is no exact correspondence because the Euclidean distance in 3-space is inequivalent to the space-time distance minimized for the classical relativistic string.
p11333
aVAlgebraic distance.
p11334
aVThis is a metric often used in computer vision that can be minimized by least squares estimation. [http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/FISHER/ALGDIST/alg.htm][http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/FISHER/CIRCLEFIT/fit2dcircle/node3.html] For curves or surfaces given by the equation formula_21 (such as a conic in homogeneous coordinates), the algebraic distance from the point formula_22 to the curve is simply formula_23.
p11335
aVIt may serve as an "initial guess" for geometric distance to refine estimations of the curve by more accurate methods, such as non-linear least squares.
p11336
aVGeneral metric.
p11337
aVIn mathematics, in particular geometry, a distance function on a given set "M" is a function , where R denotes the set of real numbers, that satisfies the following conditions:
p11338
aVFor example, the usual definition of distance between two real numbers "x" and "y" is: . This definition satisfies the three conditions above, and corresponds to the standard topology of the real line. But distance on a given set is a definitional choice. Another possible choice is to define: if , and 1 otherwise. This also defines a metric, but gives a completely different topology, the "discrete topology"; with this definition numbers cannot be arbitrarily close.
p11339
aVDistances between sets and between a point and a set.
p11340
aVVarious distance definitions are possible between objects. For example, between celestial bodies one should not confuse the surface-to-surface distance and the center-to-center distance. If the former is much less than the latter, as for a LEO, the first tends to be quoted (altitude), otherwise, e.g. for the Earth-Moon distance, the latter.
p11341
aVThere are two common definitions for the distance between two non-empty subsets of a given set:
p11342
aV:formula_24
p11343
aVThis is a symmetric premetric. On a collection of sets of which some touch or overlap each other, it is not "separating", because the distance between two different but touching or overlapping sets is zero. Also it is not hemimetric, i.e., the triangle inequality does not hold, except in special cases. Therefore only in special cases this distance makes a collection of sets a metric space.
p11344
aVThe distance between a point and a set is the infimum of the distances between the point and those in the set. This corresponds to the distance, according to the first-mentioned definition above of the distance between sets, from the set containing only this point to the other set.
p11345
aVIn terms of this, the definition of the Hausdorff distance can be simplified: it is the larger of two values, one being the supremum, for a point ranging over one set, of the distance between the point and the set, and the other value being likewise defined but with the roles of the two sets swapped.
p11346
aVGraph theory.
p11347
aVIn graph theory the distance between two vertices is the length of the shortest path between those vertices.
p11348
aVDistance versus directed distance and displacement.
p11349
aVDistance cannot be negative and distance travelled never decreases. Distance is a scalar quantity or a magnitude, whereas displacement is a vector quantity with both magnitude and direction. Directed distance is a positive, zero, or negative scalar quantity.
p11350
aVThe distance covered by a vehicle (for example as recorded by an odometer), person, animal, or object along a curved path from a point "A" to a point "B" should be distinguished from the straight line distance from "A" to "B". For example whatever the distance covered during a round trip from "A" to "B" and back to "A", the displacement is zero as start and end points coincide. In general the straight line distance does not equal distance travelled, except for journeys in a straight line.
p11351
aVDirected distance.
p11352
aVDirected distances are distances with a directional sense. They can be determined along straight lines and along curved lines. A directed distance of a point "C" from point "A" in the direction of "B" on a line "AB" in a Euclidean vector space is the distance from "A" to "C" if "C" falls on the ray "AB", but is the negative of that distance if "C" falls on the ray "BA" (I.e., if "C" is not on the same side of "A" as "B" is).
p11353
aVA directed distance along a curved line is not a vector and is represented by a segment of that curved line defined by endpoints "A" and "B", with some specific information indicating the sense (or direction) of an ideal or real motion from one endpoint of the segment to the other (see figure). For instance, just labelling the two endpoints as "A" and "B" can indicate the sense, if the ordered sequence ("A", "B") is assumed, which implies that "A" is the starting point.
p11354
aVDisplacement.
p11355
aVA displacement (see above) is a special kind of directed distance defined in mechanics. A directed distance is called displacement when it is the distance along a straight line (minimum distance) from "A" and "B", and when "A" and "B" are positions occupied by the "same particle" at two "different instants" of time. This implies motion of the particle. The distance traveled by a particle must always be greater than or equal to its displacement, with equality occurring only when the particle moves along a straight path.
p11356
aVAnother kind of directed distance is that between two different particles or point masses at a given time. For instance, the distance from the center of gravity of the Earth "A" and the center of gravity of the Moon "B" (which does not strictly imply motion from "A" to "B") falls into this category.
p11357
aVOther "distances".
p11358
aVCircular distance is the distance traveled by a wheel. The circumference of the wheel is 2"\u03c0" × radius, and assuming the radius to be 1, then each revolution of the wheel is equivalent of the distance 2"\u03c0" radians. In engineering "\u03c9" = 2"\u03c0\u0192" is often used, where "\u0192" is the frequency.
p11359
asS'Mutual information'
p11360
(lp11361
VIn probability theory and information theory, the mutual information (MI) or (formerly) transinformation of two random variables is a measure of the variables' mutual dependence. Not limited to real-valued random variables like the correlation coefficient, MI is more general and determines how similar the joint distribution p(X,Y) is to the products of factored marginal distribution p(X)p(Y). MI is the expected values of the pointwise mutual information (PMI). The most common unit of measurement of mutual information is the bit.
p11362
aVDefinition of mutual information.
p11363
aVFormally, the mutual information of two discrete random variables "X" and "Y" can be defined as:
p11364
aVformula_1
p11365
aVwhere "p"("x","y") is the joint probability distribution function of "X" and "Y", and formula_2 and formula_3 are the marginal probability distribution functions of "X" and "Y" respectively.
p11366
aVIn the case of continuous random variables, the summation is replaced by a definite double integral:
p11367
aV<math> I(X;Y) = \u005cint_Y \u005cint_X 
p11368
aVwhere "p"("x","y") is now the joint probability "density" function of "X" and "Y", and formula_2 and formula_3 are the marginal probability density functions of "X" and "Y" respectively.
p11369
aVIf the log base 2 is used, the units of mutual information are the bit.
p11370
aVIntuitively, mutual information measures the information that "X" and "Y" share: it measures how much knowing one of these variables reduces uncertainty about the other. For example, if "X" and "Y" are independent, then knowing "X" does not give any information about "Y" and vice versa, so their mutual information is zero. At the other extreme, if "X" is a deterministic function of "Y" and "Y" is a deterministic function of "X" then all information conveyed by "X" is shared with "Y": knowing "X" determines the value of "Y" and vice versa. As a result, in this case the mutual information is the same as the uncertainty contained in "Y" (or "X") alone, namely the entropy of "Y" (or "X"). Moreover, this mutual information is the same as the entropy of "X" and as the entropy of "Y". (A very special case of this is when "X" and "Y" are the same random variable.)
p11371
aVMutual information is a measure of the inherent dependence expressed in the joint distribution of "X" and "Y" relative to the joint distribution of "X" and "Y" under the assumption of independence.
p11372
aVMutual information therefore measures dependence in the following sense: "I"("X"; "Y") = 0 if and only if "X" and "Y" are independent random variables. This is easy to see in one direction: if "X" and "Y" are independent, then "p"("x","y") = "p"("x") "p"("y"), and therefore:
p11373
aVformula_6
p11374
aVwhere formula_7 and formula_8 are the marginal entropies, "H"("X"|"Y") and "H"("Y"|"X") are the conditional entropies, and "H"("X","Y") is the joint entropy of "X" and "Y". Note the analogy to the union, difference, and intersection of two sets, as illustrated in the Venn diagram.
p11375
aVUsing Jensen's inequality on the definition of mutual information we can show that "I"("X";"Y") is non-negative, consequently, formula_9. Here we give the detailed deduction of I(X;Y) = H(Y) - H(Y|X):
p11376
aVformula_10
p11377
aVThe proofs of the other identities above are similar.
p11378
aVIntuitively, if entropy "H"("Y") is regarded as a measure of uncertainty about a random variable, then "H"("Y"|"X") is a measure of what "X" does "not" say about "Y". This is "the amount of uncertainty remaining about "Y" after "X" is known", and thus the right side of the first of these equalities can be read as "the amount of uncertainty in "Y", minus the amount of uncertainty in "Y" which remains after "X" is known", which is equivalent to "the amount of uncertainty in "Y" which is removed by knowing "X"". This corroborates the intuitive meaning of mutual information as the amount of information (that is, reduction in uncertainty) that knowing either variable provides about the other.
p11379
aVNote that in the discrete case "H"("X"|"X") = 0 and therefore "H"("X") = "I"("X";"X"). Thus "I"("X";"X") \u2265 "I"("X";"Y"), and one can formulate the basic principle that a variable contains at least as much information about itself as any other variable can provide.
p11380
aVMutual information can also be expressed as a Kullback\u2013Leibler divergence, of the product "p"("x") × "p"("y") of the marginal distributions of the two random variables "X" and "Y", from "p"("x","y") the random variables' joint distribution:
p11381
aVformula_11
p11382
aVFurthermore, let "p"("x"|"y") = "p"("x", "y") / "p"("y"). Then
p11383
aVformula_12
p11384
aVNote that here, the Kullback-Leibler divergence involves integration with respect to the random variable "X" only, and the expression formula_13 is now a random variable in "Y". Thus mutual information can also be understood as the expectation of the Kullback\u2013Leibler divergence of the univariate distribution "p"("x") of "X" from the conditional distribution "p"("x"|"y") of "X" given "Y": the more different the distributions "p"("x"|"y") and "p"("x") are on average, the greater the information gain.
p11385
aVVariations of mutual information.
p11386
aVSeveral variations on mutual information have been proposed to suit various needs. Among these are normalized variants and generalizations to more than two variables.
p11387
aVMetric.
p11388
aVMany applications require a metric, that is, a distance measure between pairs of points. The quantity
p11389
aVformula_14
p11390
aVsatisfies the properties of a metric (triangle inequality, non-negativity, indiscernability and symmetry). This distance metric is also known as the Variation of information.
p11391
aVIf formula_15 are discrete random variables then all the entropy terms are non-negative, so formula_16 and one can define a normalized distance
p11392
aVformula_17
p11393
aVThe metric "D" is a universal metric, in that if any other distance measure places "X" and "Y" close-by, then the "D" will also judge them close.
p11394
aVA set-theoretic interpretation of information (see the figure for Conditional entropy) shows that
p11395
aVformula_18
p11396
aVwhich is effectively the Jaccard distance between "X" and "Y".
p11397
aVFinally,
p11398
aVformula_19
p11399
aVis also a metric.
p11400
aVConditional mutual information.
p11401
aVSometimes it is useful to express the mutual information of two random variables conditioned on a third.
p11402
aVformula_20
p11403
aVfor discrete, jointly distributed random variables "X", "Y", "Z". This result has been used as a basic building block for proving other inequalities in information theory.
p11404
aVMultivariate mutual information.
p11405
aVSeveral generalizations of mutual information to more than two random variables have been proposed, such as total correlation and interaction information. If Shannon entropy is viewed as a signed measure in the context of information diagrams, as explained in the article "Information theory and measure theory", then the only definition of multivariate mutual information that makes sense is as follows:
p11406
aVformula_21
p11407
aVand for formula_22
p11408
aVformula_23
p11409
aVwhere (as above) we define
p11410
aVformula_24
p11411
aVIf formula_25 and formula_26 are two sets of variables, then the mutual information between them is:
p11412
aVformula_27
p11413
aVApplications.
p11414
aVApplying information diagrams blindly to derive the above definition has been criticised, and indeed it has found rather limited practical application, since it is difficult to visualize or grasp the significance of this quantity for a large number of random variables. It can be zero, positive, or negative for any formula_28
p11415
aVOne high-dimensional generalization scheme which maximizes the mutual information between the joint distribution and other target variables is found to be useful in feature selection.
p11416
aVMutual information is also used in the area of signal processing as a measure of similarity between two signals. For example, FMI metric is an image fusion performance measure that makes use of mutual information in order to measure the amount of information that the fused image contains about the source images. The Matlab code for this metric can be found at.
p11417
aVNormalized variants.
p11418
aVNormalized variants of the mutual information are provided by the "coefficients of constraint", uncertainty coefficient 
p11419
aVor proficiency:
p11420
aVformula_29
p11421
aVThe two coefficients are not necessarily equal. In some cases a symmetric measure may be desired, such as the following "redundancy" measure:
p11422
aVformula_30
p11423
aVwhich attains a minimum of zero when the variables are independent and a maximum value of
p11424
aVformula_31
p11425
aVwhen one variable becomes completely redundant with the knowledge of the other. See also "Redundancy (information theory)". Another symmetrical measure is the "symmetric uncertainty" (Witten & Frank 2005), given by
p11426
aVformula_32
p11427
aVwhich represents a weighted average of the two uncertainty coefficients.
p11428
aVIf we consider mutual information as a special case of the total correlation or dual total correlation, the normalized version are respectively,
p11429
aVformula_33 and formula_34
p11430
aVFinally there's a normalization which derives from first thinking of mutual information as an analogue to covariance (thus Shannon entropy is analogous to variance). Then the normalized mutual information is calculated akin to the Pearson correlation coefficient,
p11431
aVformula_35
p11432
aVWeighted variants.
p11433
aVIn the traditional formulation of the mutual information,
p11434
aVformula_36
p11435
aVeach "event" or "object" specified by formula_37 is weighted by the corresponding probability formula_38. This assumes that all objects or events are equivalent "apart from" their probability of occurrence. However, in some applications it may be the case that certain objects or events are more "significant" than others, or that certain patterns of association are more semantically important than others.
p11436
aVFor example, the deterministic mapping formula_39 may be viewed as stronger than the deterministic mapping formula_40, although these relationships would yield the same mutual information. This is because the mutual information is not sensitive at all to any inherent ordering in the variable values (Cronbach 1954, Coombs & Dawes 1970, Lockhead 1970), and is therefore not sensitive at all to the form of the relational mapping between the associated variables. If it is desired that the former relation \u2014 showing agreement on all variable values \u2014 be judged stronger than the later relation, then it is possible to use the following "weighted mutual information" (Guiasu 1977)
p11437
aVformula_41
p11438
aVwhich places a weight formula_42 on the probability of each variable value co-occurrence, formula_38. This allows that certain probabilities may carry more or less significance than others, thereby allowing the quantification of relevant "holistic" or "prägnanz" factors. In the above example, using larger relative weights for formula_44, formula_45, and formula_46 would have the effect of assessing greater "informativeness" for the relation formula_39 than for the relation formula_40, which may be desirable in some cases of pattern recognition, and the like. This weighted mutual information is a form of weighted KL-Divergence, which is known to take negative values for some inputs, and there are examples where the weighted mutual information also takes negative values.
p11439
aVAdjusted mutual information.
p11440
aVA probability distribution can be viewed as a partition of a set. One may then ask: if a set were partitioned randomly, what would the distribution of probabilities be? What would the expectation value of the mutual information be? The adjusted mutual information or AMI subtracts the expectation value of the MI, so that the AMI is zero when two different distributions are random, and one when two distributions are identical. The AMI is defined in analogy to the adjusted Rand index of two different partitions of a set.
p11441
aVAbsolute mutual information.
p11442
aVUsing the ideas of Kolmogorov complexity, one can consider the mutual information of two sequences independent of any probability distribution:
p11443
aVformula_49
p11444
aVTo establish that this quantity is symmetric up to a logarithmic factor (formula_50) requires the chain rule for Kolmogorov complexity .
p11445
aVApproximations of this quantity via compression can be used to define a distance measure to perform a hierarchical clustering of sequences without having any domain knowledge of the sequences .
p11446
aVMutual information for discrete data.
p11447
aVWhen "X" and "Y" are limited to be in a discrete number of states, observation data is summarized
p11448
aVin a contingency table, with row variable "X" (or i) and column variable "Y" (or j).
p11449
aVMutual information is one of the measures of 
p11450
aVassociation or correlation
p11451
aVbetween the row and column variables. Other measures of association include
p11452
aVPearson's chi-squared test statistics, G-test statistics, etc. In fact,
p11453
aVmutual information is equal to G-test statistics divided by 2N where N is
p11454
aVthe sample size.
p11455
aVIn the special case where the number of states for both row and column variables
p11456
aVis 2 (i,j=1,2), the degrees of freedom of
p11457
aVthe Pearson's chi-squared test is 1. Out of the four terms in the summation:
p11458
aVformula_51
p11459
aVonly one is independent. It is the reason that mutual information function has an
p11460
aVexact relationship with the correlation function formula_52 for 
p11461
aVbinary sequences 
p11462
aVApplications of mutual information.
p11463
aVIn many applications, one wants to maximize mutual information (thus increasing dependencies), which is often equivalent to minimizing conditional entropy. Examples include:
p11464
asS'Reciprocal'
p11465
(lp11466
VReciprocal may refer to:
p11467
asS'Average'
p11468
(lp11469
VIn colloquial language, an average is the sum of a list of numbers divided by the number of numbers in the list. In mathematics and statistics, this would be called the "arithmetic mean". However, the word "average" may also refer to the median, mode, or other central or typical value. In statistics, these are all known as measures of central tendency.
p11470
aVCalculation.
p11471
aVArithmetic mean.
p11472
aVThe most common type of average is the arithmetic mean. If "n" numbers are given, each number denoted by "ai", where "i" = 1, \u2026, "n", the arithmetic mean is the sum of the "ai's" divided by "n" or
p11473
aVformula_1
p11474
aVThe arithmetic mean, often simply called the mean, of two numbers, such as 2 and 8, is obtained by finding a value A such that 2 + 8 = A + A. One may find that "A" = (2 + 8)/2 = 5. Switching the order of 2 and 8 to read 8 and 2 does not change the resulting value obtained for A. The mean 5 is not less than the minimum 2 nor greater than the maximum 8. If we increase the number of terms in the list to 2, 8, and 11, the arithmetic mean is found by solving for the value of "A" in the equation 2 + 8 + 11 = "A" + "A" + "A". One finds that "A" = (2 + 8 + 11)/3 = 7.
p11475
aVPythagorean means.
p11476
aVAlong with the arithmetic mean above, the geometric mean and the harmonic mean are known collectively as the Pythagorean means.
p11477
aVGeometric mean.
p11478
aVThe geometric mean of "n" non-negative numbers is obtained by multiplying them all together and then taking the "n"th root. In algebraic terms, the geometric mean of "a"1, "a"2, \u2026, "a""n" is defined as
p11479
aV formula_2
p11480
aVGeometric mean can be thought of as the antilog of the arithmetic mean of the logs of the numbers.
p11481
aVExample: Geometric mean of 2 and 8 is formula_3
p11482
aVHarmonic mean.
p11483
aVHarmonic mean for a non-empty collection of numbers "a"1, "a"2, \u2026, "a""n", all different from 0, is defined as the reciprocal of the arithmetic mean of the reciprocals of the "a""i"s:
p11484
aV formula_4
p11485
aVOne example where the harmonic mean is useful is when examining the speed for a number of fixed-distance trips. For example, if the speed for going from point "A" to "B" was 60 km/h, and the speed for returning from "B" to "A" was 40 km/h, then the harmonic mean speed is given by
p11486
aV formula_5
p11487
aVInequality concerning AM, GM, and HM.
p11488
aVA well known inequality concerning arithmetic, geometric, and harmonic means for any set of positive numbers is
p11489
aV formula_6
p11490
aVIt is easy to remember noting that the alphabetical order of the letters "A", "G", and "H" is preserved in the inequality. See Inequality of arithmetic and geometric means.
p11491
aVThus for the above harmonic mean example: AM = 50, GM = 49, and HM = 48 km/h.
p11492
aVStatistical location.
p11493
aVThe mode, the median, and the mid-range are often used in addition to the mean as estimates of central tendency in descriptive statistics.
p11494
aVMode.
p11495
aVThe most frequently occurring number in a list is called the mode. For example, the mode of the list (1, 2, 2, 3, 3, 3, 4) is 3. It may happen that there are two or more numbers which occur equally often and more often than any other number. In this case there is no agreed definition of mode. Some authors say they are all modes and some say there is no mode.
p11496
aVMedian.
p11497
aVThe median is the middle number of the group when they are ranked in order. (If there are an even number of numbers, the mean of the middle two is taken.)
p11498
aVThus to find the median, order the list according to its elements' magnitude and then repeatedly remove the pair consisting of the highest and lowest values until either one or two values are left. If exactly one value is left, it is the median; if two values, the median is the arithmetic mean of these two. This method takes the list 1, 7, 3, 13 and orders it to read 1, 3, 7, 13. Then the 1 and 13 are removed to obtain the list 3, 7. Since there are two elements in this remaining list, the median is their arithmetic mean, (3 + 7)/2 = 5.
p11499
aVSummary of types.
p11500
aVThe table of mathematical symbols explains the symbols used below.
p11501
aVMiscellaneous types.
p11502
aVOther more sophisticated averages are: trimean, trimedian, and normalized mean, with their generalizations.
p11503
aVOne can create one's own average metric using the generalized "f"-mean:
p11504
aV formula_7
p11505
aVwhere "f" is any invertible function. The harmonic mean is an example of this using "f"("x") = 1/"x", and the geometric mean is another, using "f"("x") = log "x".
p11506
aVHowever, this method for generating means is not general enough to capture all averages. A more general method for defining an average takes any function "g"("x"1, "x"2, \u2026, "x""n") of a list of arguments that is continuous, strictly increasing in each argument, and symmetric (invariant under permutation of the arguments). The average "y" is then the value that, when replacing each member of the list, results in the same function value: . This most general definition still captures the important property of all averages that the average of a list of identical elements is that element itself. The function provides the arithmetic mean. The function (where the list elements are positive numbers) provides the geometric mean. The function (where the list elements are positive numbers) provides the harmonic mean.
p11507
aVAverage percentage return and CAGR.
p11508
aVA type of average used in finance is the average percentage return. It is an example of a geometric mean. When the returns are annual, it is called the Compound Annual Growth Rate (CAGR). For example, if we are considering a period of two years, and the investment return in the first year is \u221210% and the return in the second year is +60%, then the average percentage return or CAGR, "R", can be obtained by solving the equation: . The value of "R" that makes this equation true is 0.2, or 20%. This means that the total return over the 2-year period is the same as if there had been 20% growth each year. Note that the order of the years makes no difference \u2013 the average percentage returns of +60% and \u221210% is the same result as that for \u221210% and +60%.
p11509
aVThis method can be generalized to examples in which the periods are not equal. For example, consider a period of a half of a year for which the return is \u221223% and a period of two and a half years for which the return is +13%. The average percentage return for the combined period is the single year return, "R", that is the solution of the following equation: , giving an average percentage return "R" of 0.0600 or 6.00%.
p11510
aVMoving average.
p11511
aVGiven a time series such as daily stock market prices or yearly temperatures people often want to create a smoother series. This helps to show underlying trends or perhaps periodic behavior. An easy way to do this is to choose a number "n" and create a new series by taking the arithmetic mean of the first "n" values, then moving forward one place and so on. This is the simplest form of moving average. More complicated forms involve using a weighted average. The weighting can be used to enhance or suppress various periodic behavior and there is very extensive analysis of what weightings to use in the literature on filtering. In digital signal processing the term \u201cmoving average\u201d is used even when the sum of the weights is not 1.0 (so the output series is a scaled version of the averages). The reason for this is that the analyst is usually interested only in the trend or the periodic behavior. A further generalization is an \u201cautoregressive moving average\u201d. In this case the average also includes some of the recently calculated outputs. This allows samples from further back in the history to affect the current output.
p11512
aVEtymology.
p11513
aVAccording to the Oxford English Dictionary, "few words have received more etymological investigation." In the 16th century "average" meant a customs duty, or the like, and was used in the Mediterranean area. It came to mean the cost of damage sustained at sea. From that came an "average adjuster" who decided how to apportion a loss between the owners and insurers of a ship and cargo.
p11514
aVMarine damage is either "particular average", which is borne only by the owner of the damaged property, or general average, where the owner can claim a proportional contribution from all the parties to the marine venture. The type of calculations used in adjusting general average gave rise to the use of "average" to mean "arithmetic mean".
p11515
aVThe root is found in Arabic as "awar", in Italian as "avaria", in French as "avarie" and in Dutch as "averij". It is unclear in which language the word first appeared.
p11516
aVThere is earlier (from at least the 11th century), unrelated use of the word. It appears to be an old legal term for a tenant's day labour obligation to a sheriff, probably anglicised from "avera" found in the English Domesday Book (1085).
p11517
asS'Relation (mathematics)'
p11518
(lp11519
sS'Flux'
p11520
(lp11521
VIn the various subfields of physics, there exist two common usages of the term flux, each with rigorous mathematical frameworks. A simple and ubiquitous concept throughout physics and applied mathematics is the flow of a physical property in space, frequently also with time variation. It is the basis of the field concept in physics and mathematics, with two principal applications: in transport phenomena and surface integrals. The terms "flux", "current", "flux density", "current density", can sometimes be used interchangeably and ambiguously, though the terms used below match those of the contexts in the literature.
p11522
aVOrigin of the term.
p11523
aVThe word "flux" comes from Latin: "fluxus" means "flow", and "fluere" is "to flow". As "fluxion", this term was introduced into differential calculus by Isaac Newton.
p11524
aVFlux as flow rate per unit area.
p11525
aVIn transport phenomena (heat transfer, mass transfer and fluid dynamics), flux is defined as the "rate of flow of a property per unit area," which has the dimensions ·\u22121·\u22121. For example, the magnitude of a river's current, i.e. the amount of water that flows through a cross-section of the river each second, or the amount of sunlight that lands on a patch of ground each second is also a kind of flux.
p11526
aVGeneral mathematical definition (transport).
p11527
aVIn this definition, flux is generally a vector due to the widespread and useful definition of vector area, although there are some cases where only the magnitude is important (like in number fluxes, see below). The frequent symbol is "j" (or "J"), and a definition for scalar flux of physical quantity "q" is the limit:
p11528
aVformula_1
p11529
aVwhere:
p11530
aVformula_2
p11531
aVis the flow of quantity "q" per unit time "t", and "A" is the area through which the quantity flows.
p11532
aVFor vector flux, the surface integral of j over a surface "S", followed by an integral over the time duration "t"1 to "t"2, gives the total amount of the property flowing through the surface in that time ("t"2 \u2212 "t"1):
p11533
aVformula_3
p11534
aVThe area required to calculate the flux is real or imaginary, flat or curved, either as a cross-sectional area or a surface. The vector area is a combination of the magnitude of the area through which the mass passes through, "A", and a unit vector normal to the area, formula_4. The relation is formula_5.
p11535
aVIf the flux j passes through the area at an angle \u03b8 to the area normal formula_4, then
p11536
aVformula_7
p11537
aVwhere · is the dot product of the unit vectors. This is, the component of flux passing through the surface (i.e. normal to it) is "j" cos \u03b8, while the component of flux passing tangential to the area is "j" sin \u03b8, but there is "no" flux actually passing "through" the area in the tangential direction. The "only" component of flux passing normal to the area is the cosine component.
p11538
aVOne could argue, based on the work of James Clerk Maxwell, that the transport definition precedes the more recent way the term is used in electromagnetism. The specific quote from Maxwell is:
p11539
aVTransport fluxes.
p11540
aVEight of the most common forms of flux from the transport phenomena literature are defined as follows:
p11541
aVThese fluxes are vectors at each point in space, and have a definite magnitude and direction. Also, one can take the divergence of any of these fluxes to determine the accumulation rate of the quantity in a control volume around a given point in space. For incompressible flow, the divergence of the volume flux is zero.
p11542
aVChemical diffusion.
p11543
aVAs mentioned above, chemical molar flux of a component A in an isothermal, isobaric system is defined in Fick's law of diffusion as:
p11544
aVformula_8
p11545
aVwhere the nabla symbol \u2207 denotes the gradient operator, "DAB" is the diffusion coefficient (m2·s\u22121) of component A diffusing through component B, "cA" is the concentration (mol/m3) of component A.
p11546
aVThis flux has units of mol·m\u22122·s\u22121, and fits Maxwell's original definition of flux.
p11547
aVFor dilute gases, kinetic molecular theory relates the diffusion coefficient "D" to the particle density "n" = "N"/"V", the molecular mass "m", the collision cross section formula_9, and the absolute temperature "T" by
p11548
aVformula_10
p11549
aVwhere the second factor is the mean free path and the square root (with Boltzmann's constant "k") is the mean velocity of the particles.
p11550
aVIn turbulent flows, the transport by eddy motion can be expressed as a grossly increased diffusion coefficient.
p11551
aVQuantum mechanics.
p11552
aVIn quantum mechanics, particles of mass "m" in the quantum state \u03c8(r, t) have a probability density defined as
p11553
aVformula_11
p11554
aVSo the probability of finding a particle in a differential volume element d3r is
p11555
aVformula_12
p11556
aVThen the number of particles passing perpendicularly through unit area of a cross-section per unit time is the probability flux;
p11557
aVformula_13
p11558
aVThis is sometimes referred to as the probability current or current density, or probability flux density.
p11559
aVFlux as a surface integral.
p11560
aVGeneral mathematical definition (surface integral).
p11561
aVAs a mathematical concept, flux is represented by the surface integral of a vector field,
p11562
aVwhere F is a vector field, and d"A" is the vector area of the surface "A", directed as the surface normal.
p11563
aVThe surface has to be orientable, i.e. two sides can be distinguished: the surface does not fold back onto itself. Also, the surface has to be actually oriented, i.e. we use a convention as to flowing which way is counted positive; flowing backward is then counted negative.
p11564
aVThe surface normal is directed usually by the right-hand rule.
p11565
aVConversely, one can consider the flux the more fundamental quantity and call the vector field the flux density.
p11566
aVOften a vector field is drawn by curves (field lines) following the "flow"; the magnitude of the vector field is then the line density, and the flux through a surface is the number of lines. Lines originate from areas of positive divergence (sources) and end at areas of negative divergence (sinks).
p11567
aVSee also the image at right: the number of red arrows passing through a unit area is the flux density, the curve encircling the red arrows denotes the boundary of the surface, and the orientation of the arrows with respect to the surface denotes the sign of the inner product of the vector field with the surface normals.
p11568
aVIf the surface encloses a 3D region, usually the surface is oriented such that the influx is counted positive; the opposite is the outflux.
p11569
aVThe divergence theorem states that the net outflux through a closed surface, in other words the net outflux from a 3D region, is found by adding the local net outflow from each point in the region (which is expressed by the divergence).
p11570
aVIf the surface is not closed, it has an oriented curve as boundary. Stokes' theorem states that the flux of the curl of a vector field is the line integral of the vector field over this boundary. This path integral is also called circulation, especially in fluid dynamics. Thus the curl is the circulation density.
p11571
aVWe can apply the flux and these theorems to many disciplines in which we see currents, forces, etc., applied through areas.
p11572
aVElectromagnetism.
p11573
aVOne way to better understand the concept of flux in electromagnetism is by comparing it to a butterfly net. The amount of air moving through the net at any given instant in time is the flux. If the wind speed is high, then the flux through the net is large. If the net is made bigger, then the flux is larger even though the wind speed is the same. For the most air to move through the net, the opening of the net must be facing the direction the wind is blowing. If the net is parallel to the wind, then no wind will be moving through the net. The simplest way to think of flux is "how much air goes through the net", where the air is a velocity field and the net is the boundary of an imaginary surface.
p11574
aVElectric flux.
p11575
aVTwo forms of electric flux are used, one for the E-field:
p11576
aVand one for the D-field (called the electric displacement):
p11577
aVThis quantity arises in Gauss's law \u2013 which states that the flux of the electric field E out of a closed surface is proportional to the electric charge "QA" enclosed in the surface (independent of how that charge is distributed), the integral form is:
p11578
aVwhere \u03b50 is the permittivity of free space.
p11579
aVIf one considers the flux of the electric field vector, E, for a tube near a point charge in the field the charge but not containing it with sides formed by lines tangent to the field, the flux for the sides is zero and there is an equal and opposite flux at both ends of the tube. This is a consequence of Gauss's Law applied to an inverse square field. The flux for any cross-sectional surface of the tube will be the same. The total flux for any surface surrounding a charge "q" is "q"/\u03b50.
p11580
aVIn free space the electric displacement is given by the constitutive relation D = \u03b50 E, so for any bounding surface the D-field flux equals the charge "QA" within it. Here the expression "flux of" indicates a mathematical operation and, as can be seen, the result is not necessarily a "flow", since nothing actually flows along electric field lines.
p11581
aVMagnetic flux.
p11582
aVThe magnetic flux density (magnetic field) having the unit Wb/m2 (Tesla) is denoted by B, and magnetic flux is defined analogously:
p11583
aVwith the same notation above. The quantity arises in Faraday's law of induction, in integral form:
p11584
aVformula_14
p11585
aVwhere "d" is an infinitesimal vector line element of the closed curve "C", with magnitude equal to the length of the infinitesimal line element, and direction given by the tangent to the curve "C", with the sign determined by the integration direction.
p11586
aVThe time-rate of change of the magnetic flux through a loop of wire is minus the electromotive force created in that wire. The direction is such that if current is allowed to pass through the wire, the electromotive force will cause a current which "opposes" the change in magnetic field by itself producing a magnetic field opposite to the change. This is the basis for inductors and many electric generators.
p11587
aVPoynting flux.
p11588
aVUsing this definition, the flux of the Poynting vector S over a specified surface is the rate at which electromagnetic energy flows through that surface, defined like before:
p11589
aVThe flux of the Poynting vector through a surface is the electromagnetic power, or energy per unit time, passing through that surface. This is commonly used in analysis of electromagnetic radiation, but has application to other electromagnetic systems as well.
p11590
aVConfusingly, the Poynting vector is sometimes called the "power flux", which is an example of the first usage of flux, above. It has units of watts per square metre (W/m2).
p11591
asS'Inequality'
p11592
(lp11593
VInequality may refer to:
p11594
aVIn mathematics:
p11595
aVIn healthcare:
p11596
aVIn economics:
p11597
aVIn the social sciences:
p11598
asS'Aleph one'
p11599
(lp11600
sS'Arithmetic precision'
p11601
(lp11602
sS'Probability theory'
p11603
(lp11604
VProbability theory is the branch of mathematics concerned with probability, the analysis of random phenomena. The central objects of probability theory are random variables, stochastic processes, and events: mathematical abstractions of non-deterministic events or measured quantities that may either be single occurrences or evolve over time in an apparently random fashion. If an individual coin toss or the roll of dice is considered to be a random event, then if repeated many times the sequence of random events will exhibit certain patterns, which can be studied and predicted. Two representative mathematical results describing such patterns are the law of large numbers and the central limit theorem.
p11605
aVAs a mathematical foundation for statistics, probability theory is essential to many human activities that involve quantitative analysis of large sets of data. Methods of probability theory also apply to descriptions of complex systems given only partial knowledge of their state, as in statistical mechanics. A great discovery of twentieth century physics was the probabilistic nature of physical phenomena at atomic scales, described in quantum mechanics.
p11606
aVHistory.
p11607
aVThe mathematical theory of probability has its roots in attempts to analyze games of chance by Gerolamo Cardano in the sixteenth century, and by Pierre de Fermat and Blaise Pascal in the seventeenth century (for example the "problem of points"). Christiaan Huygens published a book on the subject in 1657 and in the 19th century a big work was done by Laplace in what can be considered today as the classic interpretation.
p11608
aVInitially, probability theory mainly considered discrete events, and its methods were mainly combinatorial. Eventually, analytical considerations compelled the incorporation of continuous variables into the theory.
p11609
aVThis culminated in modern probability theory, on foundations laid by Andrey Nikolaevich Kolmogorov. Kolmogorov combined the notion of sample space, introduced by Richard von Mises, and measure theory and presented his axiom system for probability theory in 1933. Fairly quickly this became the mostly undisputed axiomatic basis for modern probability theory but alternatives exist, in particular the adoption of finite rather than countable additivity by Bruno de Finetti.
p11610
aVTreatment.
p11611
aVMost introductions to probability theory treat discrete probability distributions and continuous probability distributions separately. The more mathematically advanced measure theory based treatment of probability covers both the discrete, the continuous, any mix of these two and more.
p11612
aVMotivation.
p11613
aVConsider an experiment that can produce a number of outcomes. The set of all outcomes is called the "sample space" of the experiment. The "power set" of the sample space is formed by considering all different collections of possible results. For example, rolling an honest die produces one of six possible results. One collection of possible results corresponds to getting an odd number. Thus, the subset {1,3,5} is an element of the power set of the sample space of die rolls. These collections are called "events". In this case, {1,3,5} is the event that the die falls on some odd number. If the results that actually occur fall in a given event, that event is said to have occurred.
p11614
aVProbability is a way of assigning every "event" a value between zero and one, with the requirement that the event made up of all possible results (in our example, the event {1,2,3,4,5,6}) be assigned a value of one. To qualify as a probability distribution, the assignment of values must satisfy the requirement that if you look at a collection of mutually exclusive events (events that contain no common results, e.g., the events {1,6}, {3}, and {2,4} are all mutually exclusive), the probability that one of the events will occur is given by the sum of the probabilities of the individual events.
p11615
aVThe probability that any one of the events {1,6}, {3}, or {2,4} will occur is 5/6. This is the same as saying that the probability of event {1,2,3,4,6} is 5/6. This event encompasses the possibility of any number except five being rolled. The mutually exclusive event {5} has a probability of 1/6, and the event {1,2,3,4,5,6} has a probability of 1, that is, absolute certainty.
p11616
aVDiscrete probability distributions.
p11617
aVDiscrete probability theory deals with events that occur in countable sample spaces.
p11618
aVExamples: Throwing dice, experiments with decks of cards, random walk, and tossing coins
p11619
aVClassical definition:
p11620
aVInitially the probability of an event to occur was defined as number of cases favorable for the event, over the number of total outcomes possible in an equiprobable sample space: see Classical definition of probability.
p11621
aVFor example, if the event is "occurrence of an even number when a die is rolled", the probability is given by formula_1, since 3 faces out of the 6 have even numbers and each face has the same probability of appearing.
p11622
aVModern definition:
p11623
aVThe modern definition starts with a finite or countable set called the sample space, which relates to the set of all "possible outcomes" in classical sense, denoted by formula_2. It is then assumed that for each element formula_3, an intrinsic "probability" value formula_4 is attached, which satisfies the following properties:
p11624
aVThat is, the probability function "f"("x") lies between zero and one for every value of "x" in the sample space "\u03a9", and the sum of "f"("x") over all values "x" in the sample space "\u03a9" is equal to 1. An event is defined as any subset formula_7 of the sample space formula_8. The probability of the event formula_7 is defined as
p11625
aVformula_10
p11626
aVSo, the probability of the entire sample space is 1, and the probability of the null event is 0.
p11627
aVThe function formula_4 mapping a point in the sample space to the "probability" value is called a probability mass function abbreviated as pmf. The modern definition does not try to answer how probability mass functions are obtained; instead it builds a theory that assumes their existence.
p11628
aVContinuous probability distributions.
p11629
aVContinuous probability theory deals with events that occur in a continuous sample space.
p11630
aVClassical definition:
p11631
aVThe classical definition breaks down when confronted with the continuous case. See Bertrand's paradox.
p11632
aVModern definition:
p11633
aVIf the outcome space of a random variable "X" is the set of real numbers (formula_12) or a subset thereof, then a function called the cumulative distribution function (or cdf) formula_13 exists, defined by formula_14. That is, "F"("x") returns the probability that "X" will be less than or equal to "x".
p11634
aVThe cdf necessarily satisfies the following properties.
p11635
aVIf formula_13 is absolutely continuous, i.e., its derivative exists and integrating the derivative gives us the cdf back again, then the random variable "X" is said to have a probability density function or pdf or simply density formula_19
p11636
aVFor a set formula_20, the probability of the random variable "X" being in formula_7 is
p11637
aVformula_22
p11638
aVIn case the probability density function exists, this can be written as
p11639
aVformula_23
p11640
aVWhereas the "pdf" exists only for continuous random variables, the "cdf" exists for all random variables (including discrete random variables) that take values in formula_24
p11641
aVThese concepts can be generalized for multidimensional cases on formula_25 and other continuous sample spaces.
p11642
aVMeasure-theoretic probability theory.
p11643
aVThe "raison d'être" of the measure-theoretic treatment of probability is that it unifies the discrete and the continuous cases, and makes the difference a question of which measure is used. Furthermore, it covers distributions that are neither discrete nor continuous nor mixtures of the two.
p11644
aVAn example of such distributions could be a mix of discrete and continuous distributions\u2014for example, a random variable that is 0 with probability 1/2, and takes a random value from a normal distribution with probability 1/2. It can still be studied to some extent by considering it to have a pdf of formula_26, where formula_27 is the Dirac delta function.
p11645
aVOther distributions may not even be a mix, for example, the Cantor distribution has no positive probability for any single point, neither does it have a density. The modern approach to probability theory solves these problems using measure theory to define the probability space:
p11646
aVGiven any set formula_8, (also called sample space) and a \u03c3-algebra formula_29 on it, a measure formula_30 defined on formula_29 is called a probability measure if formula_32
p11647
aVIf formula_29 is the Borel \u03c3-algebra on the set of real numbers, then there is a unique probability measure on formula_29 for any cdf, and vice versa. The measure corresponding to a cdf is said to be induced by the cdf. This measure coincides with the pmf for discrete variables and pdf for continuous variables, making the measure-theoretic approach free of fallacies.
p11648
aVThe "probability" of a set formula_7 in the \u03c3-algebra formula_29 is defined as
p11649
aVformula_37
p11650
aVwhere the integration is with respect to the measure formula_38 induced by formula_39
p11651
aVAlong with providing better understanding and unification of discrete and continuous probabilities, measure-theoretic treatment also allows us to work on probabilities outside formula_25, as in the theory of stochastic processes. For example to study Brownian motion, probability is defined on a space of functions.
p11652
aVClassical probability distributions.
p11653
aVCertain random variables occur very often in probability theory because they well describe many natural or physical processes. Their distributions therefore have gained "special importance" in probability theory. Some fundamental "discrete distributions" are the discrete uniform, Bernoulli, binomial, negative binomial, Poisson and geometric distributions. Important "continuous distributions" include the continuous uniform, normal, exponential, gamma and beta distributions.
p11654
aVConvergence of random variables.
p11655
aVIn probability theory, there are several notions of convergence for random variables. They are listed below in the order of strength, i.e., any subsequent notion of convergence in the list implies convergence according to all of the preceding notions.
p11656
aVWeak convergence: A sequence of random variables formula_41 converges weakly to the random variable formula_42 if their respective cumulative "distribution functions" formula_43 converge to the cumulative distribution function formula_13 of formula_42, wherever formula_13 is continuous. Weak convergence is also called convergence in distribution.
p11657
aV:"Most common shorthand notation:" formula_47
p11658
aVConvergence in probability: The sequence of random variables formula_48 is said to converge towards the random variable formula_42 in probability if formula_50 for every \u03b5 > 0.
p11659
aV:"Most common shorthand notation:" formula_51
p11660
aVStrong convergence: The sequence of random variables formula_48 is said to converge towards the random variable formula_42 strongly if formula_54. Strong convergence is also known as almost sure convergence.
p11661
aV:"Most common shorthand notation:" formula_55
p11662
aVAs the names indicate, weak convergence is weaker than strong convergence. In fact, strong convergence implies convergence in probability, and convergence in probability implies weak convergence. The reverse statements are not always true.
p11663
aVLaw of large numbers.
p11664
aVCommon intuition suggests that if a fair coin is tossed many times, then "roughly" half of the time it will turn up "heads", and the other half it will turn up "tails". Furthermore, the more often the coin is tossed, the more likely it should be that the ratio of the number of "heads" to the number of "tails" will approach unity. Modern probability provides a formal version of this intuitive idea, known as the law of large numbers. This law is remarkable because it is not assumed in the foundations of probability theory, but instead emerges from these foundations as a theorem. Since it links theoretically derived probabilities to their actual frequency of occurrence in the real world, the law of large numbers is considered as a pillar in the history of statistical theory and has had widespread influence.
p11665
aVThe law of large numbers (LLN) states that the sample average
p11666
aVformula_56
p11667
aVof a sequence of independent and
p11668
aVidentically distributed random variables formula_57 converges towards their common expectation formula_58, provided that the expectation of formula_59 is finite.
p11669
aVIt is in the different forms of convergence of random variables that separates the "weak" and the "strong" law of large numbers
p11670
aVformula_60
p11671
aVIt follows from the LLN that if an event of probability "p" is observed repeatedly during independent experiments, the ratio of the observed frequency of that event to the total number of repetitions converges towards "p".
p11672
aVFor example, if formula_61 are independent Bernoulli random variables taking values 1 with probability "p" and 0 with probability 1-"p", then formula_62 for all "i", so that formula_63 converges to "p" almost surely.
p11673
aVCentral limit theorem.
p11674
aV"The central limit theorem (CLT) is one of the great results of mathematics." (Chapter 18 in)
p11675
aVIt explains the ubiquitous occurrence of the normal distribution in nature.
p11676
aVThe theorem states that the average of many independent and identically distributed random variables with finite variance tends towards a normal distribution "irrespective" of the distribution followed by the original random variables. Formally, let formula_48 be independent random variables with mean formula_65 and variance formula_66 Then the sequence of random variables
p11677
aVformula_67
p11678
aVconverges in distribution to a standard normal random variable.
p11679
aVNotice that for some classes of random variables the classic central limit theorem works rather fast (see Berry\u2013Esseen theorem), for example the distributions with finite first, second and third moment from the exponential family, on the other hand for some random variables of the heavy tail and fat tail variety, it works very slow or may not work at all: in such cases one may use the Generalized Central Limit Theorem (GCLT).
p11680
aV: The first major treatise blending calculus with probability theory, originally in French: "Théorie Analytique des Probabilités".
p11681
aV: An English translation by Nathan Morrison appeared under the title "Foundations of the Theory of Probability" (Chelsea, New York) in 1950, with a second edition in 1956.
p11682
aV: A lively introduction to probability theory for the beginner.
p11683
asS'Mathematical proof'
p11684
(lp11685
VIn mathematics, a proof is a deductive argument for a mathematical statement. In the argument, other previously established statements, such as theorems, can be used. In principle, a proof can be traced back to self-evident or assumed statements, known as axioms. Proofs are examples of deductive reasoning and are distinguished from inductive or empirical arguments; a proof must demonstrate that a statement is always true (occasionally by listing "all" possible cases and showing that it holds in each), rather than enumerate many confirmatory cases. An unproved statement that is believed true is known as a conjecture.
p11686
aVProofs employ logic but usually include some amount of natural language which usually admits some ambiguity. In fact, the vast majority of proofs in written mathematics can be considered as applications of rigorous informal logic. Purely formal proofs, written in symbolic language instead of natural language, are considered in proof theory. The distinction between formal and informal proofs has led to much examination of current and historical mathematical practice, quasi-empiricism in mathematics, and so-called folk mathematics (in both senses of that term). The philosophy of mathematics is concerned with the role of language and logic in proofs, and mathematics as a language.
p11687
aVHistory and etymology.
p11688
aVThe word "proof" comes from the Latin "probare" meaning "to test". Related modern words are the English "probe", "probation", and "probability", the Spanish "probar" (to smell or taste, or (lesser use) touch or test), Italian "provare" (to try), and the German "probieren" (to try). The early use of "probity" was in the presentation of legal evidence. A person of authority, such as a nobleman, was said to have probity, whereby the evidence was by his relative authority, which outweighed empirical testimony.
p11689
aVPlausibility arguments using heuristic devices such as pictures and analogies preceded strict mathematical proof. It is likely that the idea of demonstrating a conclusion first arose in connection with geometry, which originally meant the same as "land measurement". The development of mathematical proof is primarily the product of ancient Greek mathematics, and one of its greatest achievements. Thales (624\u2013546 BCE) proved some theorems in geometry. Eudoxus (408\u2013355 BCE) and Theaetetus (417\u2013369 BCE) formulated theorems but did not prove them. Aristotle (384\u2013322 BCE) said definitions should describe the concept being defined in terms of other concepts already known. Mathematical proofs were revolutionized by Euclid (300 BCE), who introduced the axiomatic method still in use today, starting with undefined terms and axioms (propositions regarding the undefined terms assumed to be self-evidently true from the Greek "axios" meaning "something worthy"), and used these to prove theorems using deductive logic. His book, the "Elements", was read by anyone who was considered educated in the West until the middle of the 20th century. In addition to the familiar theorems of geometry, such as the Pythagorean theorem, the "Elements" includes a proof that the square root of two is irrational and that there are infinitely many prime numbers.
p11690
aVFurther advances took place in medieval Islamic mathematics. While earlier Greek proofs were largely geometric demonstrations, the development of arithmetic and algebra by Islamic mathematicians allowed more general proofs that no longer depended on geometry. In the 10th century CE, the Iraqi mathematician Al-Hashimi provided general proofs for numbers (rather than geometric demonstrations) as he considered multiplication, division, etc. for "lines." He used this method to provide a proof of the existence of irrational numbers. An inductive proof for arithmetic sequences was introduced in the "Al-Fakhri" (1000) by Al-Karaji, who used it to prove the binomial theorem and properties of Pascal's triangle. Alhazen also developed the method of proof by contradiction, as the first attempt at proving the Euclidean parallel postulate.
p11691
aVModern proof theory treats proofs as inductively defined data structures. There is no longer an assumption that axioms are "true" in any sense; this allows for parallel mathematical theories built on alternate sets of axioms (see Axiomatic set theory and Non-Euclidean geometry for examples).
p11692
aVNature and purpose.
p11693
aVAs practiced, a proof is expressed in natural language and is a rigorous argument intended to convince the audience of the truth of a statement. The standard of rigor is not absolute and has varied throughout history. A proof can be presented differently depending on the intended audience. In order to gain acceptance, a proof has to meet communal statements of rigor; an argument considered vague or incomplete may be rejected.
p11694
aVThe concept of a proof is formalized in the field of mathematical logic. A formal proof is written in a formal language instead of a natural language. A formal proof is defined as sequence of formulas in a formal language, in which each formula is a logical consequence of preceding formulas. Having a definition of formal proof makes the concept of proof amenable to study. Indeed, the field of proof theory studies formal proofs and their properties, for example, the property that a statement has a formal proof. An application of proof theory is to show that certain undecidable statements are not provable.
p11695
aVThe definition of a formal proof is intended to capture the concept of proofs as written in the practice of mathematics. The soundness of this definition amounts to the belief that a published proof can, in principle, be converted into a formal proof. However, outside the field of automated proof assistants, this is rarely done in practice. A classic question in philosophy asks whether mathematical proofs are analytic or synthetic. Kant, who introduced the analytic-synthetic distinction, believed mathematical proofs are synthetic. 
p11696
aVProofs may be viewed as aesthetic objects, admired for their mathematical beauty. The mathematician Paul Erd\u0151s was known for describing proofs he found particularly elegant as coming from "The Book", a hypothetical tome containing the most beautiful method(s) of proving each theorem. The book "Proofs from THE BOOK", published in 2003, is devoted to presenting 32 proofs its editors find particularly pleasing.
p11697
aVMethods.
p11698
aVDirect proof.
p11699
aVIn direct proof, the conclusion is established by logically combining the axioms, definitions, and earlier theorems. For example, direct proof can be used to establish that the sum of two even integers is always even:
p11700
aVConsider two even integers "x" and "y". Since they are even, they can be written as "x" = 2"a" and "y" = 2"b", respectively, for integers "a" and "b". Then the sum "x" + "y" = 2"a" + 2"b" = 2("a"+"b"). Therefore "x"+"y" has 2 as a factor and, by definition, is even. Hence the sum of any two even integers is even.
p11701
aVThis proof uses the definition of even integers, the integer properties of closure under addition and multiplication, and distributivity.
p11702
aVProof by mathematical induction.
p11703
aVMathematical induction is not a form of inductive reasoning. In proof by mathematical induction, a single "base case" is proved, and an "induction rule" is proved, which establishes that a certain case implies the next case. Applying the induction rule repeatedly, starting from the independently proved base case, proves many, often infinitely many, other cases. Since the base case is true, the infinity of other cases must also be true, even if all of them cannot be proved directly because of their infinite number. A subset of induction is infinite descent. Infinite descent can be used to prove the irrationality of the square root of two.
p11704
aVA common application of proof by mathematical induction is to prove that a property known to hold for one number holds for all natural numbers:
p11705
aVLet be the set of natural numbers, and be a mathematical statement involving the natural number belonging to such that
p11706
aVFor example, we can prove by induction that all integers of the form are odd:
p11707
aV(i) For , , and is odd. Thus is true.
p11708
aV(ii) For for some , . If is odd, then must also be odd, because adding to an odd number results in an odd number. So is true if is true.
p11709
aVThus is odd, for all natural numbers .
p11710
aVIt is common for the phrase "proof by induction" to be used for a "proof by mathematical induction".
p11711
aVProof by contraposition.
p11712
aVProof by contraposition infers the conclusion "if "p" then "q"" from the premise "if "not q" then "not p"". The statement "if "not q" then "not p"" is called the contrapositive of the statement "if "p" then "q"". For example, contraposition can be used to establish that, given an integer "x", if "x"² is even, then "x" is even:
p11713
aV Suppose "x" is not even. Then "x" is odd. The product of two odd numbers is odd, hence "x"² = "x"·"x" is odd. Thus "x"² is not even.
p11714
aVProof by contradiction.
p11715
aVIn proof by contradiction (also known as "reductio ad absurdum", Latin for "by reduction to the absurd"), it is shown that if some statement were true, a logical contradiction occurs, hence the statement must be false. A famous example of proof by contradiction shows that formula_1 is an irrational number:
p11716
aVSuppose that formula_1 were a rational number, so by definition formula_3 where "a" and "b" are non-zero integers with no common factor. Thus, formula_4. Squaring both sides yields 2"b"2 = "a"2. Since 2 divides the left hand side, 2 must also divide the right hand side (as they are equal and both integers). So "a"2 is even, which implies that "a" must also be even. So we can write "a" = 2"c", where "c" is also an integer. Substitution into the original equation yields 2"b"2 = (2"c")2 = 4"c"2. Dividing both sides by 2 yields "b"2 = 2"c"2. But then, by the same argument as before, 2 divides "b"2, so "b" must be even. However, if "a" and "b" are both even, they share a factor, namely 2. This contradicts our assumption, so we are forced to conclude that formula_1 is an irrational number.
p11717
aVProof by construction.
p11718
aVProof by construction, or proof by example, is the construction of a concrete example with a property to show that something having that property exists. Joseph Liouville, for instance, proved the existence of transcendental numbers by constructing an explicit example. It can also be used to construct a counterexample to disprove a proposition that all elements have a certain property.
p11719
aVProof by exhaustion.
p11720
aVIn proof by exhaustion, the conclusion is established by dividing it into a finite number of cases and proving each one separately. The number of cases sometimes can become very large. For example, the first proof of the four color theorem was a proof by exhaustion with 1,936 cases. This proof was controversial because the majority of the cases were checked by a computer program, not by hand. The shortest known proof of the four color theorem still has over 600 cases.
p11721
aVProbabilistic proof.
p11722
aVA probabilistic proof is one in which an example is shown to exist, with certainty, by using methods of probability theory. Probabilistic proof, like proof by construction, is one of many ways to show existence theorems.
p11723
aVThis is not to be confused with an argument that a theorem is 'probably' true, a 'plausibility argument'. The work on the Collatz conjecture shows how far plausibility is from genuine proof.
p11724
aVCombinatorial proof.
p11725
aVA combinatorial proof establishes the equivalence of different expressions by showing that they count the same object in different ways. Often a bijection between two sets is used to show that the expressions for their two sizes are equal. Alternatively, a double counting argument provides two different expressions for the size of a single set, again showing that the two expressions are equal.
p11726
aVNonconstructive proof.
p11727
aVA nonconstructive proof establishes that a mathematical object with a certain property exists without explaining how such an object can be found. Often, this takes the form of a proof by contradiction in which the nonexistence of the object is proved to be impossible. In contrast, a constructive proof establishes that a particular object exists by providing a method of finding it. A famous example of a
p11728
aVnonconstructive proof shows that there exist two irrational numbers "a" and "b" such that formula_6 is a rational number:
p11729
aVEither formula_7 is a rational number and we are done (take formula_8), or formula_7 is irrational so we can write formula_10 and formula_11. This then gives formula_12, which is thus a rational of the form formula_13
p11730
aVStatistical proofs in pure mathematics.
p11731
aVThe expression "statistical proof" may be used technically or colloquially in areas of pure mathematics, such as involving cryptography, chaotic series, and probabilistic or analytic number theory. It is less commonly used to refer to a mathematical proof in the branch of mathematics known as mathematical statistics. See also "Statistical proof using data" section below.
p11732
aVComputer-assisted proofs.
p11733
aVUntil the twentieth century it was assumed that any proof could, in principle, be checked by a competent mathematician to confirm its validity. However, computers are now used both to prove theorems and to carry out calculations that are too long for any human or team of humans to check; the first proof of the four color theorem is an example of a computer-assisted proof. Some mathematicians are concerned that the possibility of an error in a computer program or a run-time error in its calculations calls the validity of such computer-assisted proofs into question. In practice, the chances of an error invalidating a computer-assisted proof can be reduced by incorporating redundancy and self-checks into calculations, and by developing multiple independent approaches and programs. Errors can never be completely ruled out in case of verification of a proof by humans either, especially if the proof contains natural language and requires deep mathematical insight.
p11734
aVUndecidable statements.
p11735
aVA statement that is neither provable nor disprovable from a set of axioms is called undecidable (from those axioms). One example is the parallel postulate, which is neither provable nor refutable from the remaining axioms of Euclidean geometry.
p11736
aVMathematicians have shown there are many statements that are neither provable nor disprovable in Zermelo-Fraenkel set theory with the axiom of choice (ZFC), the standard system of set theory in mathematics (assuming that ZFC is consistent); see list of statements undecidable in ZFC.
p11737
aVGödel's (first) incompleteness theorem shows that many axiom systems of mathematical interest will have undecidable statements.
p11738
aVHeuristic mathematics and experimental mathematics.
p11739
aVWhile early mathematicians such as Eudoxus of Cnidus did not use proofs, from Euclid to the foundational mathematics developments of the late 19th and 20th centuries, proofs were an essential part of mathematics. With the increase in computing power in the 1960s, significant work began to be done investigating mathematical objects outside of the proof-theorem framework, in experimental mathematics. Early pioneers of these methods intended the work ultimately to be embedded in a classical proof-theorem framework, e.g. the early development of fractal geometry, which was ultimately so embedded.
p11740
aVRelated concepts.
p11741
aVVisual proof.
p11742
aVAlthough not a formal proof, a visual demonstration of a mathematical theorem is sometimes called a "proof without words". The left-hand picture below is an example of a historic visual proof of the Pythagorean theorem in the case of the (3,4,5) triangle.
p11743
aVSome illusory visual proofs, such as the missing square puzzle, can be constructed in a way which appear to prove a supposed mathematical fact but only do so under the presence of tiny errors (for example, supposedly straight lines which actually bend slightly) which are unnoticeable until the entire picture is closely examined, with lengths and angles precisely measured or calculated.
p11744
aVElementary proof.
p11745
aVAn elementary proof is a proof which only uses basic techniques. More specifically, the term is used in number theory to refer to proofs that make no use of complex analysis. For some time it was thought that certain theorems, like the prime number theorem, could only be proved using "higher" mathematics. However, over time, many of these results have been reproved using only elementary techniques.
p11746
aVTwo-column proof.
p11747
aVA particular way of organising a proof using two parallel columns is often used in elementary geometry classes in the United States. The proof is written as a series of lines in two columns. In each line, the left-hand column contains a proposition, while the right-hand column contains a brief explanation of how the corresponding proposition in the left-hand column is either an axiom, a hypothesis, or can be logically derived from previous propositions. The left-hand column is typically headed "Statements" and the right-hand column is typically headed "Reasons".
p11748
aVColloquial use of "mathematical proof".
p11749
aVThe expression "mathematical proof" is used by lay people to refer to using mathematical methods or arguing with mathematical objects, such as numbers, to demonstrate something about everyday life, or when data used in an argument is numerical. It is sometimes also used to mean a "statistical proof" (below), especially when used to argue from data.
p11750
aVStatistical proof using data.
p11751
aV"Statistical proof" from data refers to the application of statistics, data analysis, or Bayesian analysis to infer propositions regarding the probability of data. While "using" mathematical proof to establish theorems in statistics, it is usually not a mathematical proof in that the "assumptions" from which probability statements are derived require empirical evidence from outside mathematics to verify. In physics, in addition to statistical methods, "statistical proof" can refer to the specialized "mathematical methods of physics" applied to analyze data in a particle physics experiment or observational study in cosmology. "Statistical proof" may also refer to raw data or a convincing diagram involving data, such as scatter plots, when the data or diagram is adequately convincing without further analysis.
p11752
aVInductive logic proofs and Bayesian analysis.
p11753
aVProofs using inductive logic, while considered mathematical in nature, seek to establish propositions with a degree of certainty, which acts in a similar manner to probability, and may be less than one certainty. Bayesian analysis establishes assertions as to the degree of a person's subjective belief. Inductive logic should not be confused with mathematical induction.
p11754
aVProofs as mental objects.
p11755
aVPsychologism views mathematical proofs as psychological or mental objects. Mathematician philosophers, such as Leibniz, Frege, and Carnap have attempted to develop a semantics for what they considered to be the language of thought, whereby standards of mathematical proof might be applied to empirical science.
p11756
aVInfluence of mathematical proof methods outside mathematics.
p11757
aVPhilosopher-mathematicians such as Spinoza have attempted to formulate philosophical arguments in an axiomatic manner, whereby mathematical proof standards could be applied to argumentation in general philosophy. Other mathematician-philosophers have tried to use standards of mathematical proof and reason, without empiricism, to arrive at statements outside of mathematics, but having the certainty of propositions deduced in a mathematical proof, such as Descarte's "cogito" argument.
p11758
aVEnding a proof.
p11759
aVSometimes, the abbreviation "Q.E.D." is written to indicate the end of a proof. This abbreviation stands for "Quod Erat Demonstrandum", which is Latin for "that which was to be demonstrated". A more common alternative is to use a square or a rectangle, such as or , known as a "tombstone" or "halmos" after its eponym Paul Halmos. Often, "which was to be shown" is verbally stated when writing "QED", , or in an oral presentation on a board.
p11760
asS'Trigonometry'
p11761
(lp11762
VTrigonometry (from Greek "trig\u014dnon", "triangle" and "metron", "measure") is a branch of mathematics that studies relationships involving lengths and angles of triangles. The field emerged in the Hellenistic world during the 3rd century BC from applications of geometry to astronomical studies.
p11763
aVThe 3rd-century astronomers first noted that the lengths of the sides of a right-angle triangle and the angles between those sides have fixed relationships: that is, if at least the length of one side and the value of one angle is known, then all other angles and lengths can be determined algorithmically. These calculations soon came to be defined as the trigonometric functions and today are pervasive in both pure and applied mathematics: fundamental methods of analysis such as the Fourier transform, for example, or the wave equation, use trigonometric functions to understand cyclical phenomena across many applications in fields as diverse as physics, mechanical and electrical engineering, music and acoustics, astronomy, ecology, and biology. Trigonometry is also the foundation of surveying.
p11764
aVTrigonometry is most simply associated with planar right-angle triangles (each of which is a two-dimensional triangle with one angle equal to 90 degrees). The applicability to non-right-angle triangles exists, but, since any non-right-angle triangle (on a flat plane) can be bisected to create two right-angle triangles, most problems can be reduced to calculations on right-angle triangles. Thus the majority of applications relate to right-angle triangles. One exception to this is spherical trigonometry, the study of triangles on spheres, surfaces of constant positive curvature, in elliptic geometry (a fundamental part of astronomy and navigation). Trigonometry on surfaces of negative curvature is part of hyperbolic geometry.
p11765
aVTrigonometry basics are often taught in schools, either as a separate course or as a part of a precalculus course.
p11766
aVHistory.
p11767
aVSumerian astronomers studied angle measure, using a division of circles into 360 degrees. They, and later the Babylonians, studied the ratios of the sides of similar triangles and discovered some properties of these ratios but did not turn that into a systematic method for finding sides and angles of triangles. The ancient Nubians used a similar method.
p11768
aVIn the 3rd century BCE, Hellenistic Greek mathematicians (such as Euclid and Archimedes) studied the properties of chords and inscribed angles in circles, and they proved theorems that are equivalent to modern trigonometric formulae, although they presented them geometrically rather than algebraically. In 140 BC Hipparchus gave the first tables of chords, analogous to modern tables of sine values, and used them to solve problems in trigonometry and spherical trigonometry. In the 2nd century AD the Greco-Egyptian astronomer Ptolemy printed detailed trigonometric tables (Ptolemy's table of chords) in Book 1, chapter 11 of his Almagest. Ptolemy used chord length to define his trigonometric functions, a minor difference from the sine convention we use today. (The value we call sin(\u03b8) can be found by looking up the chord length for twice the angle of interest (2\u03b8) in Ptolemy's table, and then dividing that value by two.) Centuries passed before more detailed tables were produced, and Ptolemy's treatise remained in use for performing trigonometric calculations in astronomy throughout the next 1200 years in the medieval Byzantine, Islamic, and, later, Western European worlds.
p11769
aVThe modern sine convention is first attested in the "Surya Siddhanta", and its properties were further documented by the 5th century (CE) Indian mathematician and astronomer Aryabhata. These Greek and Indian works were translated and expanded by medieval Islamic mathematicians. By the 10th century, Islamic mathematicians were using all six trigonometric functions, had tabulated their values, and were applying them to problems in spherical geometry. At about the same time, Chinese mathematicians developed trigonometry independently, although it was not a major field of study for them. Knowledge of trigonometric functions and methods reached Western Europe via Latin translations of Ptolemy's Greek Almagest as well as the works of Persian and Arabic astronomers such as Al Battani and Nasir al-Din al-Tusi. One of the earliest works on trigonometry by a northern European mathematician is "De Triangulis" by the 15th century German mathematician Regiomontanus, who was encouraged to write, and provided with a copy of the Almagest, by the Byzantine Greek scholar cardinal Basilios Bessarion with whom he lived for several years. At the same time another translation of the Almagest from Greek into Latin was completed by the Cretan George of Trebizond. Trigonometry was still so little known in 16th-century northern Europe that Nicolaus Copernicus devoted two chapters of "De revolutionibus orbium coelestium" to explain its basic concepts.
p11770
aVDriven by the demands of navigation and the growing need for accurate maps of large geographic areas, trigonometry grew into a major branch of mathematics. Bartholomaeus Pitiscus was the first to use the word, publishing his "Trigonometria" in 1595. Gemma Frisius described for the first time the method of triangulation still used today in surveying. It was Leonhard Euler who fully incorporated complex numbers into trigonometry. The works of James Gregory in the 17th century and Colin Maclaurin in the 18th century were influential in the development of trigonometric series. Also in the 18th century, Brook Taylor defined the general Taylor series.
p11771
aVOverview.
p11772
aVIf one angle of a triangle is 90 degrees and one of the other angles is known, the third is thereby fixed, because the three angles of any triangle add up to 180 degrees. The two acute angles therefore add up to 90 degrees: they are complementary angles. The shape of a triangle is completely determined, except for similarity, by the angles. Once the angles are known, the ratios of the sides are determined, regardless of the overall size of the triangle. If the length of one of the sides is known, the other two are determined. These ratios are given by the following trigonometric functions of the known angle "A", where "a", " b" and "c" refer to the lengths of the sides in the accompanying figure:
p11773
aV: formula_1
p11774
aV: formula_2
p11775
aV: formula_3
p11776
aVThe hypotenuse is the side opposite to the 90 degree angle in a right triangle; it is the longest side of the triangle and one of the two sides adjacent to angle "A". The adjacent leg is the other side that is adjacent to angle "A". The opposite side is the side that is opposite to angle "A". The terms perpendicular and base are sometimes used for the opposite and adjacent sides respectively. Many people find it easy to remember what sides of the right triangle are equal to sine, cosine, or tangent, by memorizing the word SOH-CAH-TOA (see below under Mnemonics).
p11777
aVThe reciprocals of these functions are named the cosecant (csc or cosec), secant (sec), and cotangent (cot), respectively:
p11778
aVformula_4
p11779
aVformula_5
p11780
aVformula_6
p11781
aVThe inverse functions are called the arcsine, arccosine, and arctangent, respectively. There are arithmetic relations between these functions, which are known as trigonometric identities. The cosine, cotangent, and cosecant are so named because they are respectively the sine, tangent, and secant of the complementary angle abbreviated to "co-".
p11782
aVWith these functions one can answer virtually all questions about arbitrary triangles by using the law of sines and the law of cosines. These laws can be used to compute the remaining angles and sides of any triangle as soon as two sides and their included angle or two angles and a side or three sides are known. These laws are useful in all branches of geometry, since every polygon may be described as a finite combination of triangles.
p11783
aVExtending the definitions.
p11784
aVThe above definitions only apply to angles between 0 and 90 degrees (0 and \u03c0/2 radians). Using the unit circle, one can extend them to all positive and negative arguments (see trigonometric function). The trigonometric functions are periodic, with a period of 360 degrees or 2\u03c0 radians. That means their values repeat at those intervals. The tangent and cotangent functions also have a shorter period, of 180 degrees or \u03c0 radians.
p11785
aVThe trigonometric functions can be defined in other ways besides the geometrical definitions above, using tools from calculus and infinite series. With these definitions the trigonometric functions can be defined for complex numbers. The complex exponential function is particularly useful.
p11786
aV formula_7
p11787
aVSee Euler's and De Moivre's formulas.
p11788
aVMnemonics.
p11789
aVA common use of mnemonics is to remember facts and relationships in trigonometry. For example, the "sine", "cosine", and "tangent" ratios in a right triangle can be remembered by representing them and their corresponding sides as strings of letters. For instance, a mnemonic is SOH-CAH-TOA:
p11790
aVSine = Opposite ÷ Hypotenuse
p11791
aVCosine = Adjacent ÷ Hypotenuse
p11792
aVTangent = Opposite ÷ Adjacent
p11793
aVOne way to remember the letters is to sound them out phonetically (i.e., "SOH-CAH-TOA", which is pronounced 'so-k\u0259-toe-uh' ). Another method is to expand the letters into a sentence, such as "Some Old Hippy Caught Another Hippy Trippin' On Acid".
p11794
aVCalculating trigonometric functions.
p11795
aVTrigonometric functions were among the earliest uses for mathematical tables. Such tables were incorporated into mathematics textbooks and students were taught to look up values and how to interpolate between the values listed to get higher accuracy. Slide rules had special scales for trigonometric functions.
p11796
aVToday scientific calculators have buttons for calculating the main trigonometric functions (sin, cos, tan, and sometimes cis and their inverses). Most allow a choice of angle measurement methods: degrees, radians, and sometimes gradians. Most computer programming languages provide function libraries that include the trigonometric functions. The floating point unit hardware incorporated into the microprocessor chips used in most personal computers has built-in instructions for calculating trigonometric functions.
p11797
aVApplications of trigonometry.
p11798
aVThere is an enormous number of uses of trigonometry and trigonometric functions. For instance, the technique of triangulation is used in astronomy to measure the distance to nearby stars, in geography to measure distances between landmarks, and in satellite navigation systems. The sine and cosine functions are fundamental to the theory of periodic functions such as those that describe sound and light waves.
p11799
aVFields that use trigonometry or trigonometric functions include astronomy (especially for locating apparent positions of celestial objects, in which spherical trigonometry is essential) and hence navigation (on the oceans, in aircraft, and in space), music theory, audio synthesis, acoustics, optics, electronics, probability theory, statistics, biology, medical imaging (CAT scans and ultrasound), pharmacy, chemistry, number theory (and hence cryptology), seismology, meteorology, oceanography, many physical sciences, land surveying and geodesy, architecture, image compression, phonetics, economics, electrical engineering, mechanical engineering, civil engineering, computer graphics, cartography, crystallography and game development.
p11800
aVPythagorean identities.
p11801
aVIdentities are those equations that hold true for any value.
p11802
aVformula_8
p11803
aVformula_9
p11804
aVformula_10
p11805
aVformula_11
p11806
aVformula_12
p11807
aVformula_13
p11808
aVformula_14
p11809
aVCommon formulae.
p11810
aVCertain equations involving trigonometric functions are true for all angles and are known as "trigonometric identities." Some identities equate an expression to a different expression involving the same angles. These are listed in List of trigonometric identities. Triangle identities that relate the sides and angles of a given triangle are listed below.
p11811
aVIn the following identities, "A", "B" and "C" are the angles of a triangle and "a", "b" and "c" are the lengths of sides of the triangle opposite the respective angles (as shown in the diagram).
p11812
aVLaw of sines.
p11813
aVThe law of sines (also known as the "sine rule") for an arbitrary triangle states:
p11814
aVformula_15
p11815
aVwhere formula_16 is the area of the triangle and "R" is the radius of the circumscribed circle of the triangle:
p11816
aVformula_17
p11817
aVAnother law involving sines can be used to calculate the area of a triangle. Given two sides "a" and "b" and the angle between the sides "C", the area of the triangle is given by half the product of the lengths of two sides and the sine of the angle between the two sides:
p11818
aVformula_18
p11819
aVLaw of cosines.
p11820
aVThe law of cosines (known as the cosine formula, or the "cos rule") is an extension of the Pythagorean theorem to arbitrary triangles:
p11821
aVformula_19
p11822
aVor equivalently:
p11823
aVformula_20
p11824
aVThe law of cosines may be used to prove Heron's formula, which is another method that may be used to calculate the area of a triangle. This formula states that if a triangle has sides of lengths "a", "b", and "c", and if the semiperimeter is
p11825
aVformula_21
p11826
aVthen the area of the triangle is:
p11827
aVformula_22, 
p11828
aVwhere R is the radius of the circumcircle of the triangle.
p11829
aVLaw of tangents.
p11830
aVThe law of tangents:
p11831
aVformula_23
p11832
aVEuler's formula.
p11833
aVEuler's formula, which states that formula_24, produces the following analytical identities for sine, cosine, and tangent in terms of "e" and the imaginary unit "i":
p11834
aVformula_25
p11835
asS'Trigonometric function'
p11836
(lp11837
sS'Lemma (mathematics)'
p11838
(lp11839
VIn mathematics, a "helping theorem" or lemma (plural lemmata or lemmas) from the Ancient Greek "\u03bb\u1fc6\u03bc\u03bc\u03b1" ("lemma", "anything which is received, such as a gift, profit, or a bribe\u201d) is a proven proposition which is used as a stepping stone to a larger result rather than as a statement of interest by itself.
p11840
aVComparison with theorem.
p11841
aVThere is no formal distinction between a lemma and a theorem, only one of intention \u2013 see Theorem terminology. However, a lemma can be considered a minor result whose sole purpose is to help prove a theorem - a step in the direction of proof, so to speak.
p11842
aVWell-known lemmas.
p11843
aVA good stepping stone can lead to many others. Some powerful results in mathematics are known as lemmata, such as Bézout's lemma, Dehn's lemma, Euclid's lemma, Farkas' lemma, Fatou's lemma, Gauss's lemma, Greendlinger's lemma, It\u014d's lemma, Jordan's lemma, Nakayama's lemma, Poincaré's lemma, Riesz's lemma, Schur's lemma, Schwarz's lemma, Urysohn's lemma, Yoneda's lemma and Zorn's lemma. While these results originally seemed too simple or too technical to warrant independent interest, they have turned out to be central to the theories in which they occur.
p11844
asS'Floating point'
p11845
(lp11846
VIn computing, floating point is a method of representing an approximation of a real number in a way that can support a trade-off between range and precision. A number is, in general, represented approximately to a fixed number of significant digits (the significand) and scaled using an exponent; the base for the scaling is normally two, ten, or sixteen. A number that can be represented exactly is of the following form:
p11847
aV formula_1
p11848
aVFor example:
p11849
aV formula_2
p11850
aVThe term "floating point" refers to the fact that a number's radix point ("decimal point", or, more commonly in computers, "binary point") can "float"; that is, it can be placed anywhere relative to the significant digits of the number. This position is indicated as the exponent component, and thus the floating-point representation can be thought of as a kind of scientific notation.
p11851
aVA floating-point system can be used to represent, with a fixed number of digits, numbers of different orders of magnitude: e.g. the distance between galaxies or the diameter of an atomic nucleus can be expressed with the same unit of length. The result of this dynamic range is that the numbers that can be represented are not uniformly spaced; the difference between two consecutive representable numbers grows with the chosen scale.
p11852
aVOver the years, a variety of floating-point representations have been used in computers. However, since the 1990s, the most commonly encountered representation is that defined by the IEEE 754 Standard.
p11853
aVThe speed of floating-point operations, commonly measured in terms of FLOPS, is an important characteristic of a computer system, especially for applications that involve intensive mathematical calculations.
p11854
aVOverview.
p11855
aVFloating-point numbers.
p11856
aVA number representation (called a numeral system in mathematics) specifies some way of encoding a number, usually as a string of digits.
p11857
aVThere are several mechanisms by which strings of digits can represent numbers. In common mathematical notation, the digit string can be of any length, and the location of the radix point is indicated by placing an explicit "point" character (dot or comma) there. If the radix point is not specified, then it is implicitly assumed to lie at the right (at the least significant) end of the string (that is, the number is an integer). In fixed-point systems, some specific assumption is made about where the radix point is located in the string; for example, the convention could be that the string consists of 8 decimal digits with the decimal point in the middle, so that "00012345" represents the value 1.2345.
p11858
aVIn scientific notation, the given number is scaled by a power of 10, so that it lies within a certain range\u2014typically between 1 and 10, with the radix point appearing immediately after the first digit. The scaling factor, as a power of ten, is then indicated separately at the end of the number. For example, the revolution period of Jupiter's moon Io is 152853.5047 seconds, a value that would be represented in standard-form scientific notation as 1.528535047 seconds.
p11859
aVFloating-point representation is similar in concept to scientific notation. Logically, a floating-point number consists of:
p11860
aVTo derive the value of the floating-point number, the "significand" is multiplied by the "base" raised to the power of the "exponent", equivalent to shifting the radix point from its implied position by a number of places equal to the value of the exponent\u2014to the right if the exponent is positive or to the left if the exponent is negative.
p11861
aVUsing base-10 (the familiar decimal notation) as an example, the number 152853.5047, which has ten decimal digits of precision, is represented as the significand 1528535047 together with 5 as the exponent. To determine the actual value, a decimal point is placed after the first digit of the significand and the result is multiplied by 105 to give 1.528535047 × 105, or 152853.5047. In storing such a number, the base (10) need not be stored, since it will be the same for the entire range of supported numbers, and can thus be inferred.
p11862
aVSymbolically, this final value is:
p11863
aV formula_3
p11864
aVwhere formula_4 is the significand (ignoring any implied decimal point), formula_5 is the precision (the number of digits in the significand), formula_6 is the base (in our example, this is the number "ten"), and formula_7 is the exponent.
p11865
aVHistorically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal), and other less common varieties, such as base sixteen (hexadecimal notation), and even base three (see Setun).
p11866
aVA floating-point number is a rational number, because it can be represented as one integer divided by another; for example 1.45×103 is (145/100)*1000 or 145000/100. The base determines the fractions that can be represented; for instance, 1/5 cannot be represented exactly as a floating-point number using a binary base, but 1/5 can be represented exactly using a decimal base (0.2, or 2×10\u22121). However, 1/3 cannot be represented exactly by either binary (0.010101...) or decimal (0.333...), but in base 3, it is trivial (0.1 or 1×3\u22121) . The occasions on which infinite expansions occur depend on the base and its prime factors, as described in the article on Positional Notation.
p11867
aVThe way in which the significand (including its sign) and exponent are stored in a computer is implementation-dependent. The common IEEE formats are described in detail later and elsewhere, but as an example, in the binary single-precision (32-bit) floating-point representation, formula_8, and so the significand is a string of 24 bits. For instance, the number \u03c0's first 33 bits are:
p11868
aV formula_9.
p11869
aVIf the leftmost bit is considered the 1st bit, then the 24th bit is zero and the 25th bit is 1; thus, in rounding to 24 bits, let's attribute to the 24th bit the value of the 25th, yielding:
p11870
aV formula_10
p11871
aVWhen this is stored using the IEEE 754 encoding, this becomes the significand formula_4 with formula_12 (where formula_4 is assumed to have a binary point to the right of the first bit) after a left-adjustment (or "normalization") during which leading or trailing zeros are truncated should there be any, which is unnecessary in this case; as a result of this normalization, the first bit of a non-zero binary significand is always 1, so it need not be stored, saving one bit of storage. In other words, from this representation, \u03c0 is calculated as follows:
p11872
aVformula_14
p11873
aVwhere formula_15 is the normalized significand's "n"th bit from the left, where counting starts with 1. Normalization, which is reversed by the addition of the implicit one, can be thought of as a form of compression; it allows a binary significand to be compressed into a field one bit shorter than the maximum precision, at the expense of extra processing.
p11874
aVAlternatives to floating-point numbers.
p11875
aVThe floating-point representation is by far the most common way of representing in computers an approximation to real numbers. However, there are alternatives:
p11876
aVHistory.
p11877
aVIn 1914, Leonardo Torres y Quevedo designed an electro-mechanical version of Charles Babbage's Analytical Engine, and included floating-point arithmetic. 
p11878
aVIn 1938, Konrad Zuse of Berlin completed the Z1, the first binary, programmable mechanical computer; it uses a 24-bit binary floating-point number representation with a 7-bit signed exponent, a 16-bit significand (including one implicit bit), and a sign bit. The more reliable relay-based Z3, completed in 1941, has representations for both positive and negative infinities; in particular, it implements defined operations with infinity, such as formula_19, and it stops on undefined operations, such as formula_20.
p11879
aVZuse also proposed, but did not complete, carefully rounded floating-point arithmetic that includes formula_21 and NaN representations, anticipating features of the IEEE Standard by four decades. In contrast, von Neumann recommended against floating-point numbers for the 1951 IAS machine, arguing that fixed-point arithmetic is preferable.
p11880
aVThe first "commercial" computer with floating-point hardware was Zuse's Z4 computer, designed in 1942\u20131945. In 1946, Bell Laboratories introduced the Mark V, which implements decimal floating-point numbers.
p11881
aVThe Pilot ACE has binary floating-point arithmetic, and it became operational in 1950 at National Physical Laboratory, UK. 33 were later sold commercially as the English Electric DEUCE. The arithmetic is actually implemented in software, but with a one megahertz clock rate, the speed of floating-point and fixed-point operations in this machine were initially faster than those of many competing computers.
p11882
aVThe mass-produced IBM 704 followed in 1954; it introduced the use of a biased exponent. For many decades after that, floating-point hardware was typically an optional feature, and computers that had it were said to be "scientific computers", or to have "scientific computing" capability. It was not until the launch of the Intel i486 in 1989 that "general-purpose" personal computers had floating-point capability in hardware as a standard feature.
p11883
aVThe UNIVAC 1100/2200 series, introduced in 1962, supports two floating-point representations:
p11884
aVThe IBM 7094, also introduced in 1962, supports single-precision and double-precision representations, but with no relation to the UNIVAC's representations. Indeed, in 1964, IBM introduced proprietary floating-point representations in its System/360 mainframes; these same representations are still available for use in modern z/Architecture systems. However, in 1998, IBM included IEEE-compatible binary floating-point arithmetic to its mainframes; in 2005, IBM also added IEEE-compatible decimal floating-point arithmetic.
p11885
aVInitially, computers used many different representations for floating-point numbers. The lack of standardization at the mainframe level was an ongoing problem by the early 1970s for those writing and maintaining higher-level source code; these manufacturer floating-point standards differed in the word sizes, the representations, and the rounding behavior and general accuracy of operations. Floating-point compatibility across multiple computing systems was in desperate need of standardization by the early 1980s, leading to the creation of the IEEE-754 standard once the 32-bit (or 64-bit) word had become commonplace. This standard was significantly based on a proposal from Intel, which was designing the i8087 numerical coprocessor; Motorola, which was designing the 68000 around the same time, gave significant input as well.
p11886
aVIn 1989, mathematician and computer scientist William Kahan was honored with the Turing Award for being the primary architect behind this proposal; he was aided by his student (Jerome Coonen) and a visiting professor (Harold Stone).
p11887
aVAmong the x86 innovations are these:
p11888
aVRange of floating-point numbers.
p11889
aVA floating-point number consists of two fixed-point components, whose range depends exclusively on the number of bits or digits in their representation. Whereas components linearly depend on their range, the floating-point range linearly depends on the significant range and exponentially on the range of exponent component, which attaches outstandingly wider range to the number.
p11890
aVOn a typical computer system, a 'double precision' (64-bit) binary floating-point number has a coefficient of 53 bits (one of which is implied), an exponent of 11 bits, and one sign bit. Positive floating-point numbers in this format have an approximate range of 10\u2212308 to 10308, because the range of the exponent is [\u22121022,1023] and 308 is approximately log10(21023). The complete range of the format is from about \u221210308 through +10308 (see IEEE 754).
p11891
aVThe number of normalized floating-point numbers in a system F ("B", "P", "L", "U") (where "B" is the base of the system, "P" is the precision of the system to "P" numbers, "L" is the smallest exponent representable in the system, and "U" is the largest exponent used in the system) is:
p11892
aVformula_22.
p11893
aVThere is a smallest positive normalized floating-point number,
p11894
aVUnderflow level = UFL = formula_23
p11895
aVwhich has a 1 as the leading digit and 0 for the remaining digits of the significand, and the smallest possible value for the exponent.
p11896
aVThere is a largest floating-point number,
p11897
aVOverflow level = OFL = formula_24 which has "B" \u2212 1 as the value for each digit of the significand and the largest possible value for the exponent.
p11898
aVIn addition there are representable values strictly between \u2212UFL and UFL. Namely, positive and negative zeros, as well as denormalized numbers.
p11899
aVIEEE 754: floating point in modern computers.
p11900
aVThe IEEE has standardized the computer representation for binary floating-point numbers in IEEE 754 (a.k.a. IEC 60559). This standard is followed by almost all modern machines. IBM mainframes support IBM's own hexadecimal floating point format and IEEE 754-2008 decimal floating point in addition to the IEEE 754 binary format. The Cray T90 series had an IEEE version, but the SV1 still uses Cray floating-point format.
p11901
aVThe standard provides for many closely related formats, differing in only a few details. Five of these formats are called "basic formats" and others are termed "extended formats"; three of these are especially widely used in computer hardware and languages:
p11902
aVIncreasing the precision of the floating point representation generally reduces the amount of accumulated round-off error caused by intermediate calculations.
p11903
aVLess common IEEE formats include:
p11904
aVAny integer with absolute value less than 224 can be exactly represented in the single precision format, and any integer with absolute value less than 253 can be exactly represented in the double precision format. Furthermore, a wide range of powers of 2 times such a number can be represented. These properties are sometimes used for purely integer data, to get 53-bit integers on platforms that have double precision floats but only 32-bit integers.
p11905
aVThe standard specifies some special values, and their representation: positive infinity (+\u221e), negative infinity (\u2212\u221e), a negative zero (\u22120) distinct from ordinary ("positive") zero, and "not a number" values (NaNs).
p11906
aVComparison of floating-point numbers, as defined by the IEEE standard, is a bit different from usual integer comparison. Negative and positive zero compare equal, and every NaN compares unequal to every value, including itself. All values except NaN are strictly smaller than +\u221e and strictly greater than \u2212\u221e. Finite floating-point numbers are ordered in the same way as their values (in the set of real numbers).
p11907
aVA project for revising the IEEE 754 standard was started in 2000 (see IEEE 754 revision); it was completed and approved in June 2008. It includes decimal floating-point formats and a 16-bit floating-point format ("binary16"). binary16 has the same structure and rules as the older formats, with 1 sign bit, 5 exponent bits and 10 trailing significand bits. It is being used in the NVIDIA Cg graphics language, and in the openEXR standard.
p11908
aVInternal representation.
p11909
aVFloating-point numbers are typically packed into a computer datum as the sign bit, the exponent field, and the significand or mantissa, from left to right. For the IEEE 754 binary formats (basic and extended) which have extant hardware implementations, they are apportioned as follows:
p11910
aVWhile the exponent can be positive or negative, in binary formats it is stored as an unsigned number that has a fixed "bias" added to it. Values of all 0s in this field are reserved for the zeros and subnormal numbers; values of all 1s are reserved for the infinities and NaNs. The exponent range for normalized numbers is [\u2212126, 127] for single precision, [\u22121022, 1023] for double, or [\u221216382, 16383] for quad. Normalized numbers exclude subnormal values, zeros, infinities, and NaNs.
p11911
aVIn the IEEE binary interchange formats the leading 1 bit of a normalized significand is not actually stored in the computer datum. It is called the "hidden" or "implicit" bit. Because of this, single precision format actually has a significand with 24 bits of precision, double precision format has 53, and quad has 113.
p11912
aVFor example, it was shown above that \u03c0, rounded to 24 bits of precision, has:
p11913
aVThe sum of the exponent bias (127) and the exponent (1) is 128, so this is represented in single precision format as
p11914
aVPiecewise linear approximation to exponential and logarithm.
p11915
aVIf one graphs the floating point value of a bit pattern ("x"-axis is bit pattern, considered as integers, "y"-axis the value of the floating point number; assume positive), one obtains a piecewise linear approximation of a shifted and scaled exponential function with base 2, formula_25 (hence actually formula_26). Conversely, given a real number, if one takes the floating point representation and considers it as an integer, one gets a piecewise linear approximation of a shifted and scaled base 2 logarithm, formula_27 (hence actually formula_28), as shown at right.
p11916
aVThis interpretation is useful for visualizing how the values of floating point numbers vary with the representation, and allow for certain efficient approximations of floating point operations by integer operations and bit shifts. For example, reinterpreting a float as an integer, taking the negative (or rather subtracting from a fixed number, due to bias and implicit 1), then reinterpreting as a float yields the reciprocal. Explicitly, ignoring significand, taking the reciprocal is just taking the additive inverse of the (unbiased) exponent, since the exponent of the reciprocal is the negative of the original exponent. (Hence actually subtracting the exponent from twice the bias, which corresponds to unbiasing, taking negative, and then biasing.) For the significand, near 1 the reciprocal is approximately linear: formula_29 (since the derivative is formula_30; this is the first term of the Taylor series), and thus for the significand as well, taking the negative (or rather subtracting from a fixed number to handle the implicit 1) is approximately taking the reciprocal.
p11917
aVMore significantly, bit shifting allows one to compute the square (shift left by 1) or take the square root (shift right by 1). This leads to approximate computations of the square root; combined with the previous technique for taking the inverse, this allows the fast inverse square root computation, which was important in graphics processing in the late 1980s and 1990s. This can be exploited in some other applications, such as volume ramping in digital sound processing.
p11918
aVConcretely, each time the exponent increments, the value doubles (hence grows exponentially), while each time the significand increments (for a given exponent), the value increases by formula_31 (hence grows linearly, with slope equal to the actual (unbiased) value of the exponent). This holds even for the last step from a given exponent, where the significand overflows into the exponent: with the implicit 1, the number after 1.11...1 is 2.0 (regardless of the exponent), i.e., an increment of the exponent:
p11919
aV(0...001)0...0 through (0...001)1...1, (0...010)0...0 are equal steps (linear)
p11920
aVThus as a graph it is linear pieces (as the significand grows for a given exponent) connecting the evenly spaced powers of two (when the significand is 0), with each linear piece having twice the slope of the previous: it is approximately a scaled and shifted exponential formula_32. Each piece takes the same horizontal space, but twice the vertical space of the last. Because the exponent is convex up, the value is always "greater" than or equal to the actual (shifted and scaled) exponential curve through the points with significand 0; by a slightly different shift one can more closely approximate an exponential, sometimes overestimating, sometimes underestimating. Conversely, interpreting a floating point number as an integer gives an approximate shifted and scaled logarithm, with each piece having half the slope of the last, taking the same vertical space but twice the horizontal space. Since the logarithm is convex down, the approximation is always "less" than the corresponding logarithmic curve; again, a different choice of scale and shift (as at above right) yields a closer approximation.
p11921
aVSpecial values.
p11922
aVSigned zero.
p11923
aVIn the IEEE 754 standard, zero is signed, meaning that there exist both a "positive zero" (+0) and a "negative zero" (\u22120). In most run-time environments, positive zero is usually printed as "0", while negative zero may be printed as "-0". The two values behave as equal in numerical comparisons, but some operations return different results for +0 and \u22120. For instance, 1/(\u22120) returns negative infinity, while 1/+0 returns positive infinity (so that the identity 1/(1/±\u221e) = ±\u221e is maintained). Other common functions with a discontinuity at x=0 which might treat +0 and \u22120 differently include log(x), signum(x), and the principal square root of for any negative number y. As with any approximation scheme, operations involving "negative zero" can occasionally cause confusion. For example, in IEEE 754, x = y does not imply 1/x = 1/y, as 0 = \u22120 but 1/0 \u2260 1/\u22120.
p11924
aVSubnormal numbers.
p11925
aVSubnormal values fill the underflow gap with values
p11926
aVwhere the absolute distance between them are the same as for
p11927
aVadjacent values just outside of the underflow gap.
p11928
aVThis is an improvement over the older practice to just have zero in the underflow gap,
p11929
aVand where underflowing results were replaced by zero (flush to zero).
p11930
aVModern floating-point hardware usually handles subnormal values (as well as normal values),
p11931
aVand does not require software emulation for subnormals.
p11932
aVInfinities.
p11933
aVThe infinities of the extended real number line can be represented in IEEE floating-point datatypes,
p11934
aVjust like ordinary floating-point values like 1, 1.5, etc.
p11935
aVThey are not error values in any way, though they are often (but not always, as it depends on the rounding) used as
p11936
aVreplacement values when there is an overflow. Upon a divide-by-zero exception,
p11937
aVa positive or negative infinity is returned as an exact result. An infinity can also be introduced as
p11938
aVa numeral (like C's "INFINITY" macro, or "\u221e" if the programming language allows that syntax).
p11939
aVIEEE 754 requires infinities to be handled in a reasonable way, such as
p11940
aVNaNs.
p11941
aVIEEE 754 specifies a special value called "Not a Number" (NaN) to be returned as the result of certain "invalid" operations, such as 0/0, \u221e×0, or sqrt(\u22121). In general, NaNs will be propagated i.e. most operations involving a NaN will result in a NaN, although functions that would give some defined result for any given floating-point value will do so for NaNs as well, e.g. NaN ^ 0 = 1. There are two kinds of NaNs: the default "quiet" NaNs and, optionally, "signaling" NaNs. A signaling NaN in any arithmetic operation (including numerical comparisons) will cause an "invalid" exception to be signaled.
p11942
aVThe representation of NaNs specified by the standard has some unspecified bits that could be used to encode the type or source of error; but there is no standard for that encoding. In theory, signaling NaNs could be used by a runtime system to flag uninitialized variables, or extend the floating-point numbers with other special values without slowing down the computations with ordinary values, although such extensions are not common.
p11943
aVIEEE 754 design rationale.
p11944
aVIt is a common misconception that the more esoteric features of the IEEE 754 standard discussed here, such as extended formats, NaN, infinities, subnormals etc., are only of interest to numerical analysts, or for advanced numerical applications; in fact the opposite is true: these features are designed to give safe robust defaults for numerically unsophisticated programmers, in addition to supporting sophisticated numerical libraries by experts. The key designer of IEEE 754, William Kahan notes that it is incorrect to "... features of IEEE Standard 754 for Binary Floating- Point Arithmetic that ...[are not appreciated to be features usable by none but numerical experts. The facts are quite the opposite. In 1977 those features were designed into the Intel 8087 to serve the widest possible market... . Error-analysis tells us how to design floating-point arithmetic, like IEEE Standard 754, moderately tolerant of well-meaning ignorance among programmers".
p11945
aVRepresentable numbers, conversion and rounding.
p11946
aVBy their nature, all numbers expressed in floating-point format are rational numbers with a terminating expansion in the relevant base (for example, a terminating decimal expansion in base-10, or a terminating binary expansion in base-2). Irrational numbers, such as \u03c0 or \u221a2, or non-terminating rational numbers, must be approximated. The number of digits (or bits) of precision also limits the set of rational numbers that can be represented exactly. For example, the number 123456789 cannot be exactly represented if only eight decimal digits of precision are available.
p11947
aVWhen a number is represented in some format (such as a character string) which is not a native floating-point representation supported in a computer implementation, then it will require a conversion before it can be used in that implementation. If the number can be represented exactly in the floating-point format then the conversion is exact. If there is not an exact representation then the conversion requires a choice of which floating-point number to use to represent the original value. The representation chosen will have a different value to the original, and the value thus adjusted is called the "rounded value".
p11948
aVWhether or not a rational number has a terminating expansion depends on the base. For example, in base-10 the number 1/2 has a terminating expansion (0.5) while the number 1/3 does not (0.333...). In base-2 only rationals with denominators that are powers of 2 (such as 1/2 or 3/16) are terminating. Any rational with a denominator that has a prime factor other than 2 will have an infinite binary expansion. This means that numbers which appear to be short and exact when written in decimal format may need to be approximated when converted to binary floating-point. For example, the decimal number 0.1 is not representable in binary floating-point of any finite precision; the exact binary representation would have a "1100" sequence continuing endlessly:
p11949
aV"e" = \u22124; "s" = 1100110011001100110011001100110011...,
p11950
aVwhere, as previously, "s" is the significand and "e" is the exponent.
p11951
aVWhen rounded to 24 bits this becomes
p11952
aV"e" = \u22124; "s" = 110011001100110011001101,
p11953
aVwhich is actually 0.100000001490116119384765625 in decimal.
p11954
aVAs a further example, the real number \u03c0, represented in binary as an infinite sequence of bits is
p11955
aV11.0010010000111111011010101000100010000101101000110000100011010011...
p11956
aVbut is
p11957
aV11.0010010000111111011011
p11958
aVwhen approximated by rounding to a precision of 24 bits.
p11959
aVIn binary single-precision floating-point, this is represented as "s" = 1.10010010000111111011011 with "e" = 1.
p11960
aVThis has a decimal value of
p11961
aV3.1415927410125732421875,
p11962
aVwhereas a more accurate approximation of the true value of \u03c0 is
p11963
aV3.14159265358979323846264338327950...
p11964
aVThe result of rounding differs from the true value by about 0.03 parts per million, and matches the decimal representation of \u03c0 in the first 7 digits. The difference is the discretization error and is limited by the machine epsilon.
p11965
aVThe arithmetical difference between two consecutive representable floating-point numbers which have the same exponent is called a unit in the last place (ULP). For example, if there is no representable number lying between the representable numbers 1.45a70c22hex and 1.45a70c24hex, the ULP is 2×16\u22128, or 2\u221231. For numbers with a base-2 exponent part of 0, i.e. numbers with an absolute value higher than or equal to 1 but lower than 2, an ULP is exactly 2\u221223 or about 10\u22127 in single precision, and exactly 2\u221253 or about 10\u221216 in double precision. The mandated behavior of IEEE-compliant hardware is that the result be within one-half of a ULP.
p11966
aVRounding modes.
p11967
aVRounding is used when the exact result of a floating-point operation (or a conversion to floating-point format) would need more digits than there are digits in the significand. IEEE 754 requires "correct rounding": that is, the rounded result is as if infinitely precise arithmetic was used to compute the value and then rounded (although in implementation only three extra bits are needed to ensure this). There are several different rounding schemes (or "rounding modes"). Historically, truncation was the typical approach. Since the introduction of IEEE 754, the default method ("round to nearest, ties to even", sometimes called Banker's Rounding) is more commonly used. This method rounds the ideal (infinitely precise) result of an arithmetic operation to the nearest representable value, and gives that representation as the result. In the case of a tie, the value that would make the significand end in an even digit is chosen. The IEEE 754 standard requires the same rounding to be applied to all fundamental algebraic operations, including square root and conversions, when there is a numeric (non-NaN) result. It means that the results of IEEE 754 operations are completely determined in all bits of the result, except for the representation of NaNs. ("Library" functions such as cosine and log are not mandated.)
p11968
aVAlternative rounding options are also available. IEEE 754 specifies the following rounding modes:
p11969
aVAlternative modes are useful when the amount of error being introduced must be bounded. Applications that require a bounded error are multi-precision floating-point, and interval arithmetic.
p11970
aVThe alternative rounding modes are also useful in diagnosing numerical instability: if the results of a subroutine vary substantially between rounding to + and - infinity then it is likely numerically unstable and affected by round-off error.
p11971
aVFloating-point arithmetic operations.
p11972
aVFor ease of presentation and understanding, decimal radix with 7 digit precision will be used in the examples, as in the IEEE 754 "decimal32" format. The fundamental principles are the same in any radix or precision, except that normalization is optional (it does not affect the numerical value of the result). Here, "s" denotes the significand and "e" denotes the exponent.
p11973
aVAddition and subtraction.
p11974
aVA simple method to add floating-point numbers is to first represent them with the same exponent. In the example below, the second number is shifted right by three digits, and we then proceed with the usual addition method:
p11975
aVIn detail:
p11976
aVThis is the true result, the exact sum of the operands. It will be rounded to seven digits and then normalized if necessary. The final result is
p11977
aVNote that the low three digits of the second operand (654) are essentially lost. This is round-off error. In extreme cases, the sum of two non-zero numbers may be equal to one of them:
p11978
aVNote that in the above conceptual examples it would appear that a large number of extra digits would need to be provided by the adder to ensure correct rounding: in fact for binary addition or subtraction using careful implementation techniques only two extra "guard" bits and one extra "sticky" bit need to be carried beyond the precision of the operands.
p11979
aVAnother problem of loss of significance occurs when two close numbers are subtracted. In the following example "e" = 5; "s" = 1.234571 and "e" = 5; "s" = 1.234567 are representations of the rationals 123457.1467 and 123456.659.
p11980
aVThe best representation of this difference is "e" = \u22121; "s" = 4.877000, which differs more than 20% from "e" = \u22121; "s" = 4.000000. In extreme cases, all significant digits of precision can be lost (although gradual underflow ensures that the result will not be zero unless the two operands were equal). This "cancellation" illustrates the danger in assuming that all of the digits of a computed result are meaningful. Dealing with the consequences of these errors is a topic in numerical analysis; see also Accuracy problems.
p11981
aVMultiplication and division.
p11982
aVTo multiply, the significands are multiplied while the exponents are added, and the result is rounded and normalized.
p11983
aVSimilarly, division is accomplished by subtracting the divisor's exponent from the dividend's exponent, and dividing the dividend's significand by the divisor's significand.
p11984
aVThere are no cancellation or absorption problems with multiplication or division, though small errors may accumulate as operations are performed in succession. In practice, the way these operations are carried out in digital logic can be quite complex (see Booth's multiplication algorithm and Division algorithm).
p11985
aVFor a fast, simple method, see the Horner method.
p11986
aVDealing with exceptional cases.
p11987
aVFloating-point computation in a computer can run into three kinds of problems:
p11988
aVPrior to the IEEE standard, such conditions usually caused the program to terminate, or triggered some kind
p11989
aVof trap that the programmer might be able to catch. How this worked was system-dependent,
p11990
aVmeaning that floating-point programs were not portable. (Note that the term "exception" as used in IEEE-754 is a general term meaning an exceptional condition, which is not necessarily an error, and is a different usage to that typically defined in programming languages such as a C++ or Java, in which an "exception" is an alternative flow of control, closer to what is termed a "trap" in IEEE-754 terminology).
p11991
aVHere, the required default method of handling exceptions according to IEEE 754 is discussed (the IEEE-754 optional trapping and other "alternate exception handling" modes are not discussed). Arithmetic exceptions are (by default) required to be recorded in "sticky" status flag bits. That they are "sticky" means that they are not reset by the next (arithmetic) operation, but stay set until explicitly reset. The use of "sticky" flags thus allows for testing of exceptional conditions to be delayed until after a full floating-point expression or subroutine: without them exceptional conditions that could not be otherwise ignored would require explicit testing immediately after every floating-point operation. By default, an operation always returns a result according to specification without interrupting computation. For instance, 1/0 returns +\u221e, while also setting the divide-by-zero flag bit (this default of \u221e is designed so as to often return a finite result when used in subsequent operations and so be safely ignored).
p11992
aVThe original IEEE 754 standard, however, failed to recommend operations to handle such sets of arithmetic exception flag bits. So while these were implemented in hardware, initially programming language implementations typically did not provide a means to access them (apart from assembler). Over time some programming language standards (e.g., C99/C11 and Fortran) have been updated to specify methods to access and change status flag bits. The 2008 version of the IEEE 754 standard now specifies a few operations for accessing and handling the arithmetic flag bits. The programming model is based on a single thread of execution and use of them by multiple threads has to be handled by a means outside of the standard (e.g. C11 specifies that the flags have thread-local storage).
p11993
aVIEEE 754 specifies five arithmetic exceptions that are to be recorded in the status flags ("sticky bits"):
p11994
aV default return value for each of the exceptions is designed to give the correct result in the majority of cases such that the exceptions can be ignored in the majority of codes. "inexact" returns a correctly rounded result, and "underflow" returns a denormalized small value and so can almost always be ignored. "divide-by-zero" returns infinity exactly, which will typically then divide a finite number and so give zero, or else will give an "invalid" exception subsequently if not, and so can also typically be ignored. For example, the effective resistance of n resistors in parallel (see fig. 1) is given by formula_33. If a short-circuit develops with formula_34 set to 0, formula_35 will return +infinity which will give a final formula_36 of 0, as expected (see the continued fraction example of for another example).
p11995
aV"Overflow" and "invalid" exceptions can typically not be ignored, but do not necessarily represent errors: for example, a root-finding routine, as part of its normal operation, may evaluate a passed-in function at values outside of its domain, returning NaN and an "invalid" exception flag to be ignored until finding a useful start point.
p11996
aVAccuracy problems.
p11997
aVThe fact that floating-point numbers cannot precisely represent all real numbers, and that floating-point operations cannot precisely represent true arithmetic operations, leads to many surprising situations. This is related to the finite precision with which computers generally represent numbers.
p11998
aVFor example, the non-representability of 0.1 and 0.01 (in binary) means that the result of attempting to square 0.1 is neither 0.01 nor the representable number closest to it. In 24-bit (single precision) representation, 0.1 (decimal) was given previously as "e" = \u22124; "s" = 110011001100110011001101, which is
p11999
aV0.100000001490116119384765625 exactly.
p12000
aVSquaring this number gives
p12001
aV0.010000000298023226097399174250313080847263336181640625 exactly.
p12002
aVSquaring it with single-precision floating-point hardware (with rounding) gives
p12003
aV0.010000000707805156707763671875 exactly.
p12004
aVBut the representable number closest to 0.01 is
p12005
aV0.009999999776482582092285156250 exactly.
p12006
aVAlso, the non-representability of \u03c0 (and \u03c0/2) means that an attempted computation of tan(\u03c0/2) will not yield a result of infinity, nor will it even overflow. It is simply not possible for standard floating-point hardware to attempt to compute tan(\u03c0/2), because \u03c0/2 cannot be represented exactly. This computation in C:
p12007
aVwill give a result of 16331239353195370.0. In single precision (using the tanf function), the result will be \u221222877332.0.
p12008
aVBy the same token, an attempted computation of sin(\u03c0) will not yield zero. The result will be (approximately) 0.1225 in double precision, or \u22120.8742 in single precision.
p12009
aVWhile floating-point addition and multiplication are both commutative ("a" + "b" = "b" + "a" and "a"×"b" = "b"×"a"), they are not necessarily associative. That is, ("a" + "b") + "c" is not necessarily equal to "a" + ("b" + "c"). Using 7-digit significand decimal arithmetic:
p12010
aVThey are also not necessarily distributive. That is, ("a" + "b") ×"c" may not be the same as "a"×"c" + "b"×"c":
p12011
aVIn addition to loss of significance, inability to represent numbers such as \u03c0 and 0.1 exactly, and other slight inaccuracies, the following phenomena may occur:
p12012
aVformula_37
p12013
aVIntuitively one would want an "h" very close to zero, however when using floating-point operations, the smallest number won't give the best approximation of a derivative. As "h" grows smaller the difference between f (a + h) and f(a) grows smaller, cancelling out the most significant and least erroneous digits and making the most erroneous digits more important. As a result the smallest number of "h" possible will give a more erroneous approximation of a derivative than a somewhat larger number. This is perhaps the most common and serious accuracy problem.
p12014
aVMachine precision and backward error analysis.
p12015
aV"Machine precision" is a quantity that characterizes the accuracy of a floating-point system, and is used in backward error analysis of floating-point algorithms. It is also known as unit roundoff or "machine epsilon". Usually denoted \u0395mach, its value depends on the particular rounding being used.
p12016
aVWith rounding to zero,
p12017
aVformula_38
p12018
aVwhereas rounding to nearest,
p12019
aVformula_39
p12020
aVThis is important since it bounds the "relative error" in representing any non-zero real number x within the normalized range of a floating-point system:
p12021
aVformula_40
p12022
aVBackward error analysis, the theory of which was developed and popularized by James H. Wilkinson, can be used to establish that an algorithm implementing a numerical function is numerically stable. The basic approach is to show that although the calculated result, due to roundoff errors, will not be exactly correct, it is the exact solution to a nearby problem with slightly perturbed input data. If the perturbation required is small, on the order of the uncertainty in the input data, then the results are in some sense as accurate as the data "deserves". The algorithm is then defined as "backward stable". Stability is a measure of the sensitivity to rounding errors of a given numerical procedure; by contrast, the condition number of a function for a given problem indicates the inherent sensitivity of the function to small perturbations in its input and is independent of the implementation used to solve the problem.
p12023
aVAs a trivial example, consider a simple expression giving the inner product of (length two) vectors formula_41 and formula_42, then
p12024
aVformula_43 where formula_44 indicates correctly rounded floating-point arithmetic
p12025
aV::formula_45 where formula_46, from above
p12026
aV::formula_47
p12027
aV::formula_48
p12028
aVand so
p12029
aVformula_49 where
p12030
aVformula_50; formula_51;
p12031
aVformula_52; formula_53
p12032
aVwhere formula_46, by definition 
p12033
aVwhich is the sum of two slightly perturbed (on the order of \u0395mach) input data, and so is backward stable. For more realistic examples in numerical linear algebra see Higham 2002 and other references below).
p12034
aVMinimizing the effect of accuracy problems.
p12035
aVAlthough, as noted previously, individual arithmetic operations of IEEE 754 are guaranteed accurate to within half a ULP, more complicated formulae can suffer from larger errors due to round-off. The loss of accuracy can be substantial if a problem or its data are ill-conditioned, meaning that the correct result is hypersensitive to tiny perturbations in its data. However, even functions that are well-conditioned can suffer from large loss of accuracy if an algorithm numerically unstable for that data is used: apparently equivalent formulations of expressions in a programming language can differ markedly in their numerical stability. One approach to remove the risk of such loss of accuracy is the design and analysis of numerically stable algorithms, which is an aim of the branch of mathematics known as numerical analysis. Another approach that can protect against the risk of numerical instabilities is the computation of intermediate (scratch) values in an algorithm at a higher precision than the final result requires, which can remove, or reduce by orders of magnitude, such risk: IEEE 754 quadruple precision and extended precision are designed for this purpose when computing at double precision.
p12036
aVFor example, the following algorithm is a direct implementation to compute the function A(x) = (x\u20131)/( exp(x\u20131) \u2013 1) which is well-conditioned at 1.0, however it can be shown to be numerically unstable and lose up to half the significant digits carried by the arithmetic when computed near 1.0. 
p12037
aVIf, however, intermediate computations are all performed in extended precision (e.g. by setting line to C99 long double), then up to full precision in the final double result can be maintained. Alternatively, a numerical analysis of the algorithm reveals that if the following non-obvious change to line [2 is made:
p12038
aVthen the algorithm becomes numerically stable and can compute to full double precision.
p12039
aVTo maintain the properties of such carefully constructed numerically stable programs, careful handling by the compiler is required. Certain "optimizations" that compilers might make (for example, reordering operations) can work against the goals of well-behaved software. There is some controversy about the failings of compilers and language designs in this area: C99 is an example of a language where such optimizations are carefully specified so as to maintain numerical precision. See the external references at the bottom of this article.
p12040
aVA detailed treatment of the techniques for writing high-quality floating-point software is beyond the scope of this article, and the reader is referred to, and the other references at the bottom of this article. Kahan suggests several rules of thumb that can substantially decrease by orders of magnitude the risk of numerical anomalies, in addition to, or in lieu of, a more careful numerical analysis. These include: as noted above, computing all expressions and intermediate results in the highest precision supported in hardware (a common rule of thumb is to carry twice the precision of the desired result i.e. compute in double precision for a final single precision result, or in double extended or quad precision for up to double precision results); and rounding input data and results to only the precision required and supported by the input data (carrying excess precision in the final result beyond that required and supported by the input data can be misleading, increases storage cost and decreases speed, and the excess bits can affect convergence of numerical procedures: notably, the first form of the iterative example given below converges correctly when using this rule of thumb). Brief descriptions of several additional issues and techniques follow.
p12041
aVAs decimal fractions can often not be exactly represented in binary floating-point, such arithmetic is at its best when it is simply being used to measure real-world quantities over a wide range of scales (such as the orbital period of a moon around Saturn or the mass of a proton), and at its worst when it is expected to model the interactions of quantities expressed as decimal strings that are expected to be exact. An example of the latter case is financial calculations. For this reason, financial software tends not to use a binary floating-point number representation. The "decimal" data type of the C# and Python programming languages, and the decimal formats of the IEEE 754-2008 standard, are designed to avoid the problems of binary floating-point representations when applied to human-entered exact decimal values, and make the arithmetic always behave as expected when numbers are printed in decimal.
p12042
aVExpectations from mathematics may not be realized in the field of floating-point computation. For example, it is known that formula_55, and that formula_56, however these facts cannot be relied on when the quantities involved are the result of floating-point computation.
p12043
aVThe use of the equality test (codice_1) requires care when dealing with floating-point numbers. Even simple expressions like codice_2 will, on most computers, fail to be true (in IEEE 754 double precision, for example, codice_3 is approximately equal to -4.44089209850063e-16). Consequently, such tests are sometimes replaced with "fuzzy" comparisons (codice_4, where epsilon is sufficiently small and tailored to the application, such as 1.0E\u221213). The wisdom of doing this varies greatly, and can require numerical analysis to bound epsilon. Values derived from the primary data representation and their comparisons should be performed in a wider, extended, precision to minimize the risk of such inconsistencies due to round-off errors. It is often better to organize the code in such a way that such tests are unnecessary. For example, in computational geometry, exact tests of whether a point lies off or on a line or plane defined by other points can be performed using adaptive precision or exact arithmetic methods.
p12044
aVSmall errors in floating-point arithmetic can grow when mathematical algorithms perform operations an enormous number of times. A few examples are matrix inversion, eigenvector computation, and differential equation solving. These algorithms must be very carefully designed, using numerical approaches such as Iterative refinement, if they are to work well.
p12045
aVSummation of a vector of floating-point values is a basic algorithm in scientific computing, and so an awareness of when loss of significance can occur is essential. For example, if one is adding a very large number of numbers, the individual addends are very small compared with the sum. This can lead to loss of significance. A typical addition would then be something like
p12046
aVThe low 3 digits of the addends are effectively lost. Suppose, for example, that one needs to add many numbers, all approximately equal to 3. After 1000 of them have been added, the running sum is about 3000; the lost digits are not regained. The Kahan summation algorithm may be used to reduce the errors.
p12047
aVRound-off error can affect the convergence and accuracy of iterative numerical procedures. As an example, Archimedes approximated \u03c0 by calculating the perimeters of polygons inscribing and circumscribing a circle, starting with hexagons, and successively doubling the number of sides. As noted above, computations may be rearranged in a way that is mathematically equivalent but less prone to error (numerical analysis). 
p12048
aVTwo forms of the recurrence formula for the circumscribed polygon are:
p12049
aVformula_57
p12050
aVformula_58
p12051
aVformula_59
p12052
aVHere is a computation using IEEE "double" (a significand with 53 bits of precision) arithmetic:
p12053
aVWhile the two forms of the recurrence formula are clearly mathematically equivalent, the first subtracts 1 from a number extremely close to 1, leading to an increasingly problematic loss of significant digits. As the recurrence is applied repeatedly, the accuracy improves at first, but then it deteriorates. It never gets better than about 8 digits, even though 53-bit arithmetic should be capable of about 16 digits of precision. When the second form of the recurrence is used, the value converges to 15 digits of precision.
p12054
asS'Counting'
p12055
(lp12056
VCounting is the action of finding the number of elements of a finite set of objects. The traditional way of counting consists of continually increasing a (mental or spoken) counter by a unit for every element of the set, in some order, while marking (or displacing) those elements to avoid visiting the same element more than once, until no unmarked elements are left; if the counter was set to one after the first object, the value after visiting the final object gives the desired number of elements. The related term "enumeration" refers to uniquely identifying the elements of a finite (combinatorial) set or infinite set by assigning a number to each element.
p12057
aVCounting sometimes involves numbers other than one; for example, when counting money, counting out change, "counting by twos" (2, 4, 6, 8, 10, 12, ...), or "counting by fives" (5, 10, 15, 20, 25, ...).
p12058
aVThere is archeological evidence suggesting that humans have been counting for at least 50,000 years. Counting was primarily used by ancient cultures to keep track of social and economic data such as number of group members, prey animals, property, or debts (i.e., accountancy). The development of counting led to the development of mathematical notation, numeral systems, and writing.
p12059
aVForms of counting.
p12060
aVCounting can occur in a variety of forms.
p12061
aVCounting can be verbal; that is, speaking every number out loud (or mentally) to keep track of progress. This is often used to count objects that are present already, instead of counting a variety of things over time.
p12062
aVCounting can also be in the form of tally marks, making a mark for each number and then counting all of the marks when done tallying. This is useful when counting objects over time, such as the number of times something occurs during the course of a day. Tallying is base 1 counting; normal counting is done in base 10. Computers use base 2 counting (0's and 1's).
p12063
aVCounting can also be in the form of finger counting, especially when counting small numbers. This is often used by children to facilitate counting and simple mathematical operations. Finger-counting uses unary notation (one finger = one unit), and is thus limited to counting 10 (unless you start in with your toes). Older finger counting used the four fingers and the three bones in each finger(phalanges) to count to the number twelve. Other hand-gesture systems are also in use, for example the Chinese system by which one can count 10 using only gestures of one hand. By using finger binary (base 2 counting), it is possible to keep a finger count up to .
p12064
aVVarious devices can also be used to facilitate counting, such as hand tally counters and abacuses.
p12065
aVInclusive counting.
p12066
aVInclusive counting is usually encountered when counting days in a calendar. Normally when counting "8" days from Sunday, Monday will be "day 1", Tuesday "day 2", and the following Monday will be the "eighth day". When counting "inclusively," the Sunday (the start day) will be "day 1" and therefore the following Sunday will be the "eighth day". For example, the French phrase for "fortnight" is "quinzaine" (15 ), and similar words are present in Greek (\u03b4\u03b5\u03ba\u03b1\u03c0\u03b5\u03bd\u03b8\u03ae\u03bc\u03b5\u03c1\u03bf, "dekapenthímero"), Spanish ("quincena") and Portuguese ("quinzena") - whereas "a fortnight" derives from "a fourteen-night", as the archaic "a sennight" does from "a seven-night". This practice appears in other calendars as well; in the Roman calendar the "nones" (meaning "nine") is 8 days before the "ides"; and in the Christian calendar Quinquagesima (meaning 50) is 49 days before Easter Sunday.
p12067
aVMusical terminology also uses inclusive counting of intervals between notes of the standard scale: going up one note is a second interval, going up two notes is a third interval, etc., and going up seven notes is an octave.
p12068
aVEducation and development.
p12069
aVLearning to count is an important educational/developmental milestone in most cultures of the world. Learning to count is a child's very first step into mathematics, and constitutes the most fundamental idea of that discipline. However, some cultures in Amazonia and the Australian Outback do not count, and their languages do not have number words.
p12070
aVMany children at just 2 years of age have some skill in reciting the count list (i.e., saying "one, two, three, ..."). They can also answer questions of ordinality for small numbers, e.g., "What comes after "three"?". They can even be skilled at pointing to each object in a set and reciting the words one after another. This leads many parents and educators to the conclusion that the child knows how to use counting to determine the size of a set. Research suggests that it takes about a year after learning these skills for a child to understand what they mean and why the procedures are performed. In the mean time, children learn how to name cardinalities that they can subitize.
p12071
aVCounting in mathematics.
p12072
aVIn mathematics, the essence of counting a set and finding a result "n", is that it establishes a one to one correspondence (or bijection) of the set with the set of numbers {1, 2, ..., "n"}. A fundamental fact, which can be proved by mathematical induction, is that no bijection can exist between {1, 2, ..., "n"} and {1, 2, ..., "m"} unless "n" = "m"; this fact (together with the fact that two bijections can be composed to give another bijection) ensures that counting the same set in different ways can never result in different numbers (unless an error is made). This is the fundamental mathematical theorem that gives counting its purpose; however you count a (finite) set, the answer is the same. In a broader context, the theorem is an example of a theorem in the mathematical field of (finite) combinatorics\u2014hence (finite) combinatorics is sometimes referred to as "the mathematics of counting."
p12073
aVMany sets that arise in mathematics do not allow a bijection to be established with {1, 2, ..., "n"} for "any" natural number "n"; these are called infinite sets, while those sets for which such a bijection does exist (for some "n") are called finite sets. Infinite sets cannot be counted in the usual sense; for one thing, the mathematical theorems which underlie this usual sense for finite sets are false for infinite sets. Furthermore, different definitions of the concepts in terms of which these theorems are stated, while equivalent for finite sets, are inequivalent in the context of infinite sets.
p12074
aVThe notion of counting may be extended to them in the sense of establishing (the existence of) a bijection with some well understood set. For instance, if a set can be brought into bijection with the set of all natural numbers, then it is called "countably infinite." This kind of counting differs in a fundamental way from counting of finite sets, in that adding new elements to a set does not necessarily increase its size, because the possibility of a bijection with the original set is not excluded. For instance, the set of all integers (including negative numbers) can be brought into bijection with the set of natural numbers, and even seemingly much larger sets like that of all finite sequences of rational numbers are still (only) countably infinite. Nevertheless there are sets, such as the set of real numbers, that can be shown to be "too large" to admit a bijection with the natural numbers, and these sets are called "uncountable." Sets for which there exists a bijection between them are said to have the same cardinality, and in the most general sense counting a set can be taken to mean determining its cardinality. Beyond the cardinalities given by each of the natural numbers, there is an infinite hierarchy of infinite cardinalities, although only very few such cardinalities occur in ordinary mathematics (that is, outside set theory that explicitly studies possible cardinalities).
p12075
aVCounting, mostly of finite sets, has various applications in mathematics. One important principle is that if two sets "X" and "Y" have the same finite number of elements, and a function is known to be injective, then it is also surjective, and vice versa. A related fact is known as the pigeonhole principle, which states that if two sets "X" and "Y" have finite numbers of elements "n" and "m" with "n" > "m", then any map is "not" injective (so there exist two distinct elements of "X" that "f" sends to the same element of "Y"); this follows from the former principle, since if "f" were injective, then so would its restriction to a strict subset "S" of "X" with "m" elements, which restriction would then be surjective, contradicting the fact that for "x" in "X" outside "S", "f"("x") cannot be in the image of the restriction. Similar counting arguments can prove the existence of certain objects without explicitly providing an example. In the case of infinite sets this can even apply in situations where it is impossible to give an example; for instance there must exists real numbers that are not computable numbers, because the latter set is only countably infinite, but by definition a non-computable number cannot be precisely specified.
p12076
aVThe domain of enumerative combinatorics deals with computing the number of elements of finite sets, without actually counting them; the latter usually being impossible because infinite families of finite sets are considered at once, such as the set of permutations of {1, 2, ..., "n"} for any natural number "n".
p12077
asS'Ordered pair'
p12078
(lp12079
VIn mathematics, an ordered pair ("a", "b") is a pair of mathematical objects. The order in which the objects appear in the pair is significant: the ordered pair ("a", "b") is different from the ordered pair ("b", "a") unless "a" = "b". (In contrast, the unordered pair {"a", "b"} equals the unordered pair {"b", "a"}.)
p12080
aVOrdered pairs are also called 2-tuples, or sequences of length 2; ordered pairs of scalars are also called 2-dimensional vectors.
p12081
aVThe entries of an ordered pair can be other ordered pairs, enabling the recursive definition of ordered "n"-tuples (ordered lists of "n" objects). For example, the ordered triple ("a","b","c") can be defined as ("a", ("b","c")), i.e., as one pair nested in another.
p12082
aVIn the ordered pair ("a", "b"), the object "a" is called the "first entry", and the object "b" the "second entry" of the pair. Alternatively, the objects are called the first and second "coordinates", or the left and right "projections" of the ordered pair.
p12083
aVCartesian products and binary relations (and hence functions) are defined in terms of ordered pairs.
p12084
aVGeneralities.
p12085
aVLet formula_1 and formula_2 be ordered pairs. Then the characteristic (or "defining") property of the ordered pair is:
p12086
aVformula_3
p12087
aVThe set of all ordered pairs whose first entry is in some set "A" and whose second entry is in some set "B" is called the Cartesian product of "A" and "B", and written "A" × "B". A binary relation between sets "A" and "B" is a subset of "A" × "B".
p12088
aVIf one wishes to employ the formula_4 notation for a different purpose (such as denoting open intervals on the real number line) the ordered pair may be denoted by the variant notation formula_5
p12089
aVThe left and right projection of a pair "p" is usually denoted by "\u03c0"1("p") and "\u03c0"2("p"), or by "\u03c0""l"("p") and "\u03c0""r"("p"), respectively.
p12090
aVIn contexts where arbitrary "n"-tuples are considered, "\u03c0""n""i"("t") is a common notation for the "i"-th component of an "n" tuple "t".
p12091
aVDefining the ordered pair using set theory.
p12092
aVThe above characteristic property of ordered pairs is all that is required to understand the role of ordered pairs in mathematics. Hence the ordered pair can be taken as a primitive notion, whose associated axiom is the characteristic property. This was the approach taken by the N. Bourbaki group in its "Theory of Sets", published in 1954, long after Kuratowski discovered his reduction (below). The Kuratowski definition was added in the second edition of "Theory of Sets", published in 1970.
p12093
aVIf one agrees that set theory is an appealing foundation of mathematics, then all mathematical objects must be defined as sets of some sort. Hence if the ordered pair is not taken as primitive, it must be defined as a set. Several set-theoretic definitions of the ordered pair are given below.
p12094
aVWiener's definition.
p12095
aVNorbert Wiener proposed the first set theoretical definition of the ordered pair in 1914:
p12096
aVformula_6
p12097
aVHe observed that this definition made it possible to define the types of "Principia Mathematica" as sets. "Principia Mathematica" had taken types, and hence relations of all arities, as primitive.
p12098
aVWiener used instead of {"b"} to make the definition compatible with type theory where all elements in a class must be of the same "type". With nesting "b" within an additional set its type is made equal to formula_7's.
p12099
aVHausdorff's definition.
p12100
aVAbout the same time as Wiener (1914), Felix Hausdorff proposed his definition:
p12101
aV formula_8
p12102
aV"where 1 and 2 are two distinct objects different from a and b."
p12103
aVKuratowski definition.
p12104
aVIn 1921 Kazimierz Kuratowski offered the now-accepted definition
p12105
aVof the ordered pair ("a", "b"):
p12106
aVformula_9
p12107
aVNote that this definition is used even when the first and the second coordinates are identical:
p12108
aV formula_10
p12109
aVGiven some ordered pair "p", the property ""x" is the first coordinate of "p" can be formulated as:
p12110
aVformula_11
p12111
aVThe property "x" is the second coordinate of "p"" can be formulated as:
p12112
aVformula_12
p12113
aVIn the case that the left and right coordinates are identical, the right conjunct formula_13 is trivially true, since "Y"1 \u2260 "Y"2 is never the case.
p12114
aVThis is how we can extract the first coordinate of a pair (using the notation for arbitrary intersection and arbitrary union):
p12115
aVformula_14
p12116
aVThis is how the second coordinate can be extracted:
p12117
aVformula_15
p12118
aVVariants.
p12119
aVThe above Kuratowski definition of the ordered pair is "adequate" in that it satisfies the characteristic property that an ordered pair must satisfy, namely that formula_16. In particular, it adequately expresses 'order', in that formula_17 is false unless formula_18. There are other definitions, of similar or lesser complexity, that are equally adequate:
p12120
aVThe reverse definition is merely a trivial variant of the Kuratowski definition, and as such is of no independent interest. The definition short is so-called because it requires two rather than three pairs of braces. Proving that short satisfies the characteristic property requires the Zermelo\u2013Fraenkel set theory axiom of regularity. Moreover, if one uses von Neumann's set-theoretic construction of the natural numbers, then 2 is defined as the set {0, 1} = {0, {0}}, which is indistinguishable from the pair (0, 0)short. Yet another disadvantage of the short pair is the fact, that even if "a" and "b" are of the same type, the elements of the short pair are not. (However, if "a" = "b" then the short version keeps having cardinality 2, which is something one might expect of any "pair", including any "ordered pair". Also note that the short version is used in Tarski\u2013Grothendieck set theory, upon which the Mizar system is founded.)
p12121
aVProving that definitions satisfy the characteristic property.
p12122
aVProve: ("a", "b") = ("c", "d") if and only if "a" = "c" and "b" = "d".
p12123
aVKuratowski:<br>
p12124
aV"If". If "a = c" and "b = d", then = . Thus ("a, b")K = ("c, d")K.
p12125
aV"Only if". Two cases: "a" = "b", and "a" \u2260 "b".
p12126
aVIf "a" = "b":
p12127
aV("a, b")K = = = .
p12128
aV("c, d")K = = .
p12129
aVThus {"c"} = {"c, d"} = {"a"}, which implies "a" = "c" and "a" = "d". By hypothesis, "a" = "b". Hence "b" = "d".
p12130
aVIf "a" \u2260 "b", then ("a, b")K = ("c, d")K implies = .
p12131
aVSuppose {"c, d"} = {"a"}. Then "c = d = a", and so = = = . But then would also equal , so that "b = a" which contradicts "a" \u2260 "b".
p12132
aVSuppose {"c"} = {"a, b"}. Then "a = b = c", which also contradicts "a" \u2260 "b".
p12133
aVTherefore {"c"} = {"a"}, so that "c = a" and {"c, d"} = {"a, b"}.
p12134
aVIf "d = a" were true, then {"c, d"} = {"a, a"} = {"a"} \u2260 {"a, b"}, a contradiction. Thus "d = b" is the case, so that "a = c" and "b = d".
p12135
aVReverse:<br>
p12136
aV("a, b")reverse = = = ("b, a")K.
p12137
aV"If". If ("a, b")reverse = ("c, d")reverse,
p12138
aV("b, a")K = ("d, c")K. Therefore "b = d" and "a = c".
p12139
aV"Only if". If "a = c" and "b = d", then = .
p12140
aVThus ("a, b")reverse = ("c, d")reverse.
p12141
aVShort:
p12142
aV"If": If "a = c" and "b = d", then {"a", {"a, b"}} = {"c", {"c, d"}}. Thus ("a, b")short = ("c, d")short.
p12143
aV"Only if": Suppose {"a", {"a, b"}} = {"c", {"c, d"}}.
p12144
aVThen "a" is in the left hand side, and thus in the right hand side.
p12145
aVBecause equal sets have equal elements, one of "a = c" or "a" = {"c, d"} must be the case.
p12146
aVIf "a" = {"c, d"}, then by similar reasoning as above, {"a, b"} is in the right hand side, so {"a, b"} = "c" or {"a, b"} = {"c, d"}.
p12147
aV:If {"a, b"} = "c" then "c" is in {"c, d"} = "a" and "a" is in "c", and this combination contradicts the axiom of regularity, as {"a, c"} has no minimal element under the relation "element of."
p12148
aV:If {"a, b"} = {"c, d"}, then "a" is an element of "a", from "a" = {"c, d"} = {"a, b"}, again contradicting regularity.
p12149
aVHence "a = c" must hold.
p12150
aVAgain, we see that {"a, b"} = "c" or {"a, b"} = {"c, d"}.
p12151
aVThe option {"a, b"} = "c" and "a = c" implies that "c" is an element of "c", contradicting regularity.
p12152
aVSo we have "a = c" and {"a, b"} = {"c, d"}, and so: {"b"} = {"a, b"} \u005c {"a"} = {"c, d"} \u005c {"c"} = {"d"}, so "b" = "d".
p12153
aVQuine-Rosser definition.
p12154
aVRosser (1953) employed a definition of the ordered pair due to Quine which requires a prior definition of the natural numbers. Let formula_22 be the set of natural numbers
p12155
aVand formula_23 be the elements of formula_24 not in formula_22. Define
p12156
aVformula_26
p12157
aVApplying this function simply increments every natural number in "x". In particular, formula_27 does not contain the number 0, so that for any sets "x" and "y",
p12158
aVformula_28
p12159
aVDefine the ordered pair ("A", "B") as
p12160
aVformula_29
p12161
aVExtracting all the elements of the pair that do not contain 0 and undoing formula_30 yields "A". Likewise, "B" can be recovered from the elements of the pair that do contain 0.
p12162
aVIn type theory and in outgrowths thereof such as the axiomatic set theory NF, the Quine-Rosser pair has the same type as its projections and hence is termed a "type-level" ordered pair. Hence this definition has the advantage of enabling a function, defined as a set of ordered pairs, to have a type only 1 higher than the type of its arguments. This definition works only if the set of natural numbers is infinite. This is the case in NF, but not in type theory or in NFU. J. Barkley Rosser showed that the existence of such a type-level ordered pair (or even a "type-raising by 1" ordered pair) implies the axiom of infinity. For an extensive discussion of the ordered pair in the context of Quinian set theories, see Holmes (1998).
p12163
aVMorse definition.
p12164
aVMorse\u2013Kelley set theory makes free use of proper classes. Morse defined the ordered pair so that its projections could be proper classes as well as sets. (The Kuratowski definition does not allow this.) He first defined ordered pairs whose projections are sets in Kuratowski's manner. He then "redefined" the pair
p12165
aVformula_31
p12166
aVwhere the component Cartesian products are Kuratowski pairs of sets and where
p12167
aVformula_32
p12168
aVThis renders possible pairs whose projections are proper classes. The Quine-Rosser definition above also admits proper classes as projections. Similarly the triple is defined as a 3-tuple as follows:
p12169
aVformula_33
p12170
aVThe use of the singleton set formula_34 which has an inserted empty set allows tuples to have the uniqueness
p12171
aVproperty that if a is an n-tuple and b is an m-tuple
p12172
aVand a = b then n = m. Ordered triples which are defined as ordered pairs do not have this property with respect to ordered pairs.
p12173
aVCategory theory.
p12174
aVA category-theoretic product "A" × "B" in a category of sets represents the set of ordered pairs, with the first element coming from "A" and the second coming from "B". In this context the characteristic property above is a consequence of the universal property of the product and the fact that elements of a set "X" can be identified with morphisms from 1 (a one element set) to "X". While different objects may have the universal property, they are all naturally isomorphic.
p12175
asS'Sequence'
p12176
(lp12177
VIn mathematics, a sequence is an ordered collection of objects in which repetitions are allowed. Like a set, it contains members (also called "elements", or "terms"). The number of elements (possibly infinite) is called the "length" of the sequence. Unlike a set, order matters, and exactly the same elements can appear multiple times at different positions in the sequence. Formally, a sequence can be defined as a function whose domain is a countable totally ordered set, such as the natural numbers.
p12178
aVFor example, (M, A, R, Y) is a sequence of letters with the letter 'M' first and 'Y' last. This sequence differs from (A, R, M, Y). Also, the sequence (1, 1, 2, 3, 5, 8), which contains the number 1 at two different positions, is a valid sequence. Sequences can be "finite", as in these examples, or "infinite", such as the sequence of all even positive integers (2, 4, 6...). In computing and computer science, finite sequences are sometimes called strings, words or lists, the different names commonly corresponding to different ways to represent them into computer memory; infinite sequences are also called streams. The empty sequence ( ) is included in most notions of sequence, but may be excluded depending on the context.
p12179
aVExamples and notation.
p12180
aVA sequence can be thought of as a list of elements with a particular order. Sequences are useful in a number of mathematical disciplines for studying functions, spaces, and other mathematical structures using the convergence properties of sequences. In particular, sequences are the basis for series, which are important in differential equations and analysis. Sequences are also of interest in their own right and can be studied as patterns or puzzles, such as in the study of prime numbers.
p12181
aVThere are a number of ways to denote a sequence, some of which are more useful for specific types of sequences. One way to specify a sequence is to list the elements. For example, the first four odd numbers form the sequence (1,3,5,7). This notation can be used for infinite sequences as well. For instance, the infinite sequence of positive odd integers can be written (1,3,5,7...). Listing is most useful for infinite sequences with a pattern that can be easily discerned from the first few elements. Other ways to denote a sequence are discussed after the examples.
p12182
aVImportant examples.
p12183
aVThere are many important integer sequences. The prime numbers are the natural numbers bigger than 1, that have no divisors but 1 and themselves. Taking these in their natural order gives the sequence (2,3,5,7,11,13,17...). The study of prime numbers has important applications for mathematics and specifically number theory. 
p12184
aVThe Fibonacci numbers are the integer sequence whose elements are the sum of the previous two elements. The first two elements are either 0 and 1 or 1 and 1 so that the sequence is (0,1,1,2,3,5,8,13,21,34...). 
p12185
aVOther interesting sequences include the ban numbers, whose spellings do not contain a certain letter of the alphabet. For instance, the eban numbers (do not contain 'e') form the sequence (2,4,6,30,32,34,36,40,42...). Another sequence based on the English spelling of the letters is the one based on their number of letters (3,3,5,4,4,3,5,5,4,3,6,6,8...).
p12186
aVFor a list of important examples of integers sequences see On-line Encyclopedia of Integer Sequences.
p12187
aVOther important examples of sequences include ones made up of rational numbers, real numbers, and complex numbers. The sequence (.9.99.999.9999...) approaches the number 1. In fact, every real number can be written as the limit of a sequence of rational numbers. It is this fact that allows us to write any real number as the limit of a sequence of decimals. For instance, \u03c0 is the limit of the sequence (3,3.1,3.14,3.141,3.1415...). The sequence for \u03c0, however, does not have any pattern that is easily discernible by eye, unlike the sequence (0.9,0.99...).
p12188
aVIndexing.
p12189
aVOther notations can be useful for sequences whose pattern cannot be easily guessed, or for sequences that do not have a pattern such as the digits of \u03c0. This section focuses on the notations used for sequences that are a map from a subset of the natural numbers. For generalizations to other countable index sets see the following section and below.
p12190
aVThe terms of a sequence are commonly denoted by a single variable, say "an", where the "index" n indicates the nth element of the sequence. 
p12191
aVformula_1
p12192
aVThis represents the sequence (1,4,9...100). This notation is often simplified further as 
p12193
aVformula_2
p12194
aVHere the subscript {k=1} and superscript 10 together tell us that the elements of this sequence are the "ak" such that "k" = 1, 2, ..., 10. 
p12195
aVSequences can be indexed beginning and ending from any integer. The infinity symbol \u221e is often used as the superscript to indicate the sequence including all integer "k"-values starting with a certain one. The sequence of all positive squares is then denoted 
p12196
aVformula_3
p12197
aVIn cases where the set of indexing numbers is understood, such as in analysis, the subscripts and superscripts are often left off. That is, one simply writes "ak" for an arbitrary sequence. In analysis, k would be understood to run from 1 to \u221e. However, sequences are often indexed starting from zero, as in 
p12198
aVformula_4
p12199
aVIn some cases the elements of the sequence are related naturally to a sequence of integers whose pattern can be easily inferred. In these cases the index set may be implied by a listing of the first few abstract elements. For instance, the sequence of squares of odd numbers could be denoted in any of the following ways. 
p12200
aVMoreover, the subscripts and superscripts could have been left off in the third, fourth, and fifth notations if the indexing set was understood to be the natural numbers. 
p12201
aVFinally, sequences can more generally be denoted by writing a set inclusion in the subscript, such as in
p12202
aVformula_10
p12203
aVThe set of values that the index can take on is called the index set. In general, the ordering of the elements "ak" is specified by the order of the elements in the indexing set. When N is the index set, the element "ak"+1 comes after the element "ak" since in N, the element ("k"+1) comes directly after the element "k".
p12204
aVSpecifying a sequence by recursion.
p12205
aVSequences whose elements are related to the previous elements in a straightforward way are often specified using recursion. This is in contrast to the specification of sequence elements in terms of their position.
p12206
aVTo specify a sequence by recursion requires a rule to construct each consecutive element in terms of the ones before it. In addition, enough initial elements must be specified so that new elements of the sequence can be specified by the rule. The principle of mathematical induction can be used to prove that a sequence is well-defined, which is to say that that every element of the sequence is specified at least once and has a single, unambiguous value. Induction can also be used to prove properties about a sequence, especially for sequences whose most natural specification is by recursion. 
p12207
aVThe Fibonacci sequence can be defined using a recursive rule along with two initial elements. The rule is that each element is the sum of the previous two elements, and the first two elements are 0 and 1.
p12208
aVformula_11, with "a"0 = 0 and "a"1 = 1.
p12209
aVThe first ten terms of this sequence are 0,1,1,2,3,5,8,13,21, and 34. A more complicated example of a sequence that is defined recursively is Recaman's sequence, considered at the beginning of this section. We can define Recaman's sequence by
p12210
aV"a"0 = 0 and "an" = "an"\u22121\u2212"n" if the result is positive and not already in the list. Otherwise, "an" = "an"\u22121+"n" . 
p12211
aVNot all sequences can be specified by a rule in the form of an equation, recursive or not, and some can be quite complicated. For example, the sequence of prime numbers is the set of prime numbers in their natural order. This gives the sequence (2,3,5,7,11,13,17...).
p12212
aVOne can also notice that the next element of a sequence is a function of the element before, and so we can write the next element as :
p12213
aVformula_12
p12214
aVThis functional notation can prove useful when one wants to prove the global monotony of the sequence.
p12215
aVFormal definition and basic properties.
p12216
aVThere are many different notions of sequences in mathematics, some of which ("e.g.", exact sequence) are not covered by the definitions and notations introduced below.
p12217
aVFormal definition.
p12218
aVA sequence is usually defined as a function whose domain is a countable totally ordered set, although in many disciplines the domain is restricted, such as to the natural numbers. In real analysis a sequence is a function from a subset of the natural numbers to the real numbers. In other words, a sequence is a map "f"("n") : N \u2192 R. To recover our earlier notation we might identify "an" = "f"("n") for all "n" or just write "an" : N \u2192 R.
p12219
aVIn complex analysis, sequences are defined as maps from the natural numbers to the complex numbers (C). In topology, sequences are often defined as functions from a subset of the natural numbers to a topological space. Sequences are an important concept for studying functions and, in topology, topological spaces. An important generalization of sequences, called a net, is to functions from a (possibly uncountable) directed set to a topological space.
p12220
aVFinite and infinite.
p12221
aVThe length of a sequence is defined as the number of terms in the sequence.
p12222
aVA sequence of a finite length "n" is also called an "n"-tuple. Finite sequences include the empty sequence ( ) that has no elements.
p12223
aVNormally, the term "infinite sequence" refers to a sequence which is infinite in one direction, and finite in the other\u2014the sequence has a first element, but no final element (a "singly infinite sequence"). A sequence that is infinite in both directions\u2014it has neither a first nor a final element\u2014is called a bi-infinite sequence, two-way infinite sequence, or doubly infinite sequence. For instance, a function from "all" integers into a set, such as the sequence of all even integers ( \u2026, \u22124, \u22122, 0, 2, 4, 6, 8\u2026 ), is bi-infinite. This sequence could be denoted formula_13. Formally, a bi-infinite sequence can be defined as a mapping from Z.
p12224
aVOne can interpret singly infinite sequences as elements of the semigroup ring of the natural numbers "R"[N], and doubly infinite sequences as elements of the group ring of the integers "R"[Z]. This perspective is used in the Cauchy product of sequences.
p12225
aVIncreasing and decreasing.
p12226
aVA sequence is said to be "monotonically increasing" if each term is greater than or equal to the one before it. For a sequence formula_14 this can be written as "a""n" \u2264 "a""n"+1 for all "n" \u2208 N. If each consecutive term is strictly greater than (>) the previous term then the sequence is called strictly monotonically increasing. A sequence is monotonically decreasing if each consecutive term is less than or equal to the previous one, and strictly monotonically decreasing if each is strictly less than the previous. If a sequence is either increasing or decreasing it is called a monotone sequence. This is a special case of the more general notion of a monotonic function.
p12227
aVThe terms nondecreasing and nonincreasing are often used in place of "increasing" and "decreasing" in order to avoid any possible confusion with "strictly increasing" and "strictly decreasing", respectively.
p12228
aVBounded.
p12229
aVIf the sequence of real numbers ("an") is such that all the terms, after a certain one, are less than some real number "M", then the sequence is said to be bounded from above. In less words, this means "an" \u2264 "M" for all "n" greater than "N" for some pair "M" and "N". Any such "M" is called an "upper bound". Likewise, if, for some real "m", "an" \u2265 "m" for all "n" greater than some "N", then the sequence is bounded from below and any such "m" is called a "lower bound". If a sequence is both bounded from above and bounded from below then the sequence is said to be bounded.
p12230
aVOther types of sequences.
p12231
aVA subsequence of a given sequence is a sequence formed from the given sequence by deleting some of the elements without disturbing the relative positions of the remaining elements. For instance, the sequence of positive even integers (2,4,6...) is a subsequence of the positive integers (1,2,3...). The positions of some elements change when other elements are deleted. However, the relative positions are preserved.
p12232
aVSome other types of sequences that are easy to define include:
p12233
aVLimits and convergence.
p12234
aVOne of the most important properties of a sequence is "convergence". Informally, a sequence converges if it has a "limit". Continuing informally, a (singly infinite) sequence has a limit if it approaches some value "L", called the limit, as "n" becomes very large. That is, for an abstract sequence ("a""n") (with "n" running from 1 to infinity understood) the value of "a""n" approaches "L" as "n" \u2192 \u221e, denoted
p12235
aVformula_15
p12236
aVMore precisely, the sequence converges if there exists a limit L such that the remaining an's are arbitrarily close to L for some n large enough. 
p12237
aVIf a sequence converges to some limit, then it is convergent; otherwise it is divergent.
p12238
aVIf "an" gets arbitrarily large as "n" \u2192 \u221e we write 
p12239
aVformula_16 
p12240
aVIn this case we say that the sequence ("an") "diverges", or that it converges to infinity. 
p12241
aVIf "an" becomes arbitrarily "small" negative numbers (large in magnitude) as "n" \u2192 \u221e we write 
p12242
aVformula_17 
p12243
aVand say that the sequence diverges or converges to minus infinity.
p12244
aVDefinition of convergence.
p12245
aVFor sequences that can be written as formula_18 with "a""n" \u2208 R we can write ("an") with the indexing set understood as N. These sequences are most common in real analysis. The generalizations to other types of sequences are considered in the following section and the main page Limit of a sequence.
p12246
aVLet ("an") be a sequence. In words, the sequence ("a""n") is said to "converge" if there exists a number "L" such that no matter how close we want the "a""n" to be to "L" (say \u03b5-close where \u03b5 > 0), we can find a natural number "N" such that all terms ("a""N+1", "a""N+2", ...) are further closer to L (within \u03b5 of "L"). This is often written more compactly using symbols. For instance,
p12247
aVfor all \u03b5 > 0, there exists a natural number "N" such that "L"\u2212\u03b5 < "an" < L+\u03b5 for all "n" \u2265 "N".
p12248
aVIn even more compact notation
p12249
aVformula_19
p12250
aVThe difference in the definitions of convergence for (one-sided) sequences in complex analysis and metric spaces is that the absolute value |"a""n" \u2212 "L"| is interpreted as the distance in the complex plane (formula_20), and the distance under the appropriate metric, respectively.
p12251
aVApplications and important results.
p12252
aVImportant results for convergence and limits of (one-sided) sequences of real numbers include the following. These equalities are all true at least when both sides exist. For a discussion of when the existence of the limit on one side implies the existence of the other see a real analysis text such as can be found in the references.
p12253
aVCauchy sequences.
p12254
aVA Cauchy sequence is a sequence whose terms become arbitrarily close together as n gets very large. The notion of a Cauchy sequence is important in the study of sequences in metric spaces, and, in particular, in real analysis. One particularly important result in real analysis is "Cauchy characterization of convergence for sequences": 
p12255
aVIn the real numbers, a sequence is convergent if and only if it is Cauchy.
p12256
aVIn contrast, in the rational numbers, e.g. the sequence defined by 
p12257
aV"x"1 = 1 and "x""n"+1 = 
p12258
aVis Cauchy, but has no rational limit, cf. .
p12259
aVSeries.
p12260
aVA "series" is, informally speaking, the sum of the terms of a sequence. That is, adding the first N terms of a (one-sided) sequence forms the Nth term of another sequence, called a "series". Thus the N series of the sequence (an) results in another sequence ("S""N") given by:
p12261
aVformula_31
p12262
aVWe can also write the "n"th term of the series as
p12263
aVformula_32
p12264
aVThen the concepts used to talk about sequences, such as convergence, carry over to series (the sequence of partial sums) and the properties can be characterized as properties of the underlying sequences (such as ("a""n") in the last example). The limit, if it exists, of an infinite series (the series created from an infinite sequence) is written as
p12265
aVformula_33
p12266
aVUse in other fields of mathematics.
p12267
aVTopology.
p12268
aVSequence play an important role in topology, especially in the study of metric spaces. For instance:
p12269
aVSequences can be generalized to nets or filters. These generalizations allow one to extend some of the above theorems to spaces without metrics.
p12270
aVProduct topology.
p12271
aVA product space of a sequence of topological spaces is the cartesian product of the spaces equipped with a natural topology called the product topology.
p12272
aVMore formally, given a sequence of spaces formula_34, define "X" such that
p12273
aVformula_35
p12274
aVis the set of sequences formula_36 where each formula_37 is an element of formula_38. Let the canonical projections be written as "pi" : "X" \u2192 "Xi". Then the product topology on "X" is defined to be the coarsest topology (i.e. the topology with the fewest open sets) for which all the projections "pi" are continuous. The product topology is sometimes called the Tychonoff topology.
p12275
aVAnalysis.
p12276
aVIn analysis, when talking about sequences, one will generally consider sequences of the form
p12277
aVformula_39
p12278
aVwhich is to say, infinite sequences of elements indexed by natural numbers.
p12279
aVIt may be convenient to have the sequence start with an index different from 1 or 0. For example, the sequence defined by "xn" = 1/log("n") would be defined only for "n" \u2265 2. When talking about such infinite sequences, it is usually sufficient (and does not change much for most considerations) to assume that the members of the sequence are defined at least for all indices large enough, that is, greater than some given "N".
p12280
aVThe most elementary type of sequences are numerical ones, that is, sequences of real or complex numbers. This type can be generalized to sequences of elements of some vector space. In analysis, the vector spaces considered are often function spaces. Even more generally, one can study sequences with elements in some topological space.
p12281
aVSequence spaces.
p12282
aVA sequence space is a vector space whose elements are infinite sequences of real or complex numbers. Equivalently, it is a function space whose elements are functions from the natural numbers to the field K of real or complex numbers. The set of all such functions is naturally identified with the set of all possible infinite sequences with elements in K, and can be turned into a vector space under the operations of pointwise addition of functions and pointwise scalar multiplication. All sequence spaces are linear subspaces of this space. Sequence spaces are typically equipped with a norm, or at least the structure of a topological vector space.
p12283
aVThe most important sequences spaces in analysis are the \u2113"p" spaces, consisting of the "p"-power summable sequences, with the "p"-norm. These are special cases of L"p" spaces for the counting measure on the set of natural numbers. Other important classes of sequences like convergent sequences or null sequences form sequence spaces, respectively denoted "c" and "c"0, with the sup norm. Any sequence space can also be equipped with the topology of pointwise convergence, under which it becomes a special kind of Fréchet space called FK-space.
p12284
aVLinear algebra.
p12285
aVSequences over a field may also be viewed as vectors in a vector space. Specifically, the set of "F"-valued sequences (where "F" is a field) is a function space (in fact, a product space) of "F"-valued functions over the set of natural numbers.
p12286
aVAbstract algebra.
p12287
aVAbstract algebra employs several types of sequences, including sequences of mathematical objects such as groups or rings.
p12288
aVFree monoid.
p12289
aVIf "A" is a set, the free monoid over "A" (denoted "A"*, also called Kleene star of "A") is a monoid containing all the finite sequences (or strings) of zero or more elements of "A", with the binary operation of concatenation. The free semigroup "A"+ is the subsemigroup of "A"* containing all elements except the empty sequence.
p12290
aVExact sequences.
p12291
aVIn the context of group theory, a sequence
p12292
aVformula_40
p12293
aVof groups and group homomorphisms is called exact if the image (or range) of each homomorphism is equal to the kernel of the next:
p12294
aVformula_41
p12295
aVNote that the sequence of groups and homomorphisms may be either finite or infinite.
p12296
aVA similar definition can be made for certain other algebraic structures. For example, one could have an exact sequence of vector spaces and linear maps, or of modules and module homomorphisms.
p12297
aVSpectral sequences.
p12298
aVIn homological algebra and algebraic topology, a spectral sequence is a means of computing homology groups by taking successive approximations. Spectral sequences are a generalization of exact sequences, and since their introduction by , they have become an important research tool, particularly in homotopy theory.
p12299
aVSet theory.
p12300
aVAn ordinal-indexed sequence is a generalization of a sequence. If \u03b1 is a limit ordinal and "X" is a set, an \u03b1-indexed sequence of elements of "X" is a function from \u03b1 to "X". In this terminology an \u03c9-indexed sequence is an ordinary sequence.
p12301
aVComputing.
p12302
aVAutomata or finite state machines can typically be thought of as directed graphs, with edges labeled using some specific alphabet, \u03a3. Most familiar types of automata transition from state to state by reading input letters from \u03a3, following edges with matching labels; the ordered input for such an automaton forms a sequence called a "word" (or input word). The sequence of states encountered by the automaton when processing a word is called a "run". A nondeterministic automaton may have unlabeled or duplicate out-edges for any state, giving more than one successor for some input letter. This is typically thought of as producing multiple possible runs for a given word, each being a sequence of single states, rather than producing a single run that is a sequence of sets of states; however, 'run' is occasionally used to mean the latter.
p12303
aVTheoretical computer science.
p12304
aVInfinite sequences of digits (or characters) drawn from a finite alphabet are of particular interest in theoretical computer science. They are often referred to simply as "sequences" or "streams", as opposed to finite "strings". Infinite binary sequences, for instance, are infinite sequences of bits (characters drawn from the alphabet {0, 1}). The set "C" = {0, 1}\u221e of all infinite, binary sequences is sometimes called the Cantor space.
p12305
aVAn infinite binary sequence can represent a formal language (a set of strings) by setting the "n"\u2009th bit of the sequence to 1 if and only if the "n"\u2009th string (in shortlex order) is in the language. Therefore, the study of complexity classes, which are sets of languages, may be regarded as studying sets of infinite sequences.
p12306
aVAn infinite sequence drawn from the alphabet {0, 1, ..., "b" \u2212 1} may also represent a real number expressed in the base-"b" positional number system. This equivalence is often used to bring the techniques of real analysis to bear on complexity classes.
p12307
aVIn particular, the term "sequence space" usually refers to a linear subspace of the set of all possible infinite sequences with elements in C.
p12308
asS'Mathematics Subject Classification'
p12309
(lp12310
VThe Mathematics Subject Classification (MSC) is an alphanumerical classification scheme collaboratively produced by staff of, and based on the coverage of, the two major mathematical reviewing databases, Mathematical Reviews and Zentralblatt MATH. It is used by many mathematics journals, which ask authors of research papers and expository articles to list subject codes from the Mathematics Subject Classification in their papers. The current version is MSC2010.
p12311
aVStructure.
p12312
aVThe MSC is a hierarchical scheme, with three levels of structure. A classification can be two, three or five digits long, depending on how many levels of the classification scheme are used.
p12313
aVThe first level is represented by a two digit number, the second by a letter, and the third by another two digit number. For example:
p12314
aVFirst level.
p12315
aVAt the top level 64 mathematical disciplines are labeled with a unique 2 digit number. As well as the typical areas of mathematical research, there are top level categories for "History and Biography", "Mathematics Education", and for the overlap with different sciences. Physics (i.e. mathematical physics) is particularly well represented in the classification scheme with a number of different categories including:
p12316
aVAll valid MSC classification codes must have at least the first level identifier.
p12317
aVSecond level.
p12318
aVThe second level codes are a single letter from the Latin alphabet. These represent specific areas covered by the first level discipline. The second level codes vary from discipline to discipline.
p12319
aVFor example, for differential geometry, the top-level code is 53, and the second-level codes are:
p12320
aVIn addition the special second level code "-" is used for specific kinds of materials. These codes are of the form:
p12321
aVThe second and third level of these codes are always the same - only the first level changes. It is not valid to put 53- as a classification, either 53 on its own, or better yet a more specific code should be used.
p12322
aVThird level.
p12323
aVThird level codes are the most specific, usually corresponding to a specific kind of mathematical object or a well-known problem or research area.
p12324
aVThe third-level code 99 exists in every category and means "none of the above, but in this section"
p12325
aVUsing the scheme.
p12326
aVThe AMS recommends that papers submitted to its journals for publication have one primary classification and one or more optional secondary classifications. A typical MSC subject class line on a research paper looks like
p12327
aVMSC Primary 03C90; Secondary 03-02;
p12328
aVHistory.
p12329
aVAccording to the American Mathematical Society help page about MSC, the MSC has been revised a number of times since 1940, but the original classification of older items has not been reclassified. This can sometimes make it difficult to search for older works dealing with particular topics. Changes at the first level involved the subjects with (present) codes 03, 08, 12-20, 28, 37, 51, 58, 74, 90, 91, 92.
p12330
aVRelation to other classification schemes.
p12331
aVFor physics papers the Physics and Astronomy Classification Scheme is often used. Due to the large overlap between mathematics and physics research it is quite common to see both PACS and MSC codes on research papers, particularly for multidisciplinary journals and repositories such as the arXiv.
p12332
aVThe ACM Computing Classification System is a similar hierarchical classification scheme for computer science. There is some overlap between the AMS and ACM classification schemes, in subjects related to both mathematics and computer science, however the two schemes differ in the details of their organization of those topics.
p12333
aVThe classification scheme used on the arXiv is chosen to reflect the papers submitted. As arXiv is multidisciplinary its classification scheme does not fit entirely with the MSC, ACM or PACS classification schemes. It is common to see codes from one or more of these schemes on individual papers.
p12334
aVFirst-level areas.
p12335
aVThe top level subjects under the MSC are, grouped here by common area names that are not part of the MSC:
p12336
asS'Series'
p12337
(lp12338
VSeries (singular) may refer to anything of a serial form:
p12339
aVMusic.
p12340
aVSee also: sequence
p12341
asS'Decimal'
p12342
(lp12343
V"This article aims to be an accessible introduction. For the mathematical definition, see Decimal representation."
p12344
aVThe decimal numeral system (also called base ten or occasionally denary) has ten as its base. It is the numerical base most widely used by modern civilizations.
p12345
aVDecimal notation often refers to a base-10 positional notation such as the Hindu-Arabic numeral system or rod calculus; however, it can also be used more generally to refer to non-positional systems such as Roman or Chinese numerals which are also based on powers of ten.
p12346
aVA decimal number, or just decimal, refers to any number written in decimal notation, although it is more commonly used to refer to numbers that have a fractional part separated from the integer part with a decimal separator (e.g. 11.25).
p12347
aVA decimal may be a terminating decimal, which has a finite fractional part (e.g. 15.600); a repeating decimal, which has an infinite (non-terminating) fractional part made up of a repeating sequence of digits (e.g. 5.8144); or an infinite decimal, which has a fractional part that neither terminates nor has an infinitely repeating pattern (e.g. 3.14159265...). Decimal fractions have terminating decimal representations, whereas irrational numbers have infinite decimal representations. 
p12348
aVDecimal notation.
p12349
aVDecimal notation is the writing of numbers in a base-10 numeral system. Examples are Greek numerals, Roman numerals, Brahmi numerals, and Chinese numerals, as well as the Hindu-Arabic numerals used by speakers of many European languages. Roman numerals have symbols for the decimal powers (1, 10, 100, 1000) and secondary symbols for half these values (5, 50, 500). Brahmi numerals have symbols for the nine numbers 1\u20139, the nine decades 10\u201390, plus a symbol for 100 and another for 1000. Chinese numerals have symbols for 1\u20139, and additional symbols for powers of 10, which in modern usage reach 1072.
p12350
aVHowever, when people who use Hindu-Arabic numerals speak of decimal notation, they often mean not just decimal numeration, as above, but also decimal fractions, all conveyed as part of a positional system. Positional decimal systems include a zero and use symbols (called digits) for the ten values (0, 1, 2, 3, 4, 5, 6, 7, 8, and 9) to represent any number, no matter how large or how small. These digits are often used with a decimal separator which indicates the start of a fractional part, and with a symbol such as the plus sign + (for positive) or minus sign \u2212 (for negative) adjacent to the numeral to indicate whether it is greater or less than zero, respectively.
p12351
aVPositional notation uses positions for each power of ten: units, tens, hundreds, thousands, etc. The position of each digit within a number denotes the multiplier (power of ten) multiplied with that digit\u2014each position has a value ten times that of the position to its right. There were at least two presumably independent sources of positional decimal systems in ancient civilization: the Chinese counting rod system and the Hindu-Arabic numeral system (the latter descended from Brahmi numerals).
p12352
aVTen is the number which is the count of fingers and thumbs on both hands (or toes on the feet). The English word digit as well as its translation in many languages is also the anatomical term for fingers and toes. In English, decimal (decimus < Lat.) means "tenth", decimate means "reduce by a tenth", and denary (denarius < Lat.) means "the unit of ten".
p12353
aVThe symbols for the digits in common use around the globe today are called Arabic numerals by Europeans and Indian numerals by Arabs, the two groups' terms both referring to the culture from which they learned the system. However, the symbols used in different areas are not identical; for instance, Western Arabic numerals (from which the European numerals are derived) differ from the forms used by other Arab cultures.
p12354
aVDecimal fractions.
p12355
aVA decimal fraction is a fraction the denominator of which is a power of ten.
p12356
aVDecimal fractions are commonly expressed in decimal notation rather than fraction notation by discarding the denominator and inserting the decimal separator into the numerator at the position from the right corresponding to the power of ten of the denominator and filling the gap with leading zeros if needed, e.g. decimal fractions 8/10, 1489/100, 24/100000, and 58900/10000 are expressed in decimal notation as 0.8, 14.89, 0.00024, 5.8900 respectively. In English-speaking, some Latin American and many Asian countries, a period (.) or raised period (·) is used as the decimal separator; in many other countries, particularly in Europe, a comma (,) is used.
p12357
aVThe integer part, or integral part of a decimal number is the part to the left of the decimal separator. (See also truncation.) The part from the decimal separator to the right is the "fractional part". It is usual for a decimal number that consists only of a fractional part (mathematically, a "proper fraction") to have a leading zero in its notation (its "numeral"). This helps disambiguation between a decimal sign and other punctuation, and especially when the negative number sign is indicated, it helps visualize the sign of the numeral as a whole.
p12358
aVTrailing zeros after the decimal point are not necessary, although in science, engineering and statistics they can be retained to indicate a required precision or to show a level of confidence in the accuracy of the number: Although 0.080 and 0.08 are numerically equal, in engineering 0.080 suggests a measurement with an error of up to one part in two thousand (±0.0005), while 0.08 suggests a measurement with an error of up to one in two hundred (see "significant figures").
p12359
aVOther rational numbers.
p12360
aVAny rational number with a denominator whose only prime factors are 2 and/or 5 may be precisely expressed as a decimal fraction and has a finite decimal expansion.
p12361
aV1/2 = 0.5
p12362
aV1/20 = 0.05
p12363
aV1/5 = 0.2
p12364
aV1/50 = 0.02
p12365
aV1/4 = 0.25
p12366
aV1/40 = 0.025
p12367
aV1/25 = 0.04
p12368
aV1/8 = 0.125
p12369
aV1/125 = 0.008
p12370
aV1/10 = 0.1
p12371
aVIf the rational number's denominator has any prime factors other than 2 or 5, it cannot be expressed as a finite decimal fraction, and has a unique eventually repeating infinite decimal expansion.
p12372
aV1/3 = 0.333333\u2026 (with 3 repeating)
p12373
aV1/9 = 0.111111\u2026 (with 1 repeating)
p12374
aV100 \u2212 1 = 99 = 9 × 11:
p12375
aV1/11 = 0.090909\u2026
p12376
aV1000 \u2212 1 = 9 × 111 = 27 × 37:
p12377
aV1/27 = 0.037037037\u2026
p12378
aV1/37 = 0.027027027\u2026
p12379
aV1/111 = 0 .009009009\u2026
p12380
aValso:
p12381
aV1/81 = 0.012345679012\u2026 (with 012345679 repeating)
p12382
aVThat a rational number must have a finite or recurring decimal expansion can be seen to be a consequence of the long division algorithm, in that there are at most q-1 possible nonzero remainders on division by q, so that the recurring pattern will have a period less than q. For instance, to find 3/7 by long division:
p12383
aVThe converse to this observation is that every recurring decimal represents a rational number "p"/"q". This is a consequence of the fact that the recurring part of a decimal representation is, in fact, an infinite geometric series which will sum to a rational number. For instance,
p12384
aVformula_1
p12385
aVReal numbers.
p12386
aVEvery real number has a (possibly infinite) decimal representation; i.e., it can be written as
p12387
aVformula_2
p12388
aVwhere
p12389
aVSuch a sum converges as more and more negative values of "i" are included, even if there are infinitely many non-zero "ai".
p12390
aVRational numbers (e.g., p/q) with prime factors in the denominator other than 2 and 5 (when reduced to simplest terms) have a unique recurring decimal representation.
p12391
aVNon-uniqueness of decimal representation.
p12392
aVConsider those rational numbers which have only the factors 2 and 5 in the denominator, i.e., which can be written as "p"/(2"a"5"b"). In this case there is a terminating decimal representation. For instance, 1/1 = 1, 1/2 = 0.5, 3/5 = 0.6, 3/25 = 0.12 and 1306/1250 = 1.0448. Such numbers are the only real numbers which do not have a unique decimal representation, as they can also be written as a representation that has a recurring 9, for instance 1 = 0.99999\u2026, 1/2 = 0.499999\u2026, etc. The number 0 = 0/1 is special in that it has no representation with recurring 9.
p12393
aVThis leaves the irrational numbers. They also have unique infinite decimal representations, and can be characterised as the numbers whose decimal representations neither terminate nor recur.
p12394
aVSo in general the decimal representation is unique, if one excludes representations that end in a recurring 9.
p12395
aVThe same trichotomy holds for other base-"n" positional numeral systems:
p12396
aVA version of this even holds for irrational-base numeration systems, such as golden mean base representation.
p12397
aVDecimal computation.
p12398
aVDecimal computation was carried out in ancient times in many ways, typically in rod calculus, with decimal multiplication table used in ancient China and with sand tables in India and Middle East or with a variety of abaci.
p12399
aVModern computer hardware and software systems commonly use a binary representation internally (although many early computers, such as the ENIAC or the IBM 650, used decimal representation internally).
p12400
aVFor external use by computer specialists, this binary representation is sometimes presented in the related octal or hexadecimal systems.
p12401
aVFor most purposes, however, binary values are converted to or from the equivalent decimal values for presentation to or input from humans; computer programs express literals in decimal by default. (123.1, for example, is written as such in a computer program, even though many computer languages are unable to encode that number precisely.)
p12402
aVBoth computer hardware and software also use internal representations which are effectively decimal for storing decimal values and doing arithmetic. Often this arithmetic is done on data which are encoded using some variant of binary-coded decimal,
p12403
aVespecially in database implementations, but there are other decimal representations in use (such as in the new IEEE 754 Standard for Floating-Point Arithmetic).
p12404
aVDecimal arithmetic is used in computers so that decimal fractional results can be computed exactly, which is not possible using a binary fractional representation.
p12405
aVThis is often important for financial and other calculations.
p12406
aVHistory.
p12407
aVMany ancient cultures calculated with numerals based on ten: Egyptian hieroglyphs, in evidence since around 3000 BC, used a purely decimal system, just as the Cretan hieroglyphs (ca. 1625\u22121500 BC) of the Minoans whose numerals are closely based on the Egyptian model. The decimal system was handed down to the consecutive Bronze Age cultures of Greece, including Linear A (ca. 18th century BC\u22121450 BC) and Linear B (ca. 1375\u22121200 BC) \u2014 the number system of classical Greece also used powers of ten, including, like the Roman numerals did, an intermediate base of 5. Notably, the polymath Archimedes (c. 287\u2013212 BC) invented a decimal positional system in his Sand Reckoner which was based on 108 and later led the German mathematician Carl Friedrich Gauss to lament what heights science would have already reached in his days if Archimedes had fully realized the potential of his ingenious discovery. The Hittites hieroglyphs (since 15th century BC), just like the Egyptian and early numerals in Greece, was strictly decimal.
p12408
aVThe Egyptian hieratic numerals, the Greek alphabet numerals, the Roman numerals, the Chinese numerals and early Indian Brahmi numerals are all non-positional decimal systems, and required large numbers of symbols. For instance, Egyptian numerals used different symbols for 10, 20, to 90, 100, 200, to 900, 1000, 2000, 3000, 4000, to 10,000.
p12409
aVThe world's earliest positional decimal system was the Chinese rod calculus
p12410
aVHistory of decimal fractions.
p12411
aVAccording to Joseph Needham and Lam Lay Yong, decimal fractions were first developed and used by the Chinese in the 1st century BC, and then spread to the Middle East and from there to Europe. The written Chinese decimal fractions were non-positional. However, counting rod fractions were positional.
p12412
aVQin Jiushao in his book Mathematical Treatise in Nine Sections (1247) denoted 0.96644 by
p12413
aV::::, meaning
p12414
aV::::096644
p12415
aVThe Jewish mathematician Immanuel Bonfils invented decimal fractions around 1350, anticipating Simon Stevin, but did not develop any notation to represent them.
p12416
aVThe Persian mathematician Jamsh\u012bd al-K\u0101sh\u012b claimed to have discovered decimal fractions himself in the 15th century, though J. Lennart Berggren notes that positional decimal fractions were used five centuries before him by Arab mathematician Abu'l-Hasan al-Uqlidisi as early as the 10th century.Al Khwarizmi introduced fraction to Islamic countries in the early 9th century, his fraction presentation was an exact copy of traditional Chinese mathematical fraction from The Mathematical Classic of Sunzi. This form of fraction with numerator on top and denominator at bottom without a horizontal bar was also used by 10th century Abu'l-Hasan al-Uqlidisi and 15th century Jamsh\u012bd al-K\u0101sh\u012b's work "Arithmetic Key".
p12417
aVA forerunner of modern European decimal notation was introduced by Simon Stevin in the 16th century.
p12418
aVNatural languages.
p12419
aVTelugu language uses a straightforward decimal system. Other Dravidian languages such as Tamil and Malayalam have replaced the number nine "tondu" with 'onpattu' ("one to ten") during the early Middle Ages, while Telugu preserved the number nine as "tommidi".
p12420
aVThe Hungarian language also uses a straightforward decimal system. All numbers between 10 and 20 are formed regularly (e.g. 11 is expressed as "tízenegy" literally "one on ten"), as with those between 20-100 (23 as "huszonhárom" = "three on twenty").
p12421
aVA straightforward decimal rank system with a word for each order 10\u5341,100\u767e,1000\u5343,10000\u4e07, and in which 11 is expressed as "ten-one" and 23 as "two-ten-three", and 89345 is expressed as 8 (ten thousands) \u4e079 (thousand) \u53433 (hundred) \u767e4 (tens) \u5341 5 is found in Chinese languages, and in Vietnamese with a few irregularities. Japanese, Korean, and Thai have imported the Chinese decimal system. Many other languages with a decimal system have special words for the numbers between 10 and 20, and decades. For example in English 11 is "eleven" not "ten-one" or "one-teen".
p12422
aVIncan languages such as Quechua and Aymara have an almost straightforward decimal system, in which 11 is expressed as "ten with one" and 23 as "two-ten with three".
p12423
aVSome psychologists suggest irregularities of the English names of numerals may hinder children's counting ability.
p12424
aVOther bases.
p12425
aVSome cultures do, or did, use other bases of numbers.
p12426
asS'Topological space'
p12427
(lp12428
VIn topology and related branches of mathematics, a topological space may be defined as a set of points, along with a set of neighbourhoods for each point, that satisfy a set of axioms relating points and neighbourhoods. The definition of a topological space relies only upon set theory and is the most general notion of a mathematical space that allows for the definition of concepts such as continuity, connectedness, and convergence. Other spaces, such as manifolds and metric spaces, are specializations of topological spaces with extra structures or constraints. Being so general, topological spaces are a central unifying notion and appear in virtually every branch of modern mathematics. The branch of mathematics that studies topological spaces in their own right is called point-set topology or general topology.
p12429
aVDefinition.
p12430
aVThe utility of the notion of a topology is shown by the fact that there are several equivalent definitions of this structure. Thus one chooses the axiomatisation suited for the application. The most commonly used, and the most elegant, is that in terms of "open sets", but the most intuitive is that in terms of "neighbourhoods" and so we give this first.
p12431
aVNote: A variety of more axiomatisations of topological spaces are listed in the Exercises of the book by Vaidyanathaswamy.
p12432
aVNeighbourhoods definition.
p12433
aVThis axiomatization is due to Felix Hausdorff.
p12434
aVLet "X" be a set; the elements of "X" are usually called "points", though they can be any mathematical object. We allow "X" to be empty. Let N be a function assigning to each "x" (point) in "X" a non-empty collection N("x") of subsets of "X". The elements of N("x") will be called "neighbourhoods" of "x" with respect to N (or, simply, "neighbourhoods of x"). The function N is called a neighbourhood topology if the axioms below are satisfied; and then "X" with N is called a topological space. 
p12435
aVThe first three axioms for neighbourhoods have a clear meaning. The fourth axiom has a very important use in the structure of the theory, that of linking together the neighbourhoods of different points of "X".
p12436
aVA standard example of such a system of neighbourhoods is for the real line R, where a subset "N" of R is defined to be a "neighbourhood" of a real number "x" if there is an open interval containing "x" and contained in "N".
p12437
aVGiven such a structure, we can define a subset "U" of "X" to be open if "U" is a neighbourhood of all points in "U". It is a remarkable fact that the open sets then satisfy the elegant axioms given below, and that, given these axioms, we can recover the neighbourhoods satisfying the above axioms by defining "N" to be a neighbourhood of "x" if "N" contains an open set "U" such that "x" \u2208 "U".
p12438
aVOpen sets definition.
p12439
aV[space examples.svg|frame|right|300px|Four examples and two non-examples of topologies on the three-point set {1,2,3}. The bottom-left example is not a topology because the union of {2} and {3} [i.e. {2,3} is missing; the bottom-right example is not a topology because the intersection of {1,2} and {2,3} {2}, is missing.]]
p12440
aVA "topological space" is then a set "X" together with a collection of subsets of "X", called open sets and satisfying the following axioms:
p12441
aVThe collection \u03c4 of open sets is then also called a topology on "X", or, if more precision is needed, an open set topology. The sets in \u03c4 are called the open sets, and their complements in "X" are called closed sets. A subset of "X" may be neither closed nor open, either closed or open, or both. A set that is both closed and open is called a clopen set.
p12442
aVClosed sets definition.
p12443
aVUsing de Morgan's laws, the above axioms defining open sets become axioms defining closed sets:
p12444
aVUsing these axioms, another way to define a topological space is as a set "X" together with a collection \u03c4 of closed subsets of "X". Thus the sets in the topology \u03c4 are the closed sets, and their complements in "X" are the open sets.
p12445
aVOther definitions.
p12446
aVThere are many other equivalent ways to define a topological space: in other words, the concepts of neighbourhood or of open respectively closed set can be reconstructed from other starting points and satisfy the correct axioms.
p12447
aVAnother way to define a topological space is by using the Kuratowski closure axioms, which define the closed sets as the fixed points of an operator on the power set of X.
p12448
aVA net is a generalisation of the concept of sequence. A topology is completely determined if for every net in "X" the set of its accumulation points is specified.
p12449
aVComparison of topologies.
p12450
aVA variety of topologies can be placed on a set to form a topological space. When every set in a topology \u03c41 is also in a topology \u03c42 and \u03c41 is a subset of \u03c42, we say that \u03c42 is "finer" than \u03c41, and \u03c41 is "coarser" than \u03c42. A proof that relies only on the existence of certain open sets will also hold for any finer topology, and similarly a proof that relies only on certain sets not being open applies to any coarser topology. The terms "larger" and "smaller" are sometimes used in place of finer and coarser, respectively. The terms "stronger" and "weaker" are also used in the literature, but with little agreement on the meaning, so one should always be sure of an author's convention when reading.
p12451
aVThe collection of all topologies on a given fixed set "X" forms a complete lattice: if "F" = {\u03c4\u03b1| \u03b1 in A} is a collection of topologies on "X", then the meet of "F" is the intersection of "F", and the join of "F" is the meet of the collection of all topologies on "X" that contain every member of "F".
p12452
aVContinuous functions.
p12453
aVA function "f" : "X"\u2192 "Y" between topological spaces is called continuous if for all "x" \u2208 "X" and all neighbourhoods "N" of "f"("x") there is a neighbourhood "M" of "x" such that "f"("M") \u2286 "N". This relates easily to the usual definition in analysis. Equivalently, "f" is continuous if the inverse image of every open set is open. This is an attempt to capture the intuition that there are no "jumps" or "separations" in the function. A homeomorphism is a bijection that is continuous and whose inverse is also continuous. Two spaces are called "homeomorphic" if there exists a homeomorphism between them. From the standpoint of topology, homeomorphic spaces are essentially identical.
p12454
aVIn category theory, Top, the category of topological spaces with topological spaces as objects and continuous functions as morphisms is one of the fundamental categories in category theory. The attempt to classify the objects of this category (up to homeomorphism) by invariants has motivated areas of research, such as homotopy theory, homology theory, and K-theory etc.
p12455
aVExamples of topological spaces.
p12456
aVA given set may have many different topologies. If a set is given a different topology, it is viewed as a different topological space. Any set can be given the discrete topology in which every subset is open. The only convergent sequences or nets in this topology are those that are eventually constant. Also, any set can be given the trivial topology (also called the indiscrete topology), in which only the empty set and the whole space are open. Every sequence and net in this topology converges to every point of the space. This example shows that in general topological spaces, limits of sequences need not be unique. However, often topological spaces must be Hausdorff spaces where limit points are unique.
p12457
aVThere are many ways of defining a topology on R, the set of real numbers. The standard topology on R is generated by the open intervals. The set of all open intervals forms a base or basis for the topology, meaning that every open set is a union of some collection of sets from the base. In particular, this means that a set is open if there exists an open interval of non zero radius about every point in the set. More generally, the Euclidean spaces R"n" can be given a topology. In the usual topology on R"n" the basic open sets are the open balls. Similarly, C, the set of complex numbers, and C"n" have a standard topology in which the basic open sets are open balls.
p12458
aVEvery metric space can be given a metric topology, in which the basic open sets are open balls defined by the metric. This is the standard topology on any normed vector space. On a finite-dimensional vector space this topology is the same for all norms.
p12459
aVMany sets of linear operators in functional analysis are endowed with topologies that are defined by specifying when a particular sequence of functions converges to the zero function.
p12460
aVAny local field has a topology native to it, and this can be extended to vector spaces over that field.
p12461
aVEvery manifold has a natural topology since it is locally Euclidean. Similarly, every simplex and every simplicial complex inherits a natural topology from Rn.
p12462
aVThe Zariski topology is defined algebraically on the spectrum of a ring or an algebraic variety. On R"n" or C"n", the closed sets of the Zariski topology are the solution sets of systems of polynomial equations.
p12463
aVA linear graph has a natural topology that generalises many of the geometric aspects of graphs with vertices and edges.
p12464
aVThe Sierpi\u0144ski space is the simplest non-discrete topological space. It has important relations to the theory of computation and semantics.
p12465
aVThere exist numerous topologies on any given finite set. Such spaces are called finite topological spaces. Finite spaces are sometimes used to provide examples or counterexamples to conjectures about topological spaces in general.
p12466
aVAny set can be given the cofinite topology in which the open sets are the empty set and the sets whose complement is finite. This is the smallest T1 topology on any infinite set.
p12467
aVAny set can be given the cocountable topology, in which a set is defined as open if it is either empty or its complement is countable. When the set is uncountable, this topology serves as a counterexample in many situations.
p12468
aVThe real line can also be given the lower limit topology. Here, the basic open sets are the half open intervals ["a", "b"). This topology on R is strictly finer than the Euclidean topology defined above; a sequence converges to a point in this topology if and only if it converges from above in the Euclidean topology. This example shows that a set may have many distinct topologies defined on it.
p12469
aVIf \u0393 is an ordinal number, then the set \u0393 = [0, \u0393) may be endowed with the order topology generated by the intervals ("a", "b"), [0, "b") and ("a", \u0393) where "a" and "b" are elements of \u0393.
p12470
aVTopological constructions.
p12471
aVEvery subset of a topological space can be given the subspace topology in which the open sets are the intersections of the open sets of the larger space with the subset. For any indexed family of topological spaces, the product can be given the product topology, which is generated by the inverse images of open sets of the factors under the projection mappings. For example, in finite products, a basis for the product topology consists of all products of open sets. For infinite products, there is the additional requirement that in a basic open set, all but finitely many of its projections are the entire space.
p12472
aVA quotient space is defined as follows: if "X" is a topological space and "Y" is a set, and if "f" : "X"\u2192 "Y" is a surjective function, then the quotient topology on "Y" is the collection of subsets of "Y" that have open inverse images under "f". In other words, the quotient topology is the finest topology on "Y" for which "f" is continuous. A common example of a quotient topology is when an equivalence relation is defined on the topological space "X". The map "f" is then the natural projection onto the set of equivalence classes.
p12473
aVThe Vietoris topology on the set of all non-empty subsets of a topological space "X", named for Leopold Vietoris, is generated by the following basis: for every "n"-tuple "U"1, ..., "U""n" of open sets in "X", we construct a basis set consisting of all subsets of the union of the "U""i" that have non-empty intersections with each "U""i".
p12474
aVClassification of topological spaces.
p12475
aVTopological spaces can be broadly classified, up to homeomorphism, by their topological properties. A topological property is a property of spaces that is invariant under homeomorphisms. To prove that two spaces are not homeomorphic it is sufficient to find a topological property not shared by them. Examples of such properties include connectedness, compactness, and various separation axioms.
p12476
aVSee the article on "topological properties" for more details and examples.
p12477
aVTopological spaces with algebraic structure.
p12478
aVFor any algebraic objects we can introduce the discrete topology, under which the algebraic operations are continuous functions. For any such structure that is not finite, we often have a natural topology compatible with the algebraic operations, in the sense that the algebraic operations are still continuous. This leads to concepts such as topological groups, topological vector spaces, topological rings and local fields.
p12479
aVSpecializations and generalizations.
p12480
aVThe following spaces and algebras are either more specialized or more general than the topological spaces discussed above.
p12481
asS'Commutative property'
p12482
(lp12483
VIn mathematics, a binary operation is commutative if changing the order of the operands does not change the result. It is a fundamental property of many binary operations, and many mathematical proofs depend on it. The idea that simple operations, such as multiplication and addition of numbers, are commutative was for many years implicitly assumed and the property was not named until the 19th century when mathematics started to become formalized. By contrast, division and subtraction are "not" commutative.
p12484
aVCommon uses.
p12485
aVThe "commutative property" (or "commutative law") is a property associated with binary operations and functions. Similarly, if the commutative property holds for a pair of elements under a certain binary operation then it is said that the two elements "commute" under that operation.
p12486
aVPropositional logic.
p12487
aVRule of replacement.
p12488
aVIn standard truth-functional propositional logic, "commutation", or "commutativity" refer to two valid rules of replacement. The rules allow one to transpose propositional variables within logical expressions in logical proofs. The rules are:
p12489
aVformula_1
p12490
aVand 
p12491
aVformula_2
p12492
aVwhere "formula_3" is a metalogical symbol representing "can be replaced in a proof with."
p12493
aVTruth functional connectives.
p12494
aV"Commutativity" is a property of some logical connectives of truth functional propositional logic. The following logical equivalences demonstrate that commutativity is a property of particular connectives. The following are truth-functional tautologies.
p12495
aVCommutativity of conjunction
p12496
aVformula_4
p12497
aVCommutativity of disjunction
p12498
aVformula_5
p12499
aVCommutativity of implication (also called the Law of permutation)
p12500
aVformula_6
p12501
aVCommutativity of equivalence (also called the Complete commutative law of equivalence)
p12502
aVformula_7
p12503
aVSet theory.
p12504
aVIn group and set theory, many algebraic structures are called commutative when certain operands satisfy the commutative property. In higher branches of mathematics, such as analysis and linear algebra the commutativity of well-known operations (such as addition and multiplication on real and complex numbers) is often used (or implicitly assumed) in proofs.
p12505
aVMathematical definitions.
p12506
aVThe term "commutative" is used in several related senses.
p12507
aV1. A binary operation formula_8 on a set "S" is called "commutative" if:
p12508
aVformula_9
p12509
aVAn operation that does not satisfy the above property is called noncommutative.
p12510
aV2. One says that "x commutes" with "y" under formula_8 if:
p12511
aVformula_11
p12512
aV3. A binary function formula_12 is called "commutative" if:
p12513
aVformula_13
p12514
aVHistory and etymology.
p12515
aVRecords of the implicit use of the commutative property go back to ancient times. The Egyptians used the commutative property of multiplication to simplify computing products. Euclid is known to have assumed the commutative property of multiplication in his book "Elements". Formal uses of the commutative property arose in the late 18th and early 19th centuries, when mathematicians began to work on a theory of functions. Today the commutative property is a well known and basic property used in most branches of mathematics.
p12516
aVThe first recorded use of the term "commutative" was in a memoir by François Servois in 1814, which used the word "commutatives" when describing functions that have what is now called the commutative property. The word is a combination of the French word "commuter" meaning "to substitute or switch" and the suffix "-ative" meaning "tending to" so the word literally means "tending to substitute or switch." The term then appeared in English in "Philosophical Transactions of the Royal Society" in 1844.
p12517
aVRelated properties.
p12518
aVAssociativity.
p12519
aVThe associative property is closely related to the commutative property. The associative property of an expression containing two or more occurrences of the same operator states that the order operations are performed in does not affect the final result, as long as the order of terms doesn't change. In contrast, the commutative property states that the order of the terms does not affect the final result.
p12520
aVMost commutative operations encountered in practice are also associative. However, commutativity does not imply associativity. A counterexample is the function
p12521
aVformula_14
p12522
aVwhich is clearly commutative (interchanging "x" and "y" does not affect the result), but it is not associative (since, for example, formula_15 but formula_16).
p12523
aVSymmetry.
p12524
aVSome forms of symmetry can be directly linked to commutativity. When a commutative operator is written as a binary function then the resulting function is symmetric across the line "y = x". As an example, if we let a function "f" represent addition (a commutative operation) so that "f"("x","y") = "x" + "y" then "f" is a symmetric function, which can be seen in the image on the right.
p12525
aVFor relations, a symmetric relation is analogous to a commutative operation, in that if a relation "R" is symmetric, then formula_17.
p12526
aVExamples.
p12527
aVCommutative operations in mathematics.
p12528
aVTwo well-known examples of commutative binary operations:
p12529
aV:formula_18
p12530
aVFor example 4 + 5 = 5 + 4, since both expressions equal 9.
p12531
aV:formula_19
p12532
aVFor example, 3 × 5 = 5 × 3, since both expressions equal 15.
p12533
aVFor example, the logical biconditional function p \u2194 q is equivalent to q \u2194 p. This function is also written as p IFF q, or as p \u2261 q, or as E"pq". 
p12534
aVThe last form is an example of the most concise notation in the article on truth functions, which lists the sixteen possible binary truth functions of which eight are commutative: V"pq" = V"qp"; A"pq" (OR) = A"qp"; D"pq" (NAND) = D"qp"; E"pq" (IFF) = E"qp"; J"pq" = J"qp"; K"pq" (AND) = K"qp"; X"pq" (NOR) = X"qp"; O"pq" = O"qp".
p12535
aVformula_20
p12536
aVNoncommutative operations in mathematics.
p12537
aVSome noncommutative binary operations:
p12538
aVFor example, the truth tables for "f" (A,B) = A \u039b ¬B (A AND NOT B) and "f" (B,A) = B \u039b ¬A are 
p12539
aVformula_23
p12540
aVNon-commuting operators in quantum mechanics.
p12541
aVIn quantum mechanics as formulated by Schrödinger, physical variables are represented by linear operators such as "x" (meaning multiply by "x"), and formula_24. These two operators do not commute as may be seen by considering the effect of their compositions formula_25 and formula_26 (also called products of operators) on a one-dimensional wave function formula_27:
p12542
aV:formula_28
p12543
aVAccording to the uncertainty principle of Heisenberg, if the two operators representing a pair of variables do not commute, then that pair of variables are mutually complementary, which means they cannot be simultaneously measured or known precisely. For example, the position and the linear momentum in the "x"-direction of a particle are represented respectively by the operators formula_29 and formula_30 (where formula_31 is the reduced Planck constant). This is the same example except for the constant formula_32, so again the operators do not commute and the physical meaning is that the position and linear momentum in a given direction are complementary.
p12544
aV"Abstract algebra theory. Covers commutativity in that context. Uses property throughout book.
p12545
aV"Linear algebra theory. Explains commutativity in chapter 1, uses it throughout."
p12546
aV"Abstract algebra theory. Uses commutativity property throughout book.
p12547
aV"Article describing the mathematical ability of ancient civilizations."
p12548
aV"Translation and interpretation of the Rhind Mathematical Papyrus."
p12549
aV"Definition of commutativity and examples of commutative operations"
p12550
aV"Explanation of the term commute"
p12551
aV"Examples proving some noncommutative operations"
p12552
aV"Article giving the history of the real numbers"
p12553
aV"Page covering the earliest uses of mathematical terms"
p12554
aV"Biography of Francois Servois, who first used the term"
p12555
asS'Complexity class'
p12556
(lp12557
VIn computational complexity theory, a complexity class is a set of problems of related resource-based complexity. A typical complexity class has a definition of the form:
p12558
aVthe set of problems that can be solved by an abstract machine M using O(f("n")) of resource R, where "n" is the size of the input.
p12559
aVFor example, the class NP is the set of decision problems whose solutions can be determined by a non-deterministic Turing machine in polynomial time, while the class PSPACE is the set of decision problems that can be solved by a deterministic Turing machine in polynomial space.
p12560
aVThe simpler complexity classes are defined by the following factors:
p12561
aVMany complexity classes can be characterized in terms of the mathematical logic needed to express them; see descriptive complexity.
p12562
aVBounding the computation time above by some concrete function "f"("n") often yields complexity classes that depend on the chosen machine model. For instance, the language {"xx" | "x" is any binary string} can be solved in linear time on a multi-tape Turing machine, but necessarily requires quadratic time in the model of single-tape Turing machines. If we allow polynomial variations in running time, Cobham-Edmonds thesis states that "the time complexities in any two reasonable and general models of computation are polynomially related" . This forms the basis for the complexity class P, which is the set of decision problems solvable by a deterministic Turing machine within polynomial time. The corresponding set of function problems is FP.
p12563
aVThe Blum axioms can be used to define complexity classes without referring to a concrete computational model.
p12564
aVImportant complexity classes.
p12565
aVMany important complexity classes can be defined by bounding the time or space used by the algorithm. Some important complexity classes of decision problems defined in this manner are the following:
p12566
aVIt turns out that PSPACE = NPSPACE and EXPSPACE = NEXPSPACE by Savitch's theorem.
p12567
aVOther important complexity classes include BPP, ZPP and RP, which are defined using probabilistic Turing machines; AC and NC, which are defined using boolean circuits and BQP and QMA, which are defined using quantum Turing machines. #P is an important complexity class of counting problems (not decision problems). Classes like IP and AM are defined using Interactive proof systems. ALL is the class of all decision problems.
p12568
aVReduction.
p12569
aVMany complexity classes are defined using the concept of a reduction. A reduction is a transformation of one problem into another problem. It captures the informal notion of a problem being at least as difficult as another problem. For instance, if a problem "X" can be solved using an algorithm for "Y", "X" is no more difficult than "Y", and we say that "X" "reduces" to "Y". There are many different types of reductions, based on the method of reduction, such as Cook reductions, Karp reductions and Levin reductions, and the bound on the complexity of reductions, such as polynomial-time reductions or log-space reductions.
p12570
aVThe most commonly used reduction is a polynomial-time reduction. This means that the reduction process takes polynomial time. For example, the problem of squaring an integer can be reduced to the problem of multiplying two integers. This means an algorithm for multiplying two integers can be used to square an integer. Indeed, this can be done by giving the same input to both inputs of the multiplication algorithm. Thus we see that squaring is not more difficult than multiplication, since squaring can be reduced to multiplication.
p12571
aVThis motivates the concept of a problem being hard for a complexity class. A problem "X" is "hard" for a class of problems "C" if every problem in "C" can be reduced to "X". Thus no problem in "C" is harder than "X", since an algorithm for "X" allows us to solve any problem in "C". Of course, the notion of hard problems depends on the type of reduction being used. For complexity classes larger than P, polynomial-time reductions are commonly used. In particular, the set of problems that are hard for NP is the set of NP-hard problems.
p12572
aVIf a problem "X" is in "C" and hard for "C", then "X" is said to be "complete" for "C". This means that "X" is the hardest problem in "C" (Since there could be many problems which are equally hard, one might say that "X" is one of the hardest problems in "C"). Thus the class of NP-complete problems contains the most difficult problems in NP, in the sense that they are the ones most likely not to be in P. Because the problem P = NP is not solved, being able to reduce another problem, \u03a01, to a known NP-complete problem, \u03a02, would indicate that there is no known polynomial-time solution for \u03a01. This is because a polynomial-time solution to \u03a01 would yield a polynomial-time solution to \u03a02. Similarly, because all NP problems can be reduced to the set, finding an NP-complete problem that can be solved in polynomial time would mean that P = NP.
p12573
aVClosure properties of classes.
p12574
aVComplexity classes have a variety of closure properties; for example, decision classes may be closed under negation, disjunction, conjunction, or even under all Boolean operations. Moreover, they might also be closed under a variety of quantification schemes. P, for instance, is closed under all Boolean operations, and under quantification over polynomially sized domains. However, it is most likely not closed under quantification over exponential sized domains.
p12575
aVEach class X that is not closed under negation has a complement class co-Y, which consists of the complements of the languages contained in X. Similarly one can define the Boolean closure of a class, and so on; this is however less commonly done.
p12576
aVOne possible route to separating two complexity classes is to find some closure property possessed by one and not by the other.
p12577
aVRelationships between complexity classes.
p12578
aVThe following table shows some of the classes of problems (or languages, or grammars) that are considered in complexity theory. If class X is a strict subset of Y, then X is shown below Y, with a dark line connecting them. If X is a subset, but it is unknown whether they are equal sets, then the line is lighter and is dotted. Technically, the breakdown into decidable and undecidable pertains more to the study of computability theory but is useful for putting the complexity classes in perspective.
p12579
aVHierarchy theorems.
p12580
aVFor the complexity classes defined in this way, it is desirable to prove that relaxing the requirements on (say) computation time indeed defines a bigger set of problems. In particular, although DTIME("n") is contained in DTIME("n"2), it would be interesting to know if the inclusion is strict. For time and space requirements, the answer to such questions is given by the time and space hierarchy theorems respectively. They are called hierarchy theorems because they induce a proper hierarchy on the classes defined by constraining the respective resources. Thus there are pairs of complexity classes such that one is properly included in the other. Having deduced such proper set inclusions, we can proceed to make quantitative statements about how much more additional time or space is needed in order to increase the number of problems that can be solved.
p12581
aVMore precisely, the time hierarchy theorem states that
p12582
aVformula_1.
p12583
aVThe space hierarchy theorem states that
p12584
aVformula_2.
p12585
aVThe time and space hierarchy theorems form the basis for most separation results of complexity classes. For instance, the time hierarchy theorem tells us that P is strictly contained in EXPTIME, and the space hierarchy theorem tells us that L is strictly contained in PSPACE.
p12586
asS'Mediant (mathematics)'
p12587
(lp12588
V"For mediant in music, see mediant. "Mediant" should not be confused with median."
p12589
aVIn mathematics, the mediant of two fractions
p12590
aVformula_1
p12591
aVis
p12592
aVformula_2
p12593
aVthat is to say, the numerator and denominator of the mediant are the sums of the numerators and denominators of the given fractions, respectively. It is sometimes called the freshman sum, as it is a very common mistake in the usual addition of fractions.
p12594
aVIn general, this is an operation on fractions rather than on rational numbers. That is to say, for two rational numbers "q"1, "q"2, the value of the mediant depends on how the rational numbers are expressed using integer pairs. For example, the mediant of 1/1 and 1/2 is 2/3, but the mediant of 2/2 and 1/2 is 3/4.
p12595
aVA way around this, where required, is to specify that both rationals are to be represented as fractions in their lowest terms
p12596
aV(with "c" > 0, "d" > 0). With such a restriction, mediant becomes a well-defined binary operation on rationals.
p12597
aVThe Stern-Brocot tree provides an enumeration of all positive rational numbers, in lowest terms, obtained purely by iterative computation of the mediant according to a simple algorithm.
p12598
aV:formula_5
p12599
aVThis property follows from the two relations
p12600
aV:formula_6 
p12601
aVand
p12602
aV:formula_7
p12603
aV:formula_14
p12604
aVand
p12605
aV:formula_15
p12606
aVmust be positive. The determinant relation 
p12607
aV:formula_16 
p12608
aVthen implies that both formula_12 must be integers, solving the system of linear equations 
p12609
aV:formula_18
p12610
aV:formula_19
p12611
aVfor formula_20. Therefore formula_21
p12612
aV:formula_23
p12613
aVA point formula_24 inside the triangle can be parametrized as 
p12614
aV:formula_25
p12615
aVwhere
p12616
aV:formula_26 
p12617
aVThe Pick formula 
p12618
aV:formula_27
p12619
aVnow implies that there must be a lattice point "q" = ("q"1, "q"2) lying inside the triangle different from the three vertices if "bc" \u2212&nsbp;"ad" >1 (then the area of the triangle is formula_28). The corresponding fraction "q"1/"q"2 lies (strictly) between the given (by assumption reduced) fractions and has denominator
p12620
aV:formula_29
p12621
aVas 
p12622
aV:formula_30
p12623
aVformula_31
p12624
aVwhere ? is Minkowski's question mark function.
p12625
aVIn fact, mediants commonly occur in the study of continued fractions and in particular, Farey fractions. The "n"th Farey sequence "F""n" is defined as the (ordered with respect to magnitude) sequence of reduced fractions "a"/"b" (with coprime "a", "b") such that "b" \u2264 "n". If two fractions "a"/"c" < "b"/"d" are adjacent (neighbouring) fractions in a segment of Fn then the determinant relation formula_32 mentioned above is generally valid and therefore the mediant is the "simplest" fraction in the interval ("a"/"c", "b"/"d"), in the sense of being the fraction with the smallest denominator. Thus the mediant will then (first) appear in the ("c" + "d")th Farey sequence and is the "next" fraction which is inserted in any Farey sequence between "a"/"c" and "b"/"d". This gives the rule how the Farey sequences "F""n" are successively built up with increasing "n".
p12626
aVGeneralization.
p12627
aVThe notion of mediant can be generalized to "n" fractions, and a generalized mediant inequality holds, a fact that seems to have been first noticed by Cauchy. More precisely, the weighted mediant formula_33 of "n" fractions formula_34 is defined by formula_35 (with formula_36). It can be shown that formula_33 lies somewhere between the smallest and the largest fraction among the formula_38.
p12628
asS'Computer Algebra System'
p12629
(lp12630
sS'4 (number)'
p12631
(lp12632
V4 (four; ) is a number, numeral, and glyph. It is the natural number following and preceding . Four is the only number that has the same number of characters as its value in the English language.
p12633
aVIn mathematics.
p12634
aVFour is the smallest composite number, its proper divisors being and . Four is also a highly composite number. The next highly composite number is .
p12635
aVFour is the second square number, the second centered triangular number.
p12636
aV4 is the smallest squared prime ("p"2) and the only even number in this form. It has an aliquot sum of 3 which is itself prime. The aliquot sequence of 4 has 4 members (4, , 1, 0) and is accordingly the first member of the 3-aliquot tree.
p12637
aVA number is a multiple of 4 if its last two digits are a multiple of 4. For example, 1092 is a multiple of 4 because 92 = 4×23.
p12638
aVOnly one number has an aliquot sum of 4 and that is squared prime .
p12639
aVThe prime factorization of four is two times two.
p12640
aVFour is the smallest composite number that is equal to the sum of its prime factors. (As a consequence of this, it is the smallest Smith number). However, it is the only composite number "n" for which formula_1 is false.
p12641
aVIt is also a Motzkin number.
p12642
aVIn bases 6 and 12, 4 is a 1-automorphic number.
p12643
aVIn addition, 2 + 2 = 2 × 2 = 22 = 4. Continuing the pattern in Knuth's up-arrow notation, formula_2, and so on, for any number of up arrows.
p12644
aVA four-sided plane figure is a quadrilateral (quadrangle) or square, sometimes also called a "tetragon". A circle divided by 4 makes right angles. Because of it, four (4) is the base number of plane (mathematics). Four cardinal directions, four seasons, duodecimal system, and vigesimal system are based on four.
p12645
aVA solid figure with four faces is a tetrahedron. The regular tetrahedron is the simplest Platonic solid. A tetrahedron, which can also be called a 3-simplex, has four triangular faces and four vertices. It is the only self-dual regular polyhedron.
p12646
aVFour-dimensional space is the highest-dimensional space featuring more than three convex regular figures:
p12647
aVFour-dimensional differential manifolds have some unique properties. There is only one differential structure on formula_3 except when "n" = 4, in which case there are uncountably many.
p12648
aVThe smallest non-cyclic group has four elements; it is the Klein four-group. Four is also the order of the smallest non-trivial groups that are not simple.
p12649
aVFour is the maximum number of dimensions of a real division algebra (the quaternions), by a theorem of Ferdinand Georg Frobenius.
p12650
aVThe four-color theorem states that a planar graph (or, equivalently, a flat map of two-dimensional regions such as countries) can be colored using four colors, so that adjacent vertices (or regions) are always different colors. Three colors are not, in general, sufficient to guarantee this. The largest planar complete graph has four vertices.
p12651
aVLagrange's four-square theorem states that every positive integer can be written as the sum of at most four square numbers. Three are not always sufficient; for instance cannot be written as the sum of three squares.
p12652
aVFour is the first positive non-Fibonacci number.
p12653
aVEach natural number divisible by 4 is a difference of squares of two natural numbers, i.e. 4"x" = "y"2 \u2212 "z"2.
p12654
aVFour is an all-Harshad number and a semi-meandric number.
p12655
aVFour is the highest degree general polynomial equation for which there is a solution in radicals.
p12656
aVOrigins.
p12657
aVRepresenting 1, 2 and 3 in as many lines as the number represented worked well. The Brahmin Indians simplified 4 by joining its four lines into a cross that looks like our modern plus sign. The Sunga would add a horizontal line on top of the numeral, and the Kshatrapa and Pallava evolved the numeral to a point where speed of writing was a secondary concern. The Arabs' 4 still had the early concept of the cross, but for the sake of efficiency, was made in one stroke by connecting the "western" end to the "northern" end; the "eastern" end was finished off with a curve. The Europeans dropped the finishing curve and gradually made the numeral less cursive, ending up with a glyph very close to the original Brahmin cross.
p12658
aVWhile the shape of the 4 character has an ascender in most modern typefaces, in typefaces with text figures the character usually has a descender, as, for example, in .
p12659
aVOn the seven-segment displays of pocket calculators and digital watches, as well as certain optical character recognition fonts, 4 is seen with an open top.
p12660
aVTelevision stations that operate on channel 4 have occasionally made use of another variation of the "open 4", with the open portion being on the side, rather than the top. This version resembles the Canadian Aboriginal syllabics letter \u1526. The magnetic ink character recognition "CMC-7" font also uses this variety of "4".
p12661
aVIn other fields.
p12662
aV"See also 4 (disambiguation)."
p12663
asS'Place value'
p12664
(lp12665
sS'Order of operations'
p12666
(lp12667
VIn mathematics and computer programming, the order of operations (sometimes called operator precedence) is a rule used to clarify which procedures should be performed first in a given mathematical expression.
p12668
aVFor example, in mathematics and most computer languages multiplication is done before addition; in the expression 2 + 3 × 4, the answer is 14. Brackets, "( and ), { and }, or [ and ]", which have their own rules, may be used to avoid confusion, thus the preceding expression may also be rendered 2 + (3 × 4), but the brackets are unnecessary as multiplication still has precedence without them.
p12669
aVSince the introduction of modern algebraic notation, multiplication has taken precedence over addition. Thus 3 + 4 × 5 = 4 × 5 + 3 = 23. When exponents were first introduced in the 16th and 17th centuries, exponents took precedence over both addition and multiplication and could be placed only as a superscript to the right of their base. Thus 3 + 52 = 28 and 3 × 52 = 75. To change the order of operations, originally a vinculum (an overline or underline) was used. Today, parentheses or brackets are used to explicitly denote precedence by grouping parts of an expression that should be evaluated first. Thus, to force addition to precede multiplication, we write (2 + 3) × 4 = 20, and to force addition to precede exponentiation, we write (3 + 5)2 = 64.
p12670
aVThe standard order of operations.
p12671
aVThe order of operations used throughout mathematics, science, technology and many computer programming languages is expressed here:
p12672
aV exponents and roots
p12673
aV multiplication and division
p12674
aV addition and subtraction
p12675
aVThis means that if a mathematical expression is preceded by one binary operator and followed by another, the operator higher on the list should be applied first. The commutative and associative laws of addition and multiplication allow terms to be added in any order and factors to be multiplied in any order, but mixed operations must obey the standard order of operations.
p12676
aVIt is helpful to treat division as multiplication by the reciprocal (multiplicative inverse) and subtraction as addition of the negation (additive inverse). Thus 3/4 = 3 ÷ 4 = 3 \u2022 ¼; in other words the quotient of 3 and 4 equals the product of 3 and  ¼. Also 3 \u2212 4 = 3 + (\u22124); in other words the difference of 3 and 4 equals the sum of positive three and negative four. With this understanding, we can think of 1 \u2212 3 + 7 as the sum of 1, negative 3, and 7, and add in any order: (1 \u2212 3) + 7 = \u22122 + 7 = 5 and in reverse order (7 \u2212 3) + 1 = 4 + 1 = 5. The important thing is to keep the negative sign with the 3.
p12677
aVThe root symbol, \u221a, requires a symbol of grouping around the radicand. The usual symbol of grouping is a bar (called vinculum) over the radicand. Other functions use parentheses around the input to avoid ambiguity. The parentheses are sometimes omitted if the input is a monomial. Thus, sin x = sin(x), but sin x + y = sin(x) + y, because x + y is not a monomial. Some calculators and programming languages require parentheses around function inputs, some do not.
p12678
aVStacked exponents are applied from the top down, i.e., from right to left.
p12679
aVSymbols of grouping can be used to override the usual order of operations. Grouped symbols can be treated as a single expression. Symbols of grouping can be removed using the associative and distributive laws, also they can be removed if the expression inside the symbol of grouping is sufficiently simplified so no ambiguity results from their removal.
p12680
aV formula_1
p12681
aVExamples.
p12682
aVA horizontal fractional line also acts as a symbol of grouping:
p12683
aV formula_2
p12684
aVFor ease in reading, other grouping symbols such as braces, sometimes called curly braces { }, or brackets, sometimes called square brackets [ ], are often used along with parentheses ( ). For example:
p12685
aV formula_3
p12686
aVExceptions to the standard.
p12687
aVThere exist differing conventions concerning the unary operator \u2212 (usually read "minus"). In written or printed mathematics, the expression \u221232 is interpreted to mean \u2212(32) = \u22129, but in some applications and programming languages, notably the Microsoft Office Excel (and other spreadsheet applications) and the programming language bc, unary operators have a higher priority than binary operators, that is, the unary minus (negation) has higher precedence than exponentiation, so in those languages \u221232 will be interpreted as (\u22123)2 = 9. Note this does not apply to the binary operator \u2212; for example while the formulas codice_1 and codice_2 return 4 in Microsoft Excel, the formula codice_3 returns \u22124. In cases where there is the possibility that the notation might be misinterpreted, parentheses are usually used to clarify the intended meaning.
p12688
aVSimilarly, there can be ambiguity in the use of the slash ('/') symbol in expressions such as 1/2"x". If one rewrites this expression as 1 ÷ 2 × "x" and then interprets the division symbol as indicating multiplication by the reciprocal, this becomes:
p12689
aV formula_4
p12690
aVHence, with this interpretation we have that 1/2"x" is equal to (1/2)"x", and not 1/(2"x"). However, there are examples, including in published literature, where implied multiplication is interpreted as having higher precedence than division, so that 1/2"x" equals 1/(2"x"), not (1/2)"x". For example, the manuscript submission instructions for the "Physical Review" journals state that multiplication is of higher precedence than division with a slash, and this is also the convention observed in prominent physics textbooks such as the "Course of Theoretical Physics" by Landau and Lifshitz and the "Feynman Lectures on Physics". Wolfram Alpha changed in early 2013 to treat implied multiplication the same as explicit multiplication (formerly, implied multiplication without parentheses was assumed to bind more strongly than explicit multiplication). 2"x"/2"x", 2*"x"/2*"x", and 2(x)/2(x) now all yield x2. Newer TI calculators (TI 83 or later) also yield "x"2 in all three cases.
p12691
aVMnemonics.
p12692
aVMnemonics are often used to help students remember the rules, but the rules taught by the use of acronyms can be misleading. In the United States the acronym "PEMDAS" is common. It stands for "P"arentheses, "E"xponents, "M"ultiplication, "D"ivision, "A"ddition, "S"ubtraction. PEMDAS is often expanded to "Please Excuse My Dear Aunt Sally", with the first letter of each word creating the acronym PEMDAS. Canada uses "BEDMAS", standing for "B"rackets, "E"xponents, "D"ivision, "M"ultiplication, "A"ddition, "S"ubtraction. Most common in the UK and Australia are "BODMAS" and "BIDMAS". 
p12693
aVIn some English speaking countries, "P"arentheses may be called "B"rackets, or symbols of inclusion and "E"xponents may be called either "I"ndices, "P"owers or "O"rders, which have the same precedence as "R"oots or "R"adicals. Since multiplication and division are of equal precedence, "M" and "D" are often interchanged, leading to such acronyms as "BOMDAS". The original order of operations in most countries was "BODMAS" which stood for "B"rackets, "O"rders, "D"ivision, "M"ultiplication, "A"ddition, "S"ubtraction. This mnemonic was used until exponentials were added into the mnemonic.
p12694
aVThese mnemonics may be misleading when written this way, especially if the user is not aware that multiplication and division are of equal precedence, as are addition and subtraction. Using any of the above rules in the order "addition first, subtraction afterward" would also give the wrong answer to the problem:
p12695
aV:formula_5.
p12696
aVThe correct answer is 9 (and not 5, which we get when we do the addition first and then the subtraction). The best way to understand a combination of addition and subtraction is to think of the subtraction as addition of a negative number. In this case, we see the problem as the sum of positive ten, negative three, and positive two:
p12697
aV:formula_6
p12698
aVTo emphasize that addition and subtraction have the same precedence (and multiplication and division have the same precedence) the mnemonic is sometimes written P E MD AS; or, simply as PEMA.
p12699
aVAll of these acronyms conflate two different ideas, operations on the one hand and symbols of grouping on the other, which can lead to confusion.
p12700
aVSpecial cases.
p12701
aVIf exponentiation is indicated by stacked symbols, the usual rule is to work from the top down, thus:
p12702
aV formula_7,
p12703
aVwhich typically is not equal to formula_8. However, some computer systems may resolve the ambiguous expression differently. For example, Microsoft Office Excel evaluates "a"^"b"^"c" as ("a"^"b")^"c" which is opposite of normally accepted convention of top-down order of execution for exponentiation. If a=4, p=3, and q=2, formula_9 is evaluated to be 4096 in Microsoft Excel 2013, the same as formula_10. The expression formula_11, on the other hand, results in 262144 using the same program.
p12704
aVCalculators.
p12705
aVDifferent calculators follow different orders of operations. Most non-scientific calculators without a stack work left to right without any priority given to different operators, for example giving:
p12706
aVformula_12
p12707
aVwhile more sophisticated calculators will use a more standard priority, for example giving:
p12708
aVformula_13
p12709
aVThe Microsoft "Calculator" program uses the former in its standard view and the latter in its scientific and programmer views.
p12710
aVThe non-scientific calculator expects two operands and an operator. When the next operator is pressed, the expression is immediately evaluated and the answer becomes the left hand of the next operator. Advanced calculators allow entry of the whole expression, grouped as necessary, and evaluates only when the user uses the equals sign.
p12711
aVCalculators may associate exponents to the left or to the right depending on the model. For example, the expression a ^ b ^ c on the TI-92, the TI-30XII and the TI-30XS MultiView (all Texas Instruments calculators) associate two different ways:
p12712
aVThe TI-92 and the TI-30XS MultiView in "MathPrint Mode" associate to the right, that is:
p12713
aV:a ^ b ^ c = a ^ (b ^ c) = formula_14
p12714
aVwhereas, the TI-30XII and the TI-30XS MultiView in "Classic Mode" associate to the left, that is:
p12715
aV:a ^ b ^ c = (a ^ b) ^ c = formula_15
p12716
aVAn expression like 1/2"x" is interpreted as 1/(2"x") by TI-82, but as (1/2)"x" by TI-83 and every other TI calculator released since 1996, as well as by all HP with algebraic notation. While the first interpretation may be expected by some users, only the latter is in agreement with the standard rule that multiplication and division are of equal precedence, so 1/2"x" is read one divided by two and the answer multiplied by "x".
p12717
aVWhen the user is unsure how a calculator will interpret an expression, it is a good idea to use parentheses so there is no ambiguity.
p12718
aVCalculators that utilize reverse Polish notation, also known as postfix notation, use stack to enter formulas without the need for parentheses.
p12719
aVProgramming languages.
p12720
aVMany programming languages use precedence levels that conform to the order commonly used in mathematics, though some, such as APL and Smalltalk, have no operator precedence rules (in APL, evaluation is strictly right to left; in Smalltalk, it's strictly left to right).
p12721
aVIn addition, because many operators are not associative, the order within any single level is usually defined by grouping left to right so that 16/4/4 = (16/4)/4 = 1 rather than 16/(4/4) = 16.
p12722
aVThe logical bitwise operators in C (and all programming languages that borrowed precedence rules from C, for example, C++, Perl and PHP) have a precedence level that the creator of the C language considered to be unsatisfactory. However, many programmers have become accustomed to this order. The relative precedence levels of operators found in many C-style languages are as follows:
p12723
aVExamples:
p12724
aVSource-to-source compilers that compile to multiple languages need to explicitly deal with the issue of different order of operations across languages. Haxe for example standardizes the order and enforces it by inserting brackets where it is appropriate.
p12725
aVThe accuracy of software developer knowledge about binary operator precedence has been found to closely follow their frequency of occurrence in source code.
p12726
asS'Compass and straightedge construction'
p12727
(lp12728
sS'Markov chain'
p12729
(lp12730
VA Markov chain (discrete-time Markov chain or DTMC), named after Andrey Markov, is a random process that undergoes transitions from one state to another on a state space. It is required to possess a property that is usually characterized as "memoryless": the probability distribution of the next state depends only on the current state and not on the sequence of events that preceded it. This specific kind of "memorylessness" is called the Markov property. Markov chains have many applications as statistical models of real-world processes.
p12731
aVIntroduction.
p12732
aVA Markov chain is a stochastic process with the Markov property. The term "Markov chain" refers to the sequence of random variables such a process moves through, with the Markov property defining serial dependence only between adjacent periods (as in a "chain"). It can thus be used for describing systems that follow a chain of linked events, where what happens next depends only on the current state of the system.
p12733
aVIn the literature, different kinds of Markov process are designated as "Markov chains". Usually the term is reserved for a process with a discrete set of times, i.e. a discrete-time Markov chain (DTMC). On the other hand, a few authors use the term "Markov process" to refer to a continuous-time Markov chain without explicit mention.
p12734
aVWhile the time parameter is usually discrete, the state space of a Markov chain does not have any generally agreed-on restrictions: the term may refer to a process on an arbitrary state space. However, many applications of Markov chains employ finite or countably infinite (that is, discrete) state spaces, which have a more straightforward statistical analysis. Besides time-index and state-space parameters, there are many other variations, extensions and generalisations (see Variations). For simplicity, most of this article concentrates on the discrete-time, discrete state-space case, unless mentioned otherwise.
p12735
aVThe changes of state of the system are called transitions. The probabilities associated with various state changes are called transition probabilities. The process is characterized by a state space, a transition matrix describing the probabilities of particular transitions, and an initial state (or initial distribution) across the state space. By convention, we assume all possible states and transitions have been included in the definition of the process, so there is always a next state, and the process does not terminate.
p12736
aVA discrete-time random process involves a system which is in a certain state at each step, with the state changing randomly between steps. The steps are often thought of as moments in time, but they can equally well refer to physical distance or any other discrete measurement. Formally, the steps are the integers or natural numbers, and the random process is a mapping of these to states. The Markov property states that the conditional probability distribution for the system at the next step (and in fact at all future steps) depends only on the current state of the system, and not additionally on the state of the system at previous steps.
p12737
aVSince the system changes randomly, it is generally impossible to predict with certainty the state of a Markov chain at a given point in the future. However, the statistical properties of the system's future can be predicted. In many applications, it is these statistical properties that are important.
p12738
aVA famous Markov chain is the so-called "drunkard's walk", a random walk on the number line where, at each step, the position may change by +1 or \u22121 with equal probability. From any position there are two possible transitions, to the next or previous integer. The transition probabilities depend only on the current position, not on the manner in which the position was reached. For example, the transition probabilities from 5 to 4 and 5 to 6 are both 0.5, and all other transition probabilities from 5 are 0. These probabilities are independent of whether the system was previously in 4 or 6.
p12739
aVAnother example is the dietary habits of a creature who eats only grapes, cheese, or lettuce, and whose dietary habits conform to the following rules:
p12740
aVThis creature's eating habits can be modeled with a Markov chain since its choice tomorrow depends solely on what it ate today, not what it ate yesterday or any other time in the past. One statistical property that could be calculated is the expected percentage, over a long period, of the days on which the creature will eat grapes.
p12741
aVA series of independent events (for example, a series of coin flips) satisfies the formal definition of a Markov chain. However, the theory is usually applied only when the probability distribution of the next step depends non-trivially on the current state.
p12742
aVMany other examples of Markov chains exist.
p12743
aVFormal definition.
p12744
aVA Markov chain is a sequence of random variables "X"1, "X"2, "X"3, ... with the Markov property, namely that, given the present state, the future and past states are independent. Formally,
p12745
aVformula_1, if both conditional probabilities are well defined, i.e. if formula_2.
p12746
aVThe possible values of "X""i" form a countable set "S" called the state space of the chain.
p12747
aVMarkov chains are often described by a sequence of directed graphs, where the edges of graph "n" are labeled by the probabilities of going from one state at time "n" to the other states at time "n+1", formula_3. The same information is represented by the transition matrix from time "n" to time "n+1". However, Markov chains are frequently assumed to be time-homogeneous (see variations below), in which case the graph and matrix are independent of "n" and so are not presented as sequences.
p12748
aVThese descriptions highlight the structure of the Markov chain that is independent of the initial distribution formula_4. When time-homogeneous, the chain can be interpreted as a state machine assigning a probability of hopping from each vertex or state to an adjacent one. The probability formula_5 of the machine's state can be analyzed as the statistical behavior of the machine with an element formula_6 of the state space as input, or as the behavior of the machine with the initial distribution formula_7 is the Iverson bracket.
p12749
aVThe fact that some sequences of states might have zero probability of occurring corresponds to graph that has multiple connected components, where we suppress edges that carry a 0 transition probability. For example, if "a" has a nonzero probability of going to "b", but "a" and "x" lie in different connected components of the graph, then formula_8 is defined, while formula_9 is not.
p12750
aV:formula_10
p12751
aV for all "n". The probability of the transition is independent of "n".
p12752
aV:formula_11
p12753
aV In other words, the future state depends on the past "m" states. It is possible to construct a chain ("Yn") from ("Xn") which has the 'classical' Markov property by taking as state space the ordered "m"-tuples of "X" values, ie. "Yn" = ("Xn", "X""n"\u22121, ..., "X""n"\u2212"m"+1).
p12754
aVExample.
p12755
aVA state diagram for a simple example is shown in the figure on the right, using a directed graph to picture the state transitions. The states represent whether a hypothetical stock market is exhibiting a bull market, bear market, or stagnant market trend during a given week. According to the figure, a bull week is followed by another bull week 90% of the time, a bear week 7.5% of the time, and a stagnant week the other 2.5% of the time. Labelling the state space {1 = bull, 2 = bear, 3 = stagnant} the transition matrix for this example is
p12756
aVformula_12
p12757
aVThe distribution over states can be written as a stochastic row vector "x" with the relation "x"("n" + 1) = "x"("n")"P". So if at time "n" the system is in state 2 (bear), then three time periods later, at time "n" + 3 the distribution is
p12758
aVformula_13
p12759
aVUsing the transition matrix it is possible to calculate, for example, the long-term fraction of weeks during which the market is stagnant, or the average number of weeks it will take to go from a stagnant to a bull market. Using the transition probabilities, the steady-state probabilities indicate that 62.5% of weeks will be in a bull market, 31.25% of weeks will be in a bear market and 6.25% of weeks will be stagnant, since:
p12760
aVformula_14
p12761
aVA thorough development and many examples can be found in the on-line monograph
p12762
aVMeyn & Tweedie 2005.
p12763
aVA finite state machine can be used as a representation of a Markov chain. Assuming a sequence of independent and identically distributed input signals (for example, symbols from a binary alphabet chosen by coin tosses), if the machine is in state "y" at time "n", then the probability that it moves to state "x" at time "n" + 1 depends only on the current state.
p12764
aVTransient evolution.
p12765
aVThe probability of going from state "i" to state "j" in "n" time steps is
p12766
aVformula_15
p12767
aVand the single-step transition is
p12768
aVformula_16
p12769
aVFor a time-homogeneous Markov chain:
p12770
aVformula_17
p12771
aVand
p12772
aVformula_18
p12773
aVThe "n"-step transition probabilities satisfy the Chapman\u2013Kolmogorov equation, that for any "k" such that 0 < "k" < "n",
p12774
aVformula_19
p12775
aVwhere "S" is the state space of the Markov chain.
p12776
aVThe marginal distribution Pr("X""n" = "x") is the distribution over states at time "n". The initial distribution is Pr("X"0 = "x"). The evolution of the process through one time step is described by
p12777
aV formula_20
p12778
aVNote: The superscript ("n") is an index and not an exponent.
p12779
aVProperties.
p12780
aVReducibility.
p12781
aVA state "j" is said to be accessible from a state "i" (written "i" \u2192 "j") if a system started in state "i" has a non-zero probability of transitioning into state "j" at some point. Formally, state "j" is accessible from state "i" if there exists an integer "nij" \u2265 0 such that
p12782
aV formula_21
p12783
aVThis integer is allowed to be different for each pair of states, hence the subscripts in nij.
p12784
aVAllowing "n" to be zero means that every state is defined to be accessible from itself.
p12785
aVA state "i" is said to communicate with state "j" (written "i" \u2194 "j") if both "i" \u2192 "j" and "j" \u2192 "i". A set of states "C" is a communicating class if every pair of states in "C" communicates with each other, and no state in "C" is communicating with any state not in "C". It can be shown that communication in this sense is an equivalence relation and thus that communicating classes are the equivalence classes of this relation. A communicating class is closed if the probability of leaving the class is zero, namely that if "i" is in "C" but "j" is not, then "j" is not accessible from "i".
p12786
aVThe set of communicating classes forms a directed, acyclic graph by inheriting the arrows from the original state space. A communicating class is closed if and only if it has no outgoing arrows in this graph.
p12787
aVA state "i" is said to be essential or final if for all "j" such that "i" \u2192 "j" it is also true that "j" \u2192 "i". A state "i" is inessential if it is not essential. A state is final if and only if its communicating class is closed.
p12788
aVA Markov chain is said to be irreducible if its state space is a single communicating class; in other words, if it is possible to get to any state from any state.
p12789
aVPeriodicity.
p12790
aVA state "i" has period "k" if any return to state "i" must occur in multiples of "k" time steps. Formally, the period of a state is defined as
p12791
aV formula_22
p12792
aV(where "gcd" is the greatest common divisor). Note that even though a state has period "k", it may not be possible to reach the state in "k" steps. For example, suppose it is possible to return to the state in {6, 8, 10, 12, ...} time steps; "k" would be 2, even though 2 does not appear in this list.
p12793
aVIf "k" = 1, then the state is said to be aperiodic: returns to state "i" can occur at irregular times. In other words, a state "i" is aperiodic if there exists "n" such that for all "n' \u2265 n",
p12794
aV formula_23
p12795
aVOtherwise ("k" > 1), the state is said to be '"periodic with period "k". A Markov chain is aperiodic if every state is aperiodic. An irreducible Markov chain only needs one aperiodic state to imply all states are aperiodic.
p12796
aVEvery state of a bipartite graph has an even period"'.
p12797
aVTransience.
p12798
aVA state "i" is said to be transient if, given that we start in state "i", there is a non-zero probability that we will never return to "i". Formally, let the random variable "Ti" be the first return time to state "i" (the "hitting time"):
p12799
aV formula_24
p12800
aVThe number
p12801
aV formula_25
p12802
aVis the probability that we return to state "i" for the first time after "n" steps.
p12803
aVTherefore, state "i" is transient if
p12804
aV formula_26
p12805
aVState "i" is recurrent (or persistent) if it is not transient.
p12806
aVRecurrent states are guaranteed (with probability 1) to have a finite hitting time.
p12807
aVRecurrence and transience are class properties, that is, they either hold or do not hold equally for all members of a communicating class.
p12808
aVMean recurrence time.
p12809
aVEven if the hitting time is finite with probability "1", it need not have a finite expectation.
p12810
aVThe mean recurrence time at state "i" is the expected return time "Mi":
p12811
aV formula_27
p12812
aVState "i" is positive recurrent (or non-null persistent) if "Mi" is finite; otherwise, state "i" is null recurrent (or null persistent).
p12813
aVExpected number of visits.
p12814
aVIt can be shown that a state "i" is recurrent if and only if the expected number of visits to this state is infinite, i.e.,
p12815
aV formula_28
p12816
aVAbsorbing states.
p12817
aVA state "i" is called absorbing if it is impossible to leave this state. Therefore, the state "i" is absorbing if and only if
p12818
aV formula_29
p12819
aVIf every state can reach an absorbing state, then the Markov chain is an absorbing Markov chain.
p12820
aVErgodicity.
p12821
aVA state "i" is said to be ergodic if it is aperiodic and positive recurrent. In other words, a state "i" is ergodic if it is recurrent, has a period of "1" and it has finite mean recurrence time. If all states in an irreducible Markov chain are ergodic, then the chain is said to be ergodic.
p12822
aVIt can be shown that a finite state irreducible Markov chain is ergodic if it has an aperiodic state. A model has the ergodic property if there's a finite number "N" such that any state can be reached from any other state in exactly "N" steps. In case of a fully connected transition matrix where all transitions have a non-zero probability, this condition is fulfilled with "N"=1. A model with more than one state and just one out-going transition per state cannot be ergodic.
p12823
aVSteady-state analysis and limiting distributions.
p12824
aVIf the Markov chain is a time-homogeneous Markov chain, so that the process is described by a single, time-independent matrix formula_30, then the vector formula_31 is called a stationary distribution (or invariant measure) if formula_32 it satisfies
p12825
aV formula_33
p12826
aV formula_34
p12827
aV formula_35
p12828
aVAn irreducible chain has a stationary distribution if and only if all of its states are positive recurrent. In that case, "\u03c0" is unique and is related to the expected return time:
p12829
aV formula_36
p12830
aVwhere formula_37 is the normalizing constant. Further, if the positive recurrent chain is both irreducible and aperiodic, it is said to have a "limiting" distribution; for any "i" and "j",
p12831
aV formula_38
p12832
aVNote that there is no assumption on the starting distribution; the chain converges to the stationary distribution regardless of where it begins. Such "formula_39" is called the equilibrium distribution of the chain.
p12833
aVIf a chain has more than one closed communicating class, its stationary distributions will not be unique (consider any closed communicating class formula_40 in the chain; each one will have its own unique stationary distribution formula_41. Extending these distributions to the overall chain, setting all values to zero outside the communication class, yields that the set of invariant measures of the original chain is the set of all convex combinations of the formula_41's). However, if a state "j" is aperiodic, then
p12834
aV formula_43
p12835
aVand for any other state "i", let "fij" be the probability that the chain ever visits state "j" if it starts at "i",
p12836
aV formula_44
p12837
aVIf a state "i" is periodic with period "k" > 1 then the limit
p12838
aV formula_45
p12839
aVdoes not exist, although the limit
p12840
aV formula_46
p12841
aVdoes exist for every integer "r".
p12842
aVSteady-state analysis and the time-inhomogeneous Markov chain.
p12843
aVA Markov chain need not necessarily be time-homogeneous to have an equilibrium distribution. If there is a probability distribution over states formula_31 such that
p12844
aV formula_48
p12845
aVfor every state "j" and every time "n" then formula_31 is an equilibrium distribution of the Markov chain. Such can occur in Markov chain Monte Carlo (MCMC) methods in situations where a number of different transition matrices are used, because each is efficient for a particular kind of mixing, but each matrix respects a shared equilibrium distribution.
p12846
aVFinite state space.
p12847
aVIf the state space is finite, the transition probability distribution can be represented by a matrix, called the transition matrix, with the ("i", "j")th element of P equal to
p12848
aVformula_50
p12849
aVSince each row of P sums to one and all elements are non-negative, P is a right stochastic matrix.
p12850
aVStationary distribution relation to eigenvectors and simplices.
p12851
aVA stationary distribution \u03c0 is a (row) vector, whose entries are non-negative and sum to 1, is unchanged by the operation of transition matrix P on it and so is defined by
p12852
aVformula_51
p12853
aVBy comparing this definition with that of an eigenvector we see that the two concepts are related and that
p12854
aVformula_52
p12855
aVis a normalized (formula_53) multiple of a left eigenvector e of the transition matrix P with an eigenvalue of 1. If there is more than one unit eigenvector then a weighted sum of the corresponding stationary states is also a stationary state. But for a Markov chain one is usually more interested in a stationary state that is the limit of the sequence distributions for some initial distribution.
p12856
aVThe values of stationary distribution formula_54 are associated with the state space of P and its eigenvectors have their relative proportions preserved. Since the components of \u03c0 are positive and the constraint that their sum is unity can be rewritten as formula_55 we see that the dot product of \u03c0 with a vector whose components are all 1 is unity and that \u03c0 lies on a simplex.
p12857
aVTime-homogeneous Markov chain with a finite state space.
p12858
aVIf the Markov chain is time-homogeneous, then the transition matrix P is the same after each step, so the "k"-step transition probability can be computed as the "k"-th power of the transition matrix, P"k".
p12859
aVIf the Markov chain is irreducible and aperiodic, then there is a unique stationary distribution \u03c0. Additionally, in this case P"k" converges to a rank-one matrix in which each row is the stationary distribution \u03c0, that is,
p12860
aVformula_56
p12861
aVwhere 1 is the column vector with all entries equal to 1. This is stated by the Perron\u2013Frobenius theorem. If, by whatever means, formula_57 is found, then the stationary distribution of the Markov chain in question can be easily determined for any starting distribution, as will be explained below.
p12862
aVFor some stochastic matrices P, the limit formula_58 does not exist while the stationary distribution does, as shown by this example:
p12863
aV formula_59
p12864
aV formula_60
p12865
aVNote that this example illustrates a periodic Markov chain.
p12866
aVBecause there are a number of different special cases to consider, the process of finding this limit if it exists can be a lengthy task. However, there are many techniques that can assist in finding this limit. Let P be an "n"×"n" matrix, and define formula_61
p12867
aVIt is always true that
p12868
aVformula_62
p12869
aVSubtracting Q from both sides and factoring then yields
p12870
aVformula_63
p12871
aVwhere I"n" is the identity matrix of size "n", and 0"n","n" is the zero matrix of size "n"×"n". Multiplying together stochastic matrices always yields another stochastic matrix, so Q must be a stochastic matrix (see the definition above). It is sometimes sufficient to use the matrix equation above and the fact that Q is a stochastic matrix to solve for Q. Including the fact that the sum of each the rows in P is 1, there are "n+1" equations for determining "n" unknowns, so it is computationally easier if on the one hand one selects one row in Q and substitute each of its elements by one, and on the other one substitute the corresponding element (the one in the same column) in the vector 0, and next left-multiply this latter vector by the inverse of transformed former matrix to find Q.
p12872
aVHere is one method for doing so: first, define the function "f"(A) to return the matrix A with its right-most column replaced with all 1's. If ["f"(P \u2212 In)]\u22121 exists then
p12873
aVformula_64
p12874
aVExplain: The original matrix equation is equivalent to a system of n×n linear equations in n×n variables. And there are n more linear equations from the fact that Q is a right stochastic matrix whose each row sums to 1. So it needs any n×n independent linear equations of the (n×n+n) equations to solve for the n×n variables. In this example, the n equations from \u201cQ multiplied by the right-most column of (P-In)\u201d have been replaced by the n stochastic ones.
p12875
aVOne thing to notice is that if P has an element P"i","i" on its main diagonal that is equal to 1 and the "i"th row or column is otherwise filled with 0's, then that row or column will remain unchanged in all of the subsequent powers P"k". Hence, the "i"th row or column of Q will have the 1 and the 0's in the same positions as in P.
p12876
aVConvergence speed to the stationary distribution.
p12877
aVAs stated earlier, from the equation formula_65, (if exists) the stationary (or steady state) distribution \u03c0 is a left eigenvector of row stochastic matrix P. Then assuming that P is diagonalizable or equivalently that P has n linearly independent eigenvectors, speed of convergence is elaborated as follows. For non-diagonalizable matrices, one may start with "Jordan Canonical Form" ("almost" diagonal form) of P and proceed with a bit more involved set of arguments in a similar way.
p12878
aVLet U be the matrix of eigenvectors (each normalized to having an L2 norm equal to 1) where each column is a left eigenvector of P and let \u03a3 be the diagonal matrix of left eigenvalues of P, i.e. \u03a3 = diag("\u03bb"1,"\u03bb"2,"\u03bb"3...,"\u03bb""n"). Then by eigendecomposition
p12879
aVformula_66
p12880
aVLet the eigenvalues be enumerated such that 1 = |"\u03bb"1| > |"\u03bb"2| \u2265 |"\u03bb"3| \u2265 ... \u2265 |"\u03bb""n"|. Since P is a row stochastic matrix, its largest left eigenvalue is 1. If there is a unique stationary distribution, then the largest eigenvalue and the corresponding eigenvector is unique too (because there is no other \u03c0 which solves the stationary distribution equation above). Let u"i" be the "i"th column of U matrix, i.e. u"i" is the left eigenvector of P corresponding to \u03bb"i". Also let x be a length n row vector that represents a valid probability distribution; since the eigenvectors u"i" span R"n", we can write
p12881
aVformula_67
p12882
aVfor some set of "a""i"\u2208\u211d. If we start multiplying P with x from left and continue this operation with the results, in the end we get the stationary distribution \u03c0. In other words \u03c0 = u"i" \u2190 xPPP...P = xP"k" as "k" goes to infinity. That means
p12883
aVformula_68
p12884
aVformula_69
p12885
aVsince UU\u22121 = I the identity matrix and power of a diagonal matrix is also a diagonal matrix where each entry is taken to that power.
p12886
aVformula_70
p12887
aVformula_71
p12888
aVsince the eigenvectors are orthonormal. Then
p12889
aVformula_72
p12890
aVSince \u03c0 = u1, \u03c0("k") approaches to \u03c0 as "k" goes to infinity with a speed in the order of "\u03bb"2/"\u03bb"1 exponentially. This follows because |"\u03bb"2| \u2265 |"\u03bb"3| \u2265 ... \u2265 |"\u03bb""n"|, hence "\u03bb"2/"\u03bb"1 is the dominant term. Random noise in the state distribution \u03c0 can also speed up this convergence to the stationary distribution.
p12891
aVReversible Markov chain.
p12892
aVA Markov chain is said to be reversible if there is a probability distribution over states, \u03c0, such that
p12893
aVformula_73
p12894
aVfor all times "n" and all states "i" and "j".
p12895
aVThis condition is also known as the detailed balance condition (some books refer the local balance equation).
p12896
aVWith a time-homogeneous Markov chain, Pr("X""n"+1 = "j" | "X""n" = "i") does not change with time "n" and it can be written more simply as formula_30. In this case, the detailed balance equation can be written more compactly as
p12897
aVformula_75
p12898
aVSumming the original equation over "i" gives
p12899
aVformula_76
p12900
aVso, for reversible Markov chains, \u03c0 is always a steady-state distribution of Pr("X"n+1 = "j" | "X"n = "i") for every "n".
p12901
aVIf the Markov chain begins in the steady-state distribution, "i.e.", if Pr("X"0 = "i") = \u03c0"i", then Pr("X""n" = "i") = \u03c0"i" for all "n" and the detailed balance equation can be written as
p12902
aVformula_77
p12903
aVThe left- and right-hand sides of this last equation are identical except for a reversing of the time indices "n" and "n" + 1.
p12904
aVKolmogorov's criterion gives a necessary and sufficient condition for a Markov chain to be reversible directly from the transition matrix probabilities. The criterion requires that the products of probabilities around every closed loop are the same in both directions around the loop.
p12905
aVReversible Markov chains are common in Markov chain Monte Carlo (MCMC) approaches because the detailed balance equation for a desired distribution \u03c0 necessarily implies that the Markov chain has been constructed so that \u03c0 is a steady-state distribution. Even with time-inhomogeneous Markov chains, where multiple transition matrices are used, if each such transition matrix exhibits detailed balance with the desired \u03c0 distribution, this necessarily implies that \u03c0 is a steady-state distribution of the Markov chain.
p12906
aVBernoulli scheme.
p12907
aVA Bernoulli scheme is a special case of a Markov chain where the transition probability matrix has identical rows, which means that the next state is even independent of the current state (in addition to being independent of the past states). A Bernoulli scheme with only two possible states is known as a Bernoulli process.
p12908
aVGeneral state space.
p12909
aVMany results for Markov chains with finite state space can be generalized to chains with uncountable state space through Harris chains. The main idea is to see if there is a point in the state space that the chain hits with probability one. Generally, it is not true for continuous state space, however, we can define sets "A" and "B" along with a positive number "\u03b5" and a probability
p12910
aVmeasure "\u03c1", such that
p12911
aVThen we could collapse the sets into an auxiliary point "\u03b1", and a recurrent Harris chain can be modified to contain "\u03b1". Lastly, the collection of Harris chains is a comfortable level of generality, which is broad enough to contain a large number of interesting examples, yet restrictive enough to allow for a rich theory.
p12912
aVThe use of Markov chains in Markov chain Monte Carlo methods covers cases where the process follows a continuous state space.
p12913
aVLocally interacting Markov chains.
p12914
aVConsidering a collection of Markov chains whose evolution takes in account the state of other Markov chains, is related to the notion
p12915
aVof locally interacting Markov chains. This corresponds to the situation when the state space has a (Cartesian-) product form.
p12916
aVSee interacting particle system and stochastic cellular automata.
p12917
aVSee for instance "Interaction of Markov Processes"
p12918
aVor
p12919
aVApplications.
p12920
aVResearch has reported the application and usefulness of Markov chains in a wide range of topics such as physics, chemistry, medicine, music, game theory and sports.
p12921
aVPhysics.
p12922
aVMarkovian systems appear extensively in thermodynamics and statistical mechanics, whenever probabilities are used to represent unknown or unmodelled details of the system, if it can be assumed that the dynamics are time-invariant, and that no relevant history need be considered which is not already included in the state description.
p12923
aVChemistry.
p12924
aVChemistry is often a place where Markov chains and continuous-time Markov processes are especially useful because these simple physical systems tend to satisfy the Markov property quite well. The classical model of enzyme activity, Michaelis\u2013Menten kinetics, can be viewed as a Markov chain, where at each time step the reaction proceeds in some direction. While Michaelis-Menten is fairly straightforward, far more complicated reaction networks can also be modeled with Markov chains.
p12925
aVAn algorithm based on a Markov chain was also used to focus the fragment-based growth of chemicals in silico towards a desired class of compounds such as drugs or natural products. As a molecule is grown, a fragment is selected from the nascent molecule as the "current" state. It is not aware of its past (i.e., it is not aware of what is already bonded to it). It then transitions to the next state when a fragment is attached to it. The transition probabilities are trained on databases of authentic classes of compounds.
p12926
aVAlso, the growth (and composition) of copolymers may be modeled using Markov chains. Based on the reactivity ratios of the monomers that make up the growing polymer chain, the chain's composition may be calculated (e.g., whether monomers tend to add in alternating fashion or in long runs of the same monomer). Due to steric effects, second-order Markov effects may also play a role in the growth of some polymer chains.
p12927
aVSimilarly, it has been suggested that the crystallization and growth of some epitaxial superlattice oxide materials can be accurately described by Markov chains.
p12928
aVTesting.
p12929
aVSeveral theorists have proposed the idea of the Markov chain statistical test (MCST), a method of conjoining Markov chains to form a "Markov blanket", arranging these chains in several recursive layers ("wafering") and producing more efficient test sets\u2014samples\u2014as a replacement for exhaustive testing. MCSTs also have uses in temporal state-based networks; Chilukuri et al.'s paper entitled "Temporal Uncertainty Reasoning Networks for Evidence Fusion with Applications to Object Detection and Tracking" (ScienceDirect) gives a background and case study for applying MCSTs to a wider range of applications.
p12930
aVSpeech Recognition.
p12931
aVHidden Markov Models are the basis for most modern automatic speech recognition systems.
p12932
aVInformation sciences.
p12933
aVMarkov chains are used throughout information processing. Claude Shannon's famous 1948 paper "A Mathematical Theory of Communication", which in a single step created the field of information theory, opens by introducing the concept of entropy through Markov modeling of the English language. Such idealized models can capture many of the statistical regularities of systems. Even without describing the full structure of the system perfectly, such signal models can make possible very effective data compression through entropy encoding techniques such as arithmetic coding. They also allow effective state estimation and pattern recognition. Markov chains also play an important role in reinforcement learning.
p12934
aVMarkov chains are also the basis for hidden Markov models, which are an important tool in such diverse fields as telephone networks (which use the Viterbi algorithm for error correction), speech recognition and bioinformatics.
p12935
aVThe LZMA lossless data compression algorithm combines Markov chains with Lempel-Ziv compression to achieve very high compression ratios.
p12936
aVQueueing theory.
p12937
aVMarkov chains are the basis for the analytical treatment of queues (queueing theory). Agner Krarup Erlang initiated the subject in 1917. This makes them critical for optimizing the performance of telecommunications networks, where messages must often compete for limited resources (such as bandwidth).
p12938
aVInternet applications.
p12939
aVThe PageRank of a webpage as used by Google is defined by a Markov chain. It is the probability to be at page formula_80 in the stationary distribution on the following Markov chain on all (known) webpages. If formula_81 is the number of known webpages, and a page formula_80 has formula_83 links to it then it has transition probability formula_84 for all pages that are linked to and formula_85 for all pages that are not linked to. The parameter formula_86 is taken to be about 0.85.
p12940
aVMarkov models have also been used to analyze web navigation behavior of users. A user's web link transition on a particular website can be modeled using first- or second-order Markov models and can be used to make predictions regarding future navigation and to personalize the web page for an individual user.
p12941
aVStatistics.
p12942
aVMarkov chain methods have also become very important for generating sequences of random numbers to accurately reflect very complicated desired probability distributions, via a process called Markov chain Monte Carlo (MCMC). In recent years this has revolutionized the practicability of Bayesian inference methods, allowing a wide range of posterior distributions to be simulated and their parameters found numerically.
p12943
aVEconomics and finance.
p12944
aVMarkov chains are used in finance and economics to model a variety of different phenomena, including asset prices and market crashes. The first financial model to use a Markov chain was from Prasad "et al." in 1974. Another was the regime-switching model of James D. Hamilton (1989), in which a Markov chain is used to model switches between periods of high volatility and low volatility of asset returns. A more recent example is the Markov Switching Multifractal model of Laurent E. Calvet and Adlai J. Fisher, which builds upon the convenience of earlier regime-switching models. It uses an arbitrarily large Markov chain to drive the level of volatility of asset returns.
p12945
aVDynamic macroeconomics heavily uses Markov chains. An example is using Markov chains to exogenously model prices of equity (stock) in a general equilibrium setting.
p12946
aVSocial sciences.
p12947
aVMarkov chains are generally used in describing path-dependent arguments, where current structural configurations condition future outcomes. An example is the reformulation of the idea, originally due to Karl Marx's Das Kapital, tying economic development to the rise of capitalism. In current research, it is common to use a Markov chain to model how once a country reaches a specific level of economic development, the configuration of structural factors, such as size of the commercial bourgeoisie, the ratio of urban to rural residence, the rate of political mobilization, etc., will generate a higher probability of transitioning from authoritarian to democratic regime.
p12948
aVMathematical biology.
p12949
aVMarkov chains also have many applications in biological modelling, particularly population processes, which are useful in modelling processes that are (at least) analogous to biological populations. The Leslie matrix is one such example, though some of its entries
p12950
aVare not probabilities (they may be greater than 1). Another example is the modeling of cell shape in dividing sheets of epithelial cells. Yet another example is the state of ion channels in cell membranes.
p12951
aVMarkov chains are also used in simulations of brain function, such as the simulation of the mammalian neocortex.
p12952
aVGenetics.
p12953
aVMarkov chains have been used in population genetics in order to describe the change in gene frequencies in small populations affected by genetic drift, for example in diffusion equation method described by Motoo Kimura.
p12954
aVGames.
p12955
aVMarkov chains can be used to model many games of chance. The children's games Snakes and Ladders and "Hi Ho! Cherry-O", for example, are represented exactly by Markov chains. At each turn, the player starts in a given state (on a given square) and from there has fixed odds of moving to certain other states (squares).
p12956
aVMusic.
p12957
aVMarkov chains are employed in algorithmic music composition, particularly in software such as CSound, Max and SuperCollider. In a first-order chain, the states of the system become note or pitch values, and a probability vector for each note is constructed, completing a transition probability matrix (see below). An algorithm is constructed to produce output note values based on the transition matrix weightings, which could be MIDI note values, frequency (Hz), or any other desirable metric.
p12958
aVA second-order Markov chain can be introduced by considering the current state "and" also the previous state, as indicated in the second table. Higher, "n"th-order chains tend to "group" particular notes together, while 'breaking off' into other patterns and sequences occasionally. These higher-order chains tend to generate results with a sense of phrasal structure, rather than the 'aimless wandering' produced by a first-order system.
p12959
aVMarkov chains can be used structurally, as in Xenakis's Analogique A and B. Markov chains are also used in systems which use a Markov model to react interactively to music input.
p12960
aVUsually musical systems need to enforce speci\ufb01c control constraints on the \ufb01nite-length sequences they generate, but control constraints are not compatible with Markov models, since they induce long-range dependencies that violate the Markov hypothesis of limited memory. In order to overcome this limitation, a new approach has been proposed.
p12961
aVBaseball.
p12962
aVMarkov chain models have been used in advanced baseball analysis since 1960, although their use is still rare. Each half-inning of a baseball game fits the Markov chain state when the number of runners and outs are considered. During any at-bat, there are 24 possible combinations of number of outs and position of the runners. Mark Pankin shows that Markov chain models can be used to evaluate runs created for both individual players as well as a team.
p12963
aVHe also discusses various kinds of strategies and play conditions: how Markov chain models have been used to analyze statistics for game situations such as bunting and base stealing and differences when playing on grass vs. astroturf.
p12964
aVMarkov text generators.
p12965
aVMarkov processes can also be used to generate superficially real-looking text given a sample document: they are used in a variety of recreational "parody generator" software (see dissociated press, Jeff Harrison, Mark V Shaney
p12966
aVThese processes are also used by spammers to inject real-looking hidden paragraphs into unsolicited email and post comments in an attempt to get these messages past spam filters.
p12967
aVFitting.
p12968
aVWhen fitting a Markov chain to data, situations where parameters poorly describe the situation may highlight interesting trends. [http://www.eng.tau.ac.il/~bengal/VOM_EST.pdf]
p12969
aVHistory.
p12970
aVAndrey Markov produced the first results (1906) for these processes, purely theoretically.
p12971
aVA generalization to countably infinite state spaces was given by Kolmogorov (1936).
p12972
aVMarkov chains are related to Brownian motion and the ergodic hypothesis, two topics in physics which were important in the early years of the twentieth century. However, Markov first pursued this in 1906 as part of his argument against Pavel Nekrasov, in particular to make the case that the law of large numbers can be extended to dependent events. In 1913, he applied his findings to the first 20,000 letters of Pushkin's "Eugene Onegin". By 1917, more practical application of his work was made by Erlang to obtain formulas for call loss and waiting time in telephone networks.
p12973
aVSeneta provides an account of Markov's motivations and the theory's early development. The term "chain" was used by Markov (1906) to suggest a sequence of pairwise dependent variables.
p12974
asS'Pure mathematics'
p12975
(lp12976
VBroadly speaking, pure mathematics is mathematics that studies entirely abstract concepts. From the eighteenth century onwards, this was a recognized category of mathematical activity, sometimes characterized as "speculative mathematics", and at variance with the trend towards meeting the needs of navigation, astronomy, physics, economics, engineering, and so on. 
p12977
aVAnother insightful view put forth is that "pure mathematics is not necessarily applied mathematics": it is possible to study abstract entities with respect to their intrinsic nature, and not be concerned with how they manifest in the real world. Even though the pure and applied viewpoints are distinct philosophical positions, in practice there is much overlap in the activity of pure and applied mathematicians.
p12978
aVTo develop accurate models for describing the real world, many applied mathematicians draw on tools and techniques that are often considered to be "pure" mathematics. On the other hand, many pure mathematicians draw on natural and social phenomena as inspiration for their abstract research. 
p12979
aVHistory.
p12980
aVAncient Greece.
p12981
aVAncient Greek mathematicians were among the earliest to make a distinction between pure and applied mathematics. Plato helped to create the gap between "arithmetic", now called number theory, and "logistic", now called arithmetic. Plato regarded logistic (arithmetic) as appropriate for businessmen and men of war who "must learn the art of numbers or will not know how to array [their troops" and arithmetic (number theory) as appropriate for philosophers "because have to arise out of the sea of change and lay hold of true being." Euclid of Alexandria, when asked by one of his students of what use was the study of geometry, asked his slave to give the student threepence, "since he must needs make gain of what he learns." The Greek mathematician Apollonius of Perga was asked about the usefulness of some of his theorems in Book IV of "Conics" to which he proudly asserted,
p12982
aVThey are worthy of acceptance for the sake of the demonstrations themselves, in the same way as we accept many other things in mathematics for this and for no other reason.
p12983
aVAnd since many of his results were not applicable to the science or engineering of his day, Apollonius further argued in the preface of the fifth book of "Conics" that the subject is one of those that "...seem worthy of study for their own sake."
p12984
aV19th century.
p12985
aVThe term itself is enshrined in the full title of the Sadleirian Chair, founded (as a professorship) in the mid-nineteenth century. The idea of a separate discipline of "pure" mathematics may have emerged at that time. The generation of Gauss made no sweeping distinction of the kind, between "pure" and "applied". In the following years, specialisation and professionalisation (particularly in the Weierstrass approach to mathematical analysis) started to make a rift more apparent.
p12986
aV20th century.
p12987
aVAt the start of the twentieth century mathematicians took up the axiomatic method, strongly influenced by David Hilbert's example. The logical formulation of pure mathematics suggested by Bertrand Russell in terms of a quantifier structure of propositions seemed more and more plausible, as large parts of mathematics became axiomatised and thus subject to the simple criteria of "rigorous proof". 
p12988
aVIn fact in an axiomatic setting "rigorous" adds nothing to the idea of "proof". Pure mathematics, according to a view that can be ascribed to the Bourbaki group, is what is proved. Pure mathematician became a recognized vocation, achievable through training.
p12989
aVGenerality and abstraction.
p12990
aVOne central concept in pure mathematics is the idea of generality; pure mathematics often exhibits a trend towards increased generality.
p12991
aVGenerality's impact on intuition is both dependent on the subject and a matter of personal preference or learning style. Often generality is seen as a hindrance to intuition, although it can certainly function as an aid to it, especially when it provides analogies to material for which one already has good intuition.
p12992
aVAs a prime example of generality, the Erlangen program involved an expansion of geometry to accommodate non-Euclidean geometries as well as the field of topology, and other forms of geometry, by viewing geometry as the study of a space together with a group of transformations. The study of numbers, called algebra at the beginning undergraduate level, extends to abstract algebra at a more advanced level; and the study of functions, called calculus at the college freshman level becomes mathematical analysis and functional analysis at a more advanced level. Each of these branches of more "abstract" mathematics have many sub-specialties, and there are in fact many connections between pure mathematics and applied mathematics disciplines. A steep rise in abstraction was seen mid 20th century.
p12993
aVIn practice, however, these developments led to a sharp divergence from physics, particularly from 1950 to 1980. Later this was criticised, for example by Vladimir Arnold, as too much Hilbert, not enough Poincaré. The point does not yet seem to be settled, in that string theory pulls one way, while discrete mathematics pulls back towards proof as central.
p12994
aVPurism.
p12995
aVMathematicians have always had differing opinions regarding the distinction between pure and applied mathematics. 
p12996
aVOne of the most famous (but perhaps misunderstood) modern examples of this debate can be found in G.H. Hardy's "A Mathematician's Apology".
p12997
aVIt is widely believed that Hardy considered applied mathematics to be ugly and dull. Although it is true that Hardy preferred pure mathematics, which he often compared to painting and poetry, Hardy saw the distinction between pure and applied mathematics to be simply that applied mathematics sought to express "physical" truth in a mathematical framework, whereas pure mathematics expressed truths that were independent of the physical world. Hardy made a separate distinction in mathematics between what he called "real" mathematics, "which has permanent aesthetic value", and "the dull and elementary parts of mathematics" that have practical use.
p12998
aVHardy considered some physicists, such as Einstein and Dirac, to be among the "real" mathematicians, but at the time that he was writing the "Apology" he also considered general relativity and quantum mechanics to be "useless", which allowed him to hold the opinion that only "dull" mathematics was useful. Moreover, Hardy briefly admitted that\u2014just as the application of matrix theory and group theory to physics had come unexpectedly\u2014the time may come where some kinds of beautiful, "real" mathematics may be useful as well.
p12999
aVAnother insightful view is offered by Magid:
p13000
aVSubfields.
p13001
aVAnalysis is concerned with the properties of functions. It deals with concepts such as continuity, limits, differentiation and integration, thus providing a rigorous foundation for the calculus of infinitesimals introduced by Newton and Leibniz in the 17th century. Real analysis studies functions of real numbers, while complex analysis extends the aforementioned concepts to functions of complex numbers. Functional analysis is a branch of analysis that studies infinite-dimensional vector spaces and views functions as points in these spaces.
p13002
aVAbstract algebra is not to be confused with the manipulation of formulae that is covered in secondary education. It studies sets together with binary operations defined on them. Sets and their binary operations may be classified according to their properties: for instance, if an operation is associative on a set that contains an identity element and inverses for each member of the set, the set and operation is considered to be a group. Other structures include rings, fields, vector spaces and lattices.
p13003
aVGeometry is the study of shapes and space, in particular, groups of transformations that act on spaces. For example, projective geometry is about the group of projective transformations that act on the real projective plane, whereas inversive geometry is concerned with the group of inversive transformations acting on the extended complex plane. Geometry has been extended to topology, which deals with objects known as topological spaces and continuous maps between them. Topology is concerned with the way in which a space is connected and ignores precise measurements of distance or angle.
p13004
aVNumber theory is the theory of the positive integers. It is based on ideas such as divisibility and congruence. Its fundamental theorem states that each positive integer has a unique prime factorization. In some ways it is the most accessible discipline in pure mathematics for the general public: for instance the Goldbach conjecture is easily stated (but is yet to be proved or disproved). In other ways it is the least accessible discipline; for example, Wiles' proof that Fermat's equation has no nontrivial solutions requires understanding automorphic forms, which though intrinsic to nature have not found a place in physics or the general public discourse.
p13005
asS'Mathematical constant'
p13006
(lp13007
VA mathematical constant is a special number, usually a real number, that is "significantly interesting in some way". Constants arise in many areas of mathematics, with constants such as e (mathematical constant) and pi occurring in such diverse contexts as geometry, number theory, and calculus.
p13008
aVWhat it means for a constant to arise "naturally", and what makes a constant "interesting", is ultimately a matter of taste, and some mathematical constants are notable more for historical reasons than for their intrinsic mathematical interest. The more popular constants have been studied throughout the ages and computed to many decimal places.
p13009
aVAll mathematical constants are definable numbers and usually are also computable numbers (Chaitin's constant being a significant exception).
p13010
aVCommon mathematical constants.
p13011
aVThese are constants which one is likely to encounter during pre-college education in many countries.
p13012
aVArchimedes' constant.
p13013
aVThe constant pi (pi) has a natural definition in Euclidean geometry (the ratio between the circumference and diameter of a circle), but may be found in many places in mathematics: for example, the Gaussian integral in complex analysis, the roots of unity in number theory, and Cauchy distributions in probability. However, its universality is not limited to pure mathematics. Indeed, various formulae in physics, such as Heisenberg's uncertainty principle, and constants such as the cosmological constant include the constant . The presence of in physical principles, laws and formulae can have very simple explanations. For example, Coulomb's law, describing the inverse square proportionality of the magnitude of the electrostatic force between two electric charges and their distance, states that, in SI units,
p13014
aVformula_1
p13015
aVBesides formula_2 corresponding to the dielectric constant in vacuum, the formula_3 factor in the above denominator expresses directly the surface of a sphere with radius r, having thus a very concrete meaning.
p13016
aVThe numeric value of is approximately 3.14159. Memorizing increasingly precise digits of is a world record pursuit.
p13017
aVEuler's number.
p13018
aVEuler's number , also known as the exponential growth constant, appears in many areas of mathematics, and one possible definition of it is the value of the following expression:
p13019
aVformula_4
p13020
aVFor example, the Swiss mathematician Jacob Bernoulli discovered that arises in compound interest: An account that starts at $1, and yields interest at annual rate with continuous compounding, will accumulate to dollars at the end of one year. The constant also has applications to probability theory, where it arises in a way not obviously related to exponential growth. Suppose that a gambler plays a slot machine with a one in probability of winning, and plays it times. Then, for large (such as a million) the probability that the gambler will win nothing at all is approximately and tends to this value as tends to infinity.
p13021
aVAnother application of , discovered in part by Jacob Bernoulli along with French mathematician Pierre Raymond de Montmort, is in the problem of derangements, also known as the "hat check problem". Here guests are invited to a party, and at the door each guest checks his hat with the butler who then places them into labelled boxes. But the butler does not know the name of the guests, and so must put them into boxes selected at random. The problem of de Montmort is: what is the probability that "none" of the hats gets put into the right box. The answer is
p13022
aVformula_5
p13023
aVand as tends to infinity, approaches .
p13024
aVThe numeric value of is approximately 2.71828.
p13025
aVPythagoras' constant.
p13026
aVThe square root of 2, often known as root 2, radical 2, or Pythagoras's constant, and written as , is the positive algebraic number that, when multiplied by itself, gives the number 2. It is more precisely called the principal square root of 2, to distinguish it from the negative number with the same property.
p13027
aVGeometrically the square root of 2 is the length of a diagonal across a square with sides of one unit of length; this follows from the Pythagorean theorem. It was probably the first number known to be irrational.
p13028
aVIts numerical value truncated to 65 decimal places is:
p13029
aVThe quick approximation 99/70 (\u2248 1.41429) for the square root of two is frequently used. Despite having a denominator of only 70, it differs from the correct value by less than 1/10,000 (approx. 7.2 × 10 \u22125).
p13030
aVThe imaginary unit.
p13031
aVThe imaginary unit or unit imaginary number, denoted as , is a mathematical concept which extends the real number system to the complex number system , which in turn provides at least one root for every polynomial (see algebraic closure and fundamental theorem of algebra). The imaginary unit's core property is that . The term "imaginary" is used because there is no real number having a negative square.
p13032
aVThere are in fact two complex square roots of \u22121, namely and , just as there are two complex square roots of every other real number, except zero, which has one double square root.
p13033
aVIn contexts where is ambiguous or problematic, or the Greek iota (see alternative notations) is sometimes used. In the disciplines of electrical engineering and control systems engineering, the imaginary unit is often denoted by instead of , because is commonly used to denote electric current in these disciplines.
p13034
aVConstants in advanced mathematics.
p13035
aVThese are constants which are encountered frequently in higher mathematics.
p13036
aVThe Feigenbaum constants \u03b1 and \u03b4.
p13037
aVIterations of continuous maps serve as the simplest examples of models for dynamical systems. Named after mathematical physicist Mitchell Feigenbaum, the two Feigenbaum constants appear in such iterative processes: they are mathematical invariants of logistic maps with quadratic maximum points and their bifurcation diagrams.
p13038
aVThe logistic map is a polynomial mapping, often cited as an archetypal example of how chaotic behaviour can arise from very simple non-linear dynamical equations. The map was popularized in a seminal 1976 paper by the Australian biologist Robert May, in part as a discrete-time demographic model analogous to the logistic equation first created by Pierre François Verhulst. The difference equation is intended to capture the two effects of reproduction and starvation.
p13039
aVThe numeric value of \u03b1 is approximately 2.5029. The numeric value of \u03b4 is approximately 4.6692.
p13040
aVApéry's constant \u03b6(3).
p13041
aVformula_6
p13042
aVDespite being a special value of the Riemann zeta function, Apéry's constant arises naturally in a number of physical problems, including in the second- and third-order terms of the electron's gyromagnetic ratio, computed using quantum electrodynamics. The numeric value of "\u03b6"(3) is approximately 1.2020569.
p13043
aVThe golden ratio \u03c6.
p13044
aVformula_7
p13045
aVAn explicit formula for the "n"th Fibonacci number involving the golden ratio \u03c6.
p13046
aVThe number \u03c6, also called the Golden ratio, turns up frequently in geometry, particularly in figures with pentagonal symmetry. Indeed, the length of a regular pentagon's diagonal is \u03c6 times its side. The vertices of a regular icosahedron are those of three mutually orthogonal golden rectangles. Also, it appears in the Fibonacci sequence, related to growth by recursion. The golden ratio has the slowest convergence of any irrational number. It is, for that reason, one of the worst cases of Lagrange's approximation theorem and it is an extremal case of the Hurwitz inequality for Diophantine approximations. This may be why angles close to the golden ratio often show up in phyllotaxis (the growth of plants). It is approximately equal to 1.61803398874, or, more precisely formula_8
p13047
aVThe Euler\u2013Mascheroni constant \u03b3.
p13048
aVThe Euler\u2013Mascheroni constant is a recurring constant in number theory. The French mathematician Charles Jean de la Vallée-Poussin proved in 1898 that when taking any positive integer n and dividing it by each positive integer m less than n, the average fraction by which the quotient n/m falls short of the next integer tends to formula_9 as n tends to infinity. Surprisingly, this average doesn't tend to one half. The Euler\u2013Mascheroni constant also appears in Merten's third theorem and has relations to the gamma function, the zeta function and many different integrals and series.
p13049
aVThe definition of the Euler\u2013Mascheroni constant exhibits a close link between the discrete and the continuous (see curves on the left).
p13050
aVThe numeric value of formula_9 is approximately 0.57721.
p13051
aVConway's constant \u03bb.
p13052
aVformula_11
p13053
aVConway's look-and-say sequence
p13054
aVConway's constant is the invariant growth rate of all derived strings similar to the look-and-say sequence (except for one trivial one).
p13055
aVIt is given by the unique positive real root of a polynomial of degree 71 with integer coefficients.
p13056
aVThe value of \u03bb is approximately 1.30357.
p13057
aVKhinchin's constant "K".
p13058
aVIf a real number "r" is written as a simple continued fraction:
p13059
aVformula_12
p13060
aVwhere "a""k" are natural numbers for all "k"
p13061
aVthen, as the Russian mathematician Aleksandr Khinchin proved in 1934, the limit as "n" tends to infinity of the geometric mean: ("a"1"a"2..."a""n")1/"n" exists and is a constant, Khinchin's constant, except for a set of measure 0.
p13062
aVThe numeric value of "K" is approximately 2.6854520010.
p13063
aVThe Glaisher-Kinkelin constant "A".
p13064
aVThe Glaisher-Kinkelin constant is defined as the limit:
p13065
aVformula_13
p13066
aVIt is an important constant which appears in many expressions for the derivative of the Riemann zeta function. It has a numerical value of approximately 1.2824271291.
p13067
aVMathematical curiosities and unspecified constants.
p13068
aVSimple representatives of sets of numbers.
p13069
aV[Babylonian clay tablet gives an approximation of the square root of 2 in four sexagesimal figures: 1; 24, 51, 10, which is accurate to about six decimal figures.[http://it.stlawu.edu/%7Edmelvill/mesomath/tablets/YBC7289.html Photograph, illustration, and description of the "root(2)" tablet from the Yale Babylonian CollectionHigh resolution photographs, descriptions, and analysis of the "root(2)" tablet (YBC 7289) from the Yale Babylonian Collection</ref>]]
p13070
aVformula_14
p13071
aVLiouville's constant is a simple example of a transcendental number.
p13072
aVSome constants, such as the square root of 2, Liouville's constant and Champernowne constant:
p13073
aVformula_15
p13074
aVare not important mathematical invariants but retain interest being simple representatives of special sets of numbers, the irrational numbers, the transcendental numbers and the normal numbers (in base 10) respectively. The discovery of the irrational numbers is usually attributed to the Pythagorean Hippasus of Metapontum who proved, most likely geometrically, the irrationality of the square root of 2. As for Liouville's constant, named after French mathematician Joseph Liouville, it was the first number to be proven transcendental.
p13075
aVChaitin's constant \u03a9.
p13076
aVIn the computer science subfield of algorithmic information theory, Chaitin's constant is the real number representing the probability that a randomly chosen Turing machine will halt, formed from a construction due to Argentine-American mathematician and computer scientist Gregory Chaitin. Chaitin's constant, though not being computable, has been proven to be transcendental and normal. Chaitin's constant is not universal, depending heavily on the numerical encoding used for Turing machines; however, its interesting properties are independent of the encoding.
p13077
aVUnspecified constants.
p13078
aVWhen unspecified, constants indicate classes of similar objects, commonly functions, all equal up to a constant\u2014technically speaking, this is may be viewed as 'similarity up to a constant'. Such constants appear frequently when dealing with integrals and differential equations. Though unspecified, they have a specific value, which often is not important.
p13079
aVIn integrals.
p13080
aVIndefinite integrals are called indefinite because their solutions are only unique up to a constant. For example, when working over the field of real numbers
p13081
aVformula_16
p13082
aVwhere "C", the constant of integration, is an arbitrary fixed real number. In other words, whatever the value of "C", differentiating sin "x" + "C" with respect to "x" always yields cos "x".
p13083
aVIn differential equations.
p13084
aVIn a similar fashion, constants appear in the solutions to differential equations where not enough initial values or boundary conditions are given. For example, the ordinary differential equation "y"' = "y"("x") has solution "Ce""x" where "C" is an arbitrary constant.
p13085
aVWhen dealing with partial differential equations, the constants may be functions, constant with respect to some variables (but not necessarily all of them). For example, the PDE
p13086
aVformula_17
p13087
aVhas solutions "f"("x","y") = "C"("y"), where "C"("y") is an arbitrary function in the variable "y".
p13088
aVNotation.
p13089
aVRepresenting constants.
p13090
aVIt is common to express the numerical value of a constant by giving its decimal representation (or just the first few digits of it). For two reasons this representation may cause problems. First, even though rational numbers all have a finite or ever-repeating decimal expansion, irrational numbers don't have such an expression making them impossible to completely describe in this manner. Also, the decimal expansion of a number is not necessarily unique. For example, the two representations 0.999... and 1 are equivalent in the sense that they represent the same number.
p13091
aVCalculating digits of the decimal expansion of constants has been a common enterprise for many centuries. For example, German mathematician Ludolph van Ceulen of the 16th century spent a major part of his life calculating the first 35 digits of pi. Using computers and supercomputers, some of the mathematical constants, including \u03c0, "e", and the square root of 2, have been computed to more than one hundred billion digits. Fast algorithms have been developed, some of which \u2014 as for Apéry's constant \u2014 are unexpectedly fast.
p13092
aVformula_18
p13093
aVGraham's number defined using Knuth's up-arrow notation.
p13094
aVSome constants differ so much from the usual kind that a new notation has been invented to represent them reasonably. Graham's number illustrates this as Knuth's up-arrow notation is used.
p13095
aVIt may be of interest to represent them using continued fractions to perform various studies, including statistical analysis. Many mathematical constants have an analytic form, that is they can be constructed using well-known operations that lend themselves readily to calculation. Not all constants have known analytic forms, though; Grossman's constant and Foias' constant are examples.
p13096
aVSymbolizing and naming of constants.
p13097
aVSymbolizing constants with letters is a frequent means of making the notation more concise. A standard convention, instigated by Leonhard Euler in the 18th century, is to use lower case letters from the beginning of the Latin alphabet formula_19 or the Greek alphabet formula_20 when dealing with constants in general.
p13098
aVErd\u0151s\u2013Borwein constant formula_21Embree\u2013Trefethen constant formula_22Brun's constant for twin prime formula_23Champernowne constants formula_24cardinal number aleph naught formula_25
p13099
aVExamples of different kinds of notation for constants.
p13100
aVHowever, for more important constants, the symbols may be more complex and have an extra letter, an asterisk, a number, a lemniscate or use different alphabets such as Hebrew, Cyrillic or Gothic.
p13101
aVformula_26
p13102
aVSometimes, the symbol representing a constant is a whole word. For example, American mathematician Edward Kasner's 9-year-old nephew coined the names googol and googolplex.
p13103
aVThe names are either related to the meaning of the constant (universal parabolic constant, twin prime constant, ...) or to a specific person (Sierpi\u0144ski's constant, Josephson constant, ...).
p13104
aVTable of selected mathematical constants.
p13105
aVAbbreviations used:
p13106
aV R \u2013 Rational number, I \u2013 Irrational number (may be algebraic or transcendental), A \u2013 Algebraic number (irrational), T \u2013 Transcendental number (irrational)
p13107
aV Gen \u2013 General, NuT \u2013 Number theory, ChT \u2013 Chaos theory, Com \u2013 Combinatorics, Inf \u2013 Information theory, Ana \u2013 Mathematical analysis
p13108
as.